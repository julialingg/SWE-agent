[
  {
    "id": "1.1.1_intent",
    "type": "sc",
    "sc_id": "1.1.1",
    "section": "intent",
    "text": "[1.1.1 Non-text Content] (Level A)\nDescription: All non-text content that is presented to the user has a text alternative that serves the equivalent purpose, except for the situations listed below.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to make information conveyed by non-text content\n         accessible through the use of a text alternative.  Text alternatives are a primary\n         way for making information accessible because they can be rendered through any sensory\n         modality (for example, visual, auditory or tactile) to match the needs of the user.\n         Providing text alternatives allows the information to be rendered in a variety of\n         ways by a variety of user agents. For example, people who cannot see a picture can\n         have the text alternative read aloud using synthesized speech. People who cannot\n         hear an audio file can have the text alternative displayed so that they can read\n         it. In the future, text alternatives will also allow information to be more easily\n         translated into sign language or into a simpler form of the same language.\nNote on CAPTCHA\nCAPTCHAs are a controversial topic in the accessibility community. As is described in the\n            paper\nInaccessibility of CAPTCHA\n, CAPTCHAs intrinsically push the edges of human abilities in an attempt to defeat\n            automated processes. Every type of CAPTCHA will be unsolvable by users with certain\n            disabilities. However, they are widely used, and the Web Content Accessibility Guidelines\n            Working Group believes that if CAPTCHAs were forbidden outright, websites would choose\n            not to conform to WCAG rather than abandon CAPTCHA. This would create barriers for\n            a great many more users with disabilities. For this reason the Working Group has chosen\n            to structure the requirement about CAPTCHA in a way that meets the needs of most people\n            with disabilities, yet is also considered adoptable by sites. Requiring two different\n            forms of CAPTCHA on a given site ensures that most people with disabilities will find\n            a form they can use.\nBecause some users with disabilities will still not be able to access sites that meet\n            the minimum requirements, the Working Group provides recommendations for additional\n            steps. Organizations motivated to conform to WCAG should be aware of the importance\n            of this topic and should go as far beyond the minimum requirements of the guidelines\n            as possible. Additional recommended steps include:\nProviding more than two modalities of CAPTCHAs\nProviding access to a human customer service representative who can bypass CAPTCHA\nNot requiring CAPTCHAs for authorized users\nNote on alternatives matching the language of content\nText alternatives and equivalents should match the human language of the original content (normally the default human language of the page). The\n5.2 Conformance Requirements\nsection, through the defined terms used there, states that success criteria be met through accessibility-supported ways (5.2.4), where the technology is used “in the human language of the content.” Where an alternative version is used (5.2.1), it is defined as something that “provides all of the same information and functionality in the same human language.”\nAdditional information\nNon-text content can take a number of forms, and this success criterion specifies\n            how each is to be handled.\nFor non-text content that is not covered by one of the other situations listed below,\nsuch as charts, diagrams, audio recordings, pictures, and animations, text alternatives\n            can make the same information available in a form that can be rendered through any\n            modality (for example, visual, auditory or tactile).  Short and long text alternatives\n            can be used as needed to convey the information in the non-text content.  Note that\nprerecorded\n               audio-only\nand\nprerecorded\n               video-only\nfiles are covered here.\nLive-audio-only\nand\nLive-video-only\nfiles are covered below (see 3rd paragraph following this one).\nFor non-text content that is a control or accepts user input\n, such as images used as submit buttons, image maps or complex animations, a name\n            is provided to describe the purpose of the non-text content so that the person at\n            least knows what the non-text content is and why it is there.\nNon-text content that is time-based media\nis made accessible through\n1.2: Time-Based Media\n.  However, it is important that users know what it is when they encounter it on a\n            page so they can decide what action if any they want to take with it.  A text alternative\n            that describes the time-based media and/or gives its title is therefore provided.\nFor Live Audio-only and live video-only content\n, it can be much more difficult to provide text alternatives that provide equivalent\n            information as live audio-only and live video-only content. For these types of non-text\n            content, text alternatives provide a descriptive label.\nSometimes a test or exercise must be partially or completely presented in non-text\n               format.\nAudio or visual information is provided that cannot be changed to text because the\n            test or exercise must be conducted using that sense.  For example, a hearing test\n            would be invalid if a text alternative were provided.  A visual skill development\n            exercise would similarly make no sense in text form.  And a spelling test with text\n            alternatives would not be very effective.  For these cases, text alternatives should\n            be provided to describe the purpose of the non-text content; of course, the text alternatives\n            would not provide the same information needed to pass the test.\nSometimes content is primarily intended to create a specific sensory experience\nthat words cannot fully capture. Examples include a symphony performance, works of\n            visual art etc. For such content, text alternatives at least identify the non-text\n            content with a descriptive label and where possible, additional descriptive text.\n            If the reason for including the content in the page is known and can be described\n            it is helpful to include that information.\nSometimes there are non-text exercises that are used to prove you are human.\nTo avoid spam robots and other software from gaining access to a site a device called\n            a CAPTCHA is used. These usually involve visual or auditory tasks that are beyond\n            the current capabilities of web robots. Providing a text alternative to them would\n            however make them operable by Robots, thus defeating their purpose. In this case a\n            text alternative would describe the purpose of the CAPTCHA, and alternate forms using\n            different modalities would be provided to address the needs of people with different\n            disabilities.\nSometimes there is non-text content that really is not meant to be seen or understood\n               by the user.\nTransparent images used to move text over on a page; an invisible image that is used\n            to track usage statistics; and a swirl in the corner that conveys no information but\n            just fills up a blank space to create an aesthetic effect are all examples of this.\n            Putting alternative text on such items just distracts people using screen readers\n            from the content on the page. Not marking the content in any way, though, leaves users\n            guessing what the non-text content is and what information they may have missed (even\n            though they have not missed anything in reality). This type of non-text content, therefore,\n            is marked or implemented in a way that assistive technologies (AT) will ignore it\n            and not present anything to the user.",
    "principle": "Perceivable",
    "guideline": "1.1 Text Alternatives"
  },
  {
    "id": "1.1.1_success_criterion",
    "type": "sc",
    "sc_id": "1.1.1",
    "section": "success_criterion",
    "text": "[1.1.1 Non-text Content] (Level A)\nDescription: All non-text content that is presented to the user has a text alternative that serves the equivalent purpose, except for the situations listed below.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nAll\nnon-text content\nthat is presented to the user has a\ntext alternative\nthat serves the equivalent purpose, except for the situations listed below.\nControls, Input\nIf non-text content is a control or accepts user input, then it has a\nname\nthat describes its purpose. (Refer to\nSuccess Criterion 4.1.2\nfor additional requirements for controls and content that accepts user input.)\nTime-Based Media\nIf non-text content is time-based media, then text alternatives at least provide descriptive\n            identification of the non-text content. (Refer to\nGuideline 1.2\nfor additional requirements for media.)\nTest\nIf non-text content is a test or exercise that would be invalid if presented in\ntext\n, then text alternatives at least provide descriptive identification of the non-text\n            content.\nSensory\nIf non-text content is primarily intended to create a\nspecific sensory experience\n, then text alternatives at least provide descriptive identification of the non-text\n            content.\nCAPTCHA\nIf the purpose of non-text content is to confirm that content is being accessed by\n            a person rather than a computer, then text alternatives that identify and describe\n            the purpose of the non-text content are provided, and alternative forms of CAPTCHA\n            using output modes for different types of sensory perception are provided to accommodate\n            different disabilities.\nDecoration, Formatting, Invisible\nIf non-text content is\npure decoration\n, is used only for visual formatting, or is not presented to users, then it is implemented\n            in a way that it can be ignored by\nassistive technology\n.",
    "principle": "Perceivable",
    "guideline": "1.1 Text Alternatives"
  },
  {
    "id": "1.1.1_benefits",
    "type": "sc",
    "sc_id": "1.1.1",
    "section": "benefits",
    "text": "[1.1.1 Non-text Content] (Level A)\nDescription: All non-text content that is presented to the user has a text alternative that serves the equivalent purpose, except for the situations listed below.\n\nSection: benefits\n\nBenefits\nThis success criterion helps people who have difficulty perceiving visual content.\n            Assistive technology can read text aloud, present it visually, or convert it to braille.\nText alternatives may help some people who have difficulty understanding the meaning\n            of photographs, drawings, and other images  (e.g., line drawings, graphic designs,\n            paintings, three-dimensional representations), graphs, charts, animations, etc.\nPeople who are deaf, are hard of hearing, or who are having trouble understanding\n            audio information for any reason can read the text presentation. Research is ongoing\n            regarding automatic translation of text into sign language.\nPeople who are deaf-blind can read the text in braille.\nAdditionally, text alternatives support the ability to search for non-text content\n            and to repurpose content in a variety of ways.",
    "principle": "Perceivable",
    "guideline": "1.1 Text Alternatives"
  },
  {
    "id": "1.1.1_examples",
    "type": "sc",
    "sc_id": "1.1.1",
    "section": "examples",
    "text": "[1.1.1 Non-text Content] (Level A)\nDescription: All non-text content that is presented to the user has a text alternative that serves the equivalent purpose, except for the situations listed below.\n\nSection: examples\n\nExamples\nA data chart\nA bar chart compares how many widgets were sold in June, July, and August. The short\n               label says, \"Figure one - Sales in June, July and August.\" The longer description\n               identifies the type of chart, provides a high-level summary of the data, trends and\n               implications comparable to those available from the chart. Where possible and practical,\n               the actual data is provided in a table.\nAn audio recording of a speech\nThe link to an audio clip says, \"Chairman's speech to the assembly.\" A link to a text\n               transcript is provided immediately after the link to the audio clip.\nAn animation that illustrates how a car engine works\nAn animation shows how a car engine works. There is no audio and the animation is\n               part of a tutorial that describes how an engine works. Since the text of the tutorial\n               already provides a full explanation, the image is an alternative for text and the\n               text alternative includes only a brief description of the animation and refers to\n               the tutorial text for more information.\nA traffic web camera\nA website allows users to select from a variety of web cameras positioned throughout\n               a major city. After a camera is selected, the image updates every two minutes. A short\n               text alternative identifies the web camera as \"traffic web camera.\" The site also\n               provides a table of travel times for each of the routes covered by the web cameras.\n               The table is also updated every two minutes.\nA photograph of an historic event in a news story\nA photograph of two world leaders shaking hands accompanies a news story about an\n               international summit meeting. The text alternative says, \"President X of Country X\n               shakes hands with Prime Minister Y of country Y.\"\nA photograph of a historic event in content discussing diplomatic relationships\nThe same image is used in a different context intended to explain nuances in diplomatic\n               encounters. The image of the president shaking hands with the prime minister appears\n               on a website discussing intricate diplomatic relationships. The first text alternative\n               reads, \"President X of country X shakes hands with Prime Minister Y of country Y on\n               January 2, 2009.\" An additional text alternative describes the room where the leaders\n               are standing as well as the expressions on the leaders' faces, and identifies the\n               other people in the room. The additional description might be included on the same\n               page as the photograph or in a separate file associated with the image through a link\n               or other standard programmatic mechanism.\nAn audio recording of a press conference\nA web page includes a link to an audio recording of a press conference. The link text\n               identifies the audio recording. The page also links to a text transcript of the press\n               conference. The transcript includes a verbatim record of everything the speakers say.\n               It identifies who is speaking as well as noting other significant sounds that are\n               part of the recording, such as applause, laughter, questions from the audience, and\n               so on.\nAn e-learning application\nAn e-learning application uses sound effects to indicate whether or not the answers\n               are correct. The chime sound indicates that the answer is correct and the beep sound\n               indicates that the answer is incorrect. A text description is also included so that\n               people who can't hear or understand the sound understand whether the answer is correct\n               or incorrect.\nA linked thumbnail image\nA thumbnail image of the front page of a newspaper links to the home page of the \"Smallville\n               Times\". The text alternative says \"Smallville Times\".\nThe same image used on different sites\nDifferent alternatives for an image of the world: An image of the world that is used\n               on a travel site as a link to the International Travel section has the text alternative\n               \"International Travel\". The same image is used as a link on a university website\n               with the text alternative \"International Campuses\".\nAn image map\nAn image of a building floor plan is interactive, allowing the user to select a\n               particular room and navigate to a page containing information about that room.\n               The short text alternative describes the image and its interactive purpose:\n               \"Building floor plan. Select a room for more information.\"",
    "principle": "Perceivable",
    "guideline": "1.1 Text Alternatives"
  },
  {
    "id": "1.1.1_brief",
    "type": "sc",
    "sc_id": "1.1.1",
    "section": "brief",
    "text": "[1.1.1 Non-text Content] (Level A)\nDescription: All non-text content that is presented to the user has a text alternative that serves the equivalent purpose, except for the situations listed below.\n\nSection: brief\n\nIn Brief\nGoal\nNon-text information is available to more people.\nWhat to do\nCreate a text alternative for visual and auditory content.\nWhy it's important\nPeople who can’t fully see or hear content can understand it.",
    "principle": "Perceivable",
    "guideline": "1.1 Text Alternatives"
  },
  {
    "id": "1.1.1_resources",
    "type": "sc",
    "sc_id": "1.1.1",
    "section": "resources",
    "text": "[1.1.1 Non-text Content] (Level A)\nDescription: All non-text content that is presented to the user has a text alternative that serves the equivalent purpose, except for the situations listed below.\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nExcerpts from the NBA Tape Recording Manual, Third Edition\nInaccessibility of CAPTCHA\nAll That Malarkey: Accessible Alternatives\n456 Berea Street: The Alt and Title Attributes\nThe Alt and Accessibility\nBetter Connected, Better Results: Alt Text",
    "principle": "Perceivable",
    "guideline": "1.1 Text Alternatives"
  },
  {
    "id": "1.1.1_test_rules",
    "type": "sc",
    "sc_id": "1.1.1",
    "section": "test_rules",
    "text": "[1.1.1 Non-text Content] (Level A)\nDescription: All non-text content that is presented to the user has a text alternative that serves the equivalent purpose, except for the situations listed below.\n\nSection: test_rules\n\nTest Rules\nThe following are Test Rules\n    for certain aspects of this Success Criterion.\n    It is not necessary to use these particular Test Rules to check for conformance with WCAG, but they are defined and approved test methods.\n    For information on using Test Rules, see\nUnderstanding Test Rules for WCAG Success Criteria\n.\nElement marked as decorative is not exposed\nImage accessible name is descriptive\nImage button has non-empty accessible name\nImage has non-empty accessible name\nLink has non-empty accessible name\nObject element rendering non-text content has non-empty accessible name\nSVG element with explicit role has non-empty accessible name\nImage filename is accessible name for image\nImage not in the accessibility tree is decorative",
    "principle": "Perceivable",
    "guideline": "1.1 Text Alternatives"
  },
  {
    "id": "1.1.1_key_terms",
    "type": "sc",
    "sc_id": "1.1.1",
    "section": "key_terms",
    "text": "[1.1.1 Non-text Content] (Level A)\nDescription: All non-text content that is presented to the user has a text alternative that serves the equivalent purpose, except for the situations listed below.\n\nSection: key_terms\n\nKey Terms\nASCII art\npicture created by a spatial arrangement of characters or glyphs (typically from the\n      95 printable characters defined by ASCII)\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\nCAPTCHA\ninitialism for \"Completely Automated Public Turing test to tell Computers and Humans\n      Apart\"\nNote 1\nCAPTCHA tests often involve asking the user to type in text that is displayed in an\n      obscured image or audio file.\nNote 2\nA Turing test is any system of tests designed to differentiate a human from a computer.\n      It is named after famed computer scientist Alan Turing. The term was coined by researchers\n      at Carnegie Mellon University.\ncontent\ninformation and sensory experience to be communicated to the user by means of a\nuser agent\n, including code or markup that defines the content's\nstructure\n,\npresentation\n, and interactions\nhuman language\nlanguage that is spoken, written or signed (through visual or tactile means) to communicate\n      with humans\nNote\nSee also\nsign language\n.\nlabel\ntext\nor other component with a\ntext alternative\nthat is presented to a user to identify a component within web\ncontent\nNote 1\nA label is presented to all users whereas the\nname\nmay be hidden and only exposed by assistive technology. In many (but not all) cases\n      the name and the label are the same.\nNote 2\nThe term label is not limited to the label element in HTML.\nname\ntext by which software can identify a component within web content to the user\nNote 1\nThe name may be hidden and only exposed by assistive technology, whereas a\nlabel\nis presented to all users. In many (but not all) cases, the label and the name are\n      the same.\nNote 2\nThis is unrelated to the name attribute in HTML.\nnon-text content\nany content that is not a sequence of characters that can be\nprogrammatically determined\nor where the sequence is not expressing something in\nhuman language\nNote\nThis includes\nASCII art\n(which is a pattern of characters), emoticons, leetspeak (which uses character substitution),\n      and images representing text\npresentation\nrendering of the\ncontent\nin a form to be perceived by users\nprogrammatically determined\ndetermined by software from author-supplied data provided in a way that different\nuser agents\n, including\nassistive technologies\n, can extract and present this information to users in different modalities\nExample 1\nDetermined in a markup language from elements and attributes that are accessed directly\n      by commonly available assistive technology.\nExample 2\nDetermined from technology-specific data structures in a non-markup language and exposed\n      to assistive technology via an accessibility API that is supported by commonly available\n      assistive technology.\npure decoration\nserving only an aesthetic purpose, providing no information, and having no functionality\nNote\nText is only purely decorative if the words can be rearranged or substituted without\n      changing their purpose.\nExample\nThe cover page of a dictionary has random words in very light text in the background.\nsign language\na language using combinations of movements of the hands and arms, facial expressions,\n      or body positions to convey meaning\nspecific sensory experience\na sensory experience that is not purely decorative and does not primarily convey important\n      information or perform a function\nExample\nExamples include a performance of a flute solo, works of visual art etc.\nstructure\nThe way the parts of a\nweb page\nare organized in relation to each other; and\nThe way a collection of\nweb pages\nis organized\ntext\nsequence of characters that can be\nprogrammatically determined\n, where the sequence is expressing something in\nhuman language\ntext alternative\nText\nthat is programmatically associated with\nnon-text content\nor referred to from text that is programmatically associated with non-text content.\n      Programmatically associated text is text whose location can be\nprogrammatically determined\nfrom the non-text content.\nExample\nAn image of a chart is described in text in the paragraph after the chart. The short\n      text alternative for the chart indicates that a description follows.\nNote\nRefer to\nUnderstanding Text Alternatives\nfor more information.\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.\nweb page\na non-embedded resource obtained from a single URI using HTTP plus any other resources\n      that are used in the rendering or intended to be rendered together with it by a\nuser agent\nNote 1\nAlthough any \"other resources\" would be rendered together with the primary resource,\n      they would not necessarily be rendered simultaneously with each other.\nNote 2\nFor the purposes of conformance with these guidelines, a resource must be \"non-embedded\"\n      within the scope of conformance to be considered a web page.\nExample 1\nA web resource including all embedded images and media.\nExample 2\nA web mail program built using Asynchronous JavaScript and XML (AJAX). The program\n      lives entirely at http://example.com/mail, but includes an inbox, a contacts area\n      and a calendar. Links or buttons are provided that cause the inbox, contacts, or calendar\n      to display, but do not change the URI of the page as a whole.\nExample 3\nA customizable portal site, where users can choose content to display from a set of\n      different content modules.\nExample 4\nWhen you enter \"http://shopping.example.com/\" in your browser, you enter a movie-like\n      interactive shopping environment where you visually move around in a store dragging\n      products off of the shelves around you and into a visual shopping cart in front of\n      you. Clicking on a product causes it to be demonstrated with a specification sheet\n      floating alongside. This might be a single-page website or just one page within a\n      website.",
    "principle": "Perceivable",
    "guideline": "1.1 Text Alternatives"
  },
  {
    "id": "1.1.1_situation_A",
    "type": "sc_situation",
    "sc_id": "1.1.1",
    "situation_id": "A",
    "techniques": [
      "G94",
      "ARIA6",
      "ARIA10",
      "G196",
      "H2",
      "H37",
      "H53",
      "H86",
      "PDF1"
    ],
    "text": "[1.1.1 Non-text Content] (Level A)\nDescription: All non-text content that is presented to the user has a text alternative that serves the equivalent purpose, except for the situations listed below.\n\nSituation A: If a short description can serve the same purpose and present the same information as the non-text content:\n\nRelated techniques: G94, ARIA6, ARIA10, G196, H2, H37, H53, H86, PDF1",
    "principle": "Perceivable",
    "guideline": "1.1 Text Alternatives"
  },
  {
    "id": "1.1.1_situation_B",
    "type": "sc_situation",
    "sc_id": "1.1.1",
    "situation_id": "B",
    "techniques": [
      "G95",
      "ARIA6",
      "ARIA10",
      "G196",
      "H2",
      "H37",
      "H53",
      "H86",
      "PDF1",
      "ARIA15",
      "G73",
      "G74",
      "G92",
      "H53"
    ],
    "text": "[1.1.1 Non-text Content] (Level A)\nDescription: All non-text content that is presented to the user has a text alternative that serves the equivalent purpose, except for the situations listed below.\n\nSituation B: If a short description can not serve the same purpose and present the same information as the non-text content (e.g., a chart or diagram):\n\nRelated techniques: G95, ARIA6, ARIA10, G196, H2, H37, H53, H86, PDF1, ARIA15, G73, G74, G92, H53",
    "principle": "Perceivable",
    "guideline": "1.1 Text Alternatives"
  },
  {
    "id": "1.1.1_situation_C",
    "type": "sc_situation",
    "sc_id": "1.1.1",
    "situation_id": "C",
    "techniques": [
      "G82",
      "ARIA6",
      "ARIA9",
      "H24",
      "H30",
      "H36",
      "H44",
      "H65"
    ],
    "text": "[1.1.1 Non-text Content] (Level A)\nDescription: All non-text content that is presented to the user has a text alternative that serves the equivalent purpose, except for the situations listed below.\n\nSituation C: If non-text content is a control or accepts user input:\n\nRelated techniques: G82, ARIA6, ARIA9, H24, H30, H36, H44, H65",
    "principle": "Perceivable",
    "guideline": "1.1 Text Alternatives"
  },
  {
    "id": "1.1.1_situation_D",
    "type": "sc_situation",
    "sc_id": "1.1.1",
    "situation_id": "D",
    "techniques": [
      "G68",
      "G100",
      "ARIA6",
      "ARIA10",
      "G196",
      "H2",
      "H37",
      "H53",
      "H86",
      "PDF1"
    ],
    "text": "[1.1.1 Non-text Content] (Level A)\nDescription: All non-text content that is presented to the user has a text alternative that serves the equivalent purpose, except for the situations listed below.\n\nSituation D: If non-text content is time-based media (including live video-only and live audio-only); a test or exercise that would be invalid if presented in text; or primarily intended to create a specific sensory experience:\n\nRelated techniques: Short text alternative techniques for Situation D, G68, G100, ARIA6, ARIA10, G196, H2, H37, H53, H86, PDF1",
    "principle": "Perceivable",
    "guideline": "1.1 Text Alternatives"
  },
  {
    "id": "1.1.1_situation_E",
    "type": "sc_situation",
    "sc_id": "1.1.1",
    "situation_id": "E",
    "techniques": [
      "G143"
    ],
    "text": "[1.1.1 Non-text Content] (Level A)\nDescription: All non-text content that is presented to the user has a text alternative that serves the equivalent purpose, except for the situations listed below.\n\nSituation E: If non-text content is a CAPTCHA:\n\nRelated techniques: G143",
    "principle": "Perceivable",
    "guideline": "1.1 Text Alternatives"
  },
  {
    "id": "1.1.1_situation_F",
    "type": "sc_situation",
    "sc_id": "1.1.1",
    "situation_id": "F",
    "techniques": [
      "C9",
      "H67",
      "PDF4"
    ],
    "text": "[1.1.1 Non-text Content] (Level A)\nDescription: All non-text content that is presented to the user has a text alternative that serves the equivalent purpose, except for the situations listed below.\n\nSituation F: If the non-text content should be ignored by assistive technology:\n\nRelated techniques: Techniques to indicate that text alternatives are not required for Situation F, C9, H67, PDF4",
    "principle": "Perceivable",
    "guideline": "1.1 Text Alternatives"
  },
  {
    "id": "1.1.1_advisory",
    "type": "sc_advisory",
    "sc_id": "1.1.1",
    "techniques": [
      "C18"
    ],
    "text": "[1.1.1 Non-text Content] (Level A)\nDescription: All non-text content that is presented to the user has a text alternative that serves the equivalent purpose, except for the situations listed below.\n\nAdvisory techniques for SC 1.1.1: C18",
    "principle": "Perceivable",
    "guideline": "1.1 Text Alternatives"
  },
  {
    "id": "1.1.1_failures",
    "type": "sc_failures",
    "sc_id": "1.1.1",
    "techniques": [
      "F3",
      "F13",
      "F20",
      "F30",
      "F38",
      "F39",
      "F65",
      "F67",
      "F71",
      "F72"
    ],
    "text": "[1.1.1 Non-text Content] (Level A)\nDescription: All non-text content that is presented to the user has a text alternative that serves the equivalent purpose, except for the situations listed below.\n\nCommon failures for SC 1.1.1: F3, F13, F20, F30, F38, F39, F65, F67, F71, F72",
    "principle": "Perceivable",
    "guideline": "1.1 Text Alternatives"
  },
  {
    "id": "1.2.1_intent",
    "type": "sc",
    "sc_id": "1.2.1",
    "section": "intent",
    "text": "[1.2.1 Audio-only and Video-only (Prerecorded)] (Level A)\nDescription: For prerecorded\naudio-only and prerecorded video-only media, the following are true, except when the audio or video is a media alternative for text and is clearly labeled as such:\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to make information conveyed by prerecorded\n         audio-only and prerecorded video-only content available to all users. Alternatives\n         for time-based media that are text based make information accessible because text\n         can be rendered through any sensory modality (for example, visual, auditory or tactile)\n         to match the needs of the user. In the future, text could also be translated into\n         symbols, sign language or simpler forms of the language (future).\nAn example of pre-recorded video with no audio information or user interaction is\n         a silent movie. The purpose of the transcript is to provide an equivalent to what\n         is presented visually. For prerecorded video content, authors have the option to provide\n         an audio track. The purpose of the audio alternative is to be an equivalent to the\n         video. This makes it possible for users with and without vision impairment to review\n         content simultaneously. The approach can also make it easier for those with cognitive,\n         language and learning disabilities to understand the content because it would provide\n         parallel presentation.\nNote\nA text equivalent is not required for audio that is provided as an equivalent for\n            video with no audio information.  For example, it is not required to caption audio\n            description that is provided as an alternative to a silent movie.\nSee also\n1.2.9: Audio-only (Live)",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.1_success_criterion",
    "type": "sc",
    "sc_id": "1.2.1",
    "section": "success_criterion",
    "text": "[1.2.1 Audio-only and Video-only (Prerecorded)] (Level A)\nDescription: For prerecorded\naudio-only and prerecorded video-only media, the following are true, except when the audio or video is a media alternative for text and is clearly labeled as such:\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nFor\nprerecorded\naudio-only\nand prerecorded\nvideo-only\nmedia, the following are true, except when the audio or video is a\nmedia alternative for text\nand is clearly labeled as such:\nPrerecorded Audio-only\nAn\nalternative for time-based media\nis provided that presents equivalent information for prerecorded audio-only content.\nPrerecorded Video-only\nEither an alternative for time-based media or an audio track is provided that presents\n            equivalent information for prerecorded video-only content.",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.1_benefits",
    "type": "sc",
    "sc_id": "1.2.1",
    "section": "benefits",
    "text": "[1.2.1 Audio-only and Video-only (Prerecorded)] (Level A)\nDescription: For prerecorded\naudio-only and prerecorded video-only media, the following are true, except when the audio or video is a media alternative for text and is clearly labeled as such:\n\nSection: benefits\n\nBenefits\nThis success criterion helps people who have difficulty perceiving visual content.\n            Assistive technology can read text alternatives aloud, present them visually, or convert\n            them to braille.\nAlternatives for timed-based media that are text based may help some people who have\n            difficulty understanding the meaning of prerecorded video content.\nPeople who are deaf, are hard of hearing, or who are having trouble understanding\n            audio information for any reason can read the text presentation. Research is ongoing\n            regarding automatic translation of text into sign language.\nPeople who are deaf-blind can read the text in braille.\nAdditionally, text supports the ability to search for non-text content and to repurpose\n            content in a variety of ways.",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.1_examples",
    "type": "sc",
    "sc_id": "1.2.1",
    "section": "examples",
    "text": "[1.2.1 Audio-only and Video-only (Prerecorded)] (Level A)\nDescription: For prerecorded\naudio-only and prerecorded video-only media, the following are true, except when the audio or video is a media alternative for text and is clearly labeled as such:\n\nSection: examples\n\nExamples\nAn audio recording of a speech\nThe link to an audio clip says, \"Chairman's speech to the assembly.\" A link to a text\n               transcript is provided immediately after the link to the audio clip.\nAn audio recording of a press conference\nA web page includes a link to an audio recording of a press conference that identifies\n               the audio recording. The page also links to a text transcript of the press conference.\n               The transcript includes a verbatim record of everything the speakers say. It identifies\n               who is speaking as well as noting other significant sounds that are part of the recording,\n               such as applause, laughter, questions from the audience, and so on.\nAn animation that illustrates how a car engine works\nAn animation shows how a car engine works. There is no audio and the animation is\n               part of a tutorial that describes how an engine works. Since the text of the tutorial\n               already provides a full explanation, the media is an alternative for text and the\n               text alternative includes only a brief description of the animation and refers to\n               the tutorial text for more information.\nA video-only file with an audio track\nA silent movie includes an audio track which includes a description of the action in the video.",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.1_brief",
    "type": "sc",
    "sc_id": "1.2.1",
    "section": "brief",
    "text": "[1.2.1 Audio-only and Video-only (Prerecorded)] (Level A)\nDescription: For prerecorded\naudio-only and prerecorded video-only media, the following are true, except when the audio or video is a media alternative for text and is clearly labeled as such:\n\nSection: brief\n\nIn Brief\nGoal\nAudio and video-only content can be understood by more people.\nWhat to do\nProvide an alternative when content is perceivable with only one sense.\nWhy it's important\nPeople who can’t fully see or hear content can understand it.",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.1_resources",
    "type": "sc",
    "sc_id": "1.2.1",
    "section": "resources",
    "text": "[1.2.1 Audio-only and Video-only (Prerecorded)] (Level A)\nDescription: For prerecorded\naudio-only and prerecorded video-only media, the following are true, except when the audio or video is a media alternative for text and is clearly labeled as such:\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nMaking Audio and Video Media Accessible, W3C Web Accessibility Initiative (WAI)\nOvercoming the challenge of podcast transcription\nuiAccess list of transcription services\nTranscripts on the Web: Getting people to your podcasts and videos",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.1_test_rules",
    "type": "sc",
    "sc_id": "1.2.1",
    "section": "test_rules",
    "text": "[1.2.1 Audio-only and Video-only (Prerecorded)] (Level A)\nDescription: For prerecorded\naudio-only and prerecorded video-only media, the following are true, except when the audio or video is a media alternative for text and is clearly labeled as such:\n\nSection: test_rules\n\nTest Rules\nThe following are Test Rules\n    for certain aspects of this Success Criterion.\n    It is not necessary to use these particular Test Rules to check for conformance with WCAG, but they are defined and approved test methods.\n    For information on using Test Rules, see\nUnderstanding Test Rules for WCAG Success Criteria\n.\nAudio element content has text alternative\nVideo element auditory content has captions\nVideo element visual-only content has accessible alternative",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.1_key_terms",
    "type": "sc",
    "sc_id": "1.2.1",
    "section": "key_terms",
    "text": "[1.2.1 Audio-only and Video-only (Prerecorded)] (Level A)\nDescription: For prerecorded\naudio-only and prerecorded video-only media, the following are true, except when the audio or video is a media alternative for text and is clearly labeled as such:\n\nSection: key_terms\n\nKey Terms\nalternative for time-based media\ndocument including correctly sequenced text descriptions of time-based visual and\n      auditory information and providing a means for achieving the outcomes of any time-based\n      interaction\nNote\nA screenplay used to create the synchronized media content would meet this definition\n      only if it was corrected to accurately represent the final synchronized media after\n      editing.\naudio\nthe technology of sound reproduction\nNote\nAudio can be created synthetically (including speech synthesis), recorded from real\n      world sounds, or both.\naudio-only\na time-based presentation that contains only\naudio\n(no\nvideo\nand no interaction)\nlive\ninformation captured from a real-world event and transmitted to the receiver with\n      no more than a broadcast delay\nNote 1\nA broadcast delay is a short (usually automated) delay, for example used in order\n      to give the broadcaster time to cue or censor the audio (or video) feed, but not sufficient\n      to allow significant editing.\nNote 2\nIf information is completely computer generated, it is not live.\nmedia alternative for text\nmedia that presents no more information than is already presented in text (directly\n      or via text alternatives)\nNote\nA media alternative for text is provided for those who benefit from alternate representations\n      of text. Media alternatives for text may be audio-only, video-only (including sign-language\n      video), or audio-video.\nprerecorded\ninformation that is not\nlive\nvideo\nthe technology of moving or sequenced pictures or images\nNote\nVideo can be made up of animated or photographic images, or both.\nvideo-only\na time-based presentation that contains only\nvideo\n(no\naudio\nand no interaction)",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.1_situation_A",
    "type": "sc_situation",
    "sc_id": "1.2.1",
    "situation_id": "A",
    "techniques": [
      "G158"
    ],
    "text": "[1.2.1 Audio-only and Video-only (Prerecorded)] (Level A)\nDescription: For prerecorded\naudio-only and prerecorded video-only media, the following are true, except when the audio or video is a media alternative for text and is clearly labeled as such:\n\nSituation A: If the content is prerecorded audio-only:\n\nRelated techniques: G158",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.1_situation_B",
    "type": "sc_situation",
    "sc_id": "1.2.1",
    "situation_id": "B",
    "techniques": [
      "G159",
      "G166"
    ],
    "text": "[1.2.1 Audio-only and Video-only (Prerecorded)] (Level A)\nDescription: For prerecorded\naudio-only and prerecorded video-only media, the following are true, except when the audio or video is a media alternative for text and is clearly labeled as such:\n\nSituation B: If the content is prerecorded video-only:\n\nRelated techniques: G159, G166",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.1_advisory",
    "type": "sc_advisory",
    "sc_id": "1.2.1",
    "techniques": [
      "H96"
    ],
    "text": "[1.2.1 Audio-only and Video-only (Prerecorded)] (Level A)\nDescription: For prerecorded\naudio-only and prerecorded video-only media, the following are true, except when the audio or video is a media alternative for text and is clearly labeled as such:\n\nAdvisory techniques for SC 1.2.1: H96",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.1_failures",
    "type": "sc_failures",
    "sc_id": "1.2.1",
    "techniques": [
      "F30",
      "F67"
    ],
    "text": "[1.2.1 Audio-only and Video-only (Prerecorded)] (Level A)\nDescription: For prerecorded\naudio-only and prerecorded video-only media, the following are true, except when the audio or video is a media alternative for text and is clearly labeled as such:\n\nCommon failures for SC 1.2.1: F30, F67",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.2_intent",
    "type": "sc",
    "sc_id": "1.2.2",
    "section": "intent",
    "text": "[1.2.2 Captions (Prerecorded)] (Level A)\nDescription: Captions are provided for all prerecorded\naudio content in synchronized media, except when the media is a media alternative for text and is clearly labeled as such.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to enable people who are deaf or hard of hearing\n         to watch synchronized media presentations. Captions provide the part of the content\n         available via the audio track. Captions not only include dialogue, but identify who\n         is speaking and include non-speech information conveyed through sound, including meaningful\n         sound effects.\nIt is acknowledged that at the present time there may be difficulty in creating captions\n         for time-sensitive material and this may result in the author being faced with the\n         choice of delaying the information until captions are available, or publishing time-sensitive\n         content that is inaccessible to the deaf, at least for the interval until captions\n         are available. Over time, the tools for captioning as well as building the captioning\n         into the delivery process can shorten or eliminate such delays.\nCaptions are not needed when the synchronized media is, itself, an alternate presentation\n         of information that is also presented via text on the web page. For example, if information\n         on a page is accompanied by a synchronized media presentation that presents no more\n         information than is already presented in text, but is easier for people with cognitive,\n         language, or learning disabilities to understand, then it would not need to be captioned\n         since the information is already presented on the page in text or in text alternatives\n         (e.g., for images).\nSee also\n1.2.4: Captions (Live)\n.",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.2_success_criterion",
    "type": "sc",
    "sc_id": "1.2.2",
    "section": "success_criterion",
    "text": "[1.2.2 Captions (Prerecorded)] (Level A)\nDescription: Captions are provided for all prerecorded\naudio content in synchronized media, except when the media is a media alternative for text and is clearly labeled as such.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nCaptions\nare provided for all\nprerecorded\naudio\ncontent in\nsynchronized media\n, except when the media is a\nmedia alternative for text\nand is clearly labeled as such.",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.2_benefits",
    "type": "sc",
    "sc_id": "1.2.2",
    "section": "benefits",
    "text": "[1.2.2 Captions (Prerecorded)] (Level A)\nDescription: Captions are provided for all prerecorded\naudio content in synchronized media, except when the media is a media alternative for text and is clearly labeled as such.\n\nSection: benefits\n\nBenefits\nPeople who are deaf or have a hearing loss can access the auditory information in\n            the synchronized media content through captions.",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.2_examples",
    "type": "sc",
    "sc_id": "1.2.2",
    "section": "examples",
    "text": "[1.2.2 Captions (Prerecorded)] (Level A)\nDescription: Captions are provided for all prerecorded\naudio content in synchronized media, except when the media is a media alternative for text and is clearly labeled as such.\n\nSection: examples\n\nExamples\nA captioned tutorial\nA video clip shows how to tie a knot. The captions read,\n\"(music)\nUsing rope to tie knots was an important skill\nfor the likes of sailors, soldiers and woodsmen..\"\nFrom Sample Transcript Formatting by Whit Anderson.\nA complex legal document contains synchronized media clips for different paragraphs\n            that show a person speaking the contents of the paragraph. Each clip is associated\n            with its corresponding paragraph. No captions are provided for the synchronized media.\nAn instruction manual containing a description of a part and its necessary orientation\n            is accompanied by a synchronized media clip showing the part in its correct orientation.\n            No captions are provided for the synchronized media clip.\nAn orchestra provides captions for videos of performances. In addition to capturing\n               dialog and lyrics verbatim, captions identify non-vocal music by title, movement,\n               composer, and any information that will help the user comprehend the nature of the\n               audio. For instance captions read,\n\"[Orchestral Suite No. 3.2 in D major, BWV 1068, Air]\n[Johann Sebastian Bach, Composer]\n♪ Calm melody with a slow tempo ♪\"\nNote\nStyle guides for captions may differ among different languages.",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.2_brief",
    "type": "sc",
    "sc_id": "1.2.2",
    "section": "brief",
    "text": "[1.2.2 Captions (Prerecorded)] (Level A)\nDescription: Captions are provided for all prerecorded\naudio content in synchronized media, except when the media is a media alternative for text and is clearly labeled as such.\n\nSection: brief\n\nIn Brief\nGoal\nVideos can be played with captions.\nWhat to do\nProvide synchronized text for audio content in existing videos.\nWhy it's important\nPeople who are deaf or hard of hearing can understand audio in videos.",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.2_resources",
    "type": "sc",
    "sc_id": "1.2.2",
    "section": "resources",
    "text": "[1.2.2 Captions (Prerecorded)] (Level A)\nDescription: Captions are provided for all prerecorded\naudio content in synchronized media, except when the media is a media alternative for text and is clearly labeled as such.\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nGuides to Captioning\nCaptions/Subtitles\n, in\nMaking Audio and Video Media Accessible\n, W3C Web Accessibility Initiative (WAI)\nBBC: Subtitle Guidelines\nCaptioning Key: Guidelines and Preferred Techniques\nBest Practices in Online Captioning\nSMIL Resources\nSynchronized Multimedia Integration Language (SMIL) 3.0\nAccessibility Features of SMIL\nOther Captioning Resources\nNational Center for Accessible Media\nWebAIM: Captioning Resource List",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.2_test_rules",
    "type": "sc",
    "sc_id": "1.2.2",
    "section": "test_rules",
    "text": "[1.2.2 Captions (Prerecorded)] (Level A)\nDescription: Captions are provided for all prerecorded\naudio content in synchronized media, except when the media is a media alternative for text and is clearly labeled as such.\n\nSection: test_rules\n\nTest Rules\nThe following are Test Rules\n    for certain aspects of this Success Criterion.\n    It is not necessary to use these particular Test Rules to check for conformance with WCAG, but they are defined and approved test methods.\n    For information on using Test Rules, see\nUnderstanding Test Rules for WCAG Success Criteria\n.\nVideo element auditory content has accessible alternative",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.2_key_terms",
    "type": "sc",
    "sc_id": "1.2.2",
    "section": "key_terms",
    "text": "[1.2.2 Captions (Prerecorded)] (Level A)\nDescription: Captions are provided for all prerecorded\naudio content in synchronized media, except when the media is a media alternative for text and is clearly labeled as such.\n\nSection: key_terms\n\nKey Terms\nASCII art\npicture created by a spatial arrangement of characters or glyphs (typically from the\n      95 printable characters defined by ASCII)\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\naudio\nthe technology of sound reproduction\nNote\nAudio can be created synthetically (including speech synthesis), recorded from real\n      world sounds, or both.\naudio description\nnarration added to the soundtrack to describe important visual details that cannot\n      be understood from the main soundtrack alone\nNote 1\nAudio description of\nvideo\nprovides information about actions, characters, scene changes, on-screen text, and\n      other visual content.\nNote 2\nIn standard audio description, narration is added during existing pauses in dialogue.\n      (See also\nextended audio description\n.)\nNote 3\nWhere all of the\nvideo\ninformation is already provided in existing\naudio\n, no additional audio description is necessary.\nNote 4\nAlso called \"video description\" and \"descriptive narration.\"\ncaptions\nsynchronized visual and/or\ntext alternative\nfor both speech and non-speech audio information needed to understand the media content\nNote 1\nCaptions are similar to dialogue-only subtitles except captions convey not only the\n      content of spoken dialogue, but also equivalents for non-dialogue audio information\n      needed to understand the program content, including sound effects, music, laughter,\n      speaker identification and location.\nNote 2\nClosed Captions are equivalents that can be turned on and off with some players.\nNote 3\nOpen Captions are any captions that cannot be turned off. For example, if the captions\n      are visual equivalent\nimages of text\nembedded in\nvideo\n.\nNote 4\nCaptions should not obscure or obstruct relevant information in the video.\nNote 5\nIn some countries, captions are called subtitles.\nNote 6\nAudio descriptions\ncan be, but do not need to be, captioned since they are descriptions of information\n      that is already presented visually.\nextended audio description\naudio description that is added to an audiovisual presentation by pausing the\nvideo\nso that there is time to add additional description\nNote\nThis technique is only used when the sense of the\nvideo\nwould be lost without the additional\naudio description\nand the pauses between dialogue/narration are too short.\nhuman language\nlanguage that is spoken, written or signed (through visual or tactile means) to communicate\n      with humans\nNote\nSee also\nsign language\n.\nimage of text\ntext that has been rendered in a non-text form (e.g., an image) in order to achieve\n      a particular visual effect\nNote\nThis does not include text that is part of a picture that contains significant other visual content.\nExample\nA person's name on a nametag in a photograph.\nlive\ninformation captured from a real-world event and transmitted to the receiver with\n      no more than a broadcast delay\nNote 1\nA broadcast delay is a short (usually automated) delay, for example used in order\n      to give the broadcaster time to cue or censor the audio (or video) feed, but not sufficient\n      to allow significant editing.\nNote 2\nIf information is completely computer generated, it is not live.\nmedia alternative for text\nmedia that presents no more information than is already presented in text (directly\n      or via text alternatives)\nNote\nA media alternative for text is provided for those who benefit from alternate representations\n      of text. Media alternatives for text may be audio-only, video-only (including sign-language\n      video), or audio-video.\nnon-text content\nany content that is not a sequence of characters that can be\nprogrammatically determined\nor where the sequence is not expressing something in\nhuman language\nNote\nThis includes\nASCII art\n(which is a pattern of characters), emoticons, leetspeak (which uses character substitution),\n      and images representing text\nprerecorded\ninformation that is not\nlive\nprogrammatically determined\ndetermined by software from author-supplied data provided in a way that different\nuser agents\n, including\nassistive technologies\n, can extract and present this information to users in different modalities\nExample 1\nDetermined in a markup language from elements and attributes that are accessed directly\n      by commonly available assistive technology.\nExample 2\nDetermined from technology-specific data structures in a non-markup language and exposed\n      to assistive technology via an accessibility API that is supported by commonly available\n      assistive technology.\nsign language\na language using combinations of movements of the hands and arms, facial expressions,\n      or body positions to convey meaning\nsynchronized media\naudio\nor\nvideo\nsynchronized with another format for presenting information and/or with time-based\n      interactive components, unless the media is a\nmedia alternative for text\nthat is clearly labeled as such\ntext\nsequence of characters that can be\nprogrammatically determined\n, where the sequence is expressing something in\nhuman language\ntext alternative\nText\nthat is programmatically associated with\nnon-text content\nor referred to from text that is programmatically associated with non-text content.\n      Programmatically associated text is text whose location can be\nprogrammatically determined\nfrom the non-text content.\nExample\nAn image of a chart is described in text in the paragraph after the chart. The short\n      text alternative for the chart indicates that a description follows.\nNote\nRefer to\nUnderstanding Text Alternatives\nfor more information.\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.\nvideo\nthe technology of moving or sequenced pictures or images\nNote\nVideo can be made up of animated or photographic images, or both.",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.2_sufficient",
    "type": "sc_sufficient",
    "sc_id": "1.2.2",
    "techniques": [
      "G93",
      "G87",
      "SM11",
      "SM12",
      "H95"
    ],
    "text": "[1.2.2 Captions (Prerecorded)] (Level A)\nDescription: Captions are provided for all prerecorded\naudio content in synchronized media, except when the media is a media alternative for text and is clearly labeled as such.\n\nSufficient techniques for SC 1.2.2 (no situation): G93, G87, SM11, SM12, H95",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.2_failures",
    "type": "sc_failures",
    "sc_id": "1.2.2",
    "techniques": [
      "F8",
      "F75",
      "F74"
    ],
    "text": "[1.2.2 Captions (Prerecorded)] (Level A)\nDescription: Captions are provided for all prerecorded\naudio content in synchronized media, except when the media is a media alternative for text and is clearly labeled as such.\n\nCommon failures for SC 1.2.2: F8, F75, F74",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.3_intent",
    "type": "sc",
    "sc_id": "1.2.3",
    "section": "intent",
    "text": "[1.2.3 Audio Description or Media Alternative (Prerecorded)] (Level A)\nDescription: An alternative for time-based media or audio description of the prerecorded\nvideo content is provided for synchronized media, except when the media is a media alternative for text and is clearly labeled as such.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to provide people who are blind or visually\n         impaired access to the visual information in a synchronized media presentation in the same\nhuman language\nas the video or page on which it appears. This\n         success criterion describes two approaches, either of which can be used.\nOne approach is to provide audio description of the video content. The audio description\n         augments the audio portion of the presentation with the information needed when the\n         video portion is not available. During existing pauses in dialogue, audio description\n         provides information about actions, characters, scene changes, and on-screen text\n         that  are important and are not described or spoken in the main sound track.\nThe second approach involves providing all of the information in the synchronized\n         media (both visual and auditory) in text form. An alternative for time-based media\n         provides a running description of all that is going on in the synchronized media content.\n         The alternative for time-based media reads something like a screenplay or book. Unlike\n         audio description, the description of the video portion is not constrained to just\n         the pauses in the existing dialogue. Full descriptions are provided of all visual\n         information, including visual context, actions and expressions of actors, and any\n         other visual material. In addition, non-speech sounds (laughter, off-screen voices,\n         etc.) are described, and transcripts of all dialogue are included. The sequence of\n         description and dialogue transcripts are the same as the sequence in the synchronized\n         media itself. As a result, the alternative for time-based media can provide a much\n         more complete representation of the synchronized media content than audio description\n         alone.\nIf there is any interaction as part of the synchronized media presentation (e.g.,\n         \"press now to answer the question\") then the alternative for time-based media would\n         provide hyperlinks or whatever is needed to provide the same functionality.\nNote\nFor 1.2.3, 1.2.5, and 1.2.7, if all of the important information in the video track is already\n            conveyed in the audio track, no additional audio description is necessary.\n1.2.3, 1.2.5, and 1.2.8 overlap somewhat with each other. This is to give the author\n            some choice at the minimum conformance level, and to provide additional requirements\n            at higher levels. At Level A in Success Criterion 1.2.3, authors do have the choice\n            of providing either an audio description or a full text alternative. If they wish\n            to conform at Level AA, under Success Criterion 1.2.5 authors must provide an audio\n            description - a requirement already met if they chose that alternative for 1.2.3,\n            otherwise an additional requirement. At Level AAA under Success Criterion 1.2.8 they\n            must provide an extended text description. This is an additional requirement if both\n            1.2.3 and 1.2.5 were met by providing an audio description only. If 1.2.3 was met,\n            however, by providing a text description, and the 1.2.5 requirement for an audio description\n            was met, then 1.2.8 does not add new requirements.\nSee also\n1.2.5 Audio Description (Prerecorded)\n,\n1.2.7 Extended Audio Description (Prerecorded)\nand\n1.2.8 Media Alternative (Prerecorded)\n.",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.3_success_criterion",
    "type": "sc",
    "sc_id": "1.2.3",
    "section": "success_criterion",
    "text": "[1.2.3 Audio Description or Media Alternative (Prerecorded)] (Level A)\nDescription: An alternative for time-based media or audio description of the prerecorded\nvideo content is provided for synchronized media, except when the media is a media alternative for text and is clearly labeled as such.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nAn\nalternative for time-based media\nor\naudio description\nof the\nprerecorded\nvideo\ncontent is provided for\nsynchronized media\n, except when the media is a\nmedia alternative for text\nand is clearly labeled as such.",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.3_benefits",
    "type": "sc",
    "sc_id": "1.2.3",
    "section": "benefits",
    "text": "[1.2.3 Audio Description or Media Alternative (Prerecorded)] (Level A)\nDescription: An alternative for time-based media or audio description of the prerecorded\nvideo content is provided for synchronized media, except when the media is a media alternative for text and is clearly labeled as such.\n\nSection: benefits\n\nBenefits\nThis success criterion may help some people who have difficulty watching video or\n            other synchronized media content, including people who have difficulty perceiving\n            or understanding moving images.",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.3_examples",
    "type": "sc",
    "sc_id": "1.2.3",
    "section": "examples",
    "text": "[1.2.3 Audio Description or Media Alternative (Prerecorded)] (Level A)\nDescription: An alternative for time-based media or audio description of the prerecorded\nvideo content is provided for synchronized media, except when the media is a media alternative for text and is clearly labeled as such.\n\nSection: examples\n\nExamples\nA movie with audio description\nDescriber:\nA title, \"Teaching Evolution Case Studies. Bonnie Chen.\" A teacher shows photographs\n               of birds with long, thin beaks.\nBonnie Chen:\n\"These photos were all taken at the Everglades.\"\nDescriber:\nThe teacher hands each student two flat, thin wooden sticks.\nBonnie Chen:\n\"Today you will pretend to be a species of wading bird that has a beak like this.\"\nDescriber:\nThe teacher holds two of the sticks to her mouth making the shape of a beak.\nTranscript of audio based on the first few minutes of \"\nTeaching Evolution Case Studies, Bonnie Chen\n\" (copyright WGBH and Clear Blue Sky Productions, Inc.)\nAn alternative for time-based media for a training video\nA company purchases a Training video for use by its employees and puts it on the companies\n               intranet. The video involves explaining use of a new technology and has a person talking\n               and showing things at the same time. Since there is no place to insert audio description\n               of the visual demonstrations during gaps in dialogue, the company provides an alternative\n               for time-based media that all employees, including those who cannot see the demonstrations,\n               can use to better understand what is being presented.",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.3_brief",
    "type": "sc",
    "sc_id": "1.2.3",
    "section": "brief",
    "text": "[1.2.3 Audio Description or Media Alternative (Prerecorded)] (Level A)\nDescription: An alternative for time-based media or audio description of the prerecorded\nvideo content is provided for synchronized media, except when the media is a media alternative for text and is clearly labeled as such.\n\nSection: brief\n\nIn Brief\nGoal\nPrerecorded videos can be understood by more people.\nWhat to do\nProvide a description of the visual content in videos.\nWhy it's important\nPeople who are blind or who cannot understand the visual content can have it described.",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.3_resources",
    "type": "sc",
    "sc_id": "1.2.3",
    "section": "resources",
    "text": "[1.2.3 Audio Description or Media Alternative (Prerecorded)] (Level A)\nDescription: An alternative for time-based media or audio description of the prerecorded\nvideo content is provided for synchronized media, except when the media is a media alternative for text and is clearly labeled as such.\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nMaking Audio and Video Media Accessible, W3C Web Accessibility Initiative (WAI)\nNCAM Rich Media Accessibility, Accessible SMIL Templates\nStandard Techniques in Audio Description\nSynchronized Multimedia Integration Language (SMIL) 1.0\nSynchronized Multimedia Integration Language (SMIL 2.0)\nAccessibility Features of SMIL",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.3_test_rules",
    "type": "sc",
    "sc_id": "1.2.3",
    "section": "test_rules",
    "text": "[1.2.3 Audio Description or Media Alternative (Prerecorded)] (Level A)\nDescription: An alternative for time-based media or audio description of the prerecorded\nvideo content is provided for synchronized media, except when the media is a media alternative for text and is clearly labeled as such.\n\nSection: test_rules\n\nTest Rules\nThe following are Test Rules\n    for certain aspects of this Success Criterion.\n    It is not necessary to use these particular Test Rules to check for conformance with WCAG, but they are defined and approved test methods.\n    For information on using Test Rules, see\nUnderstanding Test Rules for WCAG Success Criteria\n.\nVideo element visual content has accessible alternative",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.3_key_terms",
    "type": "sc",
    "sc_id": "1.2.3",
    "section": "key_terms",
    "text": "[1.2.3 Audio Description or Media Alternative (Prerecorded)] (Level A)\nDescription: An alternative for time-based media or audio description of the prerecorded\nvideo content is provided for synchronized media, except when the media is a media alternative for text and is clearly labeled as such.\n\nSection: key_terms\n\nKey Terms\nalternative for time-based media\ndocument including correctly sequenced text descriptions of time-based visual and\n      auditory information and providing a means for achieving the outcomes of any time-based\n      interaction\nNote\nA screenplay used to create the synchronized media content would meet this definition\n      only if it was corrected to accurately represent the final synchronized media after\n      editing.\naudio\nthe technology of sound reproduction\nNote\nAudio can be created synthetically (including speech synthesis), recorded from real\n      world sounds, or both.\naudio description\nnarration added to the soundtrack to describe important visual details that cannot\n      be understood from the main soundtrack alone\nNote 1\nAudio description of\nvideo\nprovides information about actions, characters, scene changes, on-screen text, and\n      other visual content.\nNote 2\nIn standard audio description, narration is added during existing pauses in dialogue.\n      (See also\nextended audio description\n.)\nNote 3\nWhere all of the\nvideo\ninformation is already provided in existing\naudio\n, no additional audio description is necessary.\nNote 4\nAlso called \"video description\" and \"descriptive narration.\"\nextended audio description\naudio description that is added to an audiovisual presentation by pausing the\nvideo\nso that there is time to add additional description\nNote\nThis technique is only used when the sense of the\nvideo\nwould be lost without the additional\naudio description\nand the pauses between dialogue/narration are too short.\nhuman language\nlanguage that is spoken, written or signed (through visual or tactile means) to communicate\n      with humans\nNote\nSee also\nsign language\n.\nlive\ninformation captured from a real-world event and transmitted to the receiver with\n      no more than a broadcast delay\nNote 1\nA broadcast delay is a short (usually automated) delay, for example used in order\n      to give the broadcaster time to cue or censor the audio (or video) feed, but not sufficient\n      to allow significant editing.\nNote 2\nIf information is completely computer generated, it is not live.\nmedia alternative for text\nmedia that presents no more information than is already presented in text (directly\n      or via text alternatives)\nNote\nA media alternative for text is provided for those who benefit from alternate representations\n      of text. Media alternatives for text may be audio-only, video-only (including sign-language\n      video), or audio-video.\nprerecorded\ninformation that is not\nlive\nsign language\na language using combinations of movements of the hands and arms, facial expressions,\n      or body positions to convey meaning\nsynchronized media\naudio\nor\nvideo\nsynchronized with another format for presenting information and/or with time-based\n      interactive components, unless the media is a\nmedia alternative for text\nthat is clearly labeled as such\nvideo\nthe technology of moving or sequenced pictures or images\nNote\nVideo can be made up of animated or photographic images, or both.",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.3_sufficient",
    "type": "sc_sufficient",
    "sc_id": "1.2.3",
    "techniques": [
      "G69",
      "G58",
      "H53",
      "H53",
      "G78",
      "G173",
      "SM6",
      "SM7",
      "G226",
      "G8",
      "SM1",
      "SM2",
      "G203"
    ],
    "text": "[1.2.3 Audio Description or Media Alternative (Prerecorded)] (Level A)\nDescription: An alternative for time-based media or audio description of the prerecorded\nvideo content is provided for synchronized media, except when the media is a media alternative for text and is clearly labeled as such.\n\nSufficient techniques for SC 1.2.3 (no situation): G69, G58, H53, H53, G78, G173, SM6, SM7, G226, G8, SM1, SM2, G203",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.3_advisory",
    "type": "sc_advisory",
    "sc_id": "1.2.3",
    "techniques": [
      "H96"
    ],
    "text": "[1.2.3 Audio Description or Media Alternative (Prerecorded)] (Level A)\nDescription: An alternative for time-based media or audio description of the prerecorded\nvideo content is provided for synchronized media, except when the media is a media alternative for text and is clearly labeled as such.\n\nAdvisory techniques for SC 1.2.3: H96",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.4_intent",
    "type": "sc",
    "sc_id": "1.2.4",
    "section": "intent",
    "text": "[1.2.4 Captions (Live)] (Level AA)\nDescription: Captions are provided for all live\naudio content in synchronized media.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to enable people who are deaf or hard of hearing\n         to watch\nreal-time\npresentations. Captions provide the part of the content available via the audio track.\n         Captions not only include dialogue, but also identify who is speaking and notate sound\n         effects and other significant audio.\nThis success criterion was intended to apply to broadcast of synchronized media and\n         is not intended to require that two-way multimedia calls between two or more individuals\n         through web apps must be captioned regardless of the needs of users. Responsibility\n         for providing captions would fall to the content providers (the callers) or the “host”\n         caller, and not the application.",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.4_success_criterion",
    "type": "sc",
    "sc_id": "1.2.4",
    "section": "success_criterion",
    "text": "[1.2.4 Captions (Live)] (Level AA)\nDescription: Captions are provided for all live\naudio content in synchronized media.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nCaptions\nare provided for all\nlive\naudio\ncontent in\nsynchronized media\n.",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.4_benefits",
    "type": "sc",
    "sc_id": "1.2.4",
    "section": "benefits",
    "text": "[1.2.4 Captions (Live)] (Level AA)\nDescription: Captions are provided for all live\naudio content in synchronized media.\n\nSection: benefits\n\nBenefits\nPeople who are deaf or have a hearing loss can access the auditory information in\n            the synchronized media content through captions.",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.4_examples",
    "type": "sc",
    "sc_id": "1.2.4",
    "section": "examples",
    "text": "[1.2.4 Captions (Live)] (Level AA)\nDescription: Captions are provided for all live\naudio content in synchronized media.\n\nSection: examples\n\nExamples\nA web cast\nA news organization provides a live, captioned web cast.\nA music web cast\nAn orchestra provides Communication Access Realtime Translation (CART) captioning\n               of each real-time web performance. The CART service captures lyrics and dialog as\n               well as identifies non-vocal music by title, movement, composer, and any information\n               that will help the user comprehend the nature of the audio.",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.4_brief",
    "type": "sc",
    "sc_id": "1.2.4",
    "section": "brief",
    "text": "[1.2.4 Captions (Live)] (Level AA)\nDescription: Captions are provided for all live\naudio content in synchronized media.\n\nSection: brief\n\nIn Brief\nGoal\nLive videos have captions.\nWhat to do\nProvide synchronized text for audio content in real-time videos.\nWhy it's important\nPeople who are deaf or hard of hearing can understand audio in real-time video content.",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.4_resources",
    "type": "sc",
    "sc_id": "1.2.4",
    "section": "resources",
    "text": "[1.2.4 Captions (Live)] (Level AA)\nDescription: Captions are provided for all live\naudio content in synchronized media.\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nSee\n1.2.2: Captions (Prerecorded)\n.",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.4_key_terms",
    "type": "sc",
    "sc_id": "1.2.4",
    "section": "key_terms",
    "text": "[1.2.4 Captions (Live)] (Level AA)\nDescription: Captions are provided for all live\naudio content in synchronized media.\n\nSection: key_terms\n\nKey Terms\nASCII art\npicture created by a spatial arrangement of characters or glyphs (typically from the\n      95 printable characters defined by ASCII)\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\naudio\nthe technology of sound reproduction\nNote\nAudio can be created synthetically (including speech synthesis), recorded from real\n      world sounds, or both.\naudio description\nnarration added to the soundtrack to describe important visual details that cannot\n      be understood from the main soundtrack alone\nNote 1\nAudio description of\nvideo\nprovides information about actions, characters, scene changes, on-screen text, and\n      other visual content.\nNote 2\nIn standard audio description, narration is added during existing pauses in dialogue.\n      (See also\nextended audio description\n.)\nNote 3\nWhere all of the\nvideo\ninformation is already provided in existing\naudio\n, no additional audio description is necessary.\nNote 4\nAlso called \"video description\" and \"descriptive narration.\"\ncaptions\nsynchronized visual and/or\ntext alternative\nfor both speech and non-speech audio information needed to understand the media content\nNote 1\nCaptions are similar to dialogue-only subtitles except captions convey not only the\n      content of spoken dialogue, but also equivalents for non-dialogue audio information\n      needed to understand the program content, including sound effects, music, laughter,\n      speaker identification and location.\nNote 2\nClosed Captions are equivalents that can be turned on and off with some players.\nNote 3\nOpen Captions are any captions that cannot be turned off. For example, if the captions\n      are visual equivalent\nimages of text\nembedded in\nvideo\n.\nNote 4\nCaptions should not obscure or obstruct relevant information in the video.\nNote 5\nIn some countries, captions are called subtitles.\nNote 6\nAudio descriptions\ncan be, but do not need to be, captioned since they are descriptions of information\n      that is already presented visually.\nextended audio description\naudio description that is added to an audiovisual presentation by pausing the\nvideo\nso that there is time to add additional description\nNote\nThis technique is only used when the sense of the\nvideo\nwould be lost without the additional\naudio description\nand the pauses between dialogue/narration are too short.\nhuman language\nlanguage that is spoken, written or signed (through visual or tactile means) to communicate\n      with humans\nNote\nSee also\nsign language\n.\nimage of text\ntext that has been rendered in a non-text form (e.g., an image) in order to achieve\n      a particular visual effect\nNote\nThis does not include text that is part of a picture that contains significant other visual content.\nExample\nA person's name on a nametag in a photograph.\nlive\ninformation captured from a real-world event and transmitted to the receiver with\n      no more than a broadcast delay\nNote 1\nA broadcast delay is a short (usually automated) delay, for example used in order\n      to give the broadcaster time to cue or censor the audio (or video) feed, but not sufficient\n      to allow significant editing.\nNote 2\nIf information is completely computer generated, it is not live.\nmedia alternative for text\nmedia that presents no more information than is already presented in text (directly\n      or via text alternatives)\nNote\nA media alternative for text is provided for those who benefit from alternate representations\n      of text. Media alternatives for text may be audio-only, video-only (including sign-language\n      video), or audio-video.\nnon-text content\nany content that is not a sequence of characters that can be\nprogrammatically determined\nor where the sequence is not expressing something in\nhuman language\nNote\nThis includes\nASCII art\n(which is a pattern of characters), emoticons, leetspeak (which uses character substitution),\n      and images representing text\nprogrammatically determined\ndetermined by software from author-supplied data provided in a way that different\nuser agents\n, including\nassistive technologies\n, can extract and present this information to users in different modalities\nExample 1\nDetermined in a markup language from elements and attributes that are accessed directly\n      by commonly available assistive technology.\nExample 2\nDetermined from technology-specific data structures in a non-markup language and exposed\n      to assistive technology via an accessibility API that is supported by commonly available\n      assistive technology.\nsign language\na language using combinations of movements of the hands and arms, facial expressions,\n      or body positions to convey meaning\nsynchronized media\naudio\nor\nvideo\nsynchronized with another format for presenting information and/or with time-based\n      interactive components, unless the media is a\nmedia alternative for text\nthat is clearly labeled as such\ntext\nsequence of characters that can be\nprogrammatically determined\n, where the sequence is expressing something in\nhuman language\ntext alternative\nText\nthat is programmatically associated with\nnon-text content\nor referred to from text that is programmatically associated with non-text content.\n      Programmatically associated text is text whose location can be\nprogrammatically determined\nfrom the non-text content.\nExample\nAn image of a chart is described in text in the paragraph after the chart. The short\n      text alternative for the chart indicates that a description follows.\nNote\nRefer to\nUnderstanding Text Alternatives\nfor more information.\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.\nvideo\nthe technology of moving or sequenced pictures or images\nNote\nVideo can be made up of animated or photographic images, or both.",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.4_sufficient",
    "type": "sc_sufficient",
    "sc_id": "1.2.4",
    "techniques": [
      "G9",
      "SM11",
      "SM12"
    ],
    "text": "[1.2.4 Captions (Live)] (Level AA)\nDescription: Captions are provided for all live\naudio content in synchronized media.\n\nSufficient techniques for SC 1.2.4 (no situation): G9, SM11, SM12",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.5_intent",
    "type": "sc",
    "sc_id": "1.2.5",
    "section": "intent",
    "text": "[1.2.5 Audio Description (Prerecorded)] (Level AA)\nDescription: Audio description is provided for all prerecorded\nvideo content in synchronized media.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to provide people who are blind or visually\n         impaired access to the visual information in a synchronized media presentation in the same\nhuman language\nas the video or page on which it appears. The\n         audio description augments the audio portion of the presentation with the information\n         needed when the video portion is not available. During existing pauses in dialogue,\n         audio description provides information about actions, characters, scene changes, and\n         on-screen text that are important and are not described or spoken in the main sound\n         track.\nNote\nFor 1.2.3, 1.2.5, and 1.2.7, if all of the important information in the video track is already\n            conveyed in the audio track, no additional audio description is necessary.\n1.2.3, 1.2.5, and 1.2.8 overlap somewhat with each other. This is to give the author\n            some choice at the minimum conformance level, and to provide additional requirements\n            at higher levels. At Level A in Success Criterion 1.2.3, authors do have the choice\n            of providing either an audio description or a full text alternative. If they wish\n            to conform at Level AA, under Success Criterion 1.2.5 authors must provide an audio\n            description - a requirement already met if they chose that alternative for 1.2.3,\n            otherwise an additional requirement. At Level AAA under Success Criterion 1.2.8 they\n            must provide an extended text description. This is an additional requirement if both\n            1.2.3 and 1.2.5 were met by providing an audio description only. If 1.2.3 was met,\n            however, by providing a text description, and the 1.2.5 requirement for an audio description\n            was met, then 1.2.8 does not add new requirements.",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.5_success_criterion",
    "type": "sc",
    "sc_id": "1.2.5",
    "section": "success_criterion",
    "text": "[1.2.5 Audio Description (Prerecorded)] (Level AA)\nDescription: Audio description is provided for all prerecorded\nvideo content in synchronized media.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nAudio description\nis provided for all\nprerecorded\nvideo\ncontent in\nsynchronized media\n.",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.5_benefits",
    "type": "sc",
    "sc_id": "1.2.5",
    "section": "benefits",
    "text": "[1.2.5 Audio Description (Prerecorded)] (Level AA)\nDescription: Audio description is provided for all prerecorded\nvideo content in synchronized media.\n\nSection: benefits\n\nBenefits\nPeople who are blind or have low vision as well as those with cognitive limitations\n            who have difficulty interpreting visually what is happening benefit from audio description\n            of visual information.",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.5_examples",
    "type": "sc",
    "sc_id": "1.2.5",
    "section": "examples",
    "text": "[1.2.5 Audio Description (Prerecorded)] (Level AA)\nDescription: Audio description is provided for all prerecorded\nvideo content in synchronized media.\n\nSection: examples\n\nExamples\nA movie with audio description\nDescriber:\nA title, \"Teaching Evolution Case Studies. Bonnie Chen.\" A teacher shows photographs\n               of birds with long, thin beaks.\nBonnie Chen:\n\"These photos were all taken at the Everglades.\"\nDescriber:\nThe teacher hands each student two flat, thin wooden sticks.\nBonnie Chen:\n\"Today you will pretend to be a species of wading bird that has a beak like this.\"\nDescriber:\nThe teacher holds two of the sticks to her mouth making the shape of a beak.\nTranscript of audio based on the first few minutes of \"\nTeaching Evolution Case Studies, Bonnie Chen\n\" (copyright WGBH and Clear Blue Sky Productions, Inc.)",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.5_brief",
    "type": "sc",
    "sc_id": "1.2.5",
    "section": "brief",
    "text": "[1.2.5 Audio Description (Prerecorded)] (Level AA)\nDescription: Audio description is provided for all prerecorded\nvideo content in synchronized media.\n\nSection: brief\n\nIn Brief\nGoal\nVideos can be played with audio descriptions.\nWhat to do\nProvide a synchronized spoken description of the visual content in videos.\nWhy it's important\nPeople who cannot see or understand the visual content can hear about it while playing videos.",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.5_resources",
    "type": "sc",
    "sc_id": "1.2.5",
    "section": "resources",
    "text": "[1.2.5 Audio Description (Prerecorded)] (Level AA)\nDescription: Audio description is provided for all prerecorded\nvideo content in synchronized media.\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nDescription of Visual Information\n, in\nMaking Audio and Video Media Accessible\n, W3C Web Accessibility Initiative (WAI)\nNCAM Rich Media Accessibility, Accessible SMIL Templates\nStandard Techniques in Audio Description\nSynchronized Multimedia Integration Language (SMIL) 1.0\nSynchronized Multimedia Integration Language (SMIL 2.0)\nAccessibility Features of SMIL",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.5_test_rules",
    "type": "sc",
    "sc_id": "1.2.5",
    "section": "test_rules",
    "text": "[1.2.5 Audio Description (Prerecorded)] (Level AA)\nDescription: Audio description is provided for all prerecorded\nvideo content in synchronized media.\n\nSection: test_rules\n\nTest Rules\nThe following are Test Rules\n    for certain aspects of this Success Criterion.\n    It is not necessary to use these particular Test Rules to check for conformance with WCAG, but they are defined and approved test methods.\n    For information on using Test Rules, see\nUnderstanding Test Rules for WCAG Success Criteria\n.\nVideo element visual content has accessible alternative\nVideo element visual content has strict accessible alternative",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.5_key_terms",
    "type": "sc",
    "sc_id": "1.2.5",
    "section": "key_terms",
    "text": "[1.2.5 Audio Description (Prerecorded)] (Level AA)\nDescription: Audio description is provided for all prerecorded\nvideo content in synchronized media.\n\nSection: key_terms\n\nKey Terms\naudio\nthe technology of sound reproduction\nNote\nAudio can be created synthetically (including speech synthesis), recorded from real\n      world sounds, or both.\naudio description\nnarration added to the soundtrack to describe important visual details that cannot\n      be understood from the main soundtrack alone\nNote 1\nAudio description of\nvideo\nprovides information about actions, characters, scene changes, on-screen text, and\n      other visual content.\nNote 2\nIn standard audio description, narration is added during existing pauses in dialogue.\n      (See also\nextended audio description\n.)\nNote 3\nWhere all of the\nvideo\ninformation is already provided in existing\naudio\n, no additional audio description is necessary.\nNote 4\nAlso called \"video description\" and \"descriptive narration.\"\nextended audio description\naudio description that is added to an audiovisual presentation by pausing the\nvideo\nso that there is time to add additional description\nNote\nThis technique is only used when the sense of the\nvideo\nwould be lost without the additional\naudio description\nand the pauses between dialogue/narration are too short.\nhuman language\nlanguage that is spoken, written or signed (through visual or tactile means) to communicate\n      with humans\nNote\nSee also\nsign language\n.\nlive\ninformation captured from a real-world event and transmitted to the receiver with\n      no more than a broadcast delay\nNote 1\nA broadcast delay is a short (usually automated) delay, for example used in order\n      to give the broadcaster time to cue or censor the audio (or video) feed, but not sufficient\n      to allow significant editing.\nNote 2\nIf information is completely computer generated, it is not live.\nmedia alternative for text\nmedia that presents no more information than is already presented in text (directly\n      or via text alternatives)\nNote\nA media alternative for text is provided for those who benefit from alternate representations\n      of text. Media alternatives for text may be audio-only, video-only (including sign-language\n      video), or audio-video.\nprerecorded\ninformation that is not\nlive\nsign language\na language using combinations of movements of the hands and arms, facial expressions,\n      or body positions to convey meaning\nsynchronized media\naudio\nor\nvideo\nsynchronized with another format for presenting information and/or with time-based\n      interactive components, unless the media is a\nmedia alternative for text\nthat is clearly labeled as such\nvideo\nthe technology of moving or sequenced pictures or images\nNote\nVideo can be made up of animated or photographic images, or both.",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.5_sufficient",
    "type": "sc_sufficient",
    "sc_id": "1.2.5",
    "techniques": [
      "G78",
      "G173",
      "SM6",
      "SM7",
      "G226",
      "G8",
      "SM1",
      "SM2",
      "G203"
    ],
    "text": "[1.2.5 Audio Description (Prerecorded)] (Level AA)\nDescription: Audio description is provided for all prerecorded\nvideo content in synchronized media.\n\nSufficient techniques for SC 1.2.5 (no situation): G78, G173, SM6, SM7, G226, G8, SM1, SM2, G203",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.5_advisory",
    "type": "sc_advisory",
    "sc_id": "1.2.5",
    "techniques": [
      "H96"
    ],
    "text": "[1.2.5 Audio Description (Prerecorded)] (Level AA)\nDescription: Audio description is provided for all prerecorded\nvideo content in synchronized media.\n\nAdvisory techniques for SC 1.2.5: H96",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.6_intent",
    "type": "sc",
    "sc_id": "1.2.6",
    "section": "intent",
    "text": "[1.2.6 Sign Language (Prerecorded)] (Level AAA)\nDescription: Sign language interpretation is provided for all prerecorded\naudio content in synchronized media.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to enable people who are deaf or hard of hearing\n         and who are fluent in a sign language to understand the content of the audio track\n         of synchronized media presentations. Written text, such as that found in captions,\n         is often a second language. Because sign language provides the ability to provide\n         intonation, emotion and other audio information that is reflected in sign language\n         interpretation, but not in captions, sign language interpretation provides richer\n         and more equivalent access to synchronized media. People who communicate extensively\n         in sign language are also faster in sign language and synchronized media is a time-based\n         presentation.",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.6_success_criterion",
    "type": "sc",
    "sc_id": "1.2.6",
    "section": "success_criterion",
    "text": "[1.2.6 Sign Language (Prerecorded)] (Level AAA)\nDescription: Sign language interpretation is provided for all prerecorded\naudio content in synchronized media.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nSign language interpretation\nis provided for all\nprerecorded\naudio\ncontent in\nsynchronized media\n.",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.6_benefits",
    "type": "sc",
    "sc_id": "1.2.6",
    "section": "benefits",
    "text": "[1.2.6 Sign Language (Prerecorded)] (Level AAA)\nDescription: Sign language interpretation is provided for all prerecorded\naudio content in synchronized media.\n\nSection: benefits\n\nBenefits\nPeople whose human language is a sign language sometimes have limited reading ability.\n            These individuals may not be able to read and comprehend the captions and thus require\n            a sign language interpretation to gain access to the synchronized media content.",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.6_examples",
    "type": "sc",
    "sc_id": "1.2.6",
    "section": "examples",
    "text": "[1.2.6 Sign Language (Prerecorded)] (Level AAA)\nDescription: Sign language interpretation is provided for all prerecorded\naudio content in synchronized media.\n\nSection: examples\n\nExamples\nExample 1.\nA corporation is making an important announcement to all of its employees. The announcement\n            will be held in the main headquarters and later streamed to the Web. A sign language interpreter\n            is provided at the announcement location for the employees that are present in the meeting room. For the Web version of\n            the announcement, the sign language interpreter is shown/superimposed in the corner of the display.\nExample 2.\nA university is providing an online version of a particular lecture by creating\n            a synchronized media presentation of the professor delivering the lecture. The presentation\n            includes video of the professor speaking and demonstrating a science experiment. A\n            sign language interpretation of the lecture is created after the lecture and presented on the web with\n            the synchronized media version.",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.6_brief",
    "type": "sc",
    "sc_id": "1.2.6",
    "section": "brief",
    "text": "[1.2.6 Sign Language (Prerecorded)] (Level AAA)\nDescription: Sign language interpretation is provided for all prerecorded\naudio content in synchronized media.\n\nSection: brief\n\nIn Brief\nGoal\nVideos can be accompanied by sign language.\nWhat to do\nProvide sign language interpretation for audio content in existing videos.\nWhy it's important\nPeople who are deaf or hard of hearing have more ways to understand multimedia content.",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.6_resources",
    "type": "sc",
    "sc_id": "1.2.6",
    "section": "resources",
    "text": "[1.2.6 Sign Language (Prerecorded)] (Level AAA)\nDescription: Sign language interpretation is provided for all prerecorded\naudio content in synchronized media.\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nSign Languages\n, in\nMaking Audio and Video Media Accessible\n, W3C Web Accessibility Initiative (WAI)\nSynchronized Multimedia Integration Language (SMIL) 1.0\nSynchronized Multimedia Integration Language (SMIL 2.0)\nAccessibility Features of SMIL\nNCAM Rich Media Accessibility, Accessible SMIL Templates\nNational Institute on Deafness and other Communication Disorders\n: Information on American Sign Language\nTechniques for filming sign language interpreters\nRoyal National Institute for Deaf People (RNID)",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.6_key_terms",
    "type": "sc",
    "sc_id": "1.2.6",
    "section": "key_terms",
    "text": "[1.2.6 Sign Language (Prerecorded)] (Level AAA)\nDescription: Sign language interpretation is provided for all prerecorded\naudio content in synchronized media.\n\nSection: key_terms\n\nKey Terms\naudio\nthe technology of sound reproduction\nNote\nAudio can be created synthetically (including speech synthesis), recorded from real\n      world sounds, or both.\nlive\ninformation captured from a real-world event and transmitted to the receiver with\n      no more than a broadcast delay\nNote 1\nA broadcast delay is a short (usually automated) delay, for example used in order\n      to give the broadcaster time to cue or censor the audio (or video) feed, but not sufficient\n      to allow significant editing.\nNote 2\nIf information is completely computer generated, it is not live.\nmedia alternative for text\nmedia that presents no more information than is already presented in text (directly\n      or via text alternatives)\nNote\nA media alternative for text is provided for those who benefit from alternate representations\n      of text. Media alternatives for text may be audio-only, video-only (including sign-language\n      video), or audio-video.\nprerecorded\ninformation that is not\nlive\nsign language\na language using combinations of movements of the hands and arms, facial expressions,\n      or body positions to convey meaning\nsign language interpretation\ntranslation of one language, generally a spoken language, into a\nsign language\nNote\nTrue sign languages are independent languages that are unrelated to the spoken language(s)\n      of the same country or region.\nsynchronized media\naudio\nor\nvideo\nsynchronized with another format for presenting information and/or with time-based\n      interactive components, unless the media is a\nmedia alternative for text\nthat is clearly labeled as such\nvideo\nthe technology of moving or sequenced pictures or images\nNote\nVideo can be made up of animated or photographic images, or both.",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.6_sufficient",
    "type": "sc_sufficient",
    "sc_id": "1.2.6",
    "techniques": [
      "G54",
      "G81",
      "SM13",
      "SM14"
    ],
    "text": "[1.2.6 Sign Language (Prerecorded)] (Level AAA)\nDescription: Sign language interpretation is provided for all prerecorded\naudio content in synchronized media.\n\nSufficient techniques for SC 1.2.6 (no situation): G54, G81, SM13, SM14",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.7_intent",
    "type": "sc",
    "sc_id": "1.2.7",
    "section": "intent",
    "text": "[1.2.7 Extended Audio Description (Prerecorded)] (Level AAA)\nDescription: Where pauses in foreground audio are insufficient to allow audio descriptions to convey the sense of the video, extended audio description is provided for all prerecorded\nvideo content in synchronized media.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to provide people who are blind or visually\n         impaired access to a synchronized media presentation beyond that which can be provided\n         by standard audio description.    This is done by periodically freezing the synchronized\n         media presentation and playing additional audio description.  The synchronized media\n         presentation is then resumed.\nBecause it disrupts viewing for those who do not need the additional description,\n         techniques that allow you to turn the feature on and off are often provided.  Alternately,\n         versions with and without the additional description can be provided.",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.7_success_criterion",
    "type": "sc",
    "sc_id": "1.2.7",
    "section": "success_criterion",
    "text": "[1.2.7 Extended Audio Description (Prerecorded)] (Level AAA)\nDescription: Where pauses in foreground audio are insufficient to allow audio descriptions to convey the sense of the video, extended audio description is provided for all prerecorded\nvideo content in synchronized media.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nWhere pauses in foreground audio are insufficient to allow\naudio descriptions\nto convey the sense of the video,\nextended audio description\nis provided for all\nprerecorded\nvideo\ncontent in\nsynchronized media\n.",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.7_benefits",
    "type": "sc",
    "sc_id": "1.2.7",
    "section": "benefits",
    "text": "[1.2.7 Extended Audio Description (Prerecorded)] (Level AAA)\nDescription: Where pauses in foreground audio are insufficient to allow audio descriptions to convey the sense of the video, extended audio description is provided for all prerecorded\nvideo content in synchronized media.\n\nSection: benefits\n\nBenefits\nPeople who are blind, people with low vision who cannot see the screen, as well as\n            those with cognitive limitations who have difficulty interpreting visually what is\n            happening, often use audio description of the visual information. However, if there\n            is too much dialogue the audio description is insufficient. Extended audio description\n            can provide the additional information needed to understand the video.",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.7_examples",
    "type": "sc",
    "sc_id": "1.2.7",
    "section": "examples",
    "text": "[1.2.7 Extended Audio Description (Prerecorded)] (Level AAA)\nDescription: Where pauses in foreground audio are insufficient to allow audio descriptions to convey the sense of the video, extended audio description is provided for all prerecorded\nvideo content in synchronized media.\n\nSection: examples\n\nExamples\nExample 1. Video of a lecture.\nA physics professor is giving a lecture. The professor makes freehand sketches on the whiteboard,\n            speaking rapidly while drawing. As soon as discussion on one problem is finished, the professor\n            erases the drawing and makes another sketch while continuing to speak and gesture.\n             The video is paused between problems, and extended audio description\n            of the professor's drawings and gestures is provided; the video is then resumed.",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.7_brief",
    "type": "sc",
    "sc_id": "1.2.7",
    "section": "brief",
    "text": "[1.2.7 Extended Audio Description (Prerecorded)] (Level AAA)\nDescription: Where pauses in foreground audio are insufficient to allow audio descriptions to convey the sense of the video, extended audio description is provided for all prerecorded\nvideo content in synchronized media.\n\nSection: brief\n\nIn Brief\nGoal\nVideos can be played with more detailed audio descriptions.\nWhat to do\nProvide extended spoken descriptions of the visual content in videos.\nWhy it's important\nPeople who are blind or who cannot understand the visual content can have it described to them while playing videos.",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.7_resources",
    "type": "sc",
    "sc_id": "1.2.7",
    "section": "resources",
    "text": "[1.2.7 Extended Audio Description (Prerecorded)] (Level AAA)\nDescription: Where pauses in foreground audio are insufficient to allow audio descriptions to convey the sense of the video, extended audio description is provided for all prerecorded\nvideo content in synchronized media.\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nSynchronized Multimedia Integration Language (SMIL) 1.0\nSynchronized Multimedia Integration Language (SMIL) 2.0\nAccessibility Features of SMIL\nNCAM Rich Media Accessibility, Accessible SMIL Templates\nStandard Techniques in Audio Description",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.7_key_terms",
    "type": "sc",
    "sc_id": "1.2.7",
    "section": "key_terms",
    "text": "[1.2.7 Extended Audio Description (Prerecorded)] (Level AAA)\nDescription: Where pauses in foreground audio are insufficient to allow audio descriptions to convey the sense of the video, extended audio description is provided for all prerecorded\nvideo content in synchronized media.\n\nSection: key_terms\n\nKey Terms\naudio\nthe technology of sound reproduction\nNote\nAudio can be created synthetically (including speech synthesis), recorded from real\n      world sounds, or both.\naudio description\nnarration added to the soundtrack to describe important visual details that cannot\n      be understood from the main soundtrack alone\nNote 1\nAudio description of\nvideo\nprovides information about actions, characters, scene changes, on-screen text, and\n      other visual content.\nNote 2\nIn standard audio description, narration is added during existing pauses in dialogue.\n      (See also\nextended audio description\n.)\nNote 3\nWhere all of the\nvideo\ninformation is already provided in existing\naudio\n, no additional audio description is necessary.\nNote 4\nAlso called \"video description\" and \"descriptive narration.\"\nextended audio description\naudio description that is added to an audiovisual presentation by pausing the\nvideo\nso that there is time to add additional description\nNote\nThis technique is only used when the sense of the\nvideo\nwould be lost without the additional\naudio description\nand the pauses between dialogue/narration are too short.\nlive\ninformation captured from a real-world event and transmitted to the receiver with\n      no more than a broadcast delay\nNote 1\nA broadcast delay is a short (usually automated) delay, for example used in order\n      to give the broadcaster time to cue or censor the audio (or video) feed, but not sufficient\n      to allow significant editing.\nNote 2\nIf information is completely computer generated, it is not live.\nmedia alternative for text\nmedia that presents no more information than is already presented in text (directly\n      or via text alternatives)\nNote\nA media alternative for text is provided for those who benefit from alternate representations\n      of text. Media alternatives for text may be audio-only, video-only (including sign-language\n      video), or audio-video.\nprerecorded\ninformation that is not\nlive\nsynchronized media\naudio\nor\nvideo\nsynchronized with another format for presenting information and/or with time-based\n      interactive components, unless the media is a\nmedia alternative for text\nthat is clearly labeled as such\nvideo\nthe technology of moving or sequenced pictures or images\nNote\nVideo can be made up of animated or photographic images, or both.",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.7_sufficient",
    "type": "sc_sufficient",
    "sc_id": "1.2.7",
    "techniques": [
      "G8",
      "SM1",
      "SM2"
    ],
    "text": "[1.2.7 Extended Audio Description (Prerecorded)] (Level AAA)\nDescription: Where pauses in foreground audio are insufficient to allow audio descriptions to convey the sense of the video, extended audio description is provided for all prerecorded\nvideo content in synchronized media.\n\nSufficient techniques for SC 1.2.7 (no situation): G8, SM1, SM2",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.7_advisory",
    "type": "sc_advisory",
    "sc_id": "1.2.7",
    "techniques": [
      "H96"
    ],
    "text": "[1.2.7 Extended Audio Description (Prerecorded)] (Level AAA)\nDescription: Where pauses in foreground audio are insufficient to allow audio descriptions to convey the sense of the video, extended audio description is provided for all prerecorded\nvideo content in synchronized media.\n\nAdvisory techniques for SC 1.2.7: H96",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.8_intent",
    "type": "sc",
    "sc_id": "1.2.8",
    "section": "intent",
    "text": "[1.2.8 Media Alternative (Prerecorded)] (Level AAA)\nDescription: An alternative for time-based media is provided for all prerecorded\nsynchronized media and for all prerecorded video-only media.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to make audio visual material available to\n         individuals whose vision is too poor to reliably read\ncaptions\nand whose hearing is too poor to reliably hear dialogue and\naudio description\n. This is done by providing an alternative for time-based media in the same\nhuman language\nas the video or page on which it appears.\nThis approach involves providing all of the information in the synchronized media\n         (both visual and auditory) in text form. An alternative for time-based media provides\n         a running description of all that is going on in the synchronized media content. The\n         alternative for time-based media reads something like a book. Unlike audio description,\n         the description of the video portion is not constrained to just the pauses in the\n         existing dialogue. Full descriptions are provided of all visual information, including\n         visual context, actions and expressions of actors, and any other visual material.\n         In addition, non-speech sounds (laughter, off-screen voices, etc.) are described,\n         and transcripts of all dialogue are included. The sequence of descriptions and dialogue\n         transcripts is the same as the sequence in the synchronized media itself. As a result,\n         the alternative for time-based media can provide a much more complete representation\n         of the synchronized media content than audio description alone.\nIf there is any interaction as part of the synchronized media presentation (e.g.,\n         \"press now to answer the question\") then the alternative for time-based media would\n         provide hyperlinks or whatever is needed to provide parallel functionality.\nIndividuals whose vision is too poor to reliably read captions and whose hearing is\n         too poor to reliably hear dialogue can access the alternative for time-based media\n         by using a refreshable braille display.\nNote\n1.2.3, 1.2.5, and 1.2.8 overlap somewhat with each other. This is to give the author\n            some choice at the minimum conformance level, and to provide additional requirements\n            at higher levels. At Level A in Success Criterion 1.2.3, authors do have the choice\n            of providing either an audio description or a full text alternative. If they wish\n            to conform at Level AA, under Success Criterion 1.2.5 authors must provide an audio\n            description - a requirement already met if they chose that alternative for 1.2.3,\n            otherwise an additional requirement. At Level AAA under Success Criterion 1.2.8 they\n            must provide an extended text description. This is an additional requirement if both\n            1.2.3 and 1.2.5 were met by providing an audio description only. If 1.2.3 was met,\n            however, by providing a text description, and the 1.2.5 requirement for an audio description\n            was met, then 1.2.8 does not add new requirements.",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.8_success_criterion",
    "type": "sc",
    "sc_id": "1.2.8",
    "section": "success_criterion",
    "text": "[1.2.8 Media Alternative (Prerecorded)] (Level AAA)\nDescription: An alternative for time-based media is provided for all prerecorded\nsynchronized media and for all prerecorded video-only media.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nAn\nalternative for time-based media\nis provided for all\nprerecorded\nsynchronized media\nand for all prerecorded\nvideo-only\nmedia.",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.8_benefits",
    "type": "sc",
    "sc_id": "1.2.8",
    "section": "benefits",
    "text": "[1.2.8 Media Alternative (Prerecorded)] (Level AAA)\nDescription: An alternative for time-based media is provided for all prerecorded\nsynchronized media and for all prerecorded video-only media.\n\nSection: benefits\n\nBenefits\nPeople who are deaf-blind, who cannot see well or at all, and who also cannot hear well or at all can get\n            access to information in audio-visual presentations.",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.8_examples",
    "type": "sc",
    "sc_id": "1.2.8",
    "section": "examples",
    "text": "[1.2.8 Media Alternative (Prerecorded)] (Level AAA)\nDescription: An alternative for time-based media is provided for all prerecorded\nsynchronized media and for all prerecorded video-only media.\n\nSection: examples\n\nExamples\nExample 1. alternative for time-based media for a training video\nA community center purchases a Training video for use by its clients and puts it on\n               the center's intranet. The video involves explaining use of a new technology and has\n               a person talking and showing things at the same time. The community center provides\n               an alternative for time-based media that all clients, including those who can neither\n               see the demonstrations nor hear the explanations in the synchronized media, can use\n               to better understand what is being presented.",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.8_brief",
    "type": "sc",
    "sc_id": "1.2.8",
    "section": "brief",
    "text": "[1.2.8 Media Alternative (Prerecorded)] (Level AAA)\nDescription: An alternative for time-based media is provided for all prerecorded\nsynchronized media and for all prerecorded video-only media.\n\nSection: brief\n\nIn Brief\nGoal\nPrecorded videos can be understood by more people.\nWhat to do\nProvide a text equivalent for all content in videos.\nWhy it's important\nMore people, including those who are deaf-blind, can better understand the content at their own pace.",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.8_resources",
    "type": "sc",
    "sc_id": "1.2.8",
    "section": "resources",
    "text": "[1.2.8 Media Alternative (Prerecorded)] (Level AAA)\nDescription: An alternative for time-based media is provided for all prerecorded\nsynchronized media and for all prerecorded video-only media.\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nTranscripts\n, in\nMaking Audio and Video Media Accessible\n, W3C Web Accessibility Initiative (WAI)\nuiAccess list of transcription services\nTranscripts on the Web: Getting people to your podcasts and videos",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.8_test_rules",
    "type": "sc",
    "sc_id": "1.2.8",
    "section": "test_rules",
    "text": "[1.2.8 Media Alternative (Prerecorded)] (Level AAA)\nDescription: An alternative for time-based media is provided for all prerecorded\nsynchronized media and for all prerecorded video-only media.\n\nSection: test_rules\n\nTest Rules\nThe following are Test Rules\n    for certain aspects of this Success Criterion.\n    It is not necessary to use these particular Test Rules to check for conformance with WCAG, but they are defined and approved test methods.\n    For information on using Test Rules, see\nUnderstanding Test Rules for WCAG Success Criteria\n.\nAudio and visuals of video element have transcript\nVideo element visual content has accessible alternative",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.8_key_terms",
    "type": "sc",
    "sc_id": "1.2.8",
    "section": "key_terms",
    "text": "[1.2.8 Media Alternative (Prerecorded)] (Level AAA)\nDescription: An alternative for time-based media is provided for all prerecorded\nsynchronized media and for all prerecorded video-only media.\n\nSection: key_terms\n\nKey Terms\nalternative for time-based media\ndocument including correctly sequenced text descriptions of time-based visual and\n      auditory information and providing a means for achieving the outcomes of any time-based\n      interaction\nNote\nA screenplay used to create the synchronized media content would meet this definition\n      only if it was corrected to accurately represent the final synchronized media after\n      editing.\nASCII art\npicture created by a spatial arrangement of characters or glyphs (typically from the\n      95 printable characters defined by ASCII)\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\naudio\nthe technology of sound reproduction\nNote\nAudio can be created synthetically (including speech synthesis), recorded from real\n      world sounds, or both.\naudio description\nnarration added to the soundtrack to describe important visual details that cannot\n      be understood from the main soundtrack alone\nNote 1\nAudio description of\nvideo\nprovides information about actions, characters, scene changes, on-screen text, and\n      other visual content.\nNote 2\nIn standard audio description, narration is added during existing pauses in dialogue.\n      (See also\nextended audio description\n.)\nNote 3\nWhere all of the\nvideo\ninformation is already provided in existing\naudio\n, no additional audio description is necessary.\nNote 4\nAlso called \"video description\" and \"descriptive narration.\"\ncaptions\nsynchronized visual and/or\ntext alternative\nfor both speech and non-speech audio information needed to understand the media content\nNote 1\nCaptions are similar to dialogue-only subtitles except captions convey not only the\n      content of spoken dialogue, but also equivalents for non-dialogue audio information\n      needed to understand the program content, including sound effects, music, laughter,\n      speaker identification and location.\nNote 2\nClosed Captions are equivalents that can be turned on and off with some players.\nNote 3\nOpen Captions are any captions that cannot be turned off. For example, if the captions\n      are visual equivalent\nimages of text\nembedded in\nvideo\n.\nNote 4\nCaptions should not obscure or obstruct relevant information in the video.\nNote 5\nIn some countries, captions are called subtitles.\nNote 6\nAudio descriptions\ncan be, but do not need to be, captioned since they are descriptions of information\n      that is already presented visually.\nextended audio description\naudio description that is added to an audiovisual presentation by pausing the\nvideo\nso that there is time to add additional description\nNote\nThis technique is only used when the sense of the\nvideo\nwould be lost without the additional\naudio description\nand the pauses between dialogue/narration are too short.\nhuman language\nlanguage that is spoken, written or signed (through visual or tactile means) to communicate\n      with humans\nNote\nSee also\nsign language\n.\nimage of text\ntext that has been rendered in a non-text form (e.g., an image) in order to achieve\n      a particular visual effect\nNote\nThis does not include text that is part of a picture that contains significant other visual content.\nExample\nA person's name on a nametag in a photograph.\nlive\ninformation captured from a real-world event and transmitted to the receiver with\n      no more than a broadcast delay\nNote 1\nA broadcast delay is a short (usually automated) delay, for example used in order\n      to give the broadcaster time to cue or censor the audio (or video) feed, but not sufficient\n      to allow significant editing.\nNote 2\nIf information is completely computer generated, it is not live.\nmedia alternative for text\nmedia that presents no more information than is already presented in text (directly\n      or via text alternatives)\nNote\nA media alternative for text is provided for those who benefit from alternate representations\n      of text. Media alternatives for text may be audio-only, video-only (including sign-language\n      video), or audio-video.\nnon-text content\nany content that is not a sequence of characters that can be\nprogrammatically determined\nor where the sequence is not expressing something in\nhuman language\nNote\nThis includes\nASCII art\n(which is a pattern of characters), emoticons, leetspeak (which uses character substitution),\n      and images representing text\nprerecorded\ninformation that is not\nlive\nprogrammatically determined\ndetermined by software from author-supplied data provided in a way that different\nuser agents\n, including\nassistive technologies\n, can extract and present this information to users in different modalities\nExample 1\nDetermined in a markup language from elements and attributes that are accessed directly\n      by commonly available assistive technology.\nExample 2\nDetermined from technology-specific data structures in a non-markup language and exposed\n      to assistive technology via an accessibility API that is supported by commonly available\n      assistive technology.\nsign language\na language using combinations of movements of the hands and arms, facial expressions,\n      or body positions to convey meaning\nsynchronized media\naudio\nor\nvideo\nsynchronized with another format for presenting information and/or with time-based\n      interactive components, unless the media is a\nmedia alternative for text\nthat is clearly labeled as such\ntext\nsequence of characters that can be\nprogrammatically determined\n, where the sequence is expressing something in\nhuman language\ntext alternative\nText\nthat is programmatically associated with\nnon-text content\nor referred to from text that is programmatically associated with non-text content.\n      Programmatically associated text is text whose location can be\nprogrammatically determined\nfrom the non-text content.\nExample\nAn image of a chart is described in text in the paragraph after the chart. The short\n      text alternative for the chart indicates that a description follows.\nNote\nRefer to\nUnderstanding Text Alternatives\nfor more information.\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.\nvideo\nthe technology of moving or sequenced pictures or images\nNote\nVideo can be made up of animated or photographic images, or both.\nvideo-only\na time-based presentation that contains only\nvideo\n(no\naudio\nand no interaction)",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.8_situation_A",
    "type": "sc_situation",
    "sc_id": "1.2.8",
    "situation_id": "A",
    "techniques": [
      "G69",
      "G58",
      "H53",
      "H53"
    ],
    "text": "[1.2.8 Media Alternative (Prerecorded)] (Level AAA)\nDescription: An alternative for time-based media is provided for all prerecorded\nsynchronized media and for all prerecorded video-only media.\n\nSituation A: If the content is prerecorded synchronized media:\n\nRelated techniques: G69, G58, H53, H53",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.8_situation_B",
    "type": "sc_situation",
    "sc_id": "1.2.8",
    "situation_id": "B",
    "techniques": [
      "G159"
    ],
    "text": "[1.2.8 Media Alternative (Prerecorded)] (Level AAA)\nDescription: An alternative for time-based media is provided for all prerecorded\nsynchronized media and for all prerecorded video-only media.\n\nSituation B: If the content is prerecorded video-only:\n\nRelated techniques: G159",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.8_failures",
    "type": "sc_failures",
    "sc_id": "1.2.8",
    "techniques": [
      "F74"
    ],
    "text": "[1.2.8 Media Alternative (Prerecorded)] (Level AAA)\nDescription: An alternative for time-based media is provided for all prerecorded\nsynchronized media and for all prerecorded video-only media.\n\nCommon failures for SC 1.2.8: F74",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.9_intent",
    "type": "sc",
    "sc_id": "1.2.9",
    "section": "intent",
    "text": "[1.2.9 Audio-only (Live)] (Level AAA)\nDescription: An alternative for time-based media that presents equivalent information for live\naudio-only content is provided.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to make information conveyed by live audio,\n         such as web-based audio conferencing, live speeches and radio Webcasts, accessible through the\n         use of a text alternative. A live text caption service will enable live audio to be\n         accessible to people who are deaf or hard of hearing, or who cannot otherwise hear\n         the audio. Such services use a trained human operator who listens in to what is being\n         said and uses a special keyboard to enter the text with only a small delay. They are\n         able to capture a live event with a high degree of fidelity, and also to insert notes\n         on any non spoken audio which is essential to understanding the event. A transcript\n         is sometimes a possibility if the live audio is following a set script; but a live\n         caption service is preferred because it plays out at the same pace as the audio itself,\n         and can adapt to any deviations from the script that might occur.\nUsing untrained operators, or providing a transcript which differs markedly from what\n         actually happens would not be considered meeting this success criterion.\nThis success criterion was intended to apply to broadcast of audio and is not intended\n         to require that two-way audio calls between two or more individuals through web apps\n         must be captioned regardless of the needs of users. Responsibility for providing captions\n         would fall to the content providers (the callers) or the “host” caller, and not the\n         application.",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.9_success_criterion",
    "type": "sc",
    "sc_id": "1.2.9",
    "section": "success_criterion",
    "text": "[1.2.9 Audio-only (Live)] (Level AAA)\nDescription: An alternative for time-based media that presents equivalent information for live\naudio-only content is provided.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nAn\nalternative for time-based media\nthat presents equivalent information for\nlive\naudio-only\ncontent is provided.",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.9_examples",
    "type": "sc",
    "sc_id": "1.2.9",
    "section": "examples",
    "text": "[1.2.9 Audio-only (Live)] (Level AAA)\nDescription: An alternative for time-based media that presents equivalent information for live\naudio-only content is provided.\n\nSection: examples\n\nExamples\nA public relations firm uses web based caption services to cover live events; the\n            output from the service is incorporated in a sub frame of the web page which includes\n            the streaming audio control.\nA live radio play of a fringe theatre group is being broadcast to the Web. As the\n            actors stick largely to a set script, and the budget for the program is small, the\n            producers provide a link (with the playwright's permission) to the script of the play.\nA streaming audio server uses a technology which can also accommodate text and graphics,\n            such as HTML. A stenographer is used to create live captions at an\n            event, and these are mixed on the fly to produce live captions in the media stream\n            which can be viewed by the media player.\nA CEO is to give a press release by telephone to the media in response to a breaking\n            news story, the audio is being recorded and streamed over the internet, but due to\n            time constraints a web captioning service cannot be set up in time. As the press release\n            is a set statement which the CEO will be reading out, the company simultaneously provides\n            the transcript of the release.",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.9_brief",
    "type": "sc",
    "sc_id": "1.2.9",
    "section": "brief",
    "text": "[1.2.9 Audio-only (Live)] (Level AAA)\nDescription: An alternative for time-based media that presents equivalent information for live\naudio-only content is provided.\n\nSection: brief\n\nIn Brief\nGoal\nLive audio can be understood by more people.\nWhat to do\nProvide a text equivalent for live audio-only content.\nWhy it's important\nPeople who cannot hear or understand real-time audio can read an equivalent.",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.9_resources",
    "type": "sc",
    "sc_id": "1.2.9",
    "section": "resources",
    "text": "[1.2.9 Audio-only (Live)] (Level AAA)\nDescription: An alternative for time-based media that presents equivalent information for live\naudio-only content is provided.\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nWebAIM Real time captioning resource\nuiAccess list of transcription services\nTranscripts on the Web: Getting people to your podcasts and videos",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.9_key_terms",
    "type": "sc",
    "sc_id": "1.2.9",
    "section": "key_terms",
    "text": "[1.2.9 Audio-only (Live)] (Level AAA)\nDescription: An alternative for time-based media that presents equivalent information for live\naudio-only content is provided.\n\nSection: key_terms\n\nKey Terms\nalternative for time-based media\ndocument including correctly sequenced text descriptions of time-based visual and\n      auditory information and providing a means for achieving the outcomes of any time-based\n      interaction\nNote\nA screenplay used to create the synchronized media content would meet this definition\n      only if it was corrected to accurately represent the final synchronized media after\n      editing.\naudio\nthe technology of sound reproduction\nNote\nAudio can be created synthetically (including speech synthesis), recorded from real\n      world sounds, or both.\naudio-only\na time-based presentation that contains only\naudio\n(no\nvideo\nand no interaction)\nlive\ninformation captured from a real-world event and transmitted to the receiver with\n      no more than a broadcast delay\nNote 1\nA broadcast delay is a short (usually automated) delay, for example used in order\n      to give the broadcaster time to cue or censor the audio (or video) feed, but not sufficient\n      to allow significant editing.\nNote 2\nIf information is completely computer generated, it is not live.\nvideo\nthe technology of moving or sequenced pictures or images\nNote\nVideo can be made up of animated or photographic images, or both.",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.2.9_sufficient",
    "type": "sc_sufficient",
    "sc_id": "1.2.9",
    "techniques": [
      "G151",
      "G150",
      "G157"
    ],
    "text": "[1.2.9 Audio-only (Live)] (Level AAA)\nDescription: An alternative for time-based media that presents equivalent information for live\naudio-only content is provided.\n\nSufficient techniques for SC 1.2.9 (no situation): G151, G150, G157",
    "principle": "Perceivable",
    "guideline": "1.2 Time-based Media"
  },
  {
    "id": "1.3.1_intent",
    "type": "sc",
    "sc_id": "1.3.1",
    "section": "intent",
    "text": "[1.3.1 Info and Relationships] (Level A)\nDescription: Information, structure, and relationships conveyed through presentation can be programmatically determined or are available in text.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to ensure that information and relationships\n         that are implied by visual or auditory formatting are preserved when the presentation\n         format changes. For example, the presentation format changes when the content is read\n         by a screen reader or when a user style sheet is substituted for the style sheet provided\n         by the author.\nSighted users perceive structure and relationships through various visual cues\n         — headings are often in a larger, bold font separated from paragraphs by blank lines;\n         list items are preceded by a bullet and perhaps indented; paragraphs are separated\n         by a blank line; items that share a common characteristic are organized into tabular\n         rows and columns; form fields may be positioned as groups that share text labels;\n         a different background color may be used to indicate that several items are related\n         to each other; words that have special status are indicated by changing the font family\n         and /or bolding, italicizing, or underlining them; items that share a common characteristic\n         are organized into a table where the relationship of cells sharing the same row or\n         column and the relationship of each cell to its row and/or column header are necessary\n         for understanding; and so on. Having these structures and these relationships programmatically\n         determined or available in text ensures that information important for comprehension\n         will be perceivable to all.\nAuditory cues may be used as well. For example, a chime might indicate the beginning\n         of a new section; a change in voice pitch or speech rate may be used to emphasize\n         important information or to indicate quoted text; etc.\nWhen such relationships are perceivable to one set of users, those relationships can\n         be made to be perceivable to all. One method of determining whether or not information\n         has been properly provided to all users is to access the information serially in different\n         modalities.\nIf links to glossary items are implemented using anchor elements (or the proper link\n         element for the technology in use) and identified using a different font face, a screen\n         reader user will hear that the item is a link when the glossary term is encountered\n         even though they may not receive information about the change in font face. An on-line\n         catalog may indicate prices using a larger font colored red. A screen reader or person\n         who cannot perceive red, still has the information about the price as long as it is\n         preceded by the currency symbol.\nSome technologies do not provide a means to programmatically determine some types\n         of information and relationships. In that case then there should be a text description\n         of the information and relationships. For instance, \"all required fields are marked\n         with an asterisk (*)\". The text description should be near the information it is describing\n         (when the page is linearized), such as in the parent element or in the adjacent element.\nThere may also be cases where it may be a judgment call as to whether the relationships\n         should be programmatically determined or be presented in text. However, when technologies\n         support programmatic relationships, it is strongly encouraged that information and\n         relationships be programmatically determined rather than described in text.\nNote\nIt is not required that color values be programmatically determined. The information\n            conveyed by color cannot be adequately presented simply by exposing the value. Therefore,\nSuccess Criterion 1.4.1\naddresses the specific case of color, rather than Success Criterion 1.3.1.",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.1_success_criterion",
    "type": "sc",
    "sc_id": "1.3.1",
    "section": "success_criterion",
    "text": "[1.3.1 Info and Relationships] (Level A)\nDescription: Information, structure, and relationships conveyed through presentation can be programmatically determined or are available in text.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nInformation,\nstructure\n, and\nrelationships\nconveyed through\npresentation\ncan be\nprogrammatically determined\nor are available in text.",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.1_benefits",
    "type": "sc",
    "sc_id": "1.3.1",
    "section": "benefits",
    "text": "[1.3.1 Info and Relationships] (Level A)\nDescription: Information, structure, and relationships conveyed through presentation can be programmatically determined or are available in text.\n\nSection: benefits\n\nBenefits\nThis success criterion helps people with different disabilities by allowing user agents\n            to adapt content according to the needs of individual users.\nUsers who are blind (using a screen reader) benefit when information conveyed through\n            color is also available in text (including text alternatives for images that use color\n            to convey information).\nUsers who are deaf-blind using braille (text) refreshable displays may be unable to\n            access color-dependent information.",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.1_examples",
    "type": "sc",
    "sc_id": "1.3.1",
    "section": "examples",
    "text": "[1.3.1 Info and Relationships] (Level A)\nDescription: Information, structure, and relationships conveyed through presentation can be programmatically determined or are available in text.\n\nSection: examples\n\nExamples\nA form with required fields\nA form contains several required fields. The labels for the required fields are displayed\n               in red. In addition, at the end of each label is an asterisk character, *. The instructions\n               for completing the form indicate that \"all required fields are displayed in red and\n               marked with an asterisk *\", followed by an example.\nA form that uses color and text to indicate required fields\nA form contains both required and optional fields. Instructions at the top of the\n               form explain that required fields are labeled with red text and also with an icon\n               whose text alternative says, \"Required.\" Both the red text and the icon are programmatically\n               associated with the appropriate form fields so that assistive technology users can\n               determine the required fields.\nA bus schedule table where the headers for each cell can be programmatically determined\nA bus schedule consists of a table with the bus stops listed vertically in the first\n               column and the different buses listed horizontally across the first row. Each cell\n               contains the time when the bus will be at that bus stop. The bus stop and bus cells\n               are identified as headers for their corresponding row or column so that assistive\n               technology can programmatically determine which bus and which bus stop are associated\n               with the time in each cell.\nA form where the labels for the checkboxes can be programmatically determined\nIn a form, the labels for each checkbox can be programmatically determined by assistive\n               technology.\nA text document\nA simple text document is formatted with double blank lines before titles, asterisks\n               to indicate list items and other standard formatting conventions so that its structure\n               can be programmatically determined.",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.1_brief",
    "type": "sc",
    "sc_id": "1.3.1",
    "section": "brief",
    "text": "[1.3.1 Info and Relationships] (Level A)\nDescription: Information, structure, and relationships conveyed through presentation can be programmatically determined or are available in text.\n\nSection: brief\n\nIn Brief\nGoal\nInformation about content structure is available to more people.\nWhat to do\nUse code to reinforce relationships and information conveyed through presentation.\nWhy it's important\nPeople can adapt the presentation to suit their needs while preserving the original meaning.",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.1_resources",
    "type": "sc",
    "sc_id": "1.3.1",
    "section": "resources",
    "text": "[1.3.1 Info and Relationships] (Level A)\nDescription: Information, structure, and relationships conveyed through presentation can be programmatically determined or are available in text.\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nWebAIM: Semantic Structure\nHeading Tags",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.1_test_rules",
    "type": "sc",
    "sc_id": "1.3.1",
    "section": "test_rules",
    "text": "[1.3.1 Info and Relationships] (Level A)\nDescription: Information, structure, and relationships conveyed through presentation can be programmatically determined or are available in text.\n\nSection: test_rules\n\nTest Rules\nThe following are Test Rules\n    for certain aspects of this Success Criterion.\n    It is not necessary to use these particular Test Rules to check for conformance with WCAG, but they are defined and approved test methods.\n    For information on using Test Rules, see\nUnderstanding Test Rules for WCAG Success Criteria\n.\nARIA attribute is defined in WAI-ARIA\nARIA state or property has valid value\nForm field has non-empty accessible name\nHeaders attribute specified on a cell refers to cells in the same table element\nRole attribute has valid value\nARIA required context role\nARIA required ID references exist\nARIA required owned elements\nARIA state or property is permitted\nElement with role attribute has required states and properties\nTable header cell has assigned cells",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.1_key_terms",
    "type": "sc",
    "sc_id": "1.3.1",
    "section": "key_terms",
    "text": "[1.3.1 Info and Relationships] (Level A)\nDescription: Information, structure, and relationships conveyed through presentation can be programmatically determined or are available in text.\n\nSection: key_terms\n\nKey Terms\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\ncontent\ninformation and sensory experience to be communicated to the user by means of a\nuser agent\n, including code or markup that defines the content's\nstructure\n,\npresentation\n, and interactions\npresentation\nrendering of the\ncontent\nin a form to be perceived by users\nprogrammatically determined\ndetermined by software from author-supplied data provided in a way that different\nuser agents\n, including\nassistive technologies\n, can extract and present this information to users in different modalities\nExample 1\nDetermined in a markup language from elements and attributes that are accessed directly\n      by commonly available assistive technology.\nExample 2\nDetermined from technology-specific data structures in a non-markup language and exposed\n      to assistive technology via an accessibility API that is supported by commonly available\n      assistive technology.\nrelationships\nmeaningful associations between distinct pieces of content\nstructure\nThe way the parts of a\nweb page\nare organized in relation to each other; and\nThe way a collection of\nweb pages\nis organized\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.\nweb page\na non-embedded resource obtained from a single URI using HTTP plus any other resources\n      that are used in the rendering or intended to be rendered together with it by a\nuser agent\nNote 1\nAlthough any \"other resources\" would be rendered together with the primary resource,\n      they would not necessarily be rendered simultaneously with each other.\nNote 2\nFor the purposes of conformance with these guidelines, a resource must be \"non-embedded\"\n      within the scope of conformance to be considered a web page.\nExample 1\nA web resource including all embedded images and media.\nExample 2\nA web mail program built using Asynchronous JavaScript and XML (AJAX). The program\n      lives entirely at http://example.com/mail, but includes an inbox, a contacts area\n      and a calendar. Links or buttons are provided that cause the inbox, contacts, or calendar\n      to display, but do not change the URI of the page as a whole.\nExample 3\nA customizable portal site, where users can choose content to display from a set of\n      different content modules.\nExample 4\nWhen you enter \"http://shopping.example.com/\" in your browser, you enter a movie-like\n      interactive shopping environment where you visually move around in a store dragging\n      products off of the shelves around you and into a visual shopping cart in front of\n      you. Clicking on a product causes it to be demonstrated with a specification sheet\n      floating alongside. This might be a single-page website or just one page within a\n      website.",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.1_situation_A",
    "type": "sc_situation",
    "sc_id": "1.3.1",
    "situation_id": "A",
    "techniques": [
      "ARIA11",
      "H101",
      "ARIA12",
      "ARIA13",
      "ARIA16",
      "ARIA17",
      "ARIA20",
      "G115",
      "G117",
      "G140",
      "ARIA24",
      "G138",
      "G138",
      "H51",
      "PDF6",
      "PDF20",
      "H39",
      "H63",
      "H43",
      "H44",
      "H65",
      "PDF10",
      "PDF12",
      "H71",
      "H85",
      "H48",
      "H42",
      "PDF9",
      "PDF11",
      "PDF17",
      "PDF21",
      "H97"
    ],
    "text": "[1.3.1 Info and Relationships] (Level A)\nDescription: Information, structure, and relationships conveyed through presentation can be programmatically determined or are available in text.\n\nSituation A: The technology provides semantic structure to make information and relationships conveyed through presentation programmatically determinable:\n\nRelated techniques: ARIA11, H101, ARIA12, ARIA13, ARIA16, ARIA17, ARIA20, G115, G117, G140, ARIA24, G138, G138, H51, PDF6, PDF20, H39, H63, H43, H44, H65, PDF10, PDF12, H71, H85, H48, H42, PDF9, PDF11, PDF17, PDF21, H97",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.1_situation_B",
    "type": "sc_situation",
    "sc_id": "1.3.1",
    "situation_id": "B",
    "techniques": [
      "G117",
      "T1",
      "T1",
      "T2",
      "T3"
    ],
    "text": "[1.3.1 Info and Relationships] (Level A)\nDescription: Information, structure, and relationships conveyed through presentation can be programmatically determined or are available in text.\n\nSituation B: The technology in use does NOT provide the semantic structure to make the information and relationships conveyed through presentation programmatically determinable:\n\nRelated techniques: G117, T1, T1, T2, T3",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.1_advisory",
    "type": "sc_advisory",
    "sc_id": "1.3.1",
    "techniques": [
      "C22",
      "G162",
      "ARIA1",
      "ARIA2",
      "G141"
    ],
    "text": "[1.3.1 Info and Relationships] (Level A)\nDescription: Information, structure, and relationships conveyed through presentation can be programmatically determined or are available in text.\n\nAdvisory techniques for SC 1.3.1: C22, G162, ARIA1, ARIA2, G141",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.1_failures",
    "type": "sc_failures",
    "sc_id": "1.3.1",
    "techniques": [
      "F2",
      "F33",
      "F34",
      "F42",
      "F43",
      "F46",
      "F48",
      "F90",
      "F91",
      "F92",
      "F111"
    ],
    "text": "[1.3.1 Info and Relationships] (Level A)\nDescription: Information, structure, and relationships conveyed through presentation can be programmatically determined or are available in text.\n\nCommon failures for SC 1.3.1: F2, F33, F34, F42, F43, F46, F48, F90, F91, F92, F111",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.2_intent",
    "type": "sc",
    "sc_id": "1.3.2",
    "section": "intent",
    "text": "[1.3.2 Meaningful Sequence] (Level A)\nDescription: When the sequence in which content is presented affects its meaning, a correct reading sequence can be programmatically determined.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to enable a user agent to provide an alternative\n         presentation of content while preserving the reading order needed to understand the\n         meaning. It is important that it be possible to programmatically determine at least\n         one sequence of the content that makes sense. Content that does not meet this Success\n         Criterion may confuse or disorient users when assistive technology reads the content\n         in the wrong order, or when alternate style sheets or other formatting changes are\n         applied.\nA sequence is\nmeaningful\nif the order of content in the sequence cannot be changed without affecting its meaning.\n         \n         For example, if a page contains two independent articles, the relative order of the\n         articles may not affect their meaning, as long as they are not interleaved. In such\n         a situation, the articles themselves may have meaningful sequence, but the container\n         that contains the articles may not have a meaningful sequence.\nThe semantics of some elements define whether or not their content is a meaningful\n         sequence. For instance, in HTML, text is always a meaningful sequence. Tables and\n         ordered lists are meaningful sequences, but unordered lists are not.\nThe order of content in a sequence is not always meaningful. For example, the relative\n         order of the main section of a web page and a navigation section does not affect their\n         meaning. They could occur in either order in the programmatically determined reading\n         sequence. As another example, a magazine article contains several callout sidebars.\n         The order of the article and the sidebars does not affect their meaning. In these\n         cases there are a number of different reading orders for a web page that can satisfy\n         the success criterion.\nFor clarity:\nProviding a particular linear order is only required where it affects meaning.\nThere may be more than one order that is \"correct\" (according to the WCAG 2.0 definition).\nOnly one correct order needs to be provided.",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.2_success_criterion",
    "type": "sc",
    "sc_id": "1.3.2",
    "section": "success_criterion",
    "text": "[1.3.2 Meaningful Sequence] (Level A)\nDescription: When the sequence in which content is presented affects its meaning, a correct reading sequence can be programmatically determined.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nWhen the sequence in which content is presented affects its meaning, a\ncorrect reading sequence\ncan be\nprogrammatically determined\n.",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.2_benefits",
    "type": "sc",
    "sc_id": "1.3.2",
    "section": "benefits",
    "text": "[1.3.2 Meaningful Sequence] (Level A)\nDescription: When the sequence in which content is presented affects its meaning, a correct reading sequence can be programmatically determined.\n\nSection: benefits\n\nBenefits\nThis success criterion may help people who rely on assistive technologies that read\n            content aloud. The meaning evident in the sequencing of the information in the default\n            presentation will be the same when the content is presented in spoken form.",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.2_examples",
    "type": "sc",
    "sc_id": "1.3.2",
    "section": "examples",
    "text": "[1.3.2 Meaningful Sequence] (Level A)\nDescription: When the sequence in which content is presented affects its meaning, a correct reading sequence can be programmatically determined.\n\nSection: examples\n\nExamples\nExample 1:\nIn a multi-column document, the linear presentation of the content flows from the\n            top of a column to the bottom of the column, then to the top of the next column.\nExample 2:\nCSS is used to position a navigation bar, the main story on a page, and a side story.\n            The visual presentation of the sections does not match the programmatically determined\n            order, but the meaning of the page does not depend on the order of the sections.",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.2_brief",
    "type": "sc",
    "sc_id": "1.3.2",
    "section": "brief",
    "text": "[1.3.2 Meaningful Sequence] (Level A)\nDescription: When the sequence in which content is presented affects its meaning, a correct reading sequence can be programmatically determined.\n\nSection: brief\n\nIn Brief\nGoal\nThe order of content can be understood by more people.\nWhat to do\nUse code to preserve meaningful content order.\nWhy it's important\nAssistive technology can present content to users in the proper order.",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.2_key_terms",
    "type": "sc",
    "sc_id": "1.3.2",
    "section": "key_terms",
    "text": "[1.3.2 Meaningful Sequence] (Level A)\nDescription: When the sequence in which content is presented affects its meaning, a correct reading sequence can be programmatically determined.\n\nSection: key_terms\n\nKey Terms\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\ncorrect reading sequence\nany sequence where words and paragraphs are presented in an order that does not change\n      the meaning of the content\nprogrammatically determined\ndetermined by software from author-supplied data provided in a way that different\nuser agents\n, including\nassistive technologies\n, can extract and present this information to users in different modalities\nExample 1\nDetermined in a markup language from elements and attributes that are accessed directly\n      by commonly available assistive technology.\nExample 2\nDetermined from technology-specific data structures in a non-markup language and exposed\n      to assistive technology via an accessibility API that is supported by commonly available\n      assistive technology.\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.2_sufficient",
    "type": "sc_sufficient",
    "sc_id": "1.3.2",
    "techniques": [
      "G57",
      "G57",
      "H34",
      "H56",
      "C6",
      "C8",
      "C27",
      "PDF3"
    ],
    "text": "[1.3.2 Meaningful Sequence] (Level A)\nDescription: When the sequence in which content is presented affects its meaning, a correct reading sequence can be programmatically determined.\n\nSufficient techniques for SC 1.3.2 (no situation): G57, G57, H34, H56, C6, C8, C27, PDF3",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.2_failures",
    "type": "sc_failures",
    "sc_id": "1.3.2",
    "techniques": [
      "F34",
      "F33",
      "F32",
      "F49",
      "F1"
    ],
    "text": "[1.3.2 Meaningful Sequence] (Level A)\nDescription: When the sequence in which content is presented affects its meaning, a correct reading sequence can be programmatically determined.\n\nCommon failures for SC 1.3.2: F34, F33, F32, F49, F1",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.3_intent",
    "type": "sc",
    "sc_id": "1.3.3",
    "section": "intent",
    "text": "[1.3.3 Sensory Characteristics] (Level A)\nDescription: Instructions provided for understanding and operating content do not rely solely on\n      sensory characteristics of components such as shape, color, size, visual location, orientation,\n      or sound.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to ensure that all users can access instructions\n         for using the content, even when they cannot perceive shape or size or use information\n         about spatial location or orientation. \n         Some content relies on knowledge of the shape or position of objects that are not\n         available from the structure of the content (for example, \"round button\" or \"button\n         to the right\"). \n         Some users with disabilities are not able to perceive shape or position due to the\n         nature of the assistive technologies they use. \n         This success criterion requires that additional information be provided to clarify\n         instructions that are dependent on this kind of information.\nProviding information using shape and/or location, however, is an effective method\n         for many users including those with cognitive limitations.\n         This provision should not discourage those types of cues as long as the information\n         is also provided in other ways.\nIn some languages, it is commonly understood that \"above\" refers to the content previous\n         to that point in the content and \"below\" refers to the content after that point. In\n         such languages, if the content being referenced is in the appropriate place in the\n         reading order and the references are unambiguous, statements such as \"choose one of\n         the links below\" or \"all of the above\" would conform to this success criterion.\nWCAG was designed to apply only to controls that were displayed on a web page. The\n         intent was to avoid describing controls solely via references to visual or auditory\n         cues. When applying this to instructions for operating physical hardware controls\n         (e.g. a web kiosk with dedicated content), tactile cues on the hardware might be described\n         (e.g. the arrow shaped key, the round key on the right side). This success criterion\n         is not intended to prevent the use of tactile cues in instructions.",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.3_success_criterion",
    "type": "sc",
    "sc_id": "1.3.3",
    "section": "success_criterion",
    "text": "[1.3.3 Sensory Characteristics] (Level A)\nDescription: Instructions provided for understanding and operating content do not rely solely on\n      sensory characteristics of components such as shape, color, size, visual location, orientation,\n      or sound.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nInstructions provided for understanding and operating content do not rely solely on\n      sensory characteristics of components such as shape, color, size, visual location, orientation,\n      or sound.\nNote\nFor requirements related to color, refer to\nGuideline 1.4\n.",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.3_benefits",
    "type": "sc",
    "sc_id": "1.3.3",
    "section": "benefits",
    "text": "[1.3.3 Sensory Characteristics] (Level A)\nDescription: Instructions provided for understanding and operating content do not rely solely on\n      sensory characteristics of components such as shape, color, size, visual location, orientation,\n      or sound.\n\nSection: benefits\n\nBenefits\nPeople who are blind and people who have low vision may not be able to understand\n            instructions if they rely only on a description of the shape and/or location of content.\n            Providing additional information in any instructions other than shape and/or location\n            will allow users to understand the instructions even if they cannot perceive shape\n            and/or location.",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.3_examples",
    "type": "sc",
    "sc_id": "1.3.3",
    "section": "examples",
    "text": "[1.3.3 Sensory Characteristics] (Level A)\nDescription: Instructions provided for understanding and operating content do not rely solely on\n      sensory characteristics of components such as shape, color, size, visual location, orientation,\n      or sound.\n\nSection: examples\n\nExamples\nExample 1: Instructions for interpreting a schedule of competitive events references\n               colored icons in different shapes to indicate the venue for each event\nA table presents a list of times across the top row and a list of events in the first\n               vertical column and instructions are provided under the table: \"Events marked with a\n               blue diamond are played on field A and events marked with a green circle are played\n               on field B.\" The instructions rely on color and shape only and result in a failure of\n               this criterion.\nExample 2: An online multi-page survey\nAn online multi-page survey uses a link implemented as a green arrow icon placed\n               in the lower right hand corner of the content to move from one survey page to the\n               next. The arrow is clearly labeled with \"Next\" and the instructions state, \"To move\n               to the next section of the survey, select the green arrow icon labeled 'Next' in the\n               lower right corner below the last survey question.\" \n               The instruction uses positioning and color to help identify the icon; \n               the instruction does not rely on these sensory characteristics since it also refers to\n               the label, so it passes this criterion.",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.3_brief",
    "type": "sc",
    "sc_id": "1.3.3",
    "section": "brief",
    "text": "[1.3.3 Sensory Characteristics] (Level A)\nDescription: Instructions provided for understanding and operating content do not rely solely on\n      sensory characteristics of components such as shape, color, size, visual location, orientation,\n      or sound.\n\nSection: brief\n\nIn Brief\nGoal\nInstructions are understandable by more people.\nWhat to do\nDescribe controls by name, not just by appearance or location.\nWhy it's important\nPeople who are blind or have low vision need non-visual instructions.",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.3_test_rules",
    "type": "sc",
    "sc_id": "1.3.3",
    "section": "test_rules",
    "text": "[1.3.3 Sensory Characteristics] (Level A)\nDescription: Instructions provided for understanding and operating content do not rely solely on\n      sensory characteristics of components such as shape, color, size, visual location, orientation,\n      or sound.\n\nSection: test_rules\n\nTest Rules\nThe following are Test Rules\n    for certain aspects of this Success Criterion.\n    It is not necessary to use these particular Test Rules to check for conformance with WCAG, but they are defined and approved test methods.\n    For information on using Test Rules, see\nUnderstanding Test Rules for WCAG Success Criteria\n.\nContent has alternative for visual reference",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.3_sufficient",
    "type": "sc_sufficient",
    "sc_id": "1.3.3",
    "techniques": [
      "G96"
    ],
    "text": "[1.3.3 Sensory Characteristics] (Level A)\nDescription: Instructions provided for understanding and operating content do not rely solely on\n      sensory characteristics of components such as shape, color, size, visual location, orientation,\n      or sound.\n\nSufficient techniques for SC 1.3.3 (no situation): G96",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.3_failures",
    "type": "sc_failures",
    "sc_id": "1.3.3",
    "techniques": [
      "F14",
      "F26"
    ],
    "text": "[1.3.3 Sensory Characteristics] (Level A)\nDescription: Instructions provided for understanding and operating content do not rely solely on\n      sensory characteristics of components such as shape, color, size, visual location, orientation,\n      or sound.\n\nCommon failures for SC 1.3.3: F14, F26",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.4_intent",
    "type": "sc",
    "sc_id": "1.3.4",
    "section": "intent",
    "text": "[1.3.4 Orientation] (Level AA)\nDescription: Content does not restrict its view and operation to a single display orientation, such as portrait or landscape, unless a specific display orientation is essential.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to ensure that content displays in the orientation (portrait or landscape) preferred by the user. Some websites and applications automatically set and restrict the screen to a particular display orientation and expect\n\t\t\tthat users will respond by rotating their device to match, but this can create problems. Some users have their devices mounted\n\t\t\tin a fixed orientation (e.g. on the arm of a power wheelchair). Therefore, websites and applications need to support both orientations\n\t\t\tby not restricting the orientation. Changes in content or functionality due to the size of display are not covered by this criterion which is focused on restrictions of orientation.\nHistorically, devices tended to have a fixed-orientation display, and all content was created to match that display orientation. Today, most handhelds and many other devices (e.g., monitors) have a hardware-level ability to dynamically adjust default display orientation based on sensor information. The goal of this success criterion is that authors should never restrict content's orientation, thus ensuring that it always match the device display orientation.\nLocking a device to an orientation\nIt is important to distinguish between an author's responsibility not to restrict content to a specific orientation, and device-specific settings governing the locking of display orientation.\nMany hand-held devices offer a mechanical switch or a system setting (or both) to allow the user to lock the device display to a specific orientation. Where a user decides to lock their entire device to an orientation, all applications are expected to pick up that setting and to display content accordingly.\nThis success criterion complements device \"lock orientation\" settings. A web page that does not restrict its display orientation will always support the system-level orientation setting, since the system setting is picked up by the user agent. Alternatively, where a device-level orientation lock is not in place, the user agent should display the page according to the orientation of the device (either its default, or the current orientation determined by any device sensors).\nThe exception for things considered essential is aimed at situations where the content would only be understood in a particular orientation, or where the technology restricts the possible orientations. If content is aimed at a specific environment which is only available in one orientation (such as a television) then the content can restrict the orientation. Technologies such as virtual reality use screens within goggles that cannot change orientation relative to the user's eyes.",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.4_success_criterion",
    "type": "sc",
    "sc_id": "1.3.4",
    "section": "success_criterion",
    "text": "[1.3.4 Orientation] (Level AA)\nDescription: Content does not restrict its view and operation to a single display orientation, such as portrait or landscape, unless a specific display orientation is essential.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nContent does not restrict its view and operation to a single display orientation, such as portrait or landscape, unless a specific display orientation is\nessential\n.\nNote\nExamples where a particular display orientation may be essential are a bank check, a piano application, slides for a projector or television, or virtual reality content where content is not necessarily restricted to landscape or portrait display orientation.",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.4_benefits",
    "type": "sc",
    "sc_id": "1.3.4",
    "section": "benefits",
    "text": "[1.3.4 Orientation] (Level AA)\nDescription: Content does not restrict its view and operation to a single display orientation, such as portrait or landscape, unless a specific display orientation is essential.\n\nSection: benefits\n\nBenefits\nUsers with dexterity impairments, who have a mounted device will be able to use the content in their fixed orientation.\nUsers with low-vision will be able to view content in the orientation that works best for them, for example to increase the text size by viewing content in landscape.",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.4_examples",
    "type": "sc",
    "sc_id": "1.3.4",
    "section": "examples",
    "text": "[1.3.4 Orientation] (Level AA)\nDescription: Content does not restrict its view and operation to a single display orientation, such as portrait or landscape, unless a specific display orientation is essential.\n\nSection: examples\n\nExamples\nExample 1: Online video site\nA video is shown in either portrait or in landscape based on the user's chosen orientation.\nExample 2: Messaging website\nA messaging website can display messages in both portrait and landscape orientations.\nExample 3: eReader web app\nAn eReader web app can display the contents of a book in both portrait and landscape orientation.\nExample 4: Check deposit in banking app\nAn example where orientation is essential could be a banking app that requires the device be in landscape mode to easily and accurately capture an image of a check for deposit. These paper forms are typically about twice as wide as they are high.\nExample 5: Piano app\nAn example where orientation is essential could be a piano app that requires the device to be in landscape mode to allow room for enough of the piano keys to be functionally usable. Since a piano app is emulating a physical piano keyboard that needs to retain relative physical characteristics between keys, either too few keys would be available, or the keys would be much too narrow.",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.4_brief",
    "type": "sc",
    "sc_id": "1.3.4",
    "section": "brief",
    "text": "[1.3.4 Orientation] (Level AA)\nDescription: Content does not restrict its view and operation to a single display orientation, such as portrait or landscape, unless a specific display orientation is essential.\n\nSection: brief\n\nIn Brief\nGoal\nDevices can be used in any orientation.\nWhat to do\nDon't lock content to either portrait or landscape presentation.\nWhy it's important\nWheelchair users and others may have devices mounted in a fixed orientation.",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.4_resources",
    "type": "sc",
    "sc_id": "1.3.4",
    "section": "resources",
    "text": "[1.3.4 Orientation] (Level AA)\nDescription: Content does not restrict its view and operation to a single display orientation, such as portrait or landscape, unless a specific display orientation is essential.\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nManaging Screen Orientation\nUsing Media Queries\nMedia Queries for Standard Devices\nOrientation Lock\nResponsive Design for Landscape Orientation\nThe Orientation Descriptor\nThe Screen Orientation API",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.4_test_rules",
    "type": "sc",
    "sc_id": "1.3.4",
    "section": "test_rules",
    "text": "[1.3.4 Orientation] (Level AA)\nDescription: Content does not restrict its view and operation to a single display orientation, such as portrait or landscape, unless a specific display orientation is essential.\n\nSection: test_rules\n\nTest Rules\nThe following are Test Rules\n    for certain aspects of this Success Criterion.\n    It is not necessary to use these particular Test Rules to check for conformance with WCAG, but they are defined and approved test methods.\n    For information on using Test Rules, see\nUnderstanding Test Rules for WCAG Success Criteria\n.\nOrientation of the page is not restricted using CSS transforms",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.4_key_terms",
    "type": "sc",
    "sc_id": "1.3.4",
    "section": "key_terms",
    "text": "[1.3.4 Orientation] (Level AA)\nDescription: Content does not restrict its view and operation to a single display orientation, such as portrait or landscape, unless a specific display orientation is essential.\n\nSection: key_terms\n\nKey Terms\nessential\nif removed, would fundamentally change the information or functionality of the content,\nand\ninformation and functionality cannot be achieved in another way that would conform",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.4_sufficient",
    "type": "sc_sufficient",
    "sc_id": "1.3.4",
    "techniques": [
      "G214"
    ],
    "text": "[1.3.4 Orientation] (Level AA)\nDescription: Content does not restrict its view and operation to a single display orientation, such as portrait or landscape, unless a specific display orientation is essential.\n\nSufficient techniques for SC 1.3.4 (no situation): G214",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.4_failures",
    "type": "sc_failures",
    "sc_id": "1.3.4",
    "techniques": [
      "F97",
      "F100"
    ],
    "text": "[1.3.4 Orientation] (Level AA)\nDescription: Content does not restrict its view and operation to a single display orientation, such as portrait or landscape, unless a specific display orientation is essential.\n\nCommon failures for SC 1.3.4: F97, F100",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.5_intent",
    "type": "sc",
    "sc_id": "1.3.5",
    "section": "intent",
    "text": "[1.3.5 Identify Input Purpose] (Level AA)\nDescription: The purpose of each input field collecting information about the user can be programmatically determined when:\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to ensure that the purpose of a form input collecting information about the user can be programmatically determined, so that user agents can extract and present this purpose to users using different modalities. The ability to programmatically declare the specific kind of data expected in a particular field makes filling out forms easier, especially for people with certain cognitive disabilities.\nAppropriate visible labels and instruction can help users understand the purpose of form input fields, but users may benefit from having fields that collect specific types of information be rendered in an unambiguous, consistent, and possibly customized way for different modalities - either through defaults in their user agent, or through the aid of assistive technologies.\nFor some input fields, the\ntype\nattribute already offers a way to broadly specify the intention of the input field, for example,\n<input type=\"tel\">\n,\n<input type=\"email\">\n, or\n<input type=\"password\">\n. However, these are only very broad categories, describing the type of input, but not necessarily its purpose, especially as it relates to user-specific input fields. As an example,\ntype=\"email\"\nindicates that the field is for an e-mail address but does not clarify if the purpose is for entering the user's e-mail address or some other person's e-mail.\nThis success criterion defines the types of user interface component input purposes, found in\nSection 7 of the WCAG 2.1 Recommendation\n, that must be programmatically identifiable. When these user input purposes are present, and if the technology supports doing so, the field purpose must be programmatically identifiable.\nThe HTML\nautocomplete\nattribute only accepts a certain number of specific well-defined fixed values. This allows a more fine-grained definition or identification of purpose than the type attribute, for example, by allowing the author to specify a specific type of name: Name (\nautocomplete=\"name\"\n), Given Name (\nautocomplete=\"given-name\"\n), Family Name (\nautocomplete=\"family-name\"\n), as well as Username (\nautocomplete=\"username\"\n), and Nickname (\nautocomplete=\"nickname\"\n).\nBy adopting and repurposing this predefined taxonomy of definitions, user agents and assistive technologies can now present the purpose of the inputs to users in different modalities. For example, assistive technologies may display familiar icons next to input fields to help users who have difficulties reading. An icon of a birthday cake may be shown in front of an input field with\nautocomplete=\"bday\"\n, or the icon of a telephone in front of an input field with\nautocomplete=\"tel\"\n.\nIn addition to repurposing this taxonomy, when the autocomplete attribute technique is used to meet this Success Criterion, browsers and other user-agents can suggest and 'autofill' the right content by autocompleting these fields based on past user input stored in the browser. By defining more granular definitions of common input purposes, for example “Birthday” (\nautocomplete=\"bday\"\n), browsers can store personalized values for each of these fields (the user's birthday date). The user is relieved of having to type the information and can instead confirm or, if needed, change the value of the field, a significant benefit for users with memory issues, dyslexia, and other disabilities. Because the\nautocomplete\nvalues are independent of language, users that may not be familiar with the text used to visually identify user input fields (the label) can still have that purpose consistently identified to them due to the fixed taxonomy of terms.\nIf an input field accepts two different types of input purpose (as in combined user name/user email fields) and the technology used does not allow multiple purpose values to be defined, it is valid to provide either one or the other value or leave out the designation of input purpose altogether.\nWhen the user agent and assistive technology support for other metadata formats matures, metadata schemes like the\nWAI-Adapt: Symbols Module\nmay be used in addition or instead of the HTML autocomplete attribute to identify the purpose of input fields. They can also support automated adaptations that identify and match author-provided input labels to defined vocabularies or symbols that are used instead for labelling inputs.",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.5_success_criterion",
    "type": "sc",
    "sc_id": "1.3.5",
    "section": "success_criterion",
    "text": "[1.3.5 Identify Input Purpose] (Level AA)\nDescription: The purpose of each input field collecting information about the user can be programmatically determined when:\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nThe purpose of each input field collecting information about the user can be\nprogrammatically determined\nwhen:\nThe input field serves a purpose identified in the\nInput Purposes for user interface components section\n; and\nThe content is implemented using technologies with support for identifying the expected meaning for form input data.",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.5_benefits",
    "type": "sc",
    "sc_id": "1.3.5",
    "section": "benefits",
    "text": "[1.3.5 Identify Input Purpose] (Level AA)\nDescription: The purpose of each input field collecting information about the user can be programmatically determined when:\n\nSection: benefits\n\nBenefits\nPeople with language and memory related disabilities or disabilities that affects executive function and decision-making benefit from the browser auto-filling personal information (such as name or address) when the autocomplete attribute is used to meet this Success Criterion, which means information does not need to be remembered by the user.\nPeople with cerebral palsy, stroke, head injury, motor neuron disease or learning disability sometimes prefer images for communication. They can employ assistive technology which adds icons to input fields to communicate the purpose of the fields visually.\nPeople with motor impairments also benefit from reducing the need for manual input when filling out forms.",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.5_examples",
    "type": "sc",
    "sc_id": "1.3.5",
    "section": "examples",
    "text": "[1.3.5 Identify Input Purpose] (Level AA)\nDescription: The purpose of each input field collecting information about the user can be programmatically determined when:\n\nSection: examples\n\nExamples\nA contact form using autofill\nA contact form auto-fills in the fields for name, street, post code, city, telephone number and email address from autofill values stored in the user's browser. Assistive technology can offer a customized way of identifying particular input fields, for example drawing on a set of symbols / icons that is familiar to the user, to communicate the purpose of the fields visually.\nAn order form with separate billing and shipping address\nA product order form fills in the address fields for billing address and a separate set of address fields for the shipping address, using the autofill detail tokens 'billing' and 'shipping'\nA contact form using icons\nA browser plugin to add icons inserts icons representing the person's name, home address, telephone number and email address to  identify the input purpose visually.",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.5_brief",
    "type": "sc",
    "sc_id": "1.3.5",
    "section": "brief",
    "text": "[1.3.5 Identify Input Purpose] (Level AA)\nDescription: The purpose of each input field collecting information about the user can be programmatically determined when:\n\nSection: brief\n\nIn Brief\nGoal\nIt is easier to fill out forms.\nWhat to do\nUse code to indicate the purpose of common inputs, where technology allows.\nWhy it's important\nSome people with cognitive disabilities may not understand the input's purpose from the label alone.",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.5_resources",
    "type": "sc",
    "sc_id": "1.3.5",
    "section": "resources",
    "text": "[1.3.5 Identify Input Purpose] (Level AA)\nDescription: The purpose of each input field collecting information about the user can be programmatically determined when:\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nCOGA Gap Analysis Table 3: Entering Data, Error Prevention, & Recovery",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.5_test_rules",
    "type": "sc",
    "sc_id": "1.3.5",
    "section": "test_rules",
    "text": "[1.3.5 Identify Input Purpose] (Level AA)\nDescription: The purpose of each input field collecting information about the user can be programmatically determined when:\n\nSection: test_rules\n\nTest Rules\nThe following are Test Rules\n    for certain aspects of this Success Criterion.\n    It is not necessary to use these particular Test Rules to check for conformance with WCAG, but they are defined and approved test methods.\n    For information on using Test Rules, see\nUnderstanding Test Rules for WCAG Success Criteria\n.\nAutocomplete attribute has valid value",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.5_key_terms",
    "type": "sc",
    "sc_id": "1.3.5",
    "section": "key_terms",
    "text": "[1.3.5 Identify Input Purpose] (Level AA)\nDescription: The purpose of each input field collecting information about the user can be programmatically determined when:\n\nSection: key_terms\n\nKey Terms\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\nprogrammatically determined\ndetermined by software from author-supplied data provided in a way that different\nuser agents\n, including\nassistive technologies\n, can extract and present this information to users in different modalities\nExample 1\nDetermined in a markup language from elements and attributes that are accessed directly\n      by commonly available assistive technology.\nExample 2\nDetermined from technology-specific data structures in a non-markup language and exposed\n      to assistive technology via an accessibility API that is supported by commonly available\n      assistive technology.\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.5_sufficient",
    "type": "sc_sufficient",
    "sc_id": "1.3.5",
    "techniques": [
      "H98"
    ],
    "text": "[1.3.5 Identify Input Purpose] (Level AA)\nDescription: The purpose of each input field collecting information about the user can be programmatically determined when:\n\nSufficient techniques for SC 1.3.5 (no situation): H98",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.5_failures",
    "type": "sc_failures",
    "sc_id": "1.3.5",
    "techniques": [
      "F107"
    ],
    "text": "[1.3.5 Identify Input Purpose] (Level AA)\nDescription: The purpose of each input field collecting information about the user can be programmatically determined when:\n\nCommon failures for SC 1.3.5: F107",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.6_intent",
    "type": "sc",
    "sc_id": "1.3.6",
    "section": "intent",
    "text": "[1.3.6 Identify Purpose] (Level AAA)\nDescription: In content implemented using markup languages, the purpose of user interface components, icons, and regions can be programmatically determined.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to ensure that the purpose of many elements on a page can be programmatically determined, so that user agents can extract and present that purpose to users using different modalities.\nMany users with limited vocabularies rely on familiar terms or symbols in order to use the web. However, what is familiar to one user may not be familiar to another. When authors indicate the purpose, users can take advantage of personalization and user preferences to load a set of symbols or vocabulary familiar to them.\nThis success criterion requires the author to programmatically associate the purpose of icons, regions and components (such as buttons, links, and fields) so that user agents can determine the purpose of each and adapt indicators or terminology to make them understandable for the user. It is achieved by adding semantics or metadata that provide this context. It is similar to adding role information (as required by 4.1.2) but instead of providing information about what the UI component is (such as an image) it provides information about what the component represents (such as a link to the home page).\nIdentifying regions of the page allows people to remove or highlight regions with their user agent.\nProducts for people who are non-vocal often use symbols to help users communicate. These symbols are in fact people's language. Unfortunately, many of these symbols are both subject to copyright and not interoperable. That means end users can only use one device, and cannot use content, apps, or assistive technologies that have not been made by a single company.\nThis Success Criterion enables symbols to be interoperable so that symbol users can understand different content that was not just made by one company.  When users' symbols are mapped to the same nodes, then user agents can load the user-understandable symbol. People can then buy the symbols and use them across different devices or applications. (Note that the symbols would still be proprietary, but they could then be interoperable.)",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.6_success_criterion",
    "type": "sc",
    "sc_id": "1.3.6",
    "section": "success_criterion",
    "text": "[1.3.6 Identify Purpose] (Level AAA)\nDescription: In content implemented using markup languages, the purpose of user interface components, icons, and regions can be programmatically determined.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nIn content implemented using markup languages, the purpose of\nuser interface components\n, icons, and\nregions\ncan be\nprogrammatically determined\n.",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.6_benefits",
    "type": "sc",
    "sc_id": "1.3.6",
    "section": "benefits",
    "text": "[1.3.6 Identify Purpose] (Level AAA)\nDescription: In content implemented using markup languages, the purpose of user interface components, icons, and regions can be programmatically determined.\n\nSection: benefits\n\nBenefits\nPeople who benefit have many different cognitive disabilities including:\nMemory\nFocus and attention\nLanguage-related\nExecutive function and decision making.\nMeeting this success criterion helps users who need extra support or a familiar interface, including the need for:\nSymbols and graphics with which users are familiar\nFewer features and less cognitive overload\nKeyboard shortcuts",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.6_examples",
    "type": "sc",
    "sc_id": "1.3.6",
    "section": "examples",
    "text": "[1.3.6 Identify Purpose] (Level AAA)\nDescription: In content implemented using markup languages, the purpose of user interface components, icons, and regions can be programmatically determined.\n\nSection: examples\n\nExamples\nA website uses\nARIA landmarks\nto identify the regions of the page, and users can hide areas that do not have a role of\nmain\n.\nThe links in the navigation of a website are marked up so that users can add their own icons.\nIcons on a website are marked up so that users can substitute their own icon sets into the page.",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.6_brief",
    "type": "sc",
    "sc_id": "1.3.6",
    "section": "brief",
    "text": "[1.3.6 Identify Purpose] (Level AAA)\nDescription: In content implemented using markup languages, the purpose of user interface components, icons, and regions can be programmatically determined.\n\nSection: brief\n\nIn Brief\nGoal\nIt is easier to operate and navigate content.\nWhat to do\nUse code to indicate the meaning of all controls and other key information, where available.\nWhy it's important\nSome people with cognitive disabilities may not understand a control's purpose from the name alone.",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.6_resources",
    "type": "sc",
    "sc_id": "1.3.6",
    "section": "resources",
    "text": "[1.3.6 Identify Purpose] (Level AAA)\nDescription: In content implemented using markup languages, the purpose of user interface components, icons, and regions can be programmatically determined.\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nMaking Content Usable for People with Cognitive and Learning Disabilities\nAn\nWAI-Adapt Overview, enabling users to adapt content presentation\nPersonalization and User Preferences\nThe coga.personalisation project",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.6_key_terms",
    "type": "sc",
    "sc_id": "1.3.6",
    "section": "key_terms",
    "text": "[1.3.6 Identify Purpose] (Level AAA)\nDescription: In content implemented using markup languages, the purpose of user interface components, icons, and regions can be programmatically determined.\n\nSection: key_terms\n\nKey Terms\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\nprogrammatically determined\ndetermined by software from author-supplied data provided in a way that different\nuser agents\n, including\nassistive technologies\n, can extract and present this information to users in different modalities\nExample 1\nDetermined in a markup language from elements and attributes that are accessed directly\n      by commonly available assistive technology.\nExample 2\nDetermined from technology-specific data structures in a non-markup language and exposed\n      to assistive technology via an accessibility API that is supported by commonly available\n      assistive technology.\nregion\nperceivable,\nprogrammatically determined\nsection\nof content\nNote\nIn HTML, any area designated with a landmark role would be a region.\nsection\na self-contained portion of written content that deals with one or more related topics\n      or thoughts\nNote\nA section may consist of one or more paragraphs and include graphics, tables, lists\n      and sub-sections.\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.\nuser interface component\na part of the content that is perceived by users as a single control for a distinct\n      function\nNote 1\nMultiple user interface components may be implemented as a single programmatic element.\n      \"Components\" here is not tied to programming techniques, but rather to what the user\n      perceives as separate controls.\nNote 2\nUser interface components include form elements and links as well as components generated\n      by scripts.\nNote 3\nWhat is meant by \"component\" or \"user interface component\" here is also sometimes\n      called \"user interface element\".\nExample\nAn applet has a \"control\" that can be used to move through content by line or page\n      or random access. Since each of these would need to have a name and be settable independently,\n      they would each be a \"user interface component.\"",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.3.6_sufficient",
    "type": "sc_sufficient",
    "sc_id": "1.3.6",
    "techniques": [
      "ARIA11",
      "ARIA11"
    ],
    "text": "[1.3.6 Identify Purpose] (Level AAA)\nDescription: In content implemented using markup languages, the purpose of user interface components, icons, and regions can be programmatically determined.\n\nSufficient techniques for SC 1.3.6 (no situation): ARIA11, ARIA11",
    "principle": "Perceivable",
    "guideline": "1.3 Adaptable"
  },
  {
    "id": "1.4.1_intent",
    "type": "sc",
    "sc_id": "1.4.1",
    "section": "intent",
    "text": "[1.4.1 Use of Color] (Level A)\nDescription: Color is not used as the only visual means of conveying information, indicating an\n      action, prompting a response, or distinguishing a visual element.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to ensure that all sighted users can access information\n         that is conveyed by color differences, that is, by the use of color where each color\n         has a meaning assigned to it. If the information is conveyed through color differences\n         in an image (or other non-text format), the color may not be seen by users with color\n         deficiencies. In this case, providing the information conveyed with color through\n         another visual means ensures users who cannot see color can still perceive the information.\nColor is an important asset in the design of web content, enhancing its aesthetic appeal,\n         its usability, and its accessibility. However, some users have difficulty perceiving\n         color. People with partial sight often experience limited color vision, and many older\n         users do not see color well. In addition, people using limited-color or\n         monochrome displays and browsers will be unable to access information that is presented\n         only in color.\nExamples of information conveyed by color differences: “required fields are red\",\n         “error is shown in red\", and “Mary's sales are in red, Tom's are in blue\". Examples\n         of indications of an action include: using color to indicate that a link will open\n         in a new window or that a database entry has been updated successfully. An example\n         of prompting a response would be: using highlighting on form fields to indicate that\n         a required field had been left blank.\nNote\nThis should not in any way discourage the use of color on a page, or even color coding if it is complemented by other visual indication.\nNote\nIf content is conveyed through the use of colors that differ not only in their hue,\n            but that also have a significant difference in lightness, then this counts as an additional\n            visual distinction, as long as the difference in relative luminance between the colors leads\n            to a contrast ratio of 3:1 or greater.\n            For example, a light green and a dark red differ\nboth\nby color (hue)\nand\nby lightness, so they would pass if the contrast ratio is at least 3:1.\n            Similarly, if content is distinguished by inverting an element's foreground and background colors,\n            this would pass (again, assuming that the foreground and background colors have a sufficient contrast).\nHowever, if content relies on the user's ability to accurately perceive or differentiate a particular color\n            an additional visual indicator will be required regardless of the contrast ratio between those colors. For example, \n           knowing whether an outline is green for valid or red for invalid.\nNote\nThis criterion does not apply to situations where color has\nnot\nbeen used to convey information, indicate an action,\n         prompt a response or distinguish a visual element. For instance, a hyperlink which has been styled to appear no different than neighboring \n         static text would not fail this success criterion, as there would be no color differentiation between the actionable hyperlink text \n         and the adjacent static text. Such lack of styling differentiation could result in poor usability for anyone looking at the interface, regardless of disability.\nNote\nThis criterion does not directly address the needs of users with assistive technologies.\n            It aims to ensure that sighted users who cannot distinguish between some colors can still\n            understand content.\n            How information is conveyed to assistive technology users is covered separately in other\n            criteria, including (but not limited to)\n1.1.1 Non-text Content\n,\n1.3.1 Info and Relationships\n, and\n4.1.2 Name, Role, Value\n.\nConversely, even if information that is conveyed by color differences is appropriately conveyed\n            to assistive technologies, it does not necessarily pass this criterion, as sighted users who cannot\n            distinguish between certain color may not necessarily be using any assistive technologies. This\n            criterion requires a visible alternative to color.\nNote\nMost user agents provide users with a color-only cue that a link has been previously activated by them (\"visited\"). However, several technical constraints result in authors having very limited control over these color-only indications of visited links.  The technical constraints are as follows:\nUser agents constrain the exposure of a link's visited state due to\nprivacy concerns\n. Author queries to user agents will indicate all links have not been visited.\nAny available information on the visited state of a link would be inaccurate since it is both user and browser-dependent. Even if an author could accurately get information on previously activated links by a certain user, the author would be constrained to the current browser's preserved history, and would be unable to determine if the user had visited the page using a different browser (or if the history was not preserved, either from cache clearing or use of private sessions).\nAuthors can\nonly\nuse color to modify the\n:visited\nCSS pseudoclass style. The technology constrains any non-color styling. Due to palette limitations, an author cannot use color alone to achieve 3:1 contrast between link and non-link text as well as between visited and unvisited links while also achieving 4.5:1 contrast for all link and non-link text.\nAuthors also cannot set the visited state of links. The anchor element does not include a \"visited\" attribute; therefore the author has no ability to alter the state through an attribute setting. As such, authors cannot achieve\n1.3.1 Info and Relationships\nor\n4.1.2 Name, Role, Value\nin regard to visited links.\nFor these reasons, setting or conveying a link's visited status is not an author responsibility. Where color alone distinguishes between visited and unvisited links, it does not result in a failure of this Success Criterion, even where the contrast between the two link colors is below 3:1. Note that authors must continue to ensure that all text links meet contrast minimums against the page background (SC 1.4.3).",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.1_success_criterion",
    "type": "sc",
    "sc_id": "1.4.1",
    "section": "success_criterion",
    "text": "[1.4.1 Use of Color] (Level A)\nDescription: Color is not used as the only visual means of conveying information, indicating an\n      action, prompting a response, or distinguishing a visual element.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nColor is not used as the only visual means of conveying information, indicating an\n      action, prompting a response, or distinguishing a visual element.\nNote\nThis success criterion addresses color perception specifically. Other forms of perception are covered in\nGuideline 1.3\nincluding programmatic access to color and other visual presentation coding.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.1_benefits",
    "type": "sc",
    "sc_id": "1.4.1",
    "section": "benefits",
    "text": "[1.4.1 Use of Color] (Level A)\nDescription: Color is not used as the only visual means of conveying information, indicating an\n      action, prompting a response, or distinguishing a visual element.\n\nSection: benefits\n\nBenefits\nUsers with partial sight often experience limited color vision.\nSome older users may not be able to see color well.\nUsers who cannot distinguish between certain colors (often called “color blindness”)\n            benefit when information conveyed by color is available in other visual ways.\nPeople using limited color monochrome displays may be unable to access\n            color-dependent information.\nUsers who have problems distinguishing between colors can look or listen for text\n            cues.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.1_examples",
    "type": "sc",
    "sc_id": "1.4.1",
    "section": "examples",
    "text": "[1.4.1 Use of Color] (Level A)\nDescription: Color is not used as the only visual means of conveying information, indicating an\n      action, prompting a response, or distinguishing a visual element.\n\nSection: examples\n\nExamples\nA form that uses color and text to indicate required fields\nA form contains both required and optional fields. Instructions at the top of the\n               form explain that required fields are labeled with red text and also with an icon.\n               Users who cannot perceive the difference between the optional field labels and the\n               red labels for the required fields will still be able to see the icon next to the\n               red labels.\nAn examination\nStudents view an SVG image of a chemical compound and identify the chemical elements\n               present based\nboth\non the colors used, as well as numbers next to each\n               element. A legend shows the color and number for each type of element. Sighted users who\n               cannot perceive all the color differences can still understand the image by relying on\n               the numbers.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.1_brief",
    "type": "sc",
    "sc_id": "1.4.1",
    "section": "brief",
    "text": "[1.4.1 Use of Color] (Level A)\nDescription: Color is not used as the only visual means of conveying information, indicating an\n      action, prompting a response, or distinguishing a visual element.\n\nSection: brief\n\nIn Brief\nGoal\nColor is not the only way of distinguishing information.\nWhat to do\nUse information in addition to color, such as shape or text, to convey meaning.\nWhy it's important\nNot everyone sees colors or sees them the same way.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.1_resources",
    "type": "sc",
    "sc_id": "1.4.1",
    "section": "resources",
    "text": "[1.4.1 Use of Color] (Level A)\nDescription: Color is not used as the only visual means of conveying information, indicating an\n      action, prompting a response, or distinguishing a visual element.\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nVischeck\nAWARE Color Laboratory\nWikipedia: Color Blindness\nMicrosoft: Verify that a page is usable by people with color blindness\nCauses of Color: How do people inherit colorblindness? How often?: Genetics\nHow to make figures and presentations that are friendly to Colorblind people\nThe Color Tutor application",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.1_situation_A",
    "type": "sc_situation",
    "sc_id": "1.4.1",
    "situation_id": "A",
    "techniques": [
      "G14",
      "G205",
      "G182",
      "G183"
    ],
    "text": "[1.4.1 Use of Color] (Level A)\nDescription: Color is not used as the only visual means of conveying information, indicating an\n      action, prompting a response, or distinguishing a visual element.\n\nSituation A: If the color of particular words, backgrounds, or other content is used to indicate information:\n\nRelated techniques: G14, G205, G182, G183",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.1_situation_B",
    "type": "sc_situation",
    "sc_id": "1.4.1",
    "situation_id": "B",
    "techniques": [
      "G111",
      "G14"
    ],
    "text": "[1.4.1 Use of Color] (Level A)\nDescription: Color is not used as the only visual means of conveying information, indicating an\n      action, prompting a response, or distinguishing a visual element.\n\nSituation B: If color is used within an image to convey information:\n\nRelated techniques: G111, G14",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.1_advisory",
    "type": "sc_advisory",
    "sc_id": "1.4.1",
    "techniques": [
      "C15"
    ],
    "text": "[1.4.1 Use of Color] (Level A)\nDescription: Color is not used as the only visual means of conveying information, indicating an\n      action, prompting a response, or distinguishing a visual element.\n\nAdvisory techniques for SC 1.4.1: C15",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.1_failures",
    "type": "sc_failures",
    "sc_id": "1.4.1",
    "techniques": [
      "F13",
      "F73",
      "F81"
    ],
    "text": "[1.4.1 Use of Color] (Level A)\nDescription: Color is not used as the only visual means of conveying information, indicating an\n      action, prompting a response, or distinguishing a visual element.\n\nCommon failures for SC 1.4.1: F13, F73, F81",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.2_intent",
    "type": "sc",
    "sc_id": "1.4.2",
    "section": "intent",
    "text": "[1.4.2 Audio Control] (Level A)\nDescription: If any audio on a web page plays automatically for more than 3 seconds, either a mechanism is available to pause or stop the audio, or a mechanism is available to control audio\n      volume independently from the overall system volume level.\n\nSection: intent\n\nIntent\nIndividuals who use screen reading software can find it hard to hear the speech output\n         if there is other audio playing at the same time. This difficulty is exacerbated when\n         the screen reader's speech output is software based (as most are today) and is controlled\n         via the same volume control as the sound. Therefore, it is important that the user\n         be able to turn off the background sound.\nHaving control of the volume includes\n         being able to reduce its volume to zero. Muting the system volume is not \"pausing or stopping\" the autoplay audio. Both the \"pause or stop\" and control of audio volume need to be independent of the overall system volume.\nNote\nPlaying audio automatically when landing on a page may affect a screen reader user's\n            ability to find the mechanism to stop it because they navigate by listening and automatically\n            started sounds might interfere with that navigation. Therefore, we discourage the\n            practice of automatically starting sounds (especially if they last more than 3 seconds),\n            and encourage that the sound be\nstarted\nby an action initiated by the user after they reach the page, rather than requiring\n            that the sound be\nstopped\nby an action of the user after they land on the page.\nSee also\n1.4.7 Low or No Background Audio\n.\nIn the context of this success criterion, \"plays automatically\" broadly refers to audio that is not started/played as a direct result of a user's intentional activation. For example, selecting a link or button with clear labelling or context that it will start an experience where audio will play is an example of starting in response to a user's intended action. This criterion is also not intended to apply to a conference call or other interaction where two-way voice communication may take place; the potential for any participant to speak during a conference call is not equivalent to audio that \"plays automatically for more than 3 seconds.\" However, a mechanism to control the volume of conference call output independently from the overall system volume would be a best practice.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.2_success_criterion",
    "type": "sc",
    "sc_id": "1.4.2",
    "section": "success_criterion",
    "text": "[1.4.2 Audio Control] (Level A)\nDescription: If any audio on a web page plays automatically for more than 3 seconds, either a mechanism is available to pause or stop the audio, or a mechanism is available to control audio\n      volume independently from the overall system volume level.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nIf any audio on a web page plays automatically for more than 3 seconds, either a\nmechanism\nis available to\npause\nor stop the audio, or a mechanism is available to control audio\n      volume independently from the overall system volume level.\nNote\nSince any content that does not meet this success criterion can interfere with a user's\n      ability to use the whole page, all content on the web page (whether or not it is used\n      to meet other success criteria) must meet this success criterion. See\nConformance Requirement 5: Non-Interference\n.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.2_benefits",
    "type": "sc",
    "sc_id": "1.4.2",
    "section": "benefits",
    "text": "[1.4.2 Audio Control] (Level A)\nDescription: If any audio on a web page plays automatically for more than 3 seconds, either a mechanism is available to pause or stop the audio, or a mechanism is available to control audio\n      volume independently from the overall system volume level.\n\nSection: benefits\n\nBenefits\nIndividuals who use screen reading technologies can hear the screen reader without\n            other sounds playing. This is especially important for those who are hard of hearing\n            and for those whose screen readers use the system volume (so they cannot turn sound\n            down and screen reader up).\nThis success criterion also benefits people who have difficulty focusing on visual\n            content (including text) when audio is playing.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.2_examples",
    "type": "sc",
    "sc_id": "1.4.2",
    "section": "examples",
    "text": "[1.4.2 Audio Control] (Level A)\nDescription: If any audio on a web page plays automatically for more than 3 seconds, either a mechanism is available to pause or stop the audio, or a mechanism is available to control audio\n      volume independently from the overall system volume level.\n\nSection: examples\n\nExamples\nAn audio file begins playing automatically when a page is opened. However, the audio\n            can be stopped by the user by selecting a \"silent\" link at the top of the page.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.2_brief",
    "type": "sc",
    "sc_id": "1.4.2",
    "section": "brief",
    "text": "[1.4.2 Audio Control] (Level A)\nDescription: If any audio on a web page plays automatically for more than 3 seconds, either a mechanism is available to pause or stop the audio, or a mechanism is available to control audio\n      volume independently from the overall system volume level.\n\nSection: brief\n\nIn Brief\nGoal\nA page that plays music or sounds doesn't disrupt people.\nWhat to do\nIf you play audio content automatically, let people turn it down or off.\nWhy it's important\nSound distracts some people, and also interferes with screen readers.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.2_test_rules",
    "type": "sc",
    "sc_id": "1.4.2",
    "section": "test_rules",
    "text": "[1.4.2 Audio Control] (Level A)\nDescription: If any audio on a web page plays automatically for more than 3 seconds, either a mechanism is available to pause or stop the audio, or a mechanism is available to control audio\n      volume independently from the overall system volume level.\n\nSection: test_rules\n\nTest Rules\nThe following are Test Rules\n    for certain aspects of this Success Criterion.\n    It is not necessary to use these particular Test Rules to check for conformance with WCAG, but they are defined and approved test methods.\n    For information on using Test Rules, see\nUnderstanding Test Rules for WCAG Success Criteria\n.\nAudio or video element avoids automatically playing audio",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.2_key_terms",
    "type": "sc",
    "sc_id": "1.4.2",
    "section": "key_terms",
    "text": "[1.4.2 Audio Control] (Level A)\nDescription: If any audio on a web page plays automatically for more than 3 seconds, either a mechanism is available to pause or stop the audio, or a mechanism is available to control audio\n      volume independently from the overall system volume level.\n\nSection: key_terms\n\nKey Terms\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\nconformance\nsatisfying all the requirements of a given standard, guideline or specification\nmechanism\nprocess\nor technique for achieving a result\nNote 1\nThe mechanism may be explicitly provided in the content, or may be\nrelied upon\nto be provided by either the platform or by\nuser agents\n, including\nassistive technologies\n.\nNote 2\nThe mechanism needs to meet all success criteria for the conformance level claimed.\npaused\nstopped by user request and not resumed until requested by user\nprocess\nseries of user actions where each action is required in order to complete an activity\nExample 1\nSuccessful use of a series of web pages on a shopping site requires users to view\n      alternative products, prices and offers, select products, submit an order, provide\n      shipping information and provide payment information.\nExample 2\nAn account registration page requires successful completion of a\nTuring test\nbefore\n      the registration form can be accessed.\nrelied upon\nthe content would not\nconform\nif that\ntechnology\nis turned off or is not supported\ntechnology\nmechanism\nfor encoding instructions to be rendered, played or executed by\nuser agents\nNote 1\nAs used in these guidelines \"web technology\" and the word \"technology\" (when used\n      alone) both refer to web content technologies.\nNote 2\nWeb content technologies may include markup languages, data formats, or programming\n      languages that authors may use alone or in combination to create end-user experiences\n      that range from static web pages to synchronized media presentations to dynamic Web\n      applications.\nExample\nSome common examples of web content technologies include HTML, CSS, SVG, PNG, PDF,\n      Flash, and JavaScript.\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.2_sufficient",
    "type": "sc_sufficient",
    "sc_id": "1.4.2",
    "techniques": [
      "G60",
      "G170",
      "G171"
    ],
    "text": "[1.4.2 Audio Control] (Level A)\nDescription: If any audio on a web page plays automatically for more than 3 seconds, either a mechanism is available to pause or stop the audio, or a mechanism is available to control audio\n      volume independently from the overall system volume level.\n\nSufficient techniques for SC 1.4.2 (no situation): G60, G170, G171",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.2_failures",
    "type": "sc_failures",
    "sc_id": "1.4.2",
    "techniques": [
      "F23",
      "F93"
    ],
    "text": "[1.4.2 Audio Control] (Level A)\nDescription: If any audio on a web page plays automatically for more than 3 seconds, either a mechanism is available to pause or stop the audio, or a mechanism is available to control audio\n      volume independently from the overall system volume level.\n\nCommon failures for SC 1.4.2: F23, F93",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.3_intent",
    "type": "sc",
    "sc_id": "1.4.3",
    "section": "intent",
    "text": "[1.4.3 Contrast (Minimum)] (Level AA)\nDescription: The visual presentation of text and images of text has a contrast ratio of at least 4.5:1, except for the following:\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to provide enough contrast between text and its background, so that it can be read by people with moderately low vision or impaired contrast perception, without the use of contrast-enhancing assistive technology.\nFor all consumers of visual content, adequate light-dark contrast is needed between the relative luminance of text and its background for good readability.\n         Many different visual impairments can substantially impact contrast sensitivity, requiring more light-dark contrast, regardless of color (hue).\n         For people who are not able to distinguish certain shades of color (often referred to as\ncolor blindness\n) hue and saturation have minimal or no effect on legibility as assessed by reading performance.\n         Further, the inability to distinguish certain shades of color does not negatively affect light-dark contrast perception.\n         Therefore, in the recommendation, contrast is calculated in such a way that color (hue) is not a key factor.\nText that is decorative and conveys no information is excluded. For example, if random\n         words are used to create a background and the words could be rearranged or substituted\n         without changing meaning, then it would be decorative and would not need to meet this\n         criterion.\nText that is larger and has wider character strokes is easier to read at lower contrast.\n         The contrast requirement for larger text is therefore lower. This allows authors to\n         use a wider range of color choices for large text, which is helpful for design of\n         pages, particularly titles. 18 point text or 14 point bold text is judged to be large\n         enough to require a lower contrast ratio. (See The American Printing House for the\n         Blind Guidelines for Large Printing and The Library of Congress Guidelines for Large\n         Print under\nResources\n). \"18 point\" and \"bold\" can both have different meanings in\n         different fonts but, except for very thin or unusual fonts, they should be sufficient. Since there\n         are so many different fonts, the general measures are used and a note regarding thin or unusual\n         fonts is included in the definition for\nlarge-scale\ntext.\nNote\nWhen evaluating this Success Criterion, the font size in points should be obtained\n            from the user agent or calculated on font metrics in the way that user agents do.\n            Point sizes are based on the CSS\npt\nsize as defined in\nCSS3 Values\n. The ratio between\n            sizes in points and CSS pixels is\n1pt = 1.333px\n, therefore\n14pt\nand\n18pt\nare equivalent to approximately\n18.5px\nand\n24px\n.\nBecause different image editing applications default to different pixel densities\n            (e.g.,\n72ppi\nor\n96ppi\n), specifying point sizes for fonts from within an\n            image editing application can be unreliable when it comes to presenting text at a specific size.\n            When creating images of large-scale text, authors should ensure that the text in the\n            resulting image is roughly equivalent to 1.2 and 1.5 em or to 120% or 150% of the\n            default size for body text. For example, for a\n72ppi\nimage, an author would need\n            to use approximately 19pt and 24pt font sizes in order to successfully present images\n            of large-scale text to a user.\nThe 3:1 and 4.5:1 contrast ratios referenced in this success criterion are intended to be\n            treated as threshold values. When comparing the computed contrast ratio to the Success Criterion\n            ratio, the computed values should not be rounded (e.g., 4.499:1 would not meet the 4.5:1 threshold).\nNote\nBecause authors do not have control over user settings for font smoothing/anti-aliasing, when evaluating this\n            Success Criterion, refer to the foreground and background colors obtained from the user agent, or the underlying\n            markup and stylesheets, rather than the text as presented on screen.\nDue to anti-aliasing, particularly thin or unusual fonts may be rendered by user agents with a much fainter\n            color than the actual text color defined in the underlying CSS. This can lead to situations where text has\n            a contrast ratio that nominally passes the Success Criterion, but has a much lower contrast in practice.\n            In these cases, best practice would be for authors to choose a font with stronger/thicker lines,\n            or to aim for a foreground/background color combination that exceeds the normative requirements\n            of this success criterion.\nThe contrast requirements for text also apply to images of text\n         (text that has been rendered into pixels and then stored in an image format) - see\nSuccess Criterion 1.4.5: Images of Text\n.\nThis requirement applies to situations in which images of text were intended to be\n         understood as text. Incidental text, such as in photographs that happen to include\n         a street sign, are not included. Nor is text that for some reason is designed to be\n         invisible to all viewers. Stylized text, such as in corporate logos, should be treated\n         in terms of its function on the page, which may or may not warrant including the content\n         in the text alternative. Corporate visual guidelines beyond logo and logotype are\n         not included in the exception.\nIn this provision there is an exception that reads \"that are part of a picture that\n         contains significant other visual content,\". This exception is intended to separate\n         pictures that have text in them from images of text that are done to replace text\n         in order to get a particular look.\nNote\nImages of text do not scale as well as text because they tend to pixelate. It is also\n            harder to change foreground and background contrast and color combinations for images\n            of text, which is necessary for some users. Therefore, we suggest using text wherever\n            possible, and when not, consider supplying an image of higher resolution.\nThis success criterion applies to text in the page, including\n         placeholder text and text that is shown when a pointer is hovering over an object\n         or when an object has keyboard focus. If any of these are used in a page, the text\n         needs to provide sufficient contrast.\nAlthough this success criterion only applies to text, similar issues occur for content presented\n         in charts, graphs, diagrams, and other non-text-based information, which is covered by\nSuccess Criterion 1.4.11 Non-Text Contrast\n.\nSee also\n1.4.6: Contrast (Enhanced)\n.\nRationale for the Ratios Chosen\nA contrast ratio of 3:1 is the minimum level recommended by [\nISO-9241-3\n] and [\nANSI-HFES-100-1988\n]\n            for standard text and vision. The 4.5:1 ratio is used in this success criterion to account\n            for the loss in contrast that results from moderately low visual acuity, congenital\n            or acquired color deficiencies, or the loss of contrast sensitivity that typically\n            accompanies aging.\nThe rationale is based on a) adoption of the 3:1 contrast ratio for minimum acceptable\n            contrast for normal observers, in the ANSI standard, and b) the empirical finding\n            that in the population, visual acuity of 20/40 is associated with a contrast sensitivity\n            loss of roughly 1.5 [\nARDITI-FAYE\n]. A user with 20/40 would thus require a contrast ratio of\n3 * 1.5 = 4.5 to 1\n. Following analogous empirical findings and the same logic,\n            the user with 20/80 visual acuity would require contrast of about 7:1. This ratio is used in\n            Success Criterion 1.4.6.\nHues are perceived differently by users with color vision deficiencies (both congenital\n            and acquired) resulting in different colors and relative luminance contrasts than\n            for normally sighted users. Because of this, effective contrast and readability are\n            different for this population. However, color deficiencies are so diverse that prescribing\n            effective general use color pairs (for contrast) based on quantitative data is not\n            feasible. Requiring good luminance contrast accommodates this by requiring contrast\n            that is independent of color perception. Fortunately, most of the luminance contribution\n            is from the mid and long wave receptors which largely overlap in their spectral responses.\n            The result is that effective luminance contrast can generally be computed without\n            regard to specific color deficiency, except for the use of predominantly long wavelength\n            colors against darker colors (generally appearing black) for those who have protanopia.\n            (We provide an advisory technique on avoiding red on black for that reason). For more\n            information see [\nARDITI-KNOBLAUCH-1994\n] \n            [\nARDITI-KNOBLAUCH-1996\n] \n            [\nARDITI\n].\nNote\nSome people with cognitive disabilities require color combinations or hues that have\n               low contrast, and therefore we allow and encourage authors to provide mechanisms to\n               adjust the foreground and background colors of the content. Some of the combinations\n               that could be chosen may have contrast levels that will be lower than those those\n               specified here. This is not a violation of this Success Criterion, provided\n               there is a mechanism that will return to the required values set out here.\nThe contrast ratio of 4.5:1 was chosen for level AA because it compensated for the\n            loss in contrast sensitivity usually experienced by users with vision loss equivalent\n            to approximately 20/40 vision. (20/40 calculates to approximately 4.5:1.) 20/40 is\n            commonly reported as typical visual acuity of elders at roughly age 80. [\nGITTINGS-FOZARD\n]\nThe contrast ratio of 7:1 was chosen for level AAA because it compensated for the\n            loss in contrast sensitivity usually experienced by users with vision loss equivalent\n            to approximately 20/80 vision. People with more than this degree of vision loss usually\n            use assistive technologies to access their content (and the assistive technologies\n            usually have contrast enhancing, as well as magnification capability built into them).\n            The 7:1 level therefore generally provides compensation for the loss in contrast sensitivity\n            experienced by users with low vision who do not use assistive technology and provides\n            contrast enhancement for color deficiency as well.\nNote\nCalculations in [\nISO-9241-3\n] and [\nANSI-HFES-100-1988\n] are for body text. A relaxed contrast\n               ratio is provided for text that is much larger.\nNotes on formula\nConversion from nonlinear to linear RGB values is based on IEC/4WD 61966-2-1 [\nIEC-4WD\n].\nThe formula (\nL1/L2\n) for contrast is based on [\nISO-9241-3\n] and [\nANSI-HFES-100-1988\n] standards.\nThe ANSI/HFS 100-1988 standard calls for the contribution from ambient light to be\n            included in the calculation of L1 and L2. The\n.05\nvalue used is based on Typical Viewing\n            Flare from [\nIEC-4WD\n].\nThis success criterion and its definitions use the terms \"contrast ratio\" and \"relative\n            luminance\" rather than \"luminance\" to reflect the fact that web content does not emit\n            light itself. The contrast ratio gives a measure of the relative luminance that would\n            result when displayed. (Because it is a ratio, it is dimensionless.)\nNote\nRefer to\nrelated resources\nfor a list of tools that utilize the contrast ratio\n               to analyze the contrast of web content.\nSee also\n2.4.7: Focus Visible\nfor techniques for indicating keyboard focus.\nInactive User Interface Components\nUser Interface Components that are not available for user interaction (e.g., a disabled control in HTML) are not required to meet contrast requirements. An inactive user interface component is visible but not currently operable. An example would be a submit button at the bottom of a form that is visible but cannot be activated until all the required fields in the form are completed.\nFigure 1.\nAn inactive button using default browser styles",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.3_success_criterion",
    "type": "sc",
    "sc_id": "1.4.3",
    "section": "success_criterion",
    "text": "[1.4.3 Contrast (Minimum)] (Level AA)\nDescription: The visual presentation of text and images of text has a contrast ratio of at least 4.5:1, except for the following:\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nThe visual presentation of\ntext\nand\nimages of text\nhas a\ncontrast ratio\nof at least 4.5:1, except for the following:\nLarge Text\nLarge-scale\ntext and images of large-scale text have a contrast ratio of at least 3:1;\nIncidental\nText or images of text that are part of an inactive\nuser interface component\n, that are\npure decoration\n, that are not visible to anyone, or that are part of a picture that contains significant\n            other visual content, have no contrast requirement.\nLogotypes\nText that is part of a logo or brand name has no contrast requirement.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.3_benefits",
    "type": "sc",
    "sc_id": "1.4.3",
    "section": "benefits",
    "text": "[1.4.3 Contrast (Minimum)] (Level AA)\nDescription: The visual presentation of text and images of text has a contrast ratio of at least 4.5:1, except for the following:\n\nSection: benefits\n\nBenefits\nPeople with low vision often have difficulty reading text that does not contrast with\n            its background. This can be exacerbated if the person has a color vision deficiency\n            that lowers the contrast even further. Providing a minimum luminance contrast ratio\n            between the text and its background can make the text more readable even if the person\n            does not see the full range of colors. It also works for the rare individuals who\n            see no color.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.3_brief",
    "type": "sc",
    "sc_id": "1.4.3",
    "section": "brief",
    "text": "[1.4.3 Contrast (Minimum)] (Level AA)\nDescription: The visual presentation of text and images of text has a contrast ratio of at least 4.5:1, except for the following:\n\nSection: brief\n\nIn Brief\nGoal\nText can be seen by more people.\nWhat to do\nProvide sufficient contrast between text and its background.\nWhy it's important\nSome people cannot read faint text.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.3_resources",
    "type": "sc",
    "sc_id": "1.4.3",
    "section": "resources",
    "text": "[1.4.3 Contrast (Minimum)] (Level AA)\nDescription: The visual presentation of text and images of text has a contrast ratio of at least 4.5:1, except for the following:\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nColour Contrast Analyser application\nLuminosity Colour Contrast Ratio Analyser\nColour Contrast Check\nContrast Ratio Calculator\nAdobe Color - Color Contrast Analyzer Tool\nAtypical colour response\nColors On the Web Color Contrast Analyzer\nTool to convert images based on color loss\nso that contrast is restored as luminance contrast when there was only color contrast (that was lost due to color deficiency)\nList of color contrast tools\nThe American Printing House for the Blind Guidelines for Large Printing\nNational Library Service for the Blind and Physically Handicapped (NLS), The Library of Congress reference guide on large print materials\nTypes of Color Blindness, National Eye Institute (NEI), National Institutes of Health (NIH), U.S. Department of Health and Human Services (HHS)\nEffects of chromatic and luminance contrast on reading, Knoblauch et al., 1991\nAchromatic luminance contrast sensitivity in X-linked color-deficient observers: an addition to the debate, Márta Janáky et al., 2013\nContrast sensitivity of patients with congenital color vision deficiency, Cagri Ilhan et al., 2018",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.3_test_rules",
    "type": "sc",
    "sc_id": "1.4.3",
    "section": "test_rules",
    "text": "[1.4.3 Contrast (Minimum)] (Level AA)\nDescription: The visual presentation of text and images of text has a contrast ratio of at least 4.5:1, except for the following:\n\nSection: test_rules\n\nTest Rules\nThe following are Test Rules\n    for certain aspects of this Success Criterion.\n    It is not necessary to use these particular Test Rules to check for conformance with WCAG, but they are defined and approved test methods.\n    For information on using Test Rules, see\nUnderstanding Test Rules for WCAG Success Criteria\n.\nText has enhanced contrast\nText has minimum contrast",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.3_key_terms",
    "type": "sc",
    "sc_id": "1.4.3",
    "section": "key_terms",
    "text": "[1.4.3 Contrast (Minimum)] (Level AA)\nDescription: The visual presentation of text and images of text has a contrast ratio of at least 4.5:1, except for the following:\n\nSection: key_terms\n\nKey Terms\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\ncontrast ratio\n(L1 + 0.05) / (L2 + 0.05), where\nL1 is the\nrelative luminance\nof the lighter of the colors, and\nL2 is the\nrelative luminance\nof the darker of the colors.\nNote 1\nContrast ratios can range from 1 to 21 (commonly written 1:1 to 21:1).\nNote 2\nBecause authors do not have control over user settings as to how text is rendered\n      (for example font smoothing or anti-aliasing), the contrast ratio for text can be\n      evaluated with anti-aliasing turned off.\nNote 3\nFor the purpose of Success Criteria 1.4.3 and 1.4.6, contrast is measured with respect\n      to the specified background over which the text is rendered in normal usage. If no\n      background color is specified, then white is assumed.\nNote 4\nBackground color is the specified color of content over which the text is to be rendered\n      in normal usage. It is a failure if no background color is specified when the text\n      color is specified, because the user's default background color is unknown and cannot\n      be evaluated for sufficient contrast. For the same reason, it is a failure if no text\n      color is specified when a background color is specified.\nNote 5\nWhen there is a border around the letter, the border can add contrast and would be\n      used in calculating the contrast between the letter and its background. A narrow border\n      around the letter would be used as the letter. A wide border around the letter that\n      fills in the inner details of the letters acts as a halo and would be considered background.\nNote 6\nWCAG conformance should be evaluated for color pairs specified in the content that\n      an author would expect to appear adjacent in typical presentation. Authors need not\n      consider unusual presentations, such as color changes made by the user agent, except\n      where caused by authors' code.\nhuman language\nlanguage that is spoken, written or signed (through visual or tactile means) to communicate\n      with humans\nNote\nSee also\nsign language\n.\nimage of text\ntext that has been rendered in a non-text form (e.g., an image) in order to achieve\n      a particular visual effect\nNote\nThis does not include text that is part of a picture that contains significant other visual content.\nExample\nA person's name on a nametag in a photograph.\nlarge scale\nwith at least 18 point or 14 point bold or font size that would yield equivalent size\n      for Chinese, Japanese and Korean (CJK) fonts\nNote 1\nFonts with extraordinarily thin strokes or unusual features and characteristics that\n      reduce the familiarity of their letter forms are harder to read, especially at lower\n      contrast levels.\nNote 2\nFont size is the size when the content is delivered. It does not include resizing\n      that may be done by a user.\nNote 3\nThe actual size of the character that a user sees is dependent both on the author-defined\n      size and the user's display or user agent settings. For many mainstream body text\n      fonts, 14 and 18 point is roughly equivalent to 1.2 and 1.5 em or to 120% or 150%\n      of the default size for body text (assuming that the body font is 100%), but authors\n      would need to check this for the particular fonts in use. When fonts are defined in\n      relative units, the actual point size is calculated by the user agent for display.\n      The point size should be obtained from the user agent, or calculated based on font\n      metrics as the user agent does, when evaluating this success criterion. Users who\n      have low vision would be responsible for choosing appropriate settings.\nNote 4\nWhen using text without specifying the font size, the smallest font size used on major\n      browsers for unspecified text would be a reasonable size to assume for the font. If\n      a level 1 heading is rendered in 14pt bold or higher on major browsers, then it would\n      be reasonable to assume it is large text. Relative scaling can be calculated from\n      the default sizes in a similar fashion.\nNote 5\nThe 18 and 14 point sizes for roman texts are taken from the minimum size for large\n      print (14pt) and the larger standard font size (18pt). For other fonts such as CJK\n      languages, the \"equivalent\" sizes would be the minimum large print size used for those\n      languages and the next larger standard large print size.\nprogrammatically determined\ndetermined by software from author-supplied data provided in a way that different\nuser agents\n, including\nassistive technologies\n, can extract and present this information to users in different modalities\nExample 1\nDetermined in a markup language from elements and attributes that are accessed directly\n      by commonly available assistive technology.\nExample 2\nDetermined from technology-specific data structures in a non-markup language and exposed\n      to assistive technology via an accessibility API that is supported by commonly available\n      assistive technology.\npure decoration\nserving only an aesthetic purpose, providing no information, and having no functionality\nNote\nText is only purely decorative if the words can be rearranged or substituted without\n      changing their purpose.\nExample\nThe cover page of a dictionary has random words in very light text in the background.\nrelative luminance\nthe relative brightness of any point in a colorspace, normalized to 0 for darkest\n      black and 1 for lightest white\nNote 1\nFor the sRGB colorspace, the relative luminance of a color is defined as L = 0.2126\n      *\nR\n+ 0.7152 *\nG\n+ 0.0722 *\nB\nwhere\nR\n,\nG\nand\nB\nare defined as:\nif RsRGB <= 0.04045 then\nR\n= RsRGB/12.92 else\nR\n= ((RsRGB+0.055)/1.055) ^ 2.4\nif GsRGB <= 0.04045 then\nG\n= GsRGB/12.92 else\nG\n= ((GsRGB+0.055)/1.055) ^ 2.4\nif BsRGB <= 0.04045 then\nB\n= BsRGB/12.92 else\nB\n= ((BsRGB+0.055)/1.055) ^ 2.4\nand RsRGB, GsRGB, and BsRGB are defined as:\nRsRGB = R8bit/255\nGsRGB = G8bit/255\nBsRGB = B8bit/255\nThe \"^\" character is the exponentiation operator. (Formula taken from \n      [\nSRGB\n].)\nNote 2\nBefore May 2021 the value of 0.04045 in the definition was different (0.03928). It was taken from an older version of the specification and has been updated. It has no practical effect on the calculations in the context of these guidelines.\nNote 3\nAlmost all systems used today to view web content assume sRGB encoding. Unless it\n      is known that another color space will be used to process and display the content,\n      authors should evaluate using sRGB colorspace. If using other color spaces, see\nUnderstanding Success Criterion 1.4.3\n.\nNote 4\nIf dithering occurs after delivery, then the source color value is used. For colors\n      that are dithered at the source, the average values of the colors that are dithered\n      should be used (average R, average G, and average B).\nNote 5\nTools are available that automatically do the calculations when testing contrast and\n      flash.\nNote 6\nA\nseparate page giving the relative luminance definition using MathML\nto display the formulas is available.\nsign language\na language using combinations of movements of the hands and arms, facial expressions,\n      or body positions to convey meaning\ntext\nsequence of characters that can be\nprogrammatically determined\n, where the sequence is expressing something in\nhuman language\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.\nuser interface component\na part of the content that is perceived by users as a single control for a distinct\n      function\nNote 1\nMultiple user interface components may be implemented as a single programmatic element.\n      \"Components\" here is not tied to programming techniques, but rather to what the user\n      perceives as separate controls.\nNote 2\nUser interface components include form elements and links as well as components generated\n      by scripts.\nNote 3\nWhat is meant by \"component\" or \"user interface component\" here is also sometimes\n      called \"user interface element\".\nExample\nAn applet has a \"control\" that can be used to move through content by line or page\n      or random access. Since each of these would need to have a name and be settable independently,\n      they would each be a \"user interface component.\"",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.3_situation_A",
    "type": "sc_situation",
    "sc_id": "1.4.3",
    "situation_id": "A",
    "techniques": [
      "G18",
      "G148",
      "G174"
    ],
    "text": "[1.4.3 Contrast (Minimum)] (Level AA)\nDescription: The visual presentation of text and images of text has a contrast ratio of at least 4.5:1, except for the following:\n\nSituation A: text is less than 18 point if not bold and less than 14 point if bold\n\nRelated techniques: G18, G148, G174",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.3_situation_B",
    "type": "sc_situation",
    "sc_id": "1.4.3",
    "situation_id": "B",
    "techniques": [
      "G145",
      "G148",
      "G174"
    ],
    "text": "[1.4.3 Contrast (Minimum)] (Level AA)\nDescription: The visual presentation of text and images of text has a contrast ratio of at least 4.5:1, except for the following:\n\nSituation B: text is at least 18 point if not bold and at least 14 point if bold\n\nRelated techniques: G145, G148, G174",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.3_advisory",
    "type": "sc_advisory",
    "sc_id": "1.4.3",
    "techniques": [
      "G156"
    ],
    "text": "[1.4.3 Contrast (Minimum)] (Level AA)\nDescription: The visual presentation of text and images of text has a contrast ratio of at least 4.5:1, except for the following:\n\nAdvisory techniques for SC 1.4.3: G156",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.3_failures",
    "type": "sc_failures",
    "sc_id": "1.4.3",
    "techniques": [
      "F24",
      "F83"
    ],
    "text": "[1.4.3 Contrast (Minimum)] (Level AA)\nDescription: The visual presentation of text and images of text has a contrast ratio of at least 4.5:1, except for the following:\n\nCommon failures for SC 1.4.3: F24, F83",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.4_intent",
    "type": "sc",
    "sc_id": "1.4.4",
    "section": "intent",
    "text": "[1.4.4 Resize Text] (Level AA)\nDescription: Except for captions and images of text, text can be resized without assistive technology up to 200 percent without loss of content or functionality.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to ensure that visually rendered text, including\n         controls and labels using text, can be made larger so that it can be read more easily by\n         people with milder visual impairments, without requiring the use of assistive technology\n         (such as a screen magnifier). Users may benefit from scaling all content on the web page,\n         but text is most critical.\nThe scaling of content is primarily a user agent responsibility. User agents that\n         satisfy\nUAAG 1.0 Checkpoint 4.1\nallow users to configure text scale through a number of mechanisms - including zoom (of the entire page's content),\n         magnification, text-only resizing, and allowing the user to configure a size for rendered text.\n         The author's responsibility is to create web content that does not prevent the user agent from scaling the content effectively.\n         Authors may satisfy this success criterion by verifying that content does not interfere\n         with user agent support for resizing text, including text-based controls, or by providing\n         direct support for resizing text or changing the layout. An example of direct support\n         might be via server-side script that can be used to assign different style sheets.\nContent satisfies the success criterion if it can be scaled up to 200% using at least one text scaling\n         mechanism supported by user agents.\nIf the author is using a technology whose user agents do not provide support for specific text scaling mechanisms,\n         the author is responsible for providing this type of functionality directly, or providing\n         content that works with the type of functionality provided by the user agent. For instance, if the\n         user agent doesn't provide full-page zoom functionality, but does let the the user change the\n\n         text size, the author is responsible for ensuring that the content remains usable\n         when the text is resized.\nSome user interface components that function as a label and require activation by\n         the user to access content are not wide enough to accommodate the label's content.\n         For example, in web mail applications the subject column may not be wide enough to\n         accommodate every possible subject header, but activating the subject header takes\n         the user to the full message with the full subject header. In Web-based spreadsheets,\n         cell content that is too long to be displayed in a column can be truncated, and the\n         full content of the cell is available to the user when the cell receives focus. The\n         content of a user interface component may also become too wide in user interfaces\n         where the user can resize the column width. In this type of user interface component,\n         line wrapping is not required; truncation is acceptable if the component's full content\n         is available on focus or after user activation and an indication that this information\n         can be accessed, is provided to the user in some way besides the fact that it is truncated.\nContent satisfies the success criterion if it can be scaled up to 200% - that is, up\n         to twice the width and height. Authors may support scaling beyond that limit, however,\n         as scaling becomes more extreme, adaptive layouts may introduce usability problems.\n         For example, words may be too wide to fit into the horizontal space available to them,\n         causing them to be truncated; layout constraints may cause text to overlap with other\n         content when it is scaled larger; or only one word of a sentence may fit on each line,\n         causing the sentence to be displayed as a vertical column of text that is difficult\n         to read.\nThe working group feels that 200% is a reasonable accommodation that can support a\n         wide range of designs and layouts, and complements older screen magnifiers that provide\n         a minimum magnification of 200%. Above 200%, zoom (which resizes text, images, and\n         layout regions and creates a larger canvas that may require both horizontal and vertical\n         scrolling) may be more effective than text resizing. Assistive technology dedicated\n         to zoom support would usually be used in such a situation, and may provide better accessibility\n         than attempts by the author to support the user directly.\nNote\nImages of text do not scale as well as text because they tend to pixelate, and therefore\n            we suggest using text wherever possible. It is also harder to change foreground and\n            background contrast and color combinations for images of text, which are necessary\n            for some users.\nNote\nAs with most other Success Criteria, this criterion applies to each variation of the page that is automatically presented for various screen sizes (e.g. media query variations in a responsive site). In an implementation where text does not consistently increase its size as people zoom in (such as when it is transformed based on a media query to adapt to small-screen usage), it must still be possible to get to 200% enlargement in order to satisfy the criterion.\nFor example, if at the default browser setting of 100% zoom, text is set at 20px when the window is 1280 CSS pixels wide, at 200% zoom it will visually appear at twice the size. After zooming by 400% the page reflows to fit within the 320 CSS pixel viewport, the author may decide to set the page's text size to 10px. The text is now half the original size in CSS pixels, but as it has been enlarged to 400%, it is still displayed at twice the size compared to the default browser setting at 100% zoom. It is not required to achieve 200% text enlargement while remaining inside a specific breakpoint (as zooming may result in the variation for a new breakpoint becoming active), but it should still be possible to get 200% text enlargement in some way compared to the default 100% zoom.\nSee also\n1.4.3: Visual Presentation\n.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.4_success_criterion",
    "type": "sc",
    "sc_id": "1.4.4",
    "section": "success_criterion",
    "text": "[1.4.4 Resize Text] (Level AA)\nDescription: Except for captions and images of text, text can be resized without assistive technology up to 200 percent without loss of content or functionality.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nExcept for\ncaptions\nand\nimages of text\n,\ntext\ncan be resized without\nassistive technology\nup to 200 percent without loss of content or functionality.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.4_benefits",
    "type": "sc",
    "sc_id": "1.4.4",
    "section": "benefits",
    "text": "[1.4.4 Resize Text] (Level AA)\nDescription: Except for captions and images of text, text can be resized without assistive technology up to 200 percent without loss of content or functionality.\n\nSection: benefits\n\nBenefits\nThis success criterion helps people with low vision by letting them increase text\n            size in content so that they can read it.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.4_examples",
    "type": "sc",
    "sc_id": "1.4.4",
    "section": "examples",
    "text": "[1.4.4 Resize Text] (Level AA)\nDescription: Except for captions and images of text, text can be resized without assistive technology up to 200 percent without loss of content or functionality.\n\nSection: examples\n\nExamples\nA user with vision impairments increases the text size on a web page in a browser\n            from 1 em to 1.2 ems. While the user could not read the text at the smaller size,\n            they can read the larger text. All the information on the page is still displayed when\n            the larger font is used for the text.\nA web page contains a control for changing the scale of the page. Selecting different\n            settings changes the layout of the page to use the best design for that scale.\nA user changes the scale of the content with the browser's full-page zoom function.\n            All the content scales uniformly, and the browser provides scroll bars, if necessary.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.4_brief",
    "type": "sc",
    "sc_id": "1.4.4",
    "section": "brief",
    "text": "[1.4.4 Resize Text] (Level AA)\nDescription: Except for captions and images of text, text can be resized without assistive technology up to 200 percent without loss of content or functionality.\n\nSection: brief\n\nIn Brief\nGoal\nText can be enlarged.\nWhat to do\nEnsure text can be doubled in size.\nWhy it's important\nSome people can only read text when it is bigger.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.4_resources",
    "type": "sc",
    "sc_id": "1.4.4",
    "section": "resources",
    "text": "[1.4.4 Resize Text] (Level AA)\nDescription: Except for captions and images of text, text can be resized without assistive technology up to 200 percent without loss of content or functionality.\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nCSS 2 Box Model\nCSS 2 Visual formatting Model\nCSS 2 Visual formatting Model Details\nAbout fluid and fixed width layouts\nAccessible CSS",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.4_test_rules",
    "type": "sc",
    "sc_id": "1.4.4",
    "section": "test_rules",
    "text": "[1.4.4 Resize Text] (Level AA)\nDescription: Except for captions and images of text, text can be resized without assistive technology up to 200 percent without loss of content or functionality.\n\nSection: test_rules\n\nTest Rules\nThe following are Test Rules\n    for certain aspects of this Success Criterion.\n    It is not necessary to use these particular Test Rules to check for conformance with WCAG, but they are defined and approved test methods.\n    For information on using Test Rules, see\nUnderstanding Test Rules for WCAG Success Criteria\n.\nMeta viewport allows for zoom\nZoomed text node is not clipped with CSS overflow",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.4_key_terms",
    "type": "sc",
    "sc_id": "1.4.4",
    "section": "key_terms",
    "text": "[1.4.4 Resize Text] (Level AA)\nDescription: Except for captions and images of text, text can be resized without assistive technology up to 200 percent without loss of content or functionality.\n\nSection: key_terms\n\nKey Terms\nASCII art\npicture created by a spatial arrangement of characters or glyphs (typically from the\n      95 printable characters defined by ASCII)\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\naudio\nthe technology of sound reproduction\nNote\nAudio can be created synthetically (including speech synthesis), recorded from real\n      world sounds, or both.\naudio description\nnarration added to the soundtrack to describe important visual details that cannot\n      be understood from the main soundtrack alone\nNote 1\nAudio description of\nvideo\nprovides information about actions, characters, scene changes, on-screen text, and\n      other visual content.\nNote 2\nIn standard audio description, narration is added during existing pauses in dialogue.\n      (See also\nextended audio description\n.)\nNote 3\nWhere all of the\nvideo\ninformation is already provided in existing\naudio\n, no additional audio description is necessary.\nNote 4\nAlso called \"video description\" and \"descriptive narration.\"\ncaptions\nsynchronized visual and/or\ntext alternative\nfor both speech and non-speech audio information needed to understand the media content\nNote 1\nCaptions are similar to dialogue-only subtitles except captions convey not only the\n      content of spoken dialogue, but also equivalents for non-dialogue audio information\n      needed to understand the program content, including sound effects, music, laughter,\n      speaker identification and location.\nNote 2\nClosed Captions are equivalents that can be turned on and off with some players.\nNote 3\nOpen Captions are any captions that cannot be turned off. For example, if the captions\n      are visual equivalent\nimages of text\nembedded in\nvideo\n.\nNote 4\nCaptions should not obscure or obstruct relevant information in the video.\nNote 5\nIn some countries, captions are called subtitles.\nNote 6\nAudio descriptions\ncan be, but do not need to be, captioned since they are descriptions of information\n      that is already presented visually.\nextended audio description\naudio description that is added to an audiovisual presentation by pausing the\nvideo\nso that there is time to add additional description\nNote\nThis technique is only used when the sense of the\nvideo\nwould be lost without the additional\naudio description\nand the pauses between dialogue/narration are too short.\nhuman language\nlanguage that is spoken, written or signed (through visual or tactile means) to communicate\n      with humans\nNote\nSee also\nsign language\n.\nimage of text\ntext that has been rendered in a non-text form (e.g., an image) in order to achieve\n      a particular visual effect\nNote\nThis does not include text that is part of a picture that contains significant other visual content.\nExample\nA person's name on a nametag in a photograph.\nnon-text content\nany content that is not a sequence of characters that can be\nprogrammatically determined\nor where the sequence is not expressing something in\nhuman language\nNote\nThis includes\nASCII art\n(which is a pattern of characters), emoticons, leetspeak (which uses character substitution),\n      and images representing text\nprogrammatically determined\ndetermined by software from author-supplied data provided in a way that different\nuser agents\n, including\nassistive technologies\n, can extract and present this information to users in different modalities\nExample 1\nDetermined in a markup language from elements and attributes that are accessed directly\n      by commonly available assistive technology.\nExample 2\nDetermined from technology-specific data structures in a non-markup language and exposed\n      to assistive technology via an accessibility API that is supported by commonly available\n      assistive technology.\nsign language\na language using combinations of movements of the hands and arms, facial expressions,\n      or body positions to convey meaning\ntext\nsequence of characters that can be\nprogrammatically determined\n, where the sequence is expressing something in\nhuman language\ntext alternative\nText\nthat is programmatically associated with\nnon-text content\nor referred to from text that is programmatically associated with non-text content.\n      Programmatically associated text is text whose location can be\nprogrammatically determined\nfrom the non-text content.\nExample\nAn image of a chart is described in text in the paragraph after the chart. The short\n      text alternative for the chart indicates that a description follows.\nNote\nRefer to\nUnderstanding Text Alternatives\nfor more information.\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.\nvideo\nthe technology of moving or sequenced pictures or images\nNote\nVideo can be made up of animated or photographic images, or both.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.4_sufficient",
    "type": "sc_sufficient",
    "sc_id": "1.4.4",
    "techniques": [
      "G142",
      "C28",
      "C28",
      "C12",
      "C12",
      "C13",
      "C14",
      "SCR34",
      "SCR34",
      "G146",
      "G178",
      "G179"
    ],
    "text": "[1.4.4 Resize Text] (Level AA)\nDescription: Except for captions and images of text, text can be resized without assistive technology up to 200 percent without loss of content or functionality.\n\nSufficient techniques for SC 1.4.4 (no situation): G142, C28, C28, C12, C12, C13, C14, SCR34, SCR34, G146, G178, G179",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.4_advisory",
    "type": "sc_advisory",
    "sc_id": "1.4.4",
    "techniques": [
      "C17",
      "C20",
      "C22"
    ],
    "text": "[1.4.4 Resize Text] (Level AA)\nDescription: Except for captions and images of text, text can be resized without assistive technology up to 200 percent without loss of content or functionality.\n\nAdvisory techniques for SC 1.4.4: C17, C20, C22",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.4_failures",
    "type": "sc_failures",
    "sc_id": "1.4.4",
    "techniques": [
      "F69",
      "F80",
      "F94"
    ],
    "text": "[1.4.4 Resize Text] (Level AA)\nDescription: Except for captions and images of text, text can be resized without assistive technology up to 200 percent without loss of content or functionality.\n\nCommon failures for SC 1.4.4: F69, F80, F94",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.5_intent",
    "type": "sc",
    "sc_id": "1.4.5",
    "section": "intent",
    "text": "[1.4.5 Images of Text] (Level AA)\nDescription: If the technologies being used can achieve the visual presentation, text is used to convey information rather than images of text except for the following:\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to encourage authors, who are using technologies\n         which are capable of achieving their desired default visual presentation, to enable\n         people who require a particular visual presentation of text to be able to adjust the\n         text presentation as needed. This includes people who require the text in a particular\n         font size, foreground and background color, font family, line spacing or alignment.\nIf authors can use text to achieve the same visual effect, they should present\n         the information as text rather than using an image. If for any reason, the author\n         cannot format the text to get the same effect, the effect won't be reliably presented\n         on the commonly available user agents, or using a technology to meet this criterion\n         would interfere with meeting other criteria such as 1.4.4, then an image of text can\n         be used. This includes instances where a particular presentation of text is essential\n         to the information being conveyed, such as type samples, logotypes, branding, etc.\n         Images of text may also be used in order to use a particular font that is either not\n         widely deployed or which the author doesn't have the right to redistribute, or to\n         ensure that the text would be anti-aliased on all user agents.\nImages of text can also be used where it is possible for users to customize the image\n         of text to match their requirements.\nThe definition of\nimages of text\ncontains the note: This does not include text that is part of a picture that contains significant\n         other visual content. Examples of such pictures include graphs, screenshots, and diagrams which visually\n         convey important information through more than just text.\nNote\nThe success criterion is intended to address situations where\nimages of text\nare used\nrather than\ntext. Where images of text are used\nin addition to\ntext to convey the same information, and where both are presented to the user, this success criterion is met. This allows authors to convey content using any styling they desire, while also presenting the information in text, which can then be manipulated by users to make it more distinguishable. This is in contrast to\n1.4.9 Images of Text (No Exception)\n, which applies to all images of text, regardless of whether or not they are used\nin addition to\ntext.\nTechniques for satisfying this success criterion are the same as those for Success\n         Criterion 1.4.9, except that they only need to apply if the visual presentation can\n         be achieved with the technologies that the author is using. For Success Criterion\n         1.4.9, the sufficient techniques would be applied only when the user can customize\n         the output.\nSee also\n1.4.9 Images of Text (No Exception)\n.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.5_success_criterion",
    "type": "sc",
    "sc_id": "1.4.5",
    "section": "success_criterion",
    "text": "[1.4.5 Images of Text] (Level AA)\nDescription: If the technologies being used can achieve the visual presentation, text is used to convey information rather than images of text except for the following:\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nIf the technologies being used can achieve the visual presentation,\ntext\nis used to convey information rather than\nimages of text\nexcept for the following:\nCustomizable\nThe image of text can be\nvisually customized\nto the user's requirements;\nEssential\nA particular presentation of text is\nessential\nto the information being conveyed.\nNote\nLogotypes (text that is part of a logo or brand name) are considered essential.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.5_benefits",
    "type": "sc",
    "sc_id": "1.4.5",
    "section": "benefits",
    "text": "[1.4.5 Images of Text] (Level AA)\nDescription: If the technologies being used can achieve the visual presentation, text is used to convey information rather than images of text except for the following:\n\nSection: benefits\n\nBenefits\nPeople with low vision (who may have trouble reading the text with the authored font\n            family, size and/or color).\nPeople with visual tracking problems (who may have trouble reading the text with the\n            authored line spacing and/or alignment).\nPeople with cognitive disabilities that affect reading.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.5_examples",
    "type": "sc",
    "sc_id": "1.4.5",
    "section": "examples",
    "text": "[1.4.5 Images of Text] (Level AA)\nDescription: If the technologies being used can achieve the visual presentation, text is used to convey information rather than images of text except for the following:\n\nSection: examples\n\nExamples\nStyled Headings\nRather than using bitmap images to present headings in a specific font and size, an\n               author uses CSS to achieve the same result.\nDynamically Generated Images\nA web page uses server-side scripting to present text as an an image. The page includes\n               controls that allow the user to adjust the font size and foreground and background\n               colors of the generated image.\nA quote\nA web page contains a quote. The quote itself is presented as italicized text, indented\n               from the left margin. The name of the person to whom the quote is attributed is below\n               the quote with 1.5x the line space and further indented from the left margin. CSS\n               is used to position the text; set the spacing between lines; as well as display the\n               text's font family, size, color and decoration.\nNavigation items\nA web page contains a menu of navigation links that have both an icon and text to\n               describe their target. CSS is used to display the text's font family, size and foreground\n               and background colors; as well as the spacing between the navigation links.\nA logo containing text\nA website contains the organization's logo in the top left corner of each web page.\n               The logo contains logotype (text as part, or all, of the logo). The visual presentation\n               of the text is essential to the identity of the logo and is included as a gif image\n               which does not allow the text characteristics to be changed. The image has a text\n               alternative.\nRepresentation of a font family\nA web page contains information about a particular font family. Substituting the font\n               family with another font would defeat the purpose of the representation. The representation\n               is included as a jpeg image which does not allow the text characteristics to be changed.\n               The image has a text alternative.\nA representation of a letter\nA web page contains a representation of an original letter. The depiction of the letter\n               in its original format is essential to information being conveyed about the time period\n               in which it was written. The letter is included as a gif image which does not allow\n               the text characteristics to be changed. The image has a text alternative.\nSymbolic text characters\nA form allows users to enter blocks of text. The form provides a number of buttons,\n               including functions to style the text and check spelling. Some of the buttons use\n               text characters that do not form a sequence that expresses something in human language.\n               For example \"B\" to increase font weight, \"I\" to italicize the text and \"ABC\" to check\n               the spelling. The symbolic text characters are included as gif images which do not\n               allow the text characteristics to be changed. The buttons have text alternatives.\nCustomizable font settings in images of text\nA website allows users to specify font settings and all images of text on the site\n               are then provided based on those settings.\nThe text in an image is also provided as text.\nA user has to upload an event poster image, which includes text, to their website's events\n            calendar. The site's CMS (content management system) is limited, and won't allow them to create\n            a custom HTML/CSS/SVG recreation of the poster. However, in addition to the image, they can add\n            regular text to the calendar entry, so they post both the poster and the text contained in the image.\n            This text is shown next to the poster image on the site's calendar page.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.5_brief",
    "type": "sc",
    "sc_id": "1.4.5",
    "section": "brief",
    "text": "[1.4.5 Images of Text] (Level AA)\nDescription: If the technologies being used can achieve the visual presentation, text is used to convey information rather than images of text except for the following:\n\nSection: brief\n\nIn Brief\nGoal\nUsers can adjust how text is presented.\nWhat to do\nUse text instead of pictures of text.\nWhy it's important\nPeople cannot alter how text looks in images.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.5_resources",
    "type": "sc",
    "sc_id": "1.4.5",
    "section": "resources",
    "text": "[1.4.5 Images of Text] (Level AA)\nDescription: If the technologies being used can achieve the visual presentation, text is used to convey information rather than images of text except for the following:\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nFundamental text and font styling\nMDN Web fonts",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.5_test_rules",
    "type": "sc",
    "sc_id": "1.4.5",
    "section": "test_rules",
    "text": "[1.4.5 Images of Text] (Level AA)\nDescription: If the technologies being used can achieve the visual presentation, text is used to convey information rather than images of text except for the following:\n\nSection: test_rules\n\nTest Rules\nThe following are Test Rules\n    for certain aspects of this Success Criterion.\n    It is not necessary to use these particular Test Rules to check for conformance with WCAG, but they are defined and approved test methods.\n    For information on using Test Rules, see\nUnderstanding Test Rules for WCAG Success Criteria\n.\nHTML images contain no text",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.5_key_terms",
    "type": "sc",
    "sc_id": "1.4.5",
    "section": "key_terms",
    "text": "[1.4.5 Images of Text] (Level AA)\nDescription: If the technologies being used can achieve the visual presentation, text is used to convey information rather than images of text except for the following:\n\nSection: key_terms\n\nKey Terms\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\nessential\nif removed, would fundamentally change the information or functionality of the content,\nand\ninformation and functionality cannot be achieved in another way that would conform\nhuman language\nlanguage that is spoken, written or signed (through visual or tactile means) to communicate\n      with humans\nNote\nSee also\nsign language\n.\nimage of text\ntext that has been rendered in a non-text form (e.g., an image) in order to achieve\n      a particular visual effect\nNote\nThis does not include text that is part of a picture that contains significant other visual content.\nExample\nA person's name on a nametag in a photograph.\nprogrammatically determined\ndetermined by software from author-supplied data provided in a way that different\nuser agents\n, including\nassistive technologies\n, can extract and present this information to users in different modalities\nExample 1\nDetermined in a markup language from elements and attributes that are accessed directly\n      by commonly available assistive technology.\nExample 2\nDetermined from technology-specific data structures in a non-markup language and exposed\n      to assistive technology via an accessibility API that is supported by commonly available\n      assistive technology.\nsign language\na language using combinations of movements of the hands and arms, facial expressions,\n      or body positions to convey meaning\ntext\nsequence of characters that can be\nprogrammatically determined\n, where the sequence is expressing something in\nhuman language\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.\nvisually customized\nthe font, size, color, and background can be set",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.5_sufficient",
    "type": "sc_sufficient",
    "sc_id": "1.4.5",
    "techniques": [
      "C22",
      "C30",
      "G140",
      "PDF7"
    ],
    "text": "[1.4.5 Images of Text] (Level AA)\nDescription: If the technologies being used can achieve the visual presentation, text is used to convey information rather than images of text except for the following:\n\nSufficient techniques for SC 1.4.5 (no situation): C22, C30, G140, PDF7",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.5_advisory",
    "type": "sc_advisory",
    "sc_id": "1.4.5",
    "techniques": [
      "C12",
      "C13",
      "C14",
      "C8",
      "C6"
    ],
    "text": "[1.4.5 Images of Text] (Level AA)\nDescription: If the technologies being used can achieve the visual presentation, text is used to convey information rather than images of text except for the following:\n\nAdvisory techniques for SC 1.4.5: C12, C13, C14, C8, C6",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.6_intent",
    "type": "sc",
    "sc_id": "1.4.6",
    "section": "intent",
    "text": "[1.4.6 Contrast (Enhanced)] (Level AAA)\nDescription: The visual presentation of text and images of text has a contrast ratio of at least 7:1, except for the following:\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to provide enough contrast between text and\n         its background so that it can be read by people with moderately low vision (who do\n         not use contrast-enhancing assistive technology). For people without color deficiencies,\n         hue and saturation have minimal or no effect on legibility as assessed by reading\n         performance (Knoblauch et al., 1991). Color deficiencies can affect luminance contrast\n         somewhat. Therefore, in the recommendation, the contrast is calculated in such a way\n         that color is not a key factor so that people who have a color vision deficit will\n         also have adequate contrast between the text and the background.\nText that is decorative and conveys no information is excluded. For example, if random\n         words are used to create a background and the words could be rearranged or substituted\n         without changing meaning, then it would be decorative and would not need to meet this\n         criterion.\nText that is larger and has wider character strokes is easier to read at lower contrast.\n         The contrast requirement for larger text is therefore lower. This allows authors to\n         use a wider range of color choices for large text, which is helpful for design of\n         pages, particularly titles. 18 point text or 14 point bold text is judged to be large\n         enough to require a lower contrast ratio. (See The American Printing House for the\n         Blind Guidelines for Large Printing and The Library of Congress Guidelines for Large\n         Print under\nResources\n). \"18 point\" and \"bold\" can both have different meanings in\n         different fonts but, except for very thin or unusual fonts, they should be sufficient. Since there\n         are so many different fonts, the general measures are used and a note regarding thin or unusual\n         fonts is included in the definition for\nlarge-scale\ntext.\nNote\nWhen evaluating this Success Criterion, the font size in points should be obtained\n            from the user agent or calculated on font metrics in the way that user agents do.\n            Point sizes are based on the CSS\npt\nsize as defined in\nCSS3 Values\n. The ratio between\n            sizes in points and CSS pixels is\n1pt = 1.333px\n, therefore\n14pt\nand\n18pt\nare equivalent to approximately\n18.5px\nand\n24px\n.\nBecause different image editing applications default to different pixel densities\n            (e.g.,\n72ppi\nor\n96ppi\n), specifying point sizes for fonts from within an\n            image editing application can be unreliable when it comes to presenting text at a specific size.\n            When creating images of large-scale text, authors should ensure that the text in the\n            resulting image is roughly equivalent to 1.2 and 1.5 em or to 120% or 150% of the\n            default size for body text. For example, for a\n72ppi\nimage, an author would need\n            to use approximately 19pt and 24pt font sizes in order to successfully present images\n            of large-scale text to a user.\nThe 7:1 and 4.5:1 contrast ratios referenced in this success criterion are intended to be\n            treated as threshold values. When comparing the computed contrast ratio to the Success Criterion\n            ratio, the computed values should not be rounded (e.g., 4.499:1 would not meet the 4.5:1 threshold).\nNote\nBecause authors do not have control over user settings for font smoothing/anti-aliasing, when evaluating this\n            Success Criterion, refer to the foreground and background colors obtained from the user agent, or the underlying\n            markup and stylesheets, rather than the text as presented on screen.\nDue to anti-aliasing, particularly thin or unusual fonts may be rendered by user agents with a much fainter\n            color than the actual text color defined in the underlying CSS. This can lead to situations where text has\n            a contrast ratio that nominally passes the Success Criterion, but has a much lower contrast in practice.\n            In these cases, best practice would be for authors to choose a font with stronger/thicker lines,\n            or to aim for a foreground/background color combination that exceeds the normative requirements\n            of this success criterion.\nThe contrast requirements for text also apply to images of text\n         (text that has been rendered into pixels and then stored in an image format) - see\nSuccess Criterion 1.4.5: Images of Text\n.\nThis requirement applies to situations in which images of text were intended to be\n         understood as text. Incidental text, such as in photographs that happen to include\n         a street sign, are not included. Nor is text that for some reason is designed to be\n         invisible to all viewers. Stylized text, such as in corporate logos, should be treated\n         in terms of its function on the page, which may or may not warrant including the content\n         in the text alternative. Corporate visual guidelines beyond logo and logotype are\n         not included in the exception.\nIn this provision there is an exception that reads \"that are part of a picture that\n         contains significant other visual content,\". This exception is intended to separate\n         pictures that have text in them from images of text that are done to replace text\n         in order to get a particular look.\nNote\nImages of text do not scale as well as text because they tend to pixelate. It is also\n            harder to change foreground and background contrast and color combinations for images\n            of text, which is necessary for some users. See\n1.4.5: Images of Text\n.\nThis success criterion applies to text in the page, including\n         placeholder text and text that is shown when a pointer is hovering over an object\n         or when an object has keyboard focus. If any of these are used in a page, the text\n         needs to provide sufficient contrast.\nAlthough this success criterion only applies to text, similar issues occur for content presented\n         in charts, graphs, diagrams, and other non-text-based information, which is covered by\nSuccess Criterion 1.4.11 Non-Text Contrast\n.\nRationale for the Ratios Chosen\nA contrast ratio of 3:1 is the minimum level recommended by [\nISO-9241-3\n] and [\nANSI-HFES-100-1988\n]\n            for standard text and vision. The 4.5:1 ratio is used in Success Criterion 1.4.3 to account\n            for the loss in contrast that results from moderately low visual acuity, congenital\n            or acquired color deficiencies, or the loss of contrast sensitivity that typically\n            accompanies aging.\nThe rationale is based on a) adoption of the 3:1 contrast ratio for minimum acceptable\n            contrast for normal observers, in the ANSI standard, and b) the empirical finding\n            that in the population, visual acuity of 20/40 is associated with a contrast sensitivity\n            loss of roughly 1.5 [\nARDITI-FAYE\n]. A user with 20/40 would thus require a contrast ratio of\n3 * 1.5 = 4.5 to 1\n. Following analogous empirical findings and the same logic,\n            the user with 20/80 visual acuity would require contrast of about 7:1. This ratio is used in\n            this success criterion.\nHues are perceived differently by users with color vision deficiencies (both congenital\n            and acquired) resulting in different colors and relative luminance contrasts than\n            for normally sighted users. Because of this, effective contrast and readability are\n            different for this population. However, color deficiencies are so diverse that prescribing\n            effective general use color pairs (for contrast) based on quantitative data is not\n            feasible. Requiring good luminance contrast accommodates this by requiring contrast\n            that is independent of color perception. Fortunately, most of the luminance contribution\n            is from the mid and long wave receptors which largely overlap in their spectral responses.\n            The result is that effective luminance contrast can generally be computed without\n            regard to specific color deficiency, except for the use of predominantly long wavelength\n            colors against darker colors (generally appearing black) for those who have protanopia.\n            (We provide an advisory technique on avoiding red on black for that reason). For more\n            information see [\nARDITI-KNOBLAUCH-1994\n] \n            [\nARDITI-KNOBLAUCH-1996\n] \n            [\nARDITI\n].\nNote\nSome people with cognitive disabilities require color combinations or hues that have\n               low contrast, and therefore we allow and encourage authors to provide mechanisms to\n               adjust the foreground and background colors of the content. Some of the combinations\n               that could be chosen may have contrast levels that will be lower than those\n               specified here. This is not a violation of this Success Criterion, provided\n               there is a mechanism that will return to the required values set out here.\nThe contrast ratio of 4.5:1 was chosen for level AA because it compensated for the\n            loss in contrast sensitivity usually experienced by users with vision loss equivalent\n            to approximately 20/40 vision. (20/40 calculates to approximately 4.5:1.) 20/40 is\n            commonly reported as typical visual acuity of elders at roughly age 80. [\nGITTINGS-FOZARD\n]\nThe contrast ratio of 7:1 was chosen for level AAA because it compensated for the\n            loss in contrast sensitivity usually experienced by users with vision loss equivalent\n            to approximately 20/80 vision. People with more than this degree of vision loss usually\n            use assistive technologies to access their content (and the assistive technologies\n            usually have contrast enhancing, as well as magnification capability built into them).\n            The 7:1 level therefore generally provides compensation for the loss in contrast sensitivity\n            experienced by users with low vision who do not use assistive technology and provides\n            contrast enhancement for color deficiency as well.\nNote\nCalculations in [\nISO-9241-3\n] and [\nANSI-HFES-100-1988\n] are for body text. A relaxed contrast\n               ratio is provided for text that is much larger.\nNotes on formula\nConversion from nonlinear to linear RGB values is based on IEC/4WD 61966-2-1 [\nIEC-4WD\n].\nThe formula (\nL1/L2\n) for contrast is based on [\nISO-9241-3\n] and [\nANSI-HFES-100-1988\n] standards.\nThe ANSI/HFS 100-1988 standard calls for the contribution from ambient light to be\n            included in the calculation of L1 and L2. The\n.05\nvalue used is based on Typical Viewing\n            Flare from [\nIEC-4WD\n].\nThis success criterion and its definitions use the terms \"contrast ratio\" and \"relative\n            luminance\" rather than \"luminance\" to reflect the fact that web content does not emit\n            light itself. The contrast ratio gives a measure of the relative luminance that would\n            result when displayed. (Because it is a ratio, it is dimensionless.)\nNote\nRefer to\nrelated resources\nfor a list of tools that utilize the contrast ratio\n               to analyze the contrast of web content.\nSee also\n2.4.7: Focus Visible\nfor techniques for indicating keyboard focus.\nInactive User Interface Components\nUser Interface Components that are not available for user interaction (e.g., a disabled control in HTML) are not required to meet contrast requirements. An inactive user interface component is visible but not currently operable. An example would be a submit button at the bottom of a form that is visible but cannot be activated until all the required fields in the form are completed.\nFigure 1.\nAn inactive button using default browser styles",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.6_success_criterion",
    "type": "sc",
    "sc_id": "1.4.6",
    "section": "success_criterion",
    "text": "[1.4.6 Contrast (Enhanced)] (Level AAA)\nDescription: The visual presentation of text and images of text has a contrast ratio of at least 7:1, except for the following:\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nThe visual presentation of\ntext\nand\nimages of text\nhas a\ncontrast ratio\nof at least 7:1, except for the following:\nLarge Text\nLarge-scale\ntext and images of large-scale text have a contrast ratio of at least 4.5:1;\nIncidental\nText or images of text that are part of an inactive\nuser interface component\n, that are\npure decoration\n, that are not visible to anyone, or that are part of a picture that contains significant\n            other visual content, have no contrast requirement.\nLogotypes\nText that is part of a logo or brand name has no contrast requirement.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.6_benefits",
    "type": "sc",
    "sc_id": "1.4.6",
    "section": "benefits",
    "text": "[1.4.6 Contrast (Enhanced)] (Level AAA)\nDescription: The visual presentation of text and images of text has a contrast ratio of at least 7:1, except for the following:\n\nSection: benefits\n\nBenefits\nPeople with low vision often have difficulty reading text that does not contrast with\n            its background. This can be exacerbated if the person has a color vision deficiency\n            that lowers the contrast even further. Providing a minimum luminance contrast ratio\n            between the text and its background can make the text more readable even if the person\n            does not see the full range of colors. It also works for the rare individuals who\n            see no color.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.6_brief",
    "type": "sc",
    "sc_id": "1.4.6",
    "section": "brief",
    "text": "[1.4.6 Contrast (Enhanced)] (Level AAA)\nDescription: The visual presentation of text and images of text has a contrast ratio of at least 7:1, except for the following:\n\nSection: brief\n\nIn Brief\nGoal\nText can be seen by people who need strong contrast.\nWhat to do\nStrongly contrast text against its background.\nWhy it's important\nSome people cannot read text with minimum contrast.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.6_resources",
    "type": "sc",
    "sc_id": "1.4.6",
    "section": "resources",
    "text": "[1.4.6 Contrast (Enhanced)] (Level AAA)\nDescription: The visual presentation of text and images of text has a contrast ratio of at least 7:1, except for the following:\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nColour Contrast Analyser application\nLuminosity Colour Contrast Ratio Analyser\nColour Contrast Check\nContrast Ratio Calculator\nAdobe Color - Color Contrast Analyzer Tool\nAtypical colour response\nColors On the Web Color Contrast Analyzer\nReading with Dyslexia - Fonts that can help alleviate visual stress.\nGood Fonts for Dyslexia - An Experimental Study",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.6_test_rules",
    "type": "sc",
    "sc_id": "1.4.6",
    "section": "test_rules",
    "text": "[1.4.6 Contrast (Enhanced)] (Level AAA)\nDescription: The visual presentation of text and images of text has a contrast ratio of at least 7:1, except for the following:\n\nSection: test_rules\n\nTest Rules\nThe following are Test Rules\n    for certain aspects of this Success Criterion.\n    It is not necessary to use these particular Test Rules to check for conformance with WCAG, but they are defined and approved test methods.\n    For information on using Test Rules, see\nUnderstanding Test Rules for WCAG Success Criteria\n.\nText has enhanced contrast\nText has minimum contrast",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.6_key_terms",
    "type": "sc",
    "sc_id": "1.4.6",
    "section": "key_terms",
    "text": "[1.4.6 Contrast (Enhanced)] (Level AAA)\nDescription: The visual presentation of text and images of text has a contrast ratio of at least 7:1, except for the following:\n\nSection: key_terms\n\nKey Terms\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\ncontrast ratio\n(L1 + 0.05) / (L2 + 0.05), where\nL1 is the\nrelative luminance\nof the lighter of the colors, and\nL2 is the\nrelative luminance\nof the darker of the colors.\nNote 1\nContrast ratios can range from 1 to 21 (commonly written 1:1 to 21:1).\nNote 2\nBecause authors do not have control over user settings as to how text is rendered\n      (for example font smoothing or anti-aliasing), the contrast ratio for text can be\n      evaluated with anti-aliasing turned off.\nNote 3\nFor the purpose of Success Criteria 1.4.3 and 1.4.6, contrast is measured with respect\n      to the specified background over which the text is rendered in normal usage. If no\n      background color is specified, then white is assumed.\nNote 4\nBackground color is the specified color of content over which the text is to be rendered\n      in normal usage. It is a failure if no background color is specified when the text\n      color is specified, because the user's default background color is unknown and cannot\n      be evaluated for sufficient contrast. For the same reason, it is a failure if no text\n      color is specified when a background color is specified.\nNote 5\nWhen there is a border around the letter, the border can add contrast and would be\n      used in calculating the contrast between the letter and its background. A narrow border\n      around the letter would be used as the letter. A wide border around the letter that\n      fills in the inner details of the letters acts as a halo and would be considered background.\nNote 6\nWCAG conformance should be evaluated for color pairs specified in the content that\n      an author would expect to appear adjacent in typical presentation. Authors need not\n      consider unusual presentations, such as color changes made by the user agent, except\n      where caused by authors' code.\nhuman language\nlanguage that is spoken, written or signed (through visual or tactile means) to communicate\n      with humans\nNote\nSee also\nsign language\n.\nimage of text\ntext that has been rendered in a non-text form (e.g., an image) in order to achieve\n      a particular visual effect\nNote\nThis does not include text that is part of a picture that contains significant other visual content.\nExample\nA person's name on a nametag in a photograph.\nlarge scale\nwith at least 18 point or 14 point bold or font size that would yield equivalent size\n      for Chinese, Japanese and Korean (CJK) fonts\nNote 1\nFonts with extraordinarily thin strokes or unusual features and characteristics that\n      reduce the familiarity of their letter forms are harder to read, especially at lower\n      contrast levels.\nNote 2\nFont size is the size when the content is delivered. It does not include resizing\n      that may be done by a user.\nNote 3\nThe actual size of the character that a user sees is dependent both on the author-defined\n      size and the user's display or user agent settings. For many mainstream body text\n      fonts, 14 and 18 point is roughly equivalent to 1.2 and 1.5 em or to 120% or 150%\n      of the default size for body text (assuming that the body font is 100%), but authors\n      would need to check this for the particular fonts in use. When fonts are defined in\n      relative units, the actual point size is calculated by the user agent for display.\n      The point size should be obtained from the user agent, or calculated based on font\n      metrics as the user agent does, when evaluating this success criterion. Users who\n      have low vision would be responsible for choosing appropriate settings.\nNote 4\nWhen using text without specifying the font size, the smallest font size used on major\n      browsers for unspecified text would be a reasonable size to assume for the font. If\n      a level 1 heading is rendered in 14pt bold or higher on major browsers, then it would\n      be reasonable to assume it is large text. Relative scaling can be calculated from\n      the default sizes in a similar fashion.\nNote 5\nThe 18 and 14 point sizes for roman texts are taken from the minimum size for large\n      print (14pt) and the larger standard font size (18pt). For other fonts such as CJK\n      languages, the \"equivalent\" sizes would be the minimum large print size used for those\n      languages and the next larger standard large print size.\nprogrammatically determined\ndetermined by software from author-supplied data provided in a way that different\nuser agents\n, including\nassistive technologies\n, can extract and present this information to users in different modalities\nExample 1\nDetermined in a markup language from elements and attributes that are accessed directly\n      by commonly available assistive technology.\nExample 2\nDetermined from technology-specific data structures in a non-markup language and exposed\n      to assistive technology via an accessibility API that is supported by commonly available\n      assistive technology.\npure decoration\nserving only an aesthetic purpose, providing no information, and having no functionality\nNote\nText is only purely decorative if the words can be rearranged or substituted without\n      changing their purpose.\nExample\nThe cover page of a dictionary has random words in very light text in the background.\nrelative luminance\nthe relative brightness of any point in a colorspace, normalized to 0 for darkest\n      black and 1 for lightest white\nNote 1\nFor the sRGB colorspace, the relative luminance of a color is defined as L = 0.2126\n      *\nR\n+ 0.7152 *\nG\n+ 0.0722 *\nB\nwhere\nR\n,\nG\nand\nB\nare defined as:\nif RsRGB <= 0.04045 then\nR\n= RsRGB/12.92 else\nR\n= ((RsRGB+0.055)/1.055) ^ 2.4\nif GsRGB <= 0.04045 then\nG\n= GsRGB/12.92 else\nG\n= ((GsRGB+0.055)/1.055) ^ 2.4\nif BsRGB <= 0.04045 then\nB\n= BsRGB/12.92 else\nB\n= ((BsRGB+0.055)/1.055) ^ 2.4\nand RsRGB, GsRGB, and BsRGB are defined as:\nRsRGB = R8bit/255\nGsRGB = G8bit/255\nBsRGB = B8bit/255\nThe \"^\" character is the exponentiation operator. (Formula taken from \n      [\nSRGB\n].)\nNote 2\nBefore May 2021 the value of 0.04045 in the definition was different (0.03928). It was taken from an older version of the specification and has been updated. It has no practical effect on the calculations in the context of these guidelines.\nNote 3\nAlmost all systems used today to view web content assume sRGB encoding. Unless it\n      is known that another color space will be used to process and display the content,\n      authors should evaluate using sRGB colorspace. If using other color spaces, see\nUnderstanding Success Criterion 1.4.3\n.\nNote 4\nIf dithering occurs after delivery, then the source color value is used. For colors\n      that are dithered at the source, the average values of the colors that are dithered\n      should be used (average R, average G, and average B).\nNote 5\nTools are available that automatically do the calculations when testing contrast and\n      flash.\nNote 6\nA\nseparate page giving the relative luminance definition using MathML\nto display the formulas is available.\nsign language\na language using combinations of movements of the hands and arms, facial expressions,\n      or body positions to convey meaning\ntext\nsequence of characters that can be\nprogrammatically determined\n, where the sequence is expressing something in\nhuman language\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.\nuser interface component\na part of the content that is perceived by users as a single control for a distinct\n      function\nNote 1\nMultiple user interface components may be implemented as a single programmatic element.\n      \"Components\" here is not tied to programming techniques, but rather to what the user\n      perceives as separate controls.\nNote 2\nUser interface components include form elements and links as well as components generated\n      by scripts.\nNote 3\nWhat is meant by \"component\" or \"user interface component\" here is also sometimes\n      called \"user interface element\".\nExample\nAn applet has a \"control\" that can be used to move through content by line or page\n      or random access. Since each of these would need to have a name and be settable independently,\n      they would each be a \"user interface component.\"",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.6_situation_A",
    "type": "sc_situation",
    "sc_id": "1.4.6",
    "situation_id": "A",
    "techniques": [
      "G17",
      "G148",
      "G174"
    ],
    "text": "[1.4.6 Contrast (Enhanced)] (Level AAA)\nDescription: The visual presentation of text and images of text has a contrast ratio of at least 7:1, except for the following:\n\nSituation A: text is less than 18 point if not bold and less than 14 point if bold\n\nRelated techniques: G17, G148, G174",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.6_situation_B",
    "type": "sc_situation",
    "sc_id": "1.4.6",
    "situation_id": "B",
    "techniques": [
      "G18",
      "G148",
      "G174"
    ],
    "text": "[1.4.6 Contrast (Enhanced)] (Level AAA)\nDescription: The visual presentation of text and images of text has a contrast ratio of at least 7:1, except for the following:\n\nSituation B: text is as least 18 point if not bold and at least 14 point if bold\n\nRelated techniques: G18, G148, G174",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.6_advisory",
    "type": "sc_advisory",
    "sc_id": "1.4.6",
    "techniques": [
      "G156"
    ],
    "text": "[1.4.6 Contrast (Enhanced)] (Level AAA)\nDescription: The visual presentation of text and images of text has a contrast ratio of at least 7:1, except for the following:\n\nAdvisory techniques for SC 1.4.6: G156",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.6_failures",
    "type": "sc_failures",
    "sc_id": "1.4.6",
    "techniques": [
      "F24",
      "F83"
    ],
    "text": "[1.4.6 Contrast (Enhanced)] (Level AAA)\nDescription: The visual presentation of text and images of text has a contrast ratio of at least 7:1, except for the following:\n\nCommon failures for SC 1.4.6: F24, F83",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.7_intent",
    "type": "sc",
    "sc_id": "1.4.7",
    "section": "intent",
    "text": "[1.4.7 Low or No Background Audio] (Level AAA)\nDescription: For prerecorded\naudio-only content that (1) contains primarily speech in the foreground, (2) is not an audio\n      CAPTCHA or audio logo, and (3) is not vocalization intended to be primarily musical expression\n      such as singing or rapping, at least one of the following is true:\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to ensure that any non-speech sounds are low\n         enough that a user who is hard of hearing can separate the speech from background\n         sounds or other noise foreground speech content.\nThe value of 20 dB was chosen based on Large area assistive listening systems (ALS):\n         Review and recommendations [\nLAALS\n] and In-the-ear measurements of interference in hearing aids from digital wireless\n         telephones [\nHEARING-AID-INT\n]",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.7_success_criterion",
    "type": "sc",
    "sc_id": "1.4.7",
    "section": "success_criterion",
    "text": "[1.4.7 Low or No Background Audio] (Level AAA)\nDescription: For prerecorded\naudio-only content that (1) contains primarily speech in the foreground, (2) is not an audio\n      CAPTCHA or audio logo, and (3) is not vocalization intended to be primarily musical expression\n      such as singing or rapping, at least one of the following is true:\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nFor\nprerecorded\naudio-only\ncontent that (1) contains primarily speech in the foreground, (2) is not an audio\nCAPTCHA\nor audio logo, and (3) is not vocalization intended to be primarily musical expression\n      such as singing or rapping, at least one of the following is true:\nNo Background\nThe audio does not contain background sounds.\nTurn Off\nThe background sounds can be turned off.\n20 dB\nThe background sounds are at least 20 decibels lower than the foreground speech content,\n            with the exception of occasional sounds that last for only one or two seconds.\nNote\nPer the definition of \"decibel,\" background sound that meets this requirement will\n            be approximately four times quieter than the foreground speech content.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.7_benefits",
    "type": "sc",
    "sc_id": "1.4.7",
    "section": "benefits",
    "text": "[1.4.7 Low or No Background Audio] (Level AAA)\nDescription: For prerecorded\naudio-only content that (1) contains primarily speech in the foreground, (2) is not an audio\n      CAPTCHA or audio logo, and (3) is not vocalization intended to be primarily musical expression\n      such as singing or rapping, at least one of the following is true:\n\nSection: benefits\n\nBenefits\nPeople who are hard of hearing often have great difficulty separating speech from\n            background sound.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.7_brief",
    "type": "sc",
    "sc_id": "1.4.7",
    "section": "brief",
    "text": "[1.4.7 Low or No Background Audio] (Level AAA)\nDescription: For prerecorded\naudio-only content that (1) contains primarily speech in the foreground, (2) is not an audio\n      CAPTCHA or audio logo, and (3) is not vocalization intended to be primarily musical expression\n      such as singing or rapping, at least one of the following is true:\n\nSection: brief\n\nIn Brief\nGoal\nPrerecorded speech is not disrupted by background sound.\nWhat to do\nAvoid or lessen background sound, or let users turn it off.\nWhy it's important\nPeople who are hard of hearing may have difficulty distinguishing speech from music and other sounds.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.7_resources",
    "type": "sc",
    "sc_id": "1.4.7",
    "section": "resources",
    "text": "[1.4.7 Low or No Background Audio] (Level AAA)\nDescription: For prerecorded\naudio-only content that (1) contains primarily speech in the foreground, (2) is not an audio\n      CAPTCHA or audio logo, and (3) is not vocalization intended to be primarily musical expression\n      such as singing or rapping, at least one of the following is true:\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nAbout Decibels",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.7_key_terms",
    "type": "sc",
    "sc_id": "1.4.7",
    "section": "key_terms",
    "text": "[1.4.7 Low or No Background Audio] (Level AAA)\nDescription: For prerecorded\naudio-only content that (1) contains primarily speech in the foreground, (2) is not an audio\n      CAPTCHA or audio logo, and (3) is not vocalization intended to be primarily musical expression\n      such as singing or rapping, at least one of the following is true:\n\nSection: key_terms\n\nKey Terms\naudio\nthe technology of sound reproduction\nNote\nAudio can be created synthetically (including speech synthesis), recorded from real\n      world sounds, or both.\naudio-only\na time-based presentation that contains only\naudio\n(no\nvideo\nand no interaction)\nCAPTCHA\ninitialism for \"Completely Automated Public Turing test to tell Computers and Humans\n      Apart\"\nNote 1\nCAPTCHA tests often involve asking the user to type in text that is displayed in an\n      obscured image or audio file.\nNote 2\nA Turing test is any system of tests designed to differentiate a human from a computer.\n      It is named after famed computer scientist Alan Turing. The term was coined by researchers\n      at Carnegie Mellon University.\nlive\ninformation captured from a real-world event and transmitted to the receiver with\n      no more than a broadcast delay\nNote 1\nA broadcast delay is a short (usually automated) delay, for example used in order\n      to give the broadcaster time to cue or censor the audio (or video) feed, but not sufficient\n      to allow significant editing.\nNote 2\nIf information is completely computer generated, it is not live.\nprerecorded\ninformation that is not\nlive\nvideo\nthe technology of moving or sequenced pictures or images\nNote\nVideo can be made up of animated or photographic images, or both.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.7_sufficient",
    "type": "sc_sufficient",
    "sc_id": "1.4.7",
    "techniques": [
      "G56"
    ],
    "text": "[1.4.7 Low or No Background Audio] (Level AAA)\nDescription: For prerecorded\naudio-only content that (1) contains primarily speech in the foreground, (2) is not an audio\n      CAPTCHA or audio logo, and (3) is not vocalization intended to be primarily musical expression\n      such as singing or rapping, at least one of the following is true:\n\nSufficient techniques for SC 1.4.7 (no situation): G56",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.8_intent",
    "type": "sc",
    "sc_id": "1.4.8",
    "section": "intent",
    "text": "[1.4.8 Visual Presentation] (Level AAA)\nDescription: For the visual presentation of blocks of text, a mechanism is available to achieve the following:\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to ensure that visually  rendered text is\n         presented in such a manner that it can be perceived  without its layout interfering\n         with its readability. People with some  cognitive, language and learning disabilities\n         and some low vision users  cannot perceive the text and/or lose their reading place\n         if the text is presented in a  manner that is difficult for them to read.\nPeople with some visual or cognitive disabilities need to be  able to select the color\n         of text and the color of the background. They  sometimes choose combinations that\n         seem unintuitive to someone without  that disability. Sometimes these combinations\n         have very low contrast.  Sometimes only very specific color combinations work for\n         them. Control of color or other aspects of text presentation makes a huge difference\n         to their comprehension.\nFor people with some reading or vision disabilities, long  lines of text can become\n         a significant barrier. They have trouble  keeping their place and following the flow\n         of text. Having a narrow  block of text makes it easier for them to continue on to\n         the next line  in a block. Lines should not exceed 80 characters or glyphs (40 if\n         CJK), where glyphs are the element of writing in the writing system for the text. Studies\n         have shown that Chinese, Japanese and Korean (CJK) characters are approximately twice\n         as wide as non-CJK characters when both types of characters are displayed with characteristics\n         that achieve the same readability, so the maximum line width for CJK characters is\n         half that of non-CJK characters.\nPeople with some cognitive disabilities find it difficult to track text where the\n         lines are close together. Providing extra space between lines and paragraphs allows\n         them to better track the next line and to recognize when they have reached the end\n         of a paragraph. It is best if there are several different options, for instance, space-and-a-half\n         and double spacing for line spacing. By space and a half within paragraphs we mean\n         that top of one line is 150% further from the top of the line below it than would\n         be true when the text is 'single spaced' (the default spacing for the font). By Paragraph\n         spacing that is 1.5 times larger than the line spacing we mean that the spacing from\n         the top of the last line of 1 paragraph is 250% farther from the Top of the first\n         line of the next paragraph (i.e., that there is a blank line between the two paragraphs\n         that is 150% of the single space blank line).\nPeople with certain cognitive disabilities have problems  reading text that is both\n         left and right justified. The uneven spacing  between words in fully justified text\n         can cause \"rivers of white\" space  to run down the page making reading difficult and\n         in some cases  impossible. Text justification can also cause words to be spaced  closely\n         together, so that it is difficult for them to locate word  boundaries.\nThe resizing provision ensures that visually rendered text, including\n         controls and labels using text, can be made larger without requiring the user to then\n         scroll left and right to see all of the content. When the content has been authored\n         so that this is possible, the content is said to reflow. This permits people with\n         low vision and people with cognitive disabilities to increase the size of the text\n         without becoming disoriented.\nThe scaling of content is primarily a user agent  responsibility. User agents that\n         satisfy UAAG 1.0 Checkpoint 4.1 allow  users to configure text scale. The author's\n         responsibility is to create  web content that does not prevent the user agent from\n         scaling the  content and that allows the reflow of the content within the current\n         width of the viewport. See\n1.4.4: Resize Text\nfor additional discussion of resizing text.\nThe horizontal scrolling requirement is not intended to apply to small-screen devices\n         where long words may be displayed on a single line and require users to scroll horizontally.\n         For the purposes of this requirement, authors should ensure that content meets this\n         requirement on standard desktop/laptop displays with the browser window maximized.\n         Since people generally keep their computers for several years, it is best not to rely\n         on the latest desktop/laptop display resolutions but to consider the common desktop/laptop\n         display resolutions over the course of several years when making this evaluation.\nWrapping should always be possible as long as words are not so long that a single\n         word is more than half the width of a full screen. Very long URIs may run off the side of an enlarged screen, but they would not be considered text\n         for \"reading\" and, therefore, would not violate this provision.\nThis provision does not mean that a user would never need to use horizontal scrolling.\n         It only means that they would not need to use horizontal scrolling back and forth\n         to read a line of text. For example, if a page consisted of two equal sized columns\n         of text, it would automatically meet this provision. Enlarging the page would mean\n         that the first column was completely on screen and the user could just scroll vertically\n         down the page to read it. To read the second column, they would horizontally scroll\n         to the right, where the right hand column would then fit entirely within the width\n         of the screen, and read that column without further horizontal scrolling.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.8_success_criterion",
    "type": "sc",
    "sc_id": "1.4.8",
    "section": "success_criterion",
    "text": "[1.4.8 Visual Presentation] (Level AAA)\nDescription: For the visual presentation of blocks of text, a mechanism is available to achieve the following:\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nFor the visual presentation of\nblocks of text\n, a\nmechanism\nis available to achieve the following:\nForeground and background colors can be selected by the user.\nWidth is no more than 80 characters or glyphs (40 if CJK).\nText is not justified (aligned to both the left and the right margins).\nLine spacing (leading) is at least space-and-a-half within paragraphs, and paragraph spacing is at least 1.5 times larger than the line spacing.\nText can be resized without\nassistive technology\nup to 200 percent in a way that does not require the user to scroll horizontally to read a line of text\non a full-screen window\n.\nNote 1\nContent is not required to use these values. The requirement is that a mechanism is available for users to change these presentation aspects. The mechanism can be provided by the browser or other user agent. Content is not required to provide the mechanism.\nNote 2\nWriting systems for some languages use different presentation aspects to improve readability and legibility. If a presentation aspect in this success criterion is not used in a writing system, content in that writing system does not need to use that presentation setting and can conform without it. Authors are encouraged to follow guidance for improving readability and legibility of text in their writing system.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.8_benefits",
    "type": "sc",
    "sc_id": "1.4.8",
    "section": "benefits",
    "text": "[1.4.8 Visual Presentation] (Level AAA)\nDescription: For the visual presentation of blocks of text, a mechanism is available to achieve the following:\n\nSection: benefits\n\nBenefits\nThis success criterion helps low vision users by letting them see  text without distracting\n         presentational features. It lets them  configure text in ways that will be easier\n         for them to see by letting  them control the color and size of blocks of text.\nThis success criterion helps people with cognitive, language  and learning disabilities\n         perceive text and track their location within  blocks of text.\nPeople with some cognitive disabilities can read text better when they select their\n            own foreground and background color combinations.\nPeople with some cognitive disabilities can track their  locations more easily when\n            blocks of text are narrow and when they can  configure the amount of space between\n            lines and paragraphs.\nPeople with some cognitive disabilities can read text more easily when the spacing\n            between words is regular.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.8_examples",
    "type": "sc",
    "sc_id": "1.4.8",
    "section": "examples",
    "text": "[1.4.8 Visual Presentation] (Level AAA)\nDescription: For the visual presentation of blocks of text, a mechanism is available to achieve the following:\n\nSection: examples\n\nExamples\nFigure 1.\nThe following images show examples of single-spacing, space-and-a-half and double-spaced text in a paragraph.\nExamples of glyphs include  \"A\", \"→\" (an arrow symbol), and \"さ\" (a Japanese character).",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.8_brief",
    "type": "sc",
    "sc_id": "1.4.8",
    "section": "brief",
    "text": "[1.4.8 Visual Presentation] (Level AAA)\nDescription: For the visual presentation of blocks of text, a mechanism is available to achieve the following:\n\nSection: brief\n\nIn Brief\nGoal\nText appearance can be altered by users to meet preferences.\nWhat to do\nMeet text display requirements or allow users to adjust them.\nWhy it's important\nSome text formats are more readable for people with cognitive disabilities and low vision.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.8_resources",
    "type": "sc",
    "sc_id": "1.4.8",
    "section": "resources",
    "text": "[1.4.8 Visual Presentation] (Level AAA)\nDescription: For the visual presentation of blocks of text, a mechanism is available to achieve the following:\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nCSS 2 Box Model\nCSS 2 Visual formatting Model\nCSS 2 Visual formatting Model Details\nAbout fluid and fixed width layouts\nAccessible CSS\nPractical Typography - Line Length\nDeveloping sites for users with Cognitive disabilities and learning difficulties\nRDFA Primer\nMULTIFUNK: Bringing computer-supported reading one step further\n, Date: April 2002, ISBN: 82-539-0491-6, Author: Gjertrud W. Kamstrup, Eva Mjøvik,\n            Anne-Lise Rygvold og Bjørn Gunnar Saltnes\nEffective Monitor Display Design\non the  ERIC web portal\nCognitive difficulties and access to information systems - an interaction design perspective\n\", Peter Gregor and Anna Dickinson, Applied Computing, University of Dundee\nLegge, G.E., Pelli, D.G., Rubin, G.S., & Schleske, M.M.:Psychophysics of reading.\n            I. Normal Vision,Vision Research, 25, 239-252, 1985.\nLegge, G.E., Rubin, G.S., Pelli, D.G., & Schleske, M.M.:Psychophysics of reading.\n            II. Low Vision,Vision Research, 25, 253-266, 1985.\nOsaka,N. and Oda, K. (1991). Effective visual field size necessary for vertical reading\n            during Japanese text processing. Bulletin of Psychonomic Society,29(4),345-347.\nBeckmann, P.J. & Legge, G.E. (1996). Psychophysics of reading. XIV. The page-navigation\n            problem in using magnifiers. Vision Research, 36, 3723-3733.\n川嶋英嗣・小田浩一(2003).読書におけるスクロール方向とウィンドウ幅の影響　日本心理学会第67回大会, 502.\n小田浩一・今橋真理子(1995). 文字認知の閾値と読みの閾値.  VISION, 7,\n            165-168.\nOsaka,N. (1994). Size of saccade and fixation duration of eye movements during reading:\n            psychophysics of Japanese text processing. Journal of Optical Society of America A,\n            9(1), 5-13.\n山中今日子・小田浩一 (2007). 漢字の画数と書体のウェイトが視認性に及ぼす\n            影響. 視覚学会2007年夏季大会ポスター 1p1 Vision, P.167.\nLine Length, Volume, and Density\nGuidance on accessible publishing\nAn Accessibility Frontier: Cognitive disabilities and learning difficulties\nCognitive/Perceptual Difference And Good Web Design\n6 Surprising Bad Practices That Hurt Dyslexic Users\nDesign for Dyslexics\nWeb Design for Dyslexia",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.8_key_terms",
    "type": "sc",
    "sc_id": "1.4.8",
    "section": "key_terms",
    "text": "[1.4.8 Visual Presentation] (Level AAA)\nDescription: For the visual presentation of blocks of text, a mechanism is available to achieve the following:\n\nSection: key_terms\n\nKey Terms\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\nblocks of text\nmore than one sentence of text\nconformance\nsatisfying all the requirements of a given standard, guideline or specification\nmechanism\nprocess\nor technique for achieving a result\nNote 1\nThe mechanism may be explicitly provided in the content, or may be\nrelied upon\nto be provided by either the platform or by\nuser agents\n, including\nassistive technologies\n.\nNote 2\nThe mechanism needs to meet all success criteria for the conformance level claimed.\non a full-screen window\non the most common sized desktop/laptop display with the\nviewport\nmaximized\nNote\nSince people generally keep their computers for several years, it is best not to rely\n      on the latest desktop/laptop display resolutions but to consider the common desktop/laptop\n      display resolutions over the course of several years when making this evaluation.\nprocess\nseries of user actions where each action is required in order to complete an activity\nExample 1\nSuccessful use of a series of web pages on a shopping site requires users to view\n      alternative products, prices and offers, select products, submit an order, provide\n      shipping information and provide payment information.\nExample 2\nAn account registration page requires successful completion of a\nTuring test\nbefore\n      the registration form can be accessed.\nrelied upon\nthe content would not\nconform\nif that\ntechnology\nis turned off or is not supported\ntechnology\nmechanism\nfor encoding instructions to be rendered, played or executed by\nuser agents\nNote 1\nAs used in these guidelines \"web technology\" and the word \"technology\" (when used\n      alone) both refer to web content technologies.\nNote 2\nWeb content technologies may include markup languages, data formats, or programming\n      languages that authors may use alone or in combination to create end-user experiences\n      that range from static web pages to synchronized media presentations to dynamic Web\n      applications.\nExample\nSome common examples of web content technologies include HTML, CSS, SVG, PNG, PDF,\n      Flash, and JavaScript.\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.\nviewport\nobject in which the\nuser agent\npresents content\nNote 1\nThe user agent presents content through one or more viewports. Viewports include windows, frames,\n      loudspeakers, and virtual magnifying glasses. A viewport may contain another viewport\n      (e.g., nested frames). Interface components created by the user agent such as prompts,\n      menus, and alerts are not viewports.\nNote 2\nThis definition is based on\nUser Agent Accessibility Guidelines 1.0 Glossary\n[\nUAAG10\n].",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.8_sufficient",
    "type": "sc_sufficient",
    "sc_id": "1.4.8",
    "techniques": [
      "C23",
      "C25",
      "G156",
      "G148",
      "G175",
      "G204",
      "C20",
      "C19",
      "G172",
      "G169",
      "G188",
      "C21",
      "G204",
      "G146",
      "C12",
      "C13",
      "C14",
      "C24",
      "SCR34",
      "G206"
    ],
    "text": "[1.4.8 Visual Presentation] (Level AAA)\nDescription: For the visual presentation of blocks of text, a mechanism is available to achieve the following:\n\nSufficient techniques for SC 1.4.8 (no situation): C23, C25, G156, G148, G175, G204, C20, C19, G172, G169, G188, C21, G204, G146, C12, C13, C14, C24, SCR34, G206",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.8_failures",
    "type": "sc_failures",
    "sc_id": "1.4.8",
    "techniques": [
      "F24",
      "F88"
    ],
    "text": "[1.4.8 Visual Presentation] (Level AAA)\nDescription: For the visual presentation of blocks of text, a mechanism is available to achieve the following:\n\nCommon failures for SC 1.4.8: F24, F88",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.9_intent",
    "type": "sc",
    "sc_id": "1.4.9",
    "section": "intent",
    "text": "[1.4.9 Images of Text (No Exception)] (Level AAA)\nDescription: Images of text are only used for pure decoration or where a particular presentation of text is essential to the information being conveyed.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to enable people who require a particular\n         visual presentation of text to be able to adjust the text presentation as required.\n         This includes people who require the text in a particular font size, foreground and\n         background color, font family, line spacing or alignment.\nThis means implementing the text in a manner that allows its presentation to be changed\n         or providing a mechanism by which users can select an alternate presentation. Using\n         images of text is an example of an implementation that does not allow users to alter\n         the presentation of the text within it.\nIn some situations, a particular visual presentation of the text is essential to the\n         information being conveyed. This means that information would be lost without that\n         particular visual presentation. In this case implementing the text in a manner that\n         allows its presentation to be changed is not required. This includes text that demonstrates\n         a particular visual aspect of the text, such as a particular font family, or text\n         that conveys an identity, such as text within a company logo.\nText that is decorative does not require implementing the text in a manner that allows\n         its presentation to be changed.\nThe definition of image of text contains the note: Note: This does not include text that is part of a picture that contains significant\n         other visual content. Examples of such pictures include graphs, screenshots, and diagrams which visually\n         convey important information through more than just text.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.9_success_criterion",
    "type": "sc",
    "sc_id": "1.4.9",
    "section": "success_criterion",
    "text": "[1.4.9 Images of Text (No Exception)] (Level AAA)\nDescription: Images of text are only used for pure decoration or where a particular presentation of text is essential to the information being conveyed.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nImages of text\nare only used for\npure decoration\nor where a particular presentation of\ntext\nis\nessential\nto the information being conveyed.\nNote\nLogotypes (text that is part of a logo or brand name) are considered essential.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.9_benefits",
    "type": "sc",
    "sc_id": "1.4.9",
    "section": "benefits",
    "text": "[1.4.9 Images of Text (No Exception)] (Level AAA)\nDescription: Images of text are only used for pure decoration or where a particular presentation of text is essential to the information being conveyed.\n\nSection: benefits\n\nBenefits\nPeople with low vision (who may have trouble reading the text with the authored font\n            family, size and/or color).\nPeople with visual tracking problems (who may have trouble reading the text with the\n            authored line spacing and/or alignment).\nPeople with cognitive disabilities that affect reading.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.9_examples",
    "type": "sc",
    "sc_id": "1.4.9",
    "section": "examples",
    "text": "[1.4.9 Images of Text (No Exception)] (Level AAA)\nDescription: Images of text are only used for pure decoration or where a particular presentation of text is essential to the information being conveyed.\n\nSection: examples\n\nExamples\nA quote\nA web page contains a quote. The quote itself is presented as italicized text, indented\n               from the left margin. The name of the person to whom the quote is attributed is below\n               the quote with 1.5x the line space and further indented from the left margin. CSS\n               is used to position the text; set the spacing between lines; as well as display the\n               text's font family, size, color and decoration.\nNavigation items\nA web page contains a menu of navigation links that have both an icon and text to\n               describe their target. CSS is used to display the text's font family, size and foreground\n               and background colors; as well as the spacing between the navigation links.\nA logo containing text\nA website contains the organization's logo in the top left corner of each web page.\n               The logo contains logotype (text as part, or all, of the logo). The visual presentation\n               of the text is essential to the identity of the logo and is included as a gif image\n               which does not allow the text characteristics to be changed. The image has a text\n               alternative.\nRepresentation of a font family\nA web page contains information about a particular font family. Substituting the font\n               family with another font would defeat the purpose of the representation. The representation\n               is included as a jpeg image which does not allow the text characteristics to be changed.\n               The image has a text alternative.\nA representation of a letter\nA web page contains a representation of an original letter. The depiction of the letter\n               in its original format is essential to information being conveyed about the time period\n               in which it was written. The letter is included as a gif image which does not allow\n               the text characteristics to be changed. The image has a text alternative.\nSymbolic text characters\nA form allows users to enter blocks of text. The form provides a number of buttons,\n               including functions to style the text and check spelling. Some of the buttons use\n               text characters that do not form a sequence that expresses something in human language.\n               For example \"B\" to increase font weight, \"I\" to italicize the text and \"ABC\" to check\n               the spelling. The symbolic text characters are included as gif images which do not\n               allow the text characteristics to be changed. The buttons have text alternatives.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.9_brief",
    "type": "sc",
    "sc_id": "1.4.9",
    "section": "brief",
    "text": "[1.4.9 Images of Text (No Exception)] (Level AAA)\nDescription: Images of text are only used for pure decoration or where a particular presentation of text is essential to the information being conveyed.\n\nSection: brief\n\nIn Brief\nGoal\nUsers can always adjust how text is presented.\nWhat to do\nDo not use pictures of text unless there is no other way to present information.\nWhy it's important\nPeople cannot alter how text looks in images.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.9_resources",
    "type": "sc",
    "sc_id": "1.4.9",
    "section": "resources",
    "text": "[1.4.9 Images of Text (No Exception)] (Level AAA)\nDescription: Images of text are only used for pure decoration or where a particular presentation of text is essential to the information being conveyed.\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nCSS Web fonts\nWeblog comments: WebKit now supports CSS @font-face rules\nCreating Cross Browser Compatible CSS Text Shadows\nCSS and text",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.9_test_rules",
    "type": "sc",
    "sc_id": "1.4.9",
    "section": "test_rules",
    "text": "[1.4.9 Images of Text (No Exception)] (Level AAA)\nDescription: Images of text are only used for pure decoration or where a particular presentation of text is essential to the information being conveyed.\n\nSection: test_rules\n\nTest Rules\nThe following are Test Rules\n    for certain aspects of this Success Criterion.\n    It is not necessary to use these particular Test Rules to check for conformance with WCAG, but they are defined and approved test methods.\n    For information on using Test Rules, see\nUnderstanding Test Rules for WCAG Success Criteria\n.\nHTML images contain no text",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.9_key_terms",
    "type": "sc",
    "sc_id": "1.4.9",
    "section": "key_terms",
    "text": "[1.4.9 Images of Text (No Exception)] (Level AAA)\nDescription: Images of text are only used for pure decoration or where a particular presentation of text is essential to the information being conveyed.\n\nSection: key_terms\n\nKey Terms\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\nessential\nif removed, would fundamentally change the information or functionality of the content,\nand\ninformation and functionality cannot be achieved in another way that would conform\nhuman language\nlanguage that is spoken, written or signed (through visual or tactile means) to communicate\n      with humans\nNote\nSee also\nsign language\n.\nimage of text\ntext that has been rendered in a non-text form (e.g., an image) in order to achieve\n      a particular visual effect\nNote\nThis does not include text that is part of a picture that contains significant other visual content.\nExample\nA person's name on a nametag in a photograph.\nprogrammatically determined\ndetermined by software from author-supplied data provided in a way that different\nuser agents\n, including\nassistive technologies\n, can extract and present this information to users in different modalities\nExample 1\nDetermined in a markup language from elements and attributes that are accessed directly\n      by commonly available assistive technology.\nExample 2\nDetermined from technology-specific data structures in a non-markup language and exposed\n      to assistive technology via an accessibility API that is supported by commonly available\n      assistive technology.\npure decoration\nserving only an aesthetic purpose, providing no information, and having no functionality\nNote\nText is only purely decorative if the words can be rearranged or substituted without\n      changing their purpose.\nExample\nThe cover page of a dictionary has random words in very light text in the background.\nsign language\na language using combinations of movements of the hands and arms, facial expressions,\n      or body positions to convey meaning\ntext\nsequence of characters that can be\nprogrammatically determined\n, where the sequence is expressing something in\nhuman language\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.9_sufficient",
    "type": "sc_sufficient",
    "sc_id": "1.4.9",
    "techniques": [
      "C22",
      "C30",
      "G140",
      "PDF7"
    ],
    "text": "[1.4.9 Images of Text (No Exception)] (Level AAA)\nDescription: Images of text are only used for pure decoration or where a particular presentation of text is essential to the information being conveyed.\n\nSufficient techniques for SC 1.4.9 (no situation): C22, C30, G140, PDF7",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.9_advisory",
    "type": "sc_advisory",
    "sc_id": "1.4.9",
    "techniques": [
      "C12",
      "C13",
      "C14",
      "C8",
      "C6"
    ],
    "text": "[1.4.9 Images of Text (No Exception)] (Level AAA)\nDescription: Images of text are only used for pure decoration or where a particular presentation of text is essential to the information being conveyed.\n\nAdvisory techniques for SC 1.4.9: C12, C13, C14, C8, C6",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.10_intent",
    "type": "sc",
    "sc_id": "1.4.10",
    "section": "intent",
    "text": "[1.4.10 Reflow] (Level AA)\nDescription: Content can be presented without loss of information or functionality, and without requiring scrolling in two dimensions for:\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to let users enlarge text and other related content without having to scroll in two dimensions to read. When lines of text extend beyond the edge of a\nviewport\n, users will be forced to scroll back-and-forth to read line by line. This can cause them to lose their place and can significantly increase both physical and cognitive effort. Therefore, most sections of content are expected to reflow within the appropriate sizing requirement defined by this success criterion.\nA\nsection of content\nthat requires two-dimensional layout for understanding or functionality, such as a table or map, has an exception to this success criterion. However, sections of content within the two-dimensional layout, such as each cell within a table, would still need to meet this success criterion. Although there is an exception for sections of content that require two-dimensional layout for understanding or functionality, authors can improve the user's experience by making efforts to reduce scrolling for that type of content.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.10_success_criterion",
    "type": "sc",
    "sc_id": "1.4.10",
    "section": "success_criterion",
    "text": "[1.4.10 Reflow] (Level AA)\nDescription: Content can be presented without loss of information or functionality, and without requiring scrolling in two dimensions for:\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nContent can be presented without loss of information or functionality, and without requiring scrolling in two dimensions for:\nVertical scrolling content at a width equivalent to 320\nCSS pixels\n;\nHorizontal scrolling content at a height equivalent to 256\nCSS pixels\n.\nExcept for parts of the content which require two-dimensional layout for usage or meaning.\nNote 1\n320 CSS pixels is equivalent to a starting\nviewport\nwidth of 1280 CSS pixels wide at 400% zoom. For web content which is designed to scroll horizontally (e.g., with vertical text), 256 CSS pixels is equivalent to a starting viewport height of 1024 CSS pixels at 400% zoom.\nNote 2\nExamples of content which requires two-dimensional layout are images required for understanding (such as maps and diagrams), video, games, presentations, data tables (not individual cells), and interfaces where it is necessary to keep toolbars in view while manipulating content. It is acceptable to provide two-dimensional scrolling for such parts of the content.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.10_examples",
    "type": "sc",
    "sc_id": "1.4.10",
    "section": "examples",
    "text": "[1.4.10 Reflow] (Level AA)\nDescription: Content can be presented without loss of information or functionality, and without requiring scrolling in two dimensions for:\n\nSection: examples\n\nExamples\nOne column view in responsive design\nNote that as the zoom percentage increases, the navigation changes first to hide options behind a \"More\" dropdown menu. As zooming continues, most navigation options are eventually behind a \"hamburger\" menu button. All the information and functionality is still available from this web page. There is no horizontal scrolling.\nPDF offering reflow\nIn a PDF created to conform to PDF/Universal Accessibility (ISO 14289), the content can be reflowed and zoomed in to make reading possible for someone with low-vision.\nAlternative presentations to truncating content\nA web page presents long strings of text which are truncated to save space. E.g., user generated content that does not fit into the space allocated for the interface's design, or authentication keys which do not wrap, etc.. The content is presented as truncated, but a link is provided to a web page where the content is fully visible without truncation, or a mechanism is provided on the web page to reveal the truncated content.\nPreformatted text conveys meaning\nThe presentation of text where the layout has specific meaning, such as code indentation for Python or \"ascii art\" as just two examples, would lose meaning if the layout were not presented correctly. This success criterion does not apply where that meaning would be lost. However, this is not the case for most other instances of text where text wrapping can be applied without loss of meaning. Additionally, for instances of indentation that convey meaning, consider reducing the size of the indentation at zoomed in levels. As the text will be bigger, the reduced indentation width can still be noticeable.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.10_brief",
    "type": "sc",
    "sc_id": "1.4.10",
    "section": "brief",
    "text": "[1.4.10 Reflow] (Level AA)\nDescription: Content can be presented without loss of information or functionality, and without requiring scrolling in two dimensions for:\n\nSection: brief\n\nIn Brief\nGoal\nContent can be enlarged without increasing line length.\nWhat to do\nMake lines of text reflow within the viewport.\nWhy it's important\nPeople who need bigger text find it difficult if they must scroll to read long lines.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.10_resources",
    "type": "sc",
    "sc_id": "1.4.10",
    "section": "resources",
    "text": "[1.4.10 Reflow] (Level AA)\nDescription: Content can be presented without loss of information or functionality, and without requiring scrolling in two dimensions for:\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nReading with Low Vision in a Digital Setting: by Wayne Dick, PhD.\nOperational Overhead Caused by Horizontal Scrolling Text\nby Wayne Dick, 2017. The study shows the impact of horizontal scrolling on reading effort\nAccessibility Requirements for People with Low Vision\n. W3C First Public Working Draft 17 March 2016\nResponsive design resources\nfrom MDN Web docs\nResponsive web design basics\ntutorial from Google",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.10_test_rules",
    "type": "sc",
    "sc_id": "1.4.10",
    "section": "test_rules",
    "text": "[1.4.10 Reflow] (Level AA)\nDescription: Content can be presented without loss of information or functionality, and without requiring scrolling in two dimensions for:\n\nSection: test_rules\n\nTest Rules\nThe following are Test Rules\n    for certain aspects of this Success Criterion.\n    It is not necessary to use these particular Test Rules to check for conformance with WCAG, but they are defined and approved test methods.\n    For information on using Test Rules, see\nUnderstanding Test Rules for WCAG Success Criteria\n.\nMeta viewport allows for zoom",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.10_key_terms",
    "type": "sc",
    "sc_id": "1.4.10",
    "section": "key_terms",
    "text": "[1.4.10 Reflow] (Level AA)\nDescription: Content can be presented without loss of information or functionality, and without requiring scrolling in two dimensions for:\n\nSection: key_terms\n\nKey Terms\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\nCSS pixel\nvisual angle of about 0.0213 degrees\nA CSS pixel is the canonical unit of measure for all lengths and measurements in CSS.\n      This unit is density-independent, and distinct from actual hardware pixels present\n      in a display. User agents and operating systems should ensure that a CSS pixel is\n      set as closely as possible to the\nCSS Values and Units Module Level 3 reference pixel\n[\ncss3-values\n], which takes into account the physical dimensions of the display\n      and the assumed viewing distance (factors that cannot be determined by content authors).\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.\nviewport\nobject in which the\nuser agent\npresents content\nNote 1\nThe user agent presents content through one or more viewports. Viewports include windows, frames,\n      loudspeakers, and virtual magnifying glasses. A viewport may contain another viewport\n      (e.g., nested frames). Interface components created by the user agent such as prompts,\n      menus, and alerts are not viewports.\nNote 2\nThis definition is based on\nUser Agent Accessibility Guidelines 1.0 Glossary\n[\nUAAG10\n].",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.11_intent",
    "type": "sc",
    "sc_id": "1.4.11",
    "section": "intent",
    "text": "[1.4.11 Non-text Contrast] (Level AA)\nDescription: The visual presentation of the following have a contrast ratio of at least 3:1 against adjacent color(s):\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to ensure that user interface components (i.e., controls) and meaningful graphics are distinguishable by people with moderately low vision. The requirements and rationale are similar to those for large text in\n1.4.3 Contrast (Minimum)\n. Note that this requirement does not apply to\ninactive\nuser interface components.\nLow contrast controls are more difficult to perceive, and may be completely missed by people with a visual impairment. Similarly, if a graphic is needed to understand the content or functionality of the web page then it should be perceivable by people with low vision or other impairments without the need for contrast-enhancing assistive technology.\nNote\nThe 3:1 contrast ratios referenced in this success criterion is intended to be treated as threshold values. When comparing the computed contrast ratio to the success criterion ratio, the computed values should not be rounded (e.g. 2.999:1 would not meet the 3:1 threshold).\nNote\nBecause authors do not have control over user settings for font smoothing and anti-aliasing, when evaluating this\n\t\t\t\t\t Success Criterion, refer to the colors obtained from the user agent, or the underlying\n\t\t\t\t\t markup and stylesheets, rather than the non-text elements as presented on screen.\nDue to anti-aliasing, particularly thin lines and shapes of non-text elements may be rendered by user agents with\n\t\t\t\t\t a much fainter color than the actual color defined in the underlying CSS. This can lead to situations where\n\t\t\t\t\t non-text elements have a contrast ratio that nominally passes the Success Criterion, but have a much lower contrast\n\t\t\t\t\t in practice. In these cases, best practice would be for authors to avoid particularly thin lines and shapes,\n\t\t\t\t\t or to use a combination of colors that exceeds the normative requirements of this success criterion.\nUser Interface Components\nUnless the control is\ninactive\n, any visual information provided that is necessary for a user to identify that a control is present and how to operate it must have a minimum 3:1 contrast ratio with the adjacent colors. Also, any visual information necessary to indicate state, such as whether a component is selected or focused must also ensure that the information used to identify the control in that state has a minimum 3:1 contrast ratio.\nThis success criterion does not require that changes in color that differentiate between states of an individual component meet the 3:1 contrast ratio when they do not appear next to each other. For example, there is not a new requirement that visited links contrast with the default color, or that mouse hover indicators contrast with the default state. However, the component must not lose contrast with the adjacent colors, and non-text indicators such as the check in a checkbox, or an arrow graphic indicating a menu is selected or open must have sufficient contrast to the adjacent colors.\nBoundaries\nThis success criterion does not require that controls have a visual boundary indicating the hit area, but if the visual indicator of the control is the only way to identify the control, then that indicator must have sufficient contrast. If text (or an icon) within a button or placeholder text inside a text input is visible and there is no visual indication of the hit area then the success criterion is passed. If a button with text also has a colored border, since the border does not provide the only indication there is no contrast requirement beyond the text contrast (\n1.4.3 Contrast (Minimum)\n). Note that for people with cognitive disabilities it is recommended to delineate the boundary of controls to aid in the recognition of controls and therefore the completion of activities.\nFigure 1.\nPass:\nA button without a visual boundary, and the same button with a focus indicator that is a defined visual boundary of grey (\n#949494\n) adjacent to white.\nAdjacent colors\nFor user interface components 'adjacent colors' means the colors adjacent to the component. For example, if an input has a white internal background, dark border, and white external background the 'adjacent color' to the component would be the white external background.\nFigure 2.\nPass:\nA standard text input with a grey border (\n#767676\n) and white adjacent color outside the component\nIf components use several colors, any color which does not interfere with identifying the component can be ignored for the purpose of measuring contrast ratio. For example, a 3D drop-shadow on an input, or a dark border line between contrasting backgrounds is considered to be subsumed into the color closest in brightness (perceived luminance).\nThe following example shows an input that has a light background on the inside and a dark background around it. The input also has a dark grey border which is considered to be subsumed into the dark background. The border does not interfere with identifying the component, so the contrast ratio is taken between the white background and dark blue background.\nFigure 3.\nPass:\nThe contrast of the input background (white) and color adjacent to the control (dark blue\n#003366\n) is sufficient. There is also a border (silver) on the component that is not required to contrast with either.\nFor visual information required to identify a state, such as the check in a checkbox or the thumb of a slider, that part might be within the component so the adjacent color might be another part of the component.\nFigure 4.\nPass:\nA customized checkbox with light grey check (\n#E5E5E5\n), which has a contrast ratio of 5.6:1 with the purple box (\n#6221EA\n).\nIt is possible to use a flat design where the status indicator fills the component and does not contrast with the component, but does contrast with the colors adjacent to the component.\nFigure 5.\nPass:\nThe first radio button shows the default state with a grey (\n#949494\n) circle. The second and third show the radio button selected and filled with a color that contrasts with the color adjacent to the component. The last example shows the state indicator contrasting with the component colors.\nRelationship with Use of Color\nThe\nUse of Color\nsuccess criterion addresses changing\nonly the color\n(hue) of an object or text without otherwise altering the object's form. The principle is that contrast ratio (the difference in brightness) can be used to distinguish text or graphics. For example,\nG183: Using a contrast ratio of 3:1 with surrounding text and providing additional visual cues on hover for links or controls where color alone is used to identify them\nis a technique to use a contrast ratio of 3:1 with surrounding text to distinguish links and controls. In that case the Working Group regards a link color that meets the 3:1 contrast ratio relative to the non-linked text color as satisfying the Success Criterion\n1.4.1 Use of color\nsince it is relying on contrast ratio as well as color (hue) to convey that the text is a link.\nNon-text information within controls that uses a change of hue alone to convey the value or state of an input, such as a 1-5 star indicator with a black outline for each star filled with either yellow (full) or white (empty) is likely to fail the Use of color criterion rather than this one.\nFigure 6.\nPass:\nTwo examples which pass this success criterion, using either a solid fill to indicate a checked-state that has contrast, or a thicker border as well as yellow fill.\nFigure 7.\nFail:\nThe first example fails the Use of color criterion due to relying on yellow and white hues. The second example fails the Non-text contrast criterion due to the yellow (\n#FFF000\n) to white contrast ratio of 1.2:1.\nUsing a change of contrast for focus and other states is a technique to differentiate the states. This is the basis for\nG195: Using an author-supplied, visible focus indicator\n, and more techniques are being added.\nRelationship with Focus Visible\nIn combination with\n2.4.7 Focus Visible\n, the visual focus indicator for a component\nmust\nhave sufficient contrast against the adjacent background when the component is focused, except where the appearance of the component is determined by the user agent and not modified by the author.\nMost focus indicators appear outside the component - in that case it needs to contrast with the background that the component is on. Other cases include focus indicators which are:\nonly inside the component and need to contrast with the adjacent color(s) within the component.\nthe border of the component (inside the component and adjacent to the outside) and need to contrast with both adjacent colours.\npartly inside and partly outside, where either part of the focus indicator can contrast with the adjacent colors.\nFigure 8.\nPass:\nThe internal yellow indicator (\n#FFFF00\n) contrasts with the blue button background (\n#4189B9\n).\nFigure 9.\nFail:\nThe external yellow indicator (\n#FFFF00\n) does not contrast with the white background (\n#FFF\n) which the component is on.\nFigure 10.\nPass:\nThe external green indicator (\n#008000\n) does contrast with the white background (\n#FFF\n) which the component is on. It does not need to contrast with both the component background and the component, as visually the effect is that the button is noticeably larger, and it's not necessary for a user to be able to discern this extra border in isolation. Although this passes non-text contrast, it is not a good indicator unless it is very thick.\nNew in WCAG 2.2:\nThere is a AAA criterion in WCAG 2.2 that addresses this aspect,\nFocus Appearance\n.\nIf an indicator is partly inside and partly outside the component, either part of the indicator could provide contrast.\nFigure 11.\nPass:\nThe focus indicator is partially inside, partially outside the button. The internal part of the yellow indicator (\n#FFFF00\n) contrasts with the blue button background (\n#4189B9\n).\nIf the focus indicator changes the border of the component within the visible boundary it must contrast with the component. Typically an outline goes around (outside) the visible boundary of the component, in this case changing the border is just inside the visible edge of the component.\nFigure 12.\nFail:\nThe border of the control changes from blue (\n#4189B9\n) to green (\n#4B933A\n). This is within the component and does not contrast with the inside background of the component.\nFigure 13.\nFail:\nAn inner border of dark green (\n#008000\n) does contrast with the black border, but does not contrast with the blue component background.\nFigure 14.\nPass:\nAn inner border of white contrasts with the black border and the blue component background.\nNote that this success criterion does not directly compare the focused and unfocused states of a control - if the focus state relies on a change of color (e.g., changing\nonly\nthe background color of a button), this success criterion does not define any requirement for the difference in contrast between the two states.\nFigure 15.\nNot in scope:\nThe change of background within the component is not in scope of non-text contrast. However, this would not pass\nUse of color\n.\nHover states\nThe language of Non-text Contrast specifically calls out \"visual information required to identify...states.\" When users talk about a hover state, they are normally referring to a visual effect that takes place when the pointer is positioned over a control. However, there are a number of HTML components (such as buttons, checkboxes, radio buttons, and selects) which do not by default display any additional visual effects when the user moves a pointer control over them. The pointer itself, via its location, is the indicator of whether the user is hovering on a component. Therefore, additional author-supplied visual treatments for hover are not \"required to identify\" the hover state. Those treatments can be considered supplemental and do not themselves need to contrast 3:1 against the background.\nThis is not to say that other hover effects are discouraged. For instance, some native components alter the shape of the pointer when it is hovering over a control; the pointer becomes an I-beam when it hovers over text inputs and text areas. There will be cases where some users may benefit from additional visual hover effects, such as bolding text or use of drop shadows. However, other users may find strong hover effects distracting. The key consideration for any hover effect is that it does not cause a component itself to lose sufficient contrast against adjacent colors, or cause the visual indicators for other states, such as focus or selection, to lose sufficient contrast.\nUser Interface Component Examples\nFor designing focus indicators, selection indicators and user interface components that need to be perceived clearly, the following are examples that have sufficient contrast.\nPassing User Interface Component Examples\nType\nDescription\nExamples\nLink text\nThe browser's default link text color is covered by\n1.4.3 Contrast (Minimum)\n. Since the underline is the same color as the text, which must meet at least 3:1 to pass, the default underline will always pass the requirements of Non-text Contrast.\nDefault focus style\nLinks are required to have a visible focus indicator by\n2.4.7 Focus Visible\n. Where the focus style of the user-agent is not adjusted on interactive controls (such as links, form fields or buttons) by the website (author), the default focus style is exempt from contrast requirements (but must still be visible).\nButtons\nA button which has a distinguishing indicator such as position, text style, or context does not need a\ncontrasting\nvisual indicator to show that it is a button, although some users are likely to identify a button with an outline that meets contrast requirements more easily.\nText input (minimal)\nWhere a text-input has a visual indicator to show it is an input, such as a bottom border (\n#767676\n), that indicator must meet 3:1 contrast ratio.\nText input\nWhere a text-input has an indicator such as a complete border (\n#767676\n), that indicator must meet 3:1 contrast ratio.\nText input focus style\nA focus indicator is required. While in this case the additional gray (\n#CCC\n) outline has an insufficient contrast of 1.6:1 against the white (\n#FFF\n) background, the cursor/caret which is displayed when the input receives focus\ndoes\nprovide a sufficiently strong visual indication.\nText input using background color\nText inputs that have no border and are differentiated only by a background color must have a 3:1 contrast ratio to the adjacent background (\n#043464\n).\nToggle button\nThe toggle button's internal background (\n#070CD5\n) has a good contrast with the external white background. Also, the round toggle within (\n#7AC2FF\n) contrasts with the internal background.\nDropdown indicator\nThe down-arrow is required to understand that there is drop-down functionality, it has a contrast of 4.7:1 for the white icon on dark gray (\n#6E747B\n).\nDropdown indicator\nThe down-arrow is required to understand that there is drop-down functionality, it has a contrast of 21:1 for the black icon on white.\nCheckbox - empty\nA black border on a white background indicates the checkbox.\nCheckbox - checked\nA black border on a white background indicates the checkbox, the black tick shape indicates the state of checked.\nCheckbox - Subtle hover style\nA checkbox is visually identified by its black border against a white background, but when the mouse pointer hovers on the checkbox, a subtle grey background is added (\n#DEDEDE\n). The black border has a 15:1 contrast ratio with the grey background, so the checkbox continues to have good contrast. Note that the grey hover effect does not itself need to contrast 3:1 with the page background, since the pointer position is the primary indicator of the hover state.\nThe following are examples that have insufficient contrast.\nFailing User Interface Component Examples\nType\nDescription\nExamples\nColored underline is the only indicator of a link\nLink and non-link text are both white on an almost-black (\n#0D0F13\n) background. The link's custom underline (\n#B1262B\n) is the only way to identify the link. The red underline contrasts less than 3:1 with the background color.\nCheckbox - border color\nThe grey border color of the checkbox (\n#9D9D9D\n) has a contrast ratio of 2.7:1 with the white background, which is not sufficient for the visual information required to identify the checkbox.\nCheckbox - subtle focus style\nA focus indicator is required. If the focus indicator is styled by the author, it must meet the 3:1 contrast ratio with adjacent colors. In this case, the gray (\n#AAA\n) indicator has an insufficient ratio of 2.3:1 with the white (\n#FFF\n) adjacent background.\nInactive User Interface Components\nUser Interface Components that are not available for user interaction (e.g., a disabled control in HTML) are not required to meet contrast requirements. An inactive user interface component is visible but not currently operable. An example would be a submit button at the bottom of a form that is visible but cannot be activated until all the required fields in the form are completed.\nFigure 16.\nAn inactive button using default browser styles\nInactive components, such as disabled controls in HTML, are not available for user interaction. The decision to exempt inactive controls from the contrast requirements was based on a number of considerations. Although it would be beneficial to some people to discern inactive controls, a one-size-fits-all solution has been very difficult to establish. A method of varying the presentation of disabled controls, such as adding an icon for disabled controls, based on user preferences is anticipated as an advancement in the future.\nGraphical Objects\nThe term \"graphical object\" applies to stand-alone icons such as a print icon (with no text), and the important parts of a more complex diagram such as each line in a graph. For simple graphics such as single-color icons the entire image is a graphical object. Images made up of multiple lines, colors and shapes will be made of multiple graphical objects, some of which are required for understanding.\nNot every graphical object needs to contrast with its surroundings - only those that are required for a user to understand what the graphic is conveying.\nGestalt principles\nsuch as the \"law of continuity\" can be used to ignore minor overlaps with other graphical objects or colors.\nImage\nNotes\nThe phone icon is a simple shape within the orange (\n#E3660E\n) circle. The meaning can be understood from that icon alone, the background behind the circle is irrelevant. The orange background and the white icon have a contrast ratio greater than 3:1, which passes.\nThe graphical object is the white phone icon.\nA magnet can be understood by the \"U\" shape with lighter colored tips. Therefore to understand this graphic you should be able to discern the overall shape (against the background) and the lighter colored tips (against the rest of the U shape and the background).\nThe graphical objects are the \"U\" shape (by outline or by the solid red color #D0021B), and each tip of the magnet.\nThe symbol to show a currency (the £) going down can be understood with recognition of the shape (down arrow) and the currency symbol (pound icon with the shape which is part of the graphic). To understand this graphic you need to discern the arrow shape against the white background, and the pound icon against the yellow background (\n#F5A623\n).\nThe graphical objects are the shape and the currency symbol.\nIn order to understand the graph you need to discern the lines and shapes for each condition. To perceive the values of each line along the chart you need to discern the grey lines marking the graduated 100 value increments.\nThe graphical objects are the lines in the graph, including the background lines for the values, and the colored lines with shapes.\nThe lines should have 3:1 contrast against their background, but as there is little overlap with other lines they do not need to contrast with each other or the graduated lines. (See the testing principles below.)\nTo understand the pie chart you have to discern each slice of the pie chart from the others.\nThe graphical objects are the slices of the pie (chart).\nNote: If the values of the pie chart slices were also presented in a conforming manner (see the Pie Charts example for details), the slices would not be required for understanding.\nTaking the magnet image above as an example, the process for establishing the graphical object(s) is to:\nAssess what part of each image is needed to understand what it represents.\nThe magnet's \"U\" shape can be conveyed by the outline or by the red background (either is acceptable). The white tips are also important (otherwise it would be a horseshoe), which needs to contrast with the red background.\nAssume that the user could only see those aspects. Do they contrast with the adjacent colors?\nThe outline of the magnet contrasts with the surrounding text (black/white), and the red and white between the tips also has sufficient contrast.\nDue to the strong contrast of the red and white, it would also be possible to only put the outline around the white tips of the magnet and it would still conform.\nRequired for Understanding\nThe term \"required for understanding\" is used in the success criterion as many graphics do not need to meet the contrast requirements. If a person needs to perceive a graphic, or part of a graphic (a graphical object) in order to understand the content it should have sufficient contrast. However, that is not a requirement when:\nA graphic with text embedded or overlayed conveys the same information, such as labels\nand\nvalues on a chart.\nNote\nText within a graphic must meet\n1.4.3 Contrast (Minimum)\n.\nThe graphic is for aesthetic purposes that does not require the user to see or understand it to understand the content or use the functionality.\nThe information is available in another form, such as in a table that follows the graph, which becomes visible when a \"Long Description\" button is pressed.\nThe graphic is part of a logo or brand name (which is considered \"essential\" to its presentation).\nGradients\nGradients can reduce the apparent contrast between areas, and make it more difficult to test. The general principles is to identify the graphical object(s) required for understanding, and take the central color of that area. If you remove the adjacent color which does not have sufficient contrast, can you still identify and understand the graphical object?\nFigure 17.\nRemoving the background which does not have sufficient contrast highlights that the graphical object (the \"i\") is not then understandable.\nDynamic Examples\nSome graphics may have interactions that either vary the contrast, or display the information as text when you mouseover/tap/focus each graphical object. In order for someone to discern the graphics exist at all, the unfocused default version must already have sufficiently contrasting colors or text. For the area that receives focus, information can then be made available dynamically as pop-up text, or be foregrounded dynamically by increasing the contrast.\nFigure 18.\nA dynamic chart where the current 'slice' is hovered or focused, which activates the associated text display of the values and highlights the series\nInfographics\nInfographics can mean any graphic conveying data, such as a chart or diagram. On the web it is often used to indicate a large graphic with lots of statements, pictures, charts or other ways of conveying data. In the context of graphics contrast, each item within such an infographic should be treated as a set of graphical objects, regardless of whether it is in one file or separate files.\nInfographics often fail to meet several WCAG level AA criteria including:\n1.1.1 Non-text Content\n1.4.1 Use of Color\n1.4.3 Contrast (Minimum)\n1.4.5 Images of Text\nAn infographic can use text which meets the other criteria to minimise the number of graphical objects required for understanding. For example, using text with sufficient contrast to provide the values in a chart. A long description would also be sufficient because then the infographic is not relied upon for understanding.\nSymbolic text characters\nWhen text characters are used as symbols – used for their visual appearance, rather than\nexpressing something in human language\n– they fall under the definition of\nnon-text content\n.\nFigure 19.\nEven though the two buttons use text characters — an uppercase\nX\n, often used for \"Close\" buttons, and a\n>\ncharacter, to act as a right-pointing arrow — they count as non-text characters/symbols. Their contrast ratio of just above 3:1 passes this success criterion.\nEssential Exception\nGraphical objects do not have to meet the contrast requirements when \"a particular presentation of graphics is essential to the information being conveyed\". The Essential exception is intended to apply when there is no way of presenting the graphic with sufficient contrast without undermining the meaning. For example:\nLogotypes and flags\n: The brand logo of an organization or product is the representation of that organization and therefore exempt. Flags may not be identifiable if the colors are changed to have sufficient contrast.\nSensory\n: There is no requirement to change pictures of real life scenes such as photos of people or scenery.\nRepresenting other things\n: If you cannot represent the graphic in any other way, it is essential. Examples include:\nScreenshots to demonstrate how a website appeared.\nDiagrams of medical information that use the colors found in biology (\nexample medical schematic from Wikipedia\n).\ncolor gradients that represent a measurement, such as heat maps (\nexample heatmap from Wikipedia\n).\nTesting Principles\nA summary of the high-level process for finding and assessing non-text content on a web page:\nIdentify each user-interface component (link, button, form control) on the page and:\nIdentify the visual (non-text) indicators of the component that are required to identify that a control exists, and indicate the current state. In the default (on page load) state, test the contrast ratio against the adjacent colors.\nTest those contrast indicators in each state.\nIdentify each graphic on the page that includes information required for understanding the content (i.e., excluding graphics which have visible text for the same information, or are decorative) and:\nCheck the contrast of the graphical object against its adjacent colors;\nIf there are multiple colors and/or a gradient, choose the least contrasting area to test;\nIf it passes, move to the next graphical object;\nIf the least-contrasting area is less than 3:1, assume that area is invisible, is the graphical object still understandable?\nIf there is enough of the graphical object to understand, it passes, else fail.\nThe techniques below each have testing criteria, and the related criteria for\nFocus visible (2.4.7)\n,\nUse of color (1.4.1)\n, and\nContrast minimum\nalso have techniques.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.11_success_criterion",
    "type": "sc",
    "sc_id": "1.4.11",
    "section": "success_criterion",
    "text": "[1.4.11 Non-text Contrast] (Level AA)\nDescription: The visual presentation of the following have a contrast ratio of at least 3:1 against adjacent color(s):\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nThe visual\npresentation\nof the following have a\ncontrast ratio\nof at least 3:1 against adjacent color(s):\nUser Interface Components\nVisual information required to identify\nuser interface components\nand\nstates\n, except for inactive components or where the appearance of the component is determined by the\nuser agent\nand not modified by the author;\nGraphical Objects\nParts of graphics required to understand the content, except when a particular presentation of graphics is\nessential\nto the information being conveyed.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.11_benefits",
    "type": "sc",
    "sc_id": "1.4.11",
    "section": "benefits",
    "text": "[1.4.11 Non-text Contrast] (Level AA)\nDescription: The visual presentation of the following have a contrast ratio of at least 3:1 against adjacent color(s):\n\nSection: benefits\n\nBenefits\nPeople with low vision often have difficulty perceiving graphics that have insufficient contrast. This can be exacerbated if the person has a color vision deficiency that lowers the contrast even further. Providing a\nrelative luminance\n(lightness difference) of 3:1 or greater can make these items more distinguishable when the person does not see a full range of colors.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.11_examples",
    "type": "sc",
    "sc_id": "1.4.11",
    "section": "examples",
    "text": "[1.4.11 Non-text Contrast] (Level AA)\nDescription: The visual presentation of the following have a contrast ratio of at least 3:1 against adjacent color(s):\n\nSection: examples\n\nExamples\nStatus icons on an application's dashboard (without associated text) have a 3:1 minimum contrast ratio.\nA text input has a dark border around the white editable area.\nA graph uses a light background and ensures that the colors for each line have a 3:1 contrast ratio against the background.\nPie Charts\nPie charts make a good case study for the graphical objects part of this success criterion, the following pie charts are intended to convey the proportion of market share each browser has. Please Note: The actual figures are made up, these are not actual market shares.\nFigure 20.\nFail:\nThe pie chart has labels for each slice (so passes 1.4.1 Use of Color), but in order to understand the proportions of the slices you must discern the edges of the slices (the graphical objects conveying essential information), and the contrast between the slices is not  3:1 or greater.\nFigure 21.\nNot applicable:\nThe pie chart has visible labels\nand\nvalues that convey equivalent information to the graphical objects (the pie slices).\nFigure 22.\nPass:\nThe pie chart has visible labels, and sufficient contrast around and between the slices of the pie chart (the graphical objects). A darker border has been added around the yellow slice in order to achieve the contrast level.\nInfographics\nFigure 23.\nFail:\nDiscerning the circles is required to understand the size of network and discerning the icons in each circle is required to identify which network it shows.\nThe graphical objects are the circles (measured against the background) and the icons in each circle (measured against the circle's background).\nFigure 24.\nPass:\nThe circles have contrasting borders and the icons are a contrasting dark color against the light circle backgrounds.\nThere are many possible solutions to ensuring contrast, the example shows the use of borders. Other techniques are to use darker colors for the circle backgrounds, or to add text labels & values for each item.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.11_brief",
    "type": "sc",
    "sc_id": "1.4.11",
    "section": "brief",
    "text": "[1.4.11 Non-text Contrast] (Level AA)\nDescription: The visual presentation of the following have a contrast ratio of at least 3:1 against adjacent color(s):\n\nSection: brief\n\nIn Brief\nGoal\nImportant visual information meets the same minimum contrast required for larger text.\nWhat to do\nEnsure meaningful visual cues achieve 3:1 against the background.\nWhy it's important\nSome people cannot see elements with low contrast.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.11_resources",
    "type": "sc",
    "sc_id": "1.4.11",
    "section": "resources",
    "text": "[1.4.11 Non-text Contrast] (Level AA)\nDescription: The visual presentation of the following have a contrast ratio of at least 3:1 against adjacent color(s):\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nAccessibility Requirements for People with Low Vision\n.\nSmith Kettlewell Eye Research Institute\n-  \"If the text is better understood with the graphics, they should be equally visible as the text\".\nGordon Legge\n- \"Contrast requirements for form controls should be equivalent to contrast requirements for text\".",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.11_key_terms",
    "type": "sc",
    "sc_id": "1.4.11",
    "section": "key_terms",
    "text": "[1.4.11 Non-text Contrast] (Level AA)\nDescription: The visual presentation of the following have a contrast ratio of at least 3:1 against adjacent color(s):\n\nSection: key_terms\n\nKey Terms\nASCII art\npicture created by a spatial arrangement of characters or glyphs (typically from the\n      95 printable characters defined by ASCII)\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\ncontent\ninformation and sensory experience to be communicated to the user by means of a\nuser agent\n, including code or markup that defines the content's\nstructure\n,\npresentation\n, and interactions\ncontrast ratio\n(L1 + 0.05) / (L2 + 0.05), where\nL1 is the\nrelative luminance\nof the lighter of the colors, and\nL2 is the\nrelative luminance\nof the darker of the colors.\nNote 1\nContrast ratios can range from 1 to 21 (commonly written 1:1 to 21:1).\nNote 2\nBecause authors do not have control over user settings as to how text is rendered\n      (for example font smoothing or anti-aliasing), the contrast ratio for text can be\n      evaluated with anti-aliasing turned off.\nNote 3\nFor the purpose of Success Criteria 1.4.3 and 1.4.6, contrast is measured with respect\n      to the specified background over which the text is rendered in normal usage. If no\n      background color is specified, then white is assumed.\nNote 4\nBackground color is the specified color of content over which the text is to be rendered\n      in normal usage. It is a failure if no background color is specified when the text\n      color is specified, because the user's default background color is unknown and cannot\n      be evaluated for sufficient contrast. For the same reason, it is a failure if no text\n      color is specified when a background color is specified.\nNote 5\nWhen there is a border around the letter, the border can add contrast and would be\n      used in calculating the contrast between the letter and its background. A narrow border\n      around the letter would be used as the letter. A wide border around the letter that\n      fills in the inner details of the letters acts as a halo and would be considered background.\nNote 6\nWCAG conformance should be evaluated for color pairs specified in the content that\n      an author would expect to appear adjacent in typical presentation. Authors need not\n      consider unusual presentations, such as color changes made by the user agent, except\n      where caused by authors' code.\nessential\nif removed, would fundamentally change the information or functionality of the content,\nand\ninformation and functionality cannot be achieved in another way that would conform\nhuman language\nlanguage that is spoken, written or signed (through visual or tactile means) to communicate\n      with humans\nNote\nSee also\nsign language\n.\nnon-text content\nany content that is not a sequence of characters that can be\nprogrammatically determined\nor where the sequence is not expressing something in\nhuman language\nNote\nThis includes\nASCII art\n(which is a pattern of characters), emoticons, leetspeak (which uses character substitution),\n      and images representing text\npresentation\nrendering of the\ncontent\nin a form to be perceived by users\nprogrammatically determined\ndetermined by software from author-supplied data provided in a way that different\nuser agents\n, including\nassistive technologies\n, can extract and present this information to users in different modalities\nExample 1\nDetermined in a markup language from elements and attributes that are accessed directly\n      by commonly available assistive technology.\nExample 2\nDetermined from technology-specific data structures in a non-markup language and exposed\n      to assistive technology via an accessibility API that is supported by commonly available\n      assistive technology.\nrelative luminance\nthe relative brightness of any point in a colorspace, normalized to 0 for darkest\n      black and 1 for lightest white\nNote 1\nFor the sRGB colorspace, the relative luminance of a color is defined as L = 0.2126\n      *\nR\n+ 0.7152 *\nG\n+ 0.0722 *\nB\nwhere\nR\n,\nG\nand\nB\nare defined as:\nif RsRGB <= 0.04045 then\nR\n= RsRGB/12.92 else\nR\n= ((RsRGB+0.055)/1.055) ^ 2.4\nif GsRGB <= 0.04045 then\nG\n= GsRGB/12.92 else\nG\n= ((GsRGB+0.055)/1.055) ^ 2.4\nif BsRGB <= 0.04045 then\nB\n= BsRGB/12.92 else\nB\n= ((BsRGB+0.055)/1.055) ^ 2.4\nand RsRGB, GsRGB, and BsRGB are defined as:\nRsRGB = R8bit/255\nGsRGB = G8bit/255\nBsRGB = B8bit/255\nThe \"^\" character is the exponentiation operator. (Formula taken from \n      [\nSRGB\n].)\nNote 2\nBefore May 2021 the value of 0.04045 in the definition was different (0.03928). It was taken from an older version of the specification and has been updated. It has no practical effect on the calculations in the context of these guidelines.\nNote 3\nAlmost all systems used today to view web content assume sRGB encoding. Unless it\n      is known that another color space will be used to process and display the content,\n      authors should evaluate using sRGB colorspace. If using other color spaces, see\nUnderstanding Success Criterion 1.4.3\n.\nNote 4\nIf dithering occurs after delivery, then the source color value is used. For colors\n      that are dithered at the source, the average values of the colors that are dithered\n      should be used (average R, average G, and average B).\nNote 5\nTools are available that automatically do the calculations when testing contrast and\n      flash.\nNote 6\nA\nseparate page giving the relative luminance definition using MathML\nto display the formulas is available.\nsign language\na language using combinations of movements of the hands and arms, facial expressions,\n      or body positions to convey meaning\nstate\ndynamic property expressing characteristics of a\nuser interface component\nthat may change in response to user action or automated processes\nStates do not affect the nature of the component, but represent data associated with the component or user interaction possibilities. Examples include focus, hover, select, press, check, visited/unvisited, and expand/collapse.\nstructure\nThe way the parts of a\nweb page\nare organized in relation to each other; and\nThe way a collection of\nweb pages\nis organized\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.\nuser interface component\na part of the content that is perceived by users as a single control for a distinct\n      function\nNote 1\nMultiple user interface components may be implemented as a single programmatic element.\n      \"Components\" here is not tied to programming techniques, but rather to what the user\n      perceives as separate controls.\nNote 2\nUser interface components include form elements and links as well as components generated\n      by scripts.\nNote 3\nWhat is meant by \"component\" or \"user interface component\" here is also sometimes\n      called \"user interface element\".\nExample\nAn applet has a \"control\" that can be used to move through content by line or page\n      or random access. Since each of these would need to have a name and be settable independently,\n      they would each be a \"user interface component.\"\nweb page\na non-embedded resource obtained from a single URI using HTTP plus any other resources\n      that are used in the rendering or intended to be rendered together with it by a\nuser agent\nNote 1\nAlthough any \"other resources\" would be rendered together with the primary resource,\n      they would not necessarily be rendered simultaneously with each other.\nNote 2\nFor the purposes of conformance with these guidelines, a resource must be \"non-embedded\"\n      within the scope of conformance to be considered a web page.\nExample 1\nA web resource including all embedded images and media.\nExample 2\nA web mail program built using Asynchronous JavaScript and XML (AJAX). The program\n      lives entirely at http://example.com/mail, but includes an inbox, a contacts area\n      and a calendar. Links or buttons are provided that cause the inbox, contacts, or calendar\n      to display, but do not change the URI of the page as a whole.\nExample 3\nA customizable portal site, where users can choose content to display from a set of\n      different content modules.\nExample 4\nWhen you enter \"http://shopping.example.com/\" in your browser, you enter a movie-like\n      interactive shopping environment where you visually move around in a store dragging\n      products off of the shelves around you and into a visual shopping cart in front of\n      you. Clicking on a product causes it to be demonstrated with a specification sheet\n      floating alongside. This might be a single-page website or just one page within a\n      website.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.12_intent",
    "type": "sc",
    "sc_id": "1.4.12",
    "section": "intent",
    "text": "[1.4.12 Text Spacing] (Level AA)\nDescription: In content implemented using markup languages that support the following text style properties, no loss of content or functionality occurs by setting all of the following and by changing no other style property:\n\nSection: intent\n\nIntent\nThe intent of this success criterion (SC) is to ensure that when people override author-specified text spacing to improve their reading experience, content is still readable and operable. Each of the requirements stipulated in the SC's four bullets helps ensure text styling can be adapted by the user to suit their needs.\nThe metrics set a target for a minimum for text spacing that must be met. Starting from the author's presentation, changing these four style properties to the specified values should not result in a loss of content or functionality.\nThis SC focuses on the adaptability of content to a change in spacing between lines, words, letters, and paragraphs. Any combination of these may assist a user with effectively reading text. As well, ensuring that content correctly adapts when users override author settings for spacing also significantly increases the likelihood other style preferences can be set by the user. For example, a user may need to change to a wider font family than the author has set in order to effectively read text.\nAuthor Responsibility\nThis SC does not dictate that authors must set all their content to the specified metrics, or provide a mechanism to do so. Rather, it specifies that an author's content has the ability to be set to those metrics without loss of content or functionality. The author requirement is both to not interfere with a user's ability to override the author settings, and to ensure that content thus modified does not break content in the manners shown in figures 1 through 3 in\nEffects of Not Allowing for Spacing Override\n. The values in the SC are a baseline. Authors are encouraged to allow spacing to surpass the values specified, not see them as a ceiling.\nIt is beneficial for users if authors use any locally available guidance for improving readability in the local language or writing system. Conversely, in some human languages and scripts, some of the metrics specified by the SC are inapplicable. For example, languages such as Japanese do not use spacing following paragraphs, meaning that users are unlikely to make any paragraph spacing changes in practice. The exception in this SC allows authors to ignore text style properties which are inapplicable to the combination of language and script being used.\nUser Responsibility\nThe user may choose to exceed the spacing adjustments in the SC. The ability to read and derive meaning from the overridden spacing rests with the user. If large changes in spacing reduce readability, or cause loss of content or functionality, the user can adjust or return to spacing within the bounds of the SC. How such changes are achieved is up to the user, who may choose a user stylesheet, bookmarklet, extension, or application. Regardless, the user needs the flexibility to adjust spacing – and within the bounds set in the SC, without loss of content or functionality.\nFurther, this SC does not require that content implement its own mechanisms to allow users to do this. It is not a failure of the content if a user agent or platform does not provide a way for users to do this. Content does not fail this SC if the method chosen by the user - for instance, the use of an extension or bookmarklet - fails to correctly set the line height and spacing text properties on the content (provided that the content is not actively and purposely preventing the properties from being added).\nApplicability\nIf the markup-based technologies being used are capable of overriding text to the Success Criterion's metrics, then this SC is applicable. For instance Cascading Style Sheet/HTML technologies are quite able to allow for the specified spacing metrics. Plugin technologies would need to have a built-in ability to modify styles to the specified metrics. Currently, this SC does not apply to PDF, as the portable document format is not implemented using markup.\nExamples of text typically not affected by\nstyle properties\nand not expected to adapt are:\nVideo captions embedded directly into the video frames and not provided as an associated caption file\nImages of text\nFor this SC,\ncanvas\nimplementations of text are considered to be\nimages of text\n.\nUse of ellipses\nThere may be regions of a page where text containers cannot expand due to design constraints (such as a maximum width for the left navigation or table column headers). A common convention if text exceeds its space is to replace truncated text with an ellipsis. Where ellipses appear as a result of modifying text style properties, the page can still meet the Text Spacing requirements, so long as the content is still available. For example:\na mechanism is provided to reveal the truncated text on the page (for instance, the text appears on focus or on activation)\nwhere the ellipsis is part of a section of content which includes a link, the truncated text is revealed on the linked page\nWhere text is not truncated but it is when text is spaced, if there is no mechanism to show the truncated text, it fails this success criterion.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.12_success_criterion",
    "type": "sc",
    "sc_id": "1.4.12",
    "section": "success_criterion",
    "text": "[1.4.12 Text Spacing] (Level AA)\nDescription: In content implemented using markup languages that support the following text style properties, no loss of content or functionality occurs by setting all of the following and by changing no other style property:\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nIn content implemented using markup languages that support the following\ntext\nstyle properties\n, no loss of content or functionality occurs by setting all of the following and by changing no other style property:\nLine height (line spacing) to at least 1.5 times the font size;\nSpacing following paragraphs to at least 2 times the font size;\nLetter spacing (tracking) to at least 0.12 times the font size;\nWord spacing to at least 0.16 times the font size.\nException:\nHuman languages\nand scripts that do not make use of one or more of these text style properties in written text can conform using only the properties that exist for that combination of language and script.\nNote 1\nContent is not required to use these text spacing values. The requirement is to ensure that when a user overrides the authored text spacing, content or functionality is not lost.\nNote 2\nWriting systems for some languages use different text spacing settings, such as paragraph start indent. Authors are encouraged to follow locally available guidance for improving readability and legibility of text in their writing system.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.12_benefits",
    "type": "sc",
    "sc_id": "1.4.12",
    "section": "benefits",
    "text": "[1.4.12 Text Spacing] (Level AA)\nDescription: In content implemented using markup languages that support the following text style properties, no loss of content or functionality occurs by setting all of the following and by changing no other style property:\n\nSection: benefits\n\nBenefits\nPeople with low vision who require increased space between lines, words, and letters are able to read text.\nPeople with dyslexia may increase space between lines, words, and letters to increase reading speed.\nAlthough not required by this SC, white space between blocks of text can help people with cognitive disabilities discern sections and call-out boxes.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.12_examples",
    "type": "sc",
    "sc_id": "1.4.12",
    "section": "examples",
    "text": "[1.4.12 Text Spacing] (Level AA)\nDescription: In content implemented using markup languages that support the following text style properties, no loss of content or functionality occurs by setting all of the following and by changing no other style property:\n\nSection: examples\n\nExamples\nWhen spacing is being overridden to the SC's metrics:\nText fits within the bounds of its containing box without being cut off.\nText fits within the bounds of its containing box without overlapping other boxes.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.12_brief",
    "type": "sc",
    "sc_id": "1.4.12",
    "section": "brief",
    "text": "[1.4.12 Text Spacing] (Level AA)\nDescription: In content implemented using markup languages that support the following text style properties, no loss of content or functionality occurs by setting all of the following and by changing no other style property:\n\nSection: brief\n\nIn Brief\nGoal\nUsers can adjust text spacing to make it easier to read.\nAuthor task\nEnsure content adapts to user-defined text settings.\nWhy it's important\nSome people need text with different spacing or font characteristics.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.12_resources",
    "type": "sc",
    "sc_id": "1.4.12",
    "section": "resources",
    "text": "[1.4.12 Text Spacing] (Level AA)\nDescription: In content implemented using markup languages that support the following text style properties, no loss of content or functionality occurs by setting all of the following and by changing no other style property:\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nResearch\nThe  grounds for this SC are\nbased on research\n. The metrics chosen as measures are based on the\nMcLeish\nstudy. She ran from .04 to .25 em tests. McLeish found an increasing curve in reading speed of actual materials up to .25, but it  started to flatten at .20. Previous studies that reported no improvement started at .5em. Right at the flat point.\nWayne E. Dick, Ph.D. analyzed the McLeish study\nand translated from points. Dr. Dick recommended the metrics that the Working Group adopted.\nLanguages and Scripts\nRoughly 480 different languages and scripts\nhave been tested\n.  Maximum spacing adjustments allowed by the SC were set on the following 3 pages:\nLanguages in their own writing systems\nOnline Encyclopedia of writing systems and languages – language names\nUniversal Declaration of Human Rights (Article 1)\nResults\nNo adverse effects occurred. The following are the specific findings:\nCharacter Spacing\nIndividual characters in words remained intact though they were spaced a bit further apart.\nWord Spacing\nWords were spaced further apart. In languages that do not have words (e.g., Japanese) applying word spacing had no effect. This is expected.\nLine Height\nChanging line height did not separate diacritics from characters, nor did it adversely impact ascenders or descenders.\nAs previously discussed, the ability to read text with adjusted spacing is a user responsibility. This is true no matter the language.\nThe SC's exception addresses cases where a text style property is not used in a language or script. In such cases, authors are only required to ensure relevant properties do not break the layout.\nOther references\nAllan, Kirkpatrick, Lawton Henry, Editors. (2017).\nAccessibility Requirements for People with Low Vision (3.4 Spacing for Reading)\n.  World Wide Web Consortium.\nStylus Team\n(2012).\nStylus browser extension\n(Firefox, Chrome, and Opera) (compatible with Userstyles.org material).\nCampbell, Alastair.  (2017).\nText Adaptation Bookmarklet\n. GitHub.\nChung, Susana T. L. (2012).\nDependence of Reading Speed on Letter Spacing in Central Vision Loss\n. Optom Vis Sci.\nChung, Susana T. L. (2002).\nThe Effect of Letter Spacing on Reading Speed in Central and Peripheral Vision (PDF)\n. IOVS ARVO Journals.\nMcleish, Eve. (2007).\nA study of the effect of letter spacing on the reading speed of young readers with low vision (PDF)\n. The British Journal of Visual Impairment 25.2: 133-43.\nRello, L., & Baeza-Yates, R. A. (2017).\nHow to present more readable text for people with dyslexia\n. Universal Access in the Information Society, 16(1), 29-49.\nSjoblom, A.M., Eaton, E. and Stagg, S.D., (2016).\nThe effects of letter spacing and coloured overlays on reading speed and accuracy in adult dyslexia\n. British Journal of Educational Psychology, 86(4), pp. 630-639).\nZorzi,  Marco et, al. (2012).\nExtra-large letter spacing improves reading in dyslexia\n. Proceedings of the National Academy of Sciences.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.12_test_rules",
    "type": "sc",
    "sc_id": "1.4.12",
    "section": "test_rules",
    "text": "[1.4.12 Text Spacing] (Level AA)\nDescription: In content implemented using markup languages that support the following text style properties, no loss of content or functionality occurs by setting all of the following and by changing no other style property:\n\nSection: test_rules\n\nTest Rules\nThe following are Test Rules\n    for certain aspects of this Success Criterion.\n    It is not necessary to use these particular Test Rules to check for conformance with WCAG, but they are defined and approved test methods.\n    For information on using Test Rules, see\nUnderstanding Test Rules for WCAG Success Criteria\n.\nImportant letter spacing in style attributes is wide enough\nImportant line height in style attributes is wide enough\nImportant word spacing in style attributes is wide enough",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.12_key_terms",
    "type": "sc",
    "sc_id": "1.4.12",
    "section": "key_terms",
    "text": "[1.4.12 Text Spacing] (Level AA)\nDescription: In content implemented using markup languages that support the following text style properties, no loss of content or functionality occurs by setting all of the following and by changing no other style property:\n\nSection: key_terms\n\nKey Terms\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\nhuman language\nlanguage that is spoken, written or signed (through visual or tactile means) to communicate\n      with humans\nNote\nSee also\nsign language\n.\nimage of text\ntext that has been rendered in a non-text form (e.g., an image) in order to achieve\n      a particular visual effect\nNote\nThis does not include text that is part of a picture that contains significant other visual content.\nExample\nA person's name on a nametag in a photograph.\nprogrammatically determined\ndetermined by software from author-supplied data provided in a way that different\nuser agents\n, including\nassistive technologies\n, can extract and present this information to users in different modalities\nExample 1\nDetermined in a markup language from elements and attributes that are accessed directly\n      by commonly available assistive technology.\nExample 2\nDetermined from technology-specific data structures in a non-markup language and exposed\n      to assistive technology via an accessibility API that is supported by commonly available\n      assistive technology.\nsign language\na language using combinations of movements of the hands and arms, facial expressions,\n      or body positions to convey meaning\nstyle property\nproperty whose value determines the presentation (e.g. font, color, size, location, padding, volume, synthesized speech prosody) of\n content elements as they are rendered (e.g. onscreen, via loudspeaker, via braille display) by user agents\nStyle properties can have several origins:\nUser agent default styles: The default style property values applied in the absence of any author or user styles. Some web content technologies specify a default rendering, others do not;\nAuthor styles: Style property values that are set by the author as part of the content (e.g. in-line styles, author style\nsheets);\nUser styles: Style property values that are set by the user (e.g. via user agent interface settings, user style sheets)\ntext\nsequence of characters that can be\nprogrammatically determined\n, where the sequence is expressing something in\nhuman language\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.13_intent",
    "type": "sc",
    "sc_id": "1.4.13",
    "section": "intent",
    "text": "[1.4.13 Content on Hover or Focus] (Level AA)\nDescription: Where receiving and then removing pointer hover or keyboard focus triggers additional content to become visible and then hidden, the following are true:\n\nSection: intent\n\nIntent\nAdditional content that appears and disappears in coordination with keyboard focus or pointer hover often leads to accessibility issues. Reasons for such issues include:\nthe user may not have intended to trigger the interaction\nthe user may not know new content has appeared\nthe new content may intefere with a user's ability to do a task\nExamples of such interactions can include custom tooltips, sub-menus and other nonmodal popups which display on hover and focus. The intent of this success criterion is to ensure that authors who cause additional content to appear and disappear in this manner must design the interaction in such a way that users can:\nperceive the additional content AND\ndismiss it without disrupting their page experience.\nThere are usually more predictable and accessible means of adding content to the page, which authors are recommended to employ. If an author\ndoes\nchoose to make additional content appear and disappear in coordination with hover and keyboard focus, this success criterion specifies three conditions that must be met:\ndismissible\nhoverable\npersistent\nEach of these is discussed in a separate section.\nDismissible\nThe intent of this condition is to ensure that the additional content does not interfere with viewing or operating the page's original content. When magnified, the portion of the page visible in the viewport can be significantly reduced. Mouse users frequently move the pointer to pan the magnified viewport and display another portion of the screen. However, almost the entire portion of the page visible in this restricted viewport may trigger the additional content, making it difficult for a user to pan without re-triggering the content. A keyboard means of dismissing the additional content provides a workaround.\nAlternatively, low vision users who can only navigate via the keyboard do not want the small area of their magnified viewport cluttered with hover text. They need a keyboard method of dismissing something that is obscuring the current focal area.\nTwo methods may be used to satisfy this condition and prevent such interference:\nPosition the additional content so that it does not obscure any other content including the trigger, with the exception of white space and purely decorative content, such as a background graphic which provides no information.\nProvide a mechanism to easily dismiss the additional content, such as by pressing Escape.\nFor most triggers of relatively small size, it is desirable for both methods to be implemented.  If the trigger is large, noticing the additional content may be of concern if it appears away from the trigger.  In those cases, only the second method may be appropriate.\nThe success criterion allows for input error messages to persist as there are cases that require attention, explicit confirmation or remedial action.\nHoverable\nThe intent of this condition is to ensure that additional content which may appear on hover of a target may also be hovered itself.  Content which appears on hover can be difficult or impossible to perceive if a user is required to keep their mouse pointer over the trigger. When the added content is large, magnified views may mean that the user needs to scroll or pan to completely view it, which is impossible unless the user is able to move their pointer off the trigger without the additional content disappearing.\nAnother common situation is when large pointers have been selected via platform settings or assistive technology. Here, the pointer can obscure a significant area of the additional content. A technique to view the content fully in both situations is to move the mouse pointer directly from the trigger onto the new content.  This capability also offers significant advantages for users who utilize screen reader feedback on mouse interactions.  This condition generally implies that the additional content overlaps or is positioned adjacent to the target.\nPersistent\nThe intent of this condition is to ensure users have adequate time to perceive the additional content after it becomes visible.  Users with disabilities may require more time for many reasons, such as to change magnification, move the pointer, or simply to bring the new content into their visual field.  Once it appears, the content should remain visible until:\nThe user removes hover or focus from the trigger and the additional content, consistent with the typical user experience;\nThe user dismisses the additional content via the mechanism provided to satisfy the Dismissible condition; or\nThe information conveyed by the additional content becomes invalid, such as a 'busy' message that is no longer valid.\nAdditional Notes\nThis criterion does not attempt to solve such issues when the appearance of the additional content is completely controlled by the user agent. A prominent example is the common behavior of browsers to display the\ntitle\nattribute in HTML as a small tooltip.\nModal dialogs are out of scope for this criterion because they must take keyboard focus  and thus should not appear on hover or focus.  Refer to\nSuccess Criterion 3.2.1, On Focus\n.\nContent which can be triggered via pointer hover should also be able to be triggered by keyboard focus.  Refer to\nSuccess Criterion 2.1.1, Keyboard\n.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.13_success_criterion",
    "type": "sc",
    "sc_id": "1.4.13",
    "section": "success_criterion",
    "text": "[1.4.13 Content on Hover or Focus] (Level AA)\nDescription: Where receiving and then removing pointer hover or keyboard focus triggers additional content to become visible and then hidden, the following are true:\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nWhere receiving and then removing pointer hover or keyboard focus triggers additional content to become visible and then hidden, the following are true:\nDismissible\nA\nmechanism\nis available to dismiss the additional content without moving pointer hover or keyboard focus, unless the additional content communicates an\ninput error\nor does not obscure or replace other content;\nHoverable\nIf pointer hover can trigger the additional content, then the pointer can be moved  over the additional content without the additional content disappearing;\nPersistent\nThe additional content remains visible until the hover or focus trigger is removed, the user dismisses it, or its information is no longer valid.\nException: The visual presentation of the additional content is controlled by the\nuser agent\nand is not modified by the author.\nNote 1\nExamples of additional content controlled by the user agent include browser tooltips created through use of the\nHTML\ntitle\nattribute\n[\nHTML\n].\nNote 2\nCustom tooltips, sub-menus, and other nonmodal popups that display on hover and focus are examples of additional content covered by this criterion.\nNote 3\nThis criterion applies to content that appears in addition to the triggering component itself. Since hidden components that are made visible on keyboard focus (such as links used to skip to another part of a page) do not present additional content they are not covered by this criterion.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.13_benefits",
    "type": "sc",
    "sc_id": "1.4.13",
    "section": "benefits",
    "text": "[1.4.13 Content on Hover or Focus] (Level AA)\nDescription: Where receiving and then removing pointer hover or keyboard focus triggers additional content to become visible and then hidden, the following are true:\n\nSection: benefits\n\nBenefits\nUsers with low vision who view content under magnification will be better able to view content on hover or focus without reducing their desired magnification.\nUsers who increase the size of mouse cursors via platform settings or assistive technology will be able to employ a technique to view obscured content on hover.\nUsers with low vision or cognitive disabilities will have adequate time to perceive additional content appearing on hover or focus and to view the trigger content with less distraction.\nusers with low pointer accuracy will be able to more easily dismiss unintentionally-triggered additional content",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.13_examples",
    "type": "sc",
    "sc_id": "1.4.13",
    "section": "examples",
    "text": "[1.4.13 Content on Hover or Focus] (Level AA)\nDescription: Where receiving and then removing pointer hover or keyboard focus triggers additional content to become visible and then hidden, the following are true:\n\nSection: examples\n\nExamples\nExample 1: Dismissible Tooltip\nFigure 1.\nA tooltip is displayed below a LVTF button on hover so as not to obscure the button itself. It does however obscure content below the button (the next red button, called ~comment-zoom-content). To meet the Dismissible requirement, a user can press the Escape key to clear the tooltip without moving the mouse, as demonstrated in the second image.\nFigure 2.\nThe button's tooltip also appears on focus and can be removed with the Escape key. The screen shot shows the same LVTF button with focus, but the tooltip has been dismissed and is no longer visible.\nExample 2: Hoverable Tooltip\nFigure 3.\nA button's tooltip is displayed directly below it on mouse hover which can easily be obscured by a large pointer.  The tooltip itself is able to be hovered so the mouse pointer can be moved down to its bottom edge in order to view the tooltip text.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.13_brief",
    "type": "sc",
    "sc_id": "1.4.13",
    "section": "brief",
    "text": "[1.4.13 Content on Hover or Focus] (Level AA)\nDescription: Where receiving and then removing pointer hover or keyboard focus triggers additional content to become visible and then hidden, the following are true:\n\nSection: brief\n\nIn Brief\nGoal\nMore users can perceive and dismiss non-persistent content.\nWhat to do\nIf hover or focus causes content changes, ensure interaction is predictable.\nWhy it's important\nUnpredictable temporary content can be hard for some to consume and may disrupt others.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.13_resources",
    "type": "sc",
    "sc_id": "1.4.13",
    "section": "resources",
    "text": "[1.4.13 Content on Hover or Focus] (Level AA)\nDescription: Where receiving and then removing pointer hover or keyboard focus triggers additional content to become visible and then hidden, the following are true:\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nTooltip design described in WAI-ARIA Authoring Practices",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "1.4.13_key_terms",
    "type": "sc",
    "sc_id": "1.4.13",
    "section": "key_terms",
    "text": "[1.4.13 Content on Hover or Focus] (Level AA)\nDescription: Where receiving and then removing pointer hover or keyboard focus triggers additional content to become visible and then hidden, the following are true:\n\nSection: key_terms\n\nKey Terms\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\nconformance\nsatisfying all the requirements of a given standard, guideline or specification\ninput error\ninformation provided by the user that is not accepted\nNote\nThis includes:\nInformation that is required by the\nweb page\nbut omitted by the user\nInformation that is provided by the user but that falls outside the required data\n         format or values\nmechanism\nprocess\nor technique for achieving a result\nNote 1\nThe mechanism may be explicitly provided in the content, or may be\nrelied upon\nto be provided by either the platform or by\nuser agents\n, including\nassistive technologies\n.\nNote 2\nThe mechanism needs to meet all success criteria for the conformance level claimed.\nprocess\nseries of user actions where each action is required in order to complete an activity\nExample 1\nSuccessful use of a series of web pages on a shopping site requires users to view\n      alternative products, prices and offers, select products, submit an order, provide\n      shipping information and provide payment information.\nExample 2\nAn account registration page requires successful completion of a\nTuring test\nbefore\n      the registration form can be accessed.\nrelied upon\nthe content would not\nconform\nif that\ntechnology\nis turned off or is not supported\ntechnology\nmechanism\nfor encoding instructions to be rendered, played or executed by\nuser agents\nNote 1\nAs used in these guidelines \"web technology\" and the word \"technology\" (when used\n      alone) both refer to web content technologies.\nNote 2\nWeb content technologies may include markup languages, data formats, or programming\n      languages that authors may use alone or in combination to create end-user experiences\n      that range from static web pages to synchronized media presentations to dynamic Web\n      applications.\nExample\nSome common examples of web content technologies include HTML, CSS, SVG, PNG, PDF,\n      Flash, and JavaScript.\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.\nweb page\na non-embedded resource obtained from a single URI using HTTP plus any other resources\n      that are used in the rendering or intended to be rendered together with it by a\nuser agent\nNote 1\nAlthough any \"other resources\" would be rendered together with the primary resource,\n      they would not necessarily be rendered simultaneously with each other.\nNote 2\nFor the purposes of conformance with these guidelines, a resource must be \"non-embedded\"\n      within the scope of conformance to be considered a web page.\nExample 1\nA web resource including all embedded images and media.\nExample 2\nA web mail program built using Asynchronous JavaScript and XML (AJAX). The program\n      lives entirely at http://example.com/mail, but includes an inbox, a contacts area\n      and a calendar. Links or buttons are provided that cause the inbox, contacts, or calendar\n      to display, but do not change the URI of the page as a whole.\nExample 3\nA customizable portal site, where users can choose content to display from a set of\n      different content modules.\nExample 4\nWhen you enter \"http://shopping.example.com/\" in your browser, you enter a movie-like\n      interactive shopping environment where you visually move around in a store dragging\n      products off of the shelves around you and into a visual shopping cart in front of\n      you. Clicking on a product causes it to be demonstrated with a specification sheet\n      floating alongside. This might be a single-page website or just one page within a\n      website.",
    "principle": "Perceivable",
    "guideline": "1.4 Distinguishable"
  },
  {
    "id": "2.1.1_intent",
    "type": "sc",
    "sc_id": "2.1.1",
    "section": "intent",
    "text": "[2.1.1 Keyboard] (Level A)\nDescription: All functionality of the content is operable through a keyboard interface without requiring specific timings for individual keystrokes, except where the underlying\n      function requires input that depends on the path of the user's movement and not just\n      the endpoints.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to ensure that, wherever possible, content\n         can be operated through a keyboard or keyboard interface (so an alternate keyboard\n         can be used). When content can be operated through a keyboard or alternate keyboard,\n         it is operable by people with no vision (who cannot use devices such as mice that\n         require eye-hand coordination) as well as by people who must use alternate keyboards\n         or input devices that act as keyboard emulators. Keyboard emulators include speech\n         input software, sip-and-puff software, on-screen keyboards, scanning software and\n         a variety of assistive technologies and alternate keyboards. Individuals with low\n         vision also may have trouble tracking a pointer and find the use of software much\n         easier (or only possible) if they can control it from the keyboard.\nExamples of \"specific timings for individual keystrokes\" include situations where\n         a user would be required to repeat or execute multiple keystrokes within a short period\n         of time or where a key must be held down for an extended period before the keystroke\n         is registered.\nThe phrase \"except where the underlying function requires input that depends on the\n         path of the user's movement and not just the endpoints\" is included to separate those\n         things that cannot reasonably be controlled from a keyboard.\nMost actions carried out by a pointing device can also be done from the keyboard (for\n         example, clicking, selecting, moving, sizing). However, there is a small class of\n         input that is done with a pointing device that cannot be done from the keyboard in\n         any known fashion without requiring an inordinate number of keystrokes. Free hand\n         drawing, or watercolor painting require path dependent input. Drawing straight lines,\n         regular geometric shapes, re-sizing windows and dragging objects to a location (when\n         the path to that location is not relevant) do not require path dependent input.\nThe use of MouseKeys would not satisfy this success criterion because it is not a\n         keyboard equivalent to the application; it is a mouse equivalent (i.e., it looks like\n         a mouse to the application).\nIt is assumed that the design of user input features takes into account that operating\n         system keyboard accessibility features may be in use. For example, modifier key locking\n         may be turned on. Content continues to function in such an environment, not sending\n         events that would collide with the modifier key lock to produce unexpected results.\nNote\nPlatforms and user agents usually have conventions for how web content or\n            applications are controlled with a keyboard interface. If content does not follow\n            the platform/user agent conventions it may be difficult to use, as users will need\n            to learn different interaction methods. As a\nbest practice\n, content\n            should follow the platform/user agent conventions. However, deviating from these\n            conventions does\nnot\nfail the normative requirement of this success criterion.\nFor instance, buttons that have focus can generally be activated using both the\nEnter\nkey and the\nSpace\nbar. If a custom button control\n            in a web application instead only reacts to\nEnter\n(or even a completely custom key or key combination), this still\nsatisfies\nthe requirements of this success criterion.\nNote\nThis success criterion does not require that every visible control that can be activated\n            using a mouse or touch screen must also be focusable and actionable using the keyboard.\n            The normative requirement is only that there must be a way for keyboard interface users to perform\n            the same, or comparable, actions and to operate the content. Generally, the easiest way\n            to achieve this is to provide controls that can be operated with all possible input devices;\n            however, if a web application implements a separate mode of operation for keyboard interface users,\n            it will\nnot\nfail the success criterion.",
    "principle": "Operable",
    "guideline": "2.1 Keyboard Accessible"
  },
  {
    "id": "2.1.1_success_criterion",
    "type": "sc",
    "sc_id": "2.1.1",
    "section": "success_criterion",
    "text": "[2.1.1 Keyboard] (Level A)\nDescription: All functionality of the content is operable through a keyboard interface without requiring specific timings for individual keystrokes, except where the underlying\n      function requires input that depends on the path of the user's movement and not just\n      the endpoints.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nAll\nfunctionality\nof the content is operable through a\nkeyboard interface\nwithout requiring specific timings for individual keystrokes, except where the underlying\n      function requires input that depends on the path of the user's movement and not just\n      the endpoints.\nNote 1\nThis exception relates to the underlying function, not the input technique. For example,\n      if using handwriting to enter text, the input technique (handwriting) requires path-dependent\n      input but the underlying function (text input) does not.\nNote 2\nThis does not forbid and should not discourage providing mouse input or other input\n      methods in addition to keyboard operation.",
    "principle": "Operable",
    "guideline": "2.1 Keyboard Accessible"
  },
  {
    "id": "2.1.1_benefits",
    "type": "sc",
    "sc_id": "2.1.1",
    "section": "benefits",
    "text": "[2.1.1 Keyboard] (Level A)\nDescription: All functionality of the content is operable through a keyboard interface without requiring specific timings for individual keystrokes, except where the underlying\n      function requires input that depends on the path of the user's movement and not just\n      the endpoints.\n\nSection: benefits\n\nBenefits\nPeople who are blind (who cannot use devices such as mice that require eye-hand coordination)\nPeople with low vision (who may have trouble finding or tracking a pointer indicator\n            on screen)\nSome people with hand tremors find using a mouse very difficult and therefore usually\n            use a keyboard",
    "principle": "Operable",
    "guideline": "2.1 Keyboard Accessible"
  },
  {
    "id": "2.1.1_examples",
    "type": "sc",
    "sc_id": "2.1.1",
    "section": "examples",
    "text": "[2.1.1 Keyboard] (Level A)\nDescription: All functionality of the content is operable through a keyboard interface without requiring specific timings for individual keystrokes, except where the underlying\n      function requires input that depends on the path of the user's movement and not just\n      the endpoints.\n\nSection: examples\n\nExamples\nExample 1: A drawing Program\nA drawing program allows users to create, size, position and rotate objects from the keyboard.\nExample 2: A drag and Drop Feature\nAn application that uses drag and drop also supports \"cut\" and \"paste\" or form controls to move objects.\nExample 3: Moving between and connecting discrete points\nA connect-the-dots program allows the user to move between dots on a screen and use\n               the spacebar to connect the current dot to the previous one.\nExample 4: Exception - Painting Program\nA watercolor painting program passes as an exception because the brush strokes vary\n               depending on the speed and duration of the movements.\nExample 5: Exception - Model helicopter flight training simulator\nA model helicopter flight training simulator passes as an exception because the nature\n               of the simulator is to teach real-time behavior of a model helicopter.\nExample 6: A PDA with an optional keyboard\nA PDA device that is usually operated via a stylus has an optional keyboard that can\n               be attached.  The keyboard allows full web browsing in standard fashion.  The Web\n               content is operable because it was designed to work with keyboard-only access.\nExample 7: Simple search form with pointer-operable submit button\nA search form includes a text input field followed by a submit button. The submit button itself\n               has been coded so that it does\nnot\nreceive focus, and can only be activated using a pointer input.\n               However, since keyboard users can submit the search by pressing\nEnter\nin the text input\n               after typing their search terms, the form passes this success criterion.",
    "principle": "Operable",
    "guideline": "2.1 Keyboard Accessible"
  },
  {
    "id": "2.1.1_brief",
    "type": "sc",
    "sc_id": "2.1.1",
    "section": "brief",
    "text": "[2.1.1 Keyboard] (Level A)\nDescription: All functionality of the content is operable through a keyboard interface without requiring specific timings for individual keystrokes, except where the underlying\n      function requires input that depends on the path of the user's movement and not just\n      the endpoints.\n\nSection: brief\n\nIn Brief\nGoal\nEverything can be done with a keyboard except freehand movements.\nWhat to do\nEnsure pointer actions have a keyboard equivalent.\nWhy it's important\nMany people rely on the keyboard interface, including blind and some mobility impaired people.",
    "principle": "Operable",
    "guideline": "2.1 Keyboard Accessible"
  },
  {
    "id": "2.1.1_test_rules",
    "type": "sc",
    "sc_id": "2.1.1",
    "section": "test_rules",
    "text": "[2.1.1 Keyboard] (Level A)\nDescription: All functionality of the content is operable through a keyboard interface without requiring specific timings for individual keystrokes, except where the underlying\n      function requires input that depends on the path of the user's movement and not just\n      the endpoints.\n\nSection: test_rules\n\nTest Rules\nThe following are Test Rules\n    for certain aspects of this Success Criterion.\n    It is not necessary to use these particular Test Rules to check for conformance with WCAG, but they are defined and approved test methods.\n    For information on using Test Rules, see\nUnderstanding Test Rules for WCAG Success Criteria\n.\nIframe with interactive elements is not excluded from tab-order\nScrollable content can be reached with sequential focus navigation",
    "principle": "Operable",
    "guideline": "2.1 Keyboard Accessible"
  },
  {
    "id": "2.1.1_key_terms",
    "type": "sc",
    "sc_id": "2.1.1",
    "section": "key_terms",
    "text": "[2.1.1 Keyboard] (Level A)\nDescription: All functionality of the content is operable through a keyboard interface without requiring specific timings for individual keystrokes, except where the underlying\n      function requires input that depends on the path of the user's movement and not just\n      the endpoints.\n\nSection: key_terms\n\nKey Terms\nfunctionality\nprocesses\nand outcomes achievable through user action\nkeyboard interface\ninterface used by software to obtain keystroke input\nNote 1\nA keyboard interface allows users to provide keystroke input to programs even if the\n        native technology does not contain a keyboard.\nExample\nA touchscreen PDA has a keyboard interface built into its operating system as well\n        as a connector for external keyboards. Applications on the PDA can use the interface\n        to obtain keyboard input either from an external keyboard or from other applications\n        that provide simulated keyboard output, such as handwriting interpreters or speech-to-text\n        applications with \"keyboard emulation\" functionality.\nNote 2\nOperation of the application (or parts of the application) through a keyboard-operated\n      mouse emulator, such as MouseKeys, does not qualify as operation through a keyboard\n      interface because operation of the program is through its pointing device interface,\n      not through its keyboard interface.\nprocess\nseries of user actions where each action is required in order to complete an activity\nExample 1\nSuccessful use of a series of web pages on a shopping site requires users to view\n      alternative products, prices and offers, select products, submit an order, provide\n      shipping information and provide payment information.\nExample 2\nAn account registration page requires successful completion of a\nTuring test\nbefore\n      the registration form can be accessed.",
    "principle": "Operable",
    "guideline": "2.1 Keyboard Accessible"
  },
  {
    "id": "2.1.1_sufficient",
    "type": "sc_sufficient",
    "sc_id": "2.1.1",
    "techniques": [
      "G202",
      "H91",
      "H91",
      "PDF3",
      "PDF11",
      "PDF23",
      "G90",
      "SCR20",
      "SCR35",
      "SCR2"
    ],
    "text": "[2.1.1 Keyboard] (Level A)\nDescription: All functionality of the content is operable through a keyboard interface without requiring specific timings for individual keystrokes, except where the underlying\n      function requires input that depends on the path of the user's movement and not just\n      the endpoints.\n\nSufficient techniques for SC 2.1.1 (no situation): G202, H91, H91, PDF3, PDF11, PDF23, G90, SCR20, SCR35, SCR2",
    "principle": "Operable",
    "guideline": "2.1 Keyboard Accessible"
  },
  {
    "id": "2.1.1_advisory",
    "type": "sc_advisory",
    "sc_id": "2.1.1",
    "techniques": [
      "SCR29"
    ],
    "text": "[2.1.1 Keyboard] (Level A)\nDescription: All functionality of the content is operable through a keyboard interface without requiring specific timings for individual keystrokes, except where the underlying\n      function requires input that depends on the path of the user's movement and not just\n      the endpoints.\n\nAdvisory techniques for SC 2.1.1: SCR29",
    "principle": "Operable",
    "guideline": "2.1 Keyboard Accessible"
  },
  {
    "id": "2.1.1_failures",
    "type": "sc_failures",
    "sc_id": "2.1.1",
    "techniques": [
      "F54",
      "F55",
      "F42"
    ],
    "text": "[2.1.1 Keyboard] (Level A)\nDescription: All functionality of the content is operable through a keyboard interface without requiring specific timings for individual keystrokes, except where the underlying\n      function requires input that depends on the path of the user's movement and not just\n      the endpoints.\n\nCommon failures for SC 2.1.1: F54, F55, F42",
    "principle": "Operable",
    "guideline": "2.1 Keyboard Accessible"
  },
  {
    "id": "2.1.2_intent",
    "type": "sc",
    "sc_id": "2.1.2",
    "section": "intent",
    "text": "[2.1.2 No Keyboard Trap] (Level A)\nDescription: If keyboard focus can be moved to a component of the page using a keyboard interface, then focus can be moved away from that component using only a keyboard interface,\n      and, if it requires more than unmodified arrow or tab keys or other standard exit\n      methods, the user is advised of the method for moving focus away.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to ensure that that content does not \"trap\"\n         keyboard focus within subsections of content on a web page. This is a common problem\n         when multiple formats are combined within a page and rendered using plug-ins or embedded\n         applications.\nThere may be times when the functionality of the web page restricts the focus to a\n         subsection of the content, as long as the user knows how to leave that state and \"untrap\"\n         the focus.",
    "principle": "Operable",
    "guideline": "2.1 Keyboard Accessible"
  },
  {
    "id": "2.1.2_success_criterion",
    "type": "sc",
    "sc_id": "2.1.2",
    "section": "success_criterion",
    "text": "[2.1.2 No Keyboard Trap] (Level A)\nDescription: If keyboard focus can be moved to a component of the page using a keyboard interface, then focus can be moved away from that component using only a keyboard interface,\n      and, if it requires more than unmodified arrow or tab keys or other standard exit\n      methods, the user is advised of the method for moving focus away.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nIf keyboard focus can be moved to a component of the page using a\nkeyboard interface\n, then focus can be moved away from that component using only a keyboard interface,\n      and, if it requires more than unmodified arrow or tab keys or other standard exit\n      methods, the user is advised of the method for moving focus away.\nNote\nSince any content that does not meet this success criterion can interfere with a user's\n      ability to use the whole page, all content on the web page (whether it is used to\n      meet other success criteria or not) must meet this success criterion. See\nConformance Requirement 5: Non-Interference\n.",
    "principle": "Operable",
    "guideline": "2.1 Keyboard Accessible"
  },
  {
    "id": "2.1.2_benefits",
    "type": "sc",
    "sc_id": "2.1.2",
    "section": "benefits",
    "text": "[2.1.2 No Keyboard Trap] (Level A)\nDescription: If keyboard focus can be moved to a component of the page using a keyboard interface, then focus can be moved away from that component using only a keyboard interface,\n      and, if it requires more than unmodified arrow or tab keys or other standard exit\n      methods, the user is advised of the method for moving focus away.\n\nSection: benefits\n\nBenefits\nPeople who rely on a keyboard or keyboard interface to use the Web including people\n            who are blind and people with physical disabilities.",
    "principle": "Operable",
    "guideline": "2.1 Keyboard Accessible"
  },
  {
    "id": "2.1.2_examples",
    "type": "sc",
    "sc_id": "2.1.2",
    "section": "examples",
    "text": "[2.1.2 No Keyboard Trap] (Level A)\nDescription: If keyboard focus can be moved to a component of the page using a keyboard interface, then focus can be moved away from that component using only a keyboard interface,\n      and, if it requires more than unmodified arrow or tab keys or other standard exit\n      methods, the user is advised of the method for moving focus away.\n\nSection: examples\n\nExamples\nA calendar widget\nA calendar widget allows users to add, remove or update items in their calendar using\n               the keyboard. The controls in the widget are part of the tab order within the Web\n               page, allowing users to tab through the controls in the widget as well as to any links\n               or controls that follow.\nA puzzle applet\nOnce a user tabs into an applet, further tabs and other keystrokes are handled by\n               the applet. Instructions describing the keystroke used to exit the applet are provided\n               prior to the applet as well as within the applet itself.\nA modal dialog box\nA web application brings up a dialog box. At the bottom of the dialog are two buttons,\n               Cancel and OK. When the dialog has been opened, focus is trapped within the dialog;\n               tabbing from the last control in the dialog takes focus to the first control in the\n               dialog. The dialog is dismissed by activating the Cancel button or the OK button.",
    "principle": "Operable",
    "guideline": "2.1 Keyboard Accessible"
  },
  {
    "id": "2.1.2_brief",
    "type": "sc",
    "sc_id": "2.1.2",
    "section": "brief",
    "text": "[2.1.2 No Keyboard Trap] (Level A)\nDescription: If keyboard focus can be moved to a component of the page using a keyboard interface, then focus can be moved away from that component using only a keyboard interface,\n      and, if it requires more than unmodified arrow or tab keys or other standard exit\n      methods, the user is advised of the method for moving focus away.\n\nSection: brief\n\nIn Brief\nGoal\nKeyboard users don't get stuck.\nWhat to do\nEnsure users always know how to navigate away from components.\nWhy it's important\nPeople who rely on the keyboard often have no other means to navigate.",
    "principle": "Operable",
    "guideline": "2.1 Keyboard Accessible"
  },
  {
    "id": "2.1.2_test_rules",
    "type": "sc",
    "sc_id": "2.1.2",
    "section": "test_rules",
    "text": "[2.1.2 No Keyboard Trap] (Level A)\nDescription: If keyboard focus can be moved to a component of the page using a keyboard interface, then focus can be moved away from that component using only a keyboard interface,\n      and, if it requires more than unmodified arrow or tab keys or other standard exit\n      methods, the user is advised of the method for moving focus away.\n\nSection: test_rules\n\nTest Rules\nThe following are Test Rules\n    for certain aspects of this Success Criterion.\n    It is not necessary to use these particular Test Rules to check for conformance with WCAG, but they are defined and approved test methods.\n    For information on using Test Rules, see\nUnderstanding Test Rules for WCAG Success Criteria\n.\nFocusable element has no keyboard trap",
    "principle": "Operable",
    "guideline": "2.1 Keyboard Accessible"
  },
  {
    "id": "2.1.2_key_terms",
    "type": "sc",
    "sc_id": "2.1.2",
    "section": "key_terms",
    "text": "[2.1.2 No Keyboard Trap] (Level A)\nDescription: If keyboard focus can be moved to a component of the page using a keyboard interface, then focus can be moved away from that component using only a keyboard interface,\n      and, if it requires more than unmodified arrow or tab keys or other standard exit\n      methods, the user is advised of the method for moving focus away.\n\nSection: key_terms\n\nKey Terms\nkeyboard interface\ninterface used by software to obtain keystroke input\nNote 1\nA keyboard interface allows users to provide keystroke input to programs even if the\n        native technology does not contain a keyboard.\nExample\nA touchscreen PDA has a keyboard interface built into its operating system as well\n        as a connector for external keyboards. Applications on the PDA can use the interface\n        to obtain keyboard input either from an external keyboard or from other applications\n        that provide simulated keyboard output, such as handwriting interpreters or speech-to-text\n        applications with \"keyboard emulation\" functionality.\nNote 2\nOperation of the application (or parts of the application) through a keyboard-operated\n      mouse emulator, such as MouseKeys, does not qualify as operation through a keyboard\n      interface because operation of the program is through its pointing device interface,\n      not through its keyboard interface.",
    "principle": "Operable",
    "guideline": "2.1 Keyboard Accessible"
  },
  {
    "id": "2.1.2_sufficient",
    "type": "sc_sufficient",
    "sc_id": "2.1.2",
    "techniques": [
      "G21"
    ],
    "text": "[2.1.2 No Keyboard Trap] (Level A)\nDescription: If keyboard focus can be moved to a component of the page using a keyboard interface, then focus can be moved away from that component using only a keyboard interface,\n      and, if it requires more than unmodified arrow or tab keys or other standard exit\n      methods, the user is advised of the method for moving focus away.\n\nSufficient techniques for SC 2.1.2 (no situation): G21",
    "principle": "Operable",
    "guideline": "2.1 Keyboard Accessible"
  },
  {
    "id": "2.1.2_failures",
    "type": "sc_failures",
    "sc_id": "2.1.2",
    "techniques": [
      "F10"
    ],
    "text": "[2.1.2 No Keyboard Trap] (Level A)\nDescription: If keyboard focus can be moved to a component of the page using a keyboard interface, then focus can be moved away from that component using only a keyboard interface,\n      and, if it requires more than unmodified arrow or tab keys or other standard exit\n      methods, the user is advised of the method for moving focus away.\n\nCommon failures for SC 2.1.2: F10",
    "principle": "Operable",
    "guideline": "2.1 Keyboard Accessible"
  },
  {
    "id": "2.1.3_intent",
    "type": "sc",
    "sc_id": "2.1.3",
    "section": "intent",
    "text": "[2.1.3 Keyboard (No Exception)] (Level AAA)\nDescription: All functionality of the content is operable through a keyboard interface without requiring specific timings for individual keystrokes.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to ensure that\nall\ncontent is operable from the keyboard. This is the same as Success Criterion 2.1.1,\n         except that no exceptions are allowed. This does not mean that content where the underlying\n         function requires input that depends on the path of the user's movement and not just\n         the endpoints (excluded from the requirements of 2.1.1) must be made keyboard accessible.\n         Rather, it means that content that uses path-dependent input cannot conform to this\n         success criterion and therefore cannot meet Guideline 2.1 at Level AAA.\nNote\nPlatforms and user agents usually have conventions for how web content or\n            applications are controlled with a keyboard interface. If content does not follow\n            the platform/user agent conventions it may be difficult to use, as users will need\n            to learn different interaction methods. As a\nbest practice\n, content\n            should follow the platform/user agent conventions. However, deviating from these\n            conventions does\nnot\nfail the normative requirement of this success criterion.\nFor instance, buttons that have focus can generally be activated using both the\nEnter\nkey and the\nSpace\nbar. If a custom button control\n            in a web application instead only reacts to\nEnter\n(or even a completely custom key or key combination), this still\nsatisfies\nthe requirements of this success criterion.\nNote\nThis success criterion does not require that every visible control that can be activated\n            using a pointer (such as a mouse or touch screen input) must also be focusable and actionable using the keyboard.\n            The normative requirement is only that there must be a way for keyboard interface users to perform\n            the same, or comparable, actions and to operate the content. Generally, the easiest way\n            to achieve this is to provide controls that can be operated with all possible input devices;\n            however, if a web application implements a separate mode of operation for keyboard interface users,\n            it will\nnot\nfail the success criterion.",
    "principle": "Operable",
    "guideline": "2.1 Keyboard Accessible"
  },
  {
    "id": "2.1.3_success_criterion",
    "type": "sc",
    "sc_id": "2.1.3",
    "section": "success_criterion",
    "text": "[2.1.3 Keyboard (No Exception)] (Level AAA)\nDescription: All functionality of the content is operable through a keyboard interface without requiring specific timings for individual keystrokes.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nAll\nfunctionality\nof the content is operable through a\nkeyboard interface\nwithout requiring specific timings for individual keystrokes.",
    "principle": "Operable",
    "guideline": "2.1 Keyboard Accessible"
  },
  {
    "id": "2.1.3_brief",
    "type": "sc",
    "sc_id": "2.1.3",
    "section": "brief",
    "text": "[2.1.3 Keyboard (No Exception)] (Level AAA)\nDescription: All functionality of the content is operable through a keyboard interface without requiring specific timings for individual keystrokes.\n\nSection: brief\n\nIn Brief\nGoal\nEverything can be done with a keyboard.\nWhat to do\nEnsure all pointer actions have a keyboard equivalent.\nWhy it's important\nPeople who can only use the keyboard interface need to be able to accomplish everything.",
    "principle": "Operable",
    "guideline": "2.1 Keyboard Accessible"
  },
  {
    "id": "2.1.3_test_rules",
    "type": "sc",
    "sc_id": "2.1.3",
    "section": "test_rules",
    "text": "[2.1.3 Keyboard (No Exception)] (Level AAA)\nDescription: All functionality of the content is operable through a keyboard interface without requiring specific timings for individual keystrokes.\n\nSection: test_rules\n\nTest Rules\nThe following are Test Rules\n    for certain aspects of this Success Criterion.\n    It is not necessary to use these particular Test Rules to check for conformance with WCAG, but they are defined and approved test methods.\n    For information on using Test Rules, see\nUnderstanding Test Rules for WCAG Success Criteria\n.\nIframe with interactive elements is not excluded from tab-order\nScrollable content can be reached with sequential focus navigation",
    "principle": "Operable",
    "guideline": "2.1 Keyboard Accessible"
  },
  {
    "id": "2.1.3_key_terms",
    "type": "sc",
    "sc_id": "2.1.3",
    "section": "key_terms",
    "text": "[2.1.3 Keyboard (No Exception)] (Level AAA)\nDescription: All functionality of the content is operable through a keyboard interface without requiring specific timings for individual keystrokes.\n\nSection: key_terms\n\nKey Terms\nfunctionality\nprocesses\nand outcomes achievable through user action\nkeyboard interface\ninterface used by software to obtain keystroke input\nNote 1\nA keyboard interface allows users to provide keystroke input to programs even if the\n        native technology does not contain a keyboard.\nExample\nA touchscreen PDA has a keyboard interface built into its operating system as well\n        as a connector for external keyboards. Applications on the PDA can use the interface\n        to obtain keyboard input either from an external keyboard or from other applications\n        that provide simulated keyboard output, such as handwriting interpreters or speech-to-text\n        applications with \"keyboard emulation\" functionality.\nNote 2\nOperation of the application (or parts of the application) through a keyboard-operated\n      mouse emulator, such as MouseKeys, does not qualify as operation through a keyboard\n      interface because operation of the program is through its pointing device interface,\n      not through its keyboard interface.\nprocess\nseries of user actions where each action is required in order to complete an activity\nExample 1\nSuccessful use of a series of web pages on a shopping site requires users to view\n      alternative products, prices and offers, select products, submit an order, provide\n      shipping information and provide payment information.\nExample 2\nAn account registration page requires successful completion of a\nTuring test\nbefore\n      the registration form can be accessed.",
    "principle": "Operable",
    "guideline": "2.1 Keyboard Accessible"
  },
  {
    "id": "2.1.4_intent",
    "type": "sc",
    "sc_id": "2.1.4",
    "section": "intent",
    "text": "[2.1.4 Character Key Shortcuts] (Level A)\nDescription: If a keyboard shortcut is implemented in content using only letter (including upper- and lower-case letters), punctuation, number, or symbol characters, then at least one of the following is true:\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to reduce accidental activation of keyboard shortcuts. Character key shortcuts work well for many keyboard users. However, they can be inappropriate and frustrating for speech input users, whose dictation is interpreted as strings of letters, and for keyboard users who are prone to accidentally hit keys. To rectify this issue, authors need to allow users to turn off or reconfigure shortcuts that are made up of only character keys.\nNote\nEven though this success criterion refers to\ncharacter keys\n, note that it's not relevant whether a shortcut can be activated using a single physical key on a keyboard, or if it requires a combination of keys to be pressed. For instance, on most full-size US and UK keyboard, the\n?\n(question mark) symbol is accessed using\nShift\n+\n/\n(forward slash key next to the right-hand\nShift\nkey). On a UK keyboard, in Windows, the\né\n(lowercase \"e\" with an acute accent) requires the use of\nAltGr\n+\ne\n. The specific key combination required for certain characters will also vary depending on the user's keyboard layout. However, shortcuts that use these characters still fall under the requirements of this success criterion. What matters is that a shortcut relies on a printable character (letters, punctuation, numbers, symbol characters), and not the number of physical keyboard keys that users need to press to trigger it.\nNote\nThe success criterion also applies to situations where a shortcut is based on a\nsequence\nof character keys – for example, pressing\nG\nand then\nA\nin quick succession to trigger an action. While the individual character key presses don't immediately trigger the action, overall these types of shortcuts still rely on a series of\ncharacter keys\n.\nThis success criterion doesn't affect components such as listboxes and drop-down menus. Although these components contain values (words) that may be selected by one or more character keys, the shortcuts are only active when the components have focus. Other components such as menus may be accessed or opened with a single non-character shortcut (e.g.,\nAlt\nor\nAlt\n+\nF\n) before pressing a single character key to select an item. This makes the full path to invoking a menu a two-step shortcut that includes a non-printable key.\nAccesskeys\nare also not affected because they are generally (depending on the user agent) activated using modifier keys.\nBackground on the mechanics of speech input\nSpeech input users generally work in a single mode where they can use a mix of dictation and speech commands. This works well because the user knows to pause before and after commands, and commands are usually at least two words long. So, for instance, a user might say a bit of dictation, such as \"the small boat\", then pause, and say a command to delete that dictation, such as \"Delete Line\". In contrast, if the user were to say the two phrases together without a pause, the whole phrase would come out as dictation (i.e., \"the small boat delete line\"). Although speech input programs often include modes that listen only for dictation or only for commands, most speech users use the all-encompassing mode all the time because it is a much more efficient workflow. It could decrease command efficiency significantly if users were to change to command mode and back before and after issuing each command.\nSpeech users can also speak most keyboard commands (e.g., \"press Control Foxtrot\") without any problems. If the website or app is keyboard enabled, the speech user can also write a native speech macro that calls the keyboard command, such as \"This Print\" to carry out\nCtrl\n+\nP\n.\nSingle-key shortcuts are the exception. While using single letter keys as controls might be appropriate and efficient for many keyboard users, single-key shortcuts are disastrous for speech users. The reason for this is that when only a single key is used to trip a command, a spoken word can become a barrage of single-key commands if the cursor focus happens to be in the wrong place.\nFor example, a speech-input user named Kim has her cursor focus in the main window of a web mail application that uses common keyboard shortcuts to navigate (\nk\n), archive (\ny\n) and mute messages (\nm\n). A coworker named Mike enters her office and says \"Hey Kim\" and her microphone picks that up. The Y of \"hey\" archives the current message. K in \"Kim\" moves down one conversation and M mutes a message or thread. And, if Kim looks up and says \"Hey Mike\" without remembering to turn off the microphone, the same three things happen in a different sequence.\nA user interacting with a web page or web app that doesn't use single-character shortcuts doesn't have this problem. Inadvertent strings of characters from the speech application are not interpreted as shortcuts if a modifier key is required. A speech user filling in a text input form may find that a phrase that is accidentally picked up by the speech microphone results in stray text being entered into the field, but that is easily seen and undone. The Resources section of this page contains links to videos demonstrating these types of issues.",
    "principle": "Operable",
    "guideline": "2.1 Keyboard Accessible"
  },
  {
    "id": "2.1.4_success_criterion",
    "type": "sc",
    "sc_id": "2.1.4",
    "section": "success_criterion",
    "text": "[2.1.4 Character Key Shortcuts] (Level A)\nDescription: If a keyboard shortcut is implemented in content using only letter (including upper- and lower-case letters), punctuation, number, or symbol characters, then at least one of the following is true:\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nIf a\nkeyboard shortcut\nis implemented in content using only letter (including upper- and lower-case letters), punctuation, number, or symbol characters, then at least one of the following is true:\nTurn off\nA\nmechanism\nis available to turn the shortcut off;\nRemap\nA mechanism is available to remap the shortcut to include one or more non-printable keyboard keys (e.g., Ctrl, Alt);\nActive only on focus\nThe keyboard shortcut for a\nuser interface component\nis only active when that component has focus.",
    "principle": "Operable",
    "guideline": "2.1 Keyboard Accessible"
  },
  {
    "id": "2.1.4_benefits",
    "type": "sc",
    "sc_id": "2.1.4",
    "section": "benefits",
    "text": "[2.1.4 Character Key Shortcuts] (Level A)\nDescription: If a keyboard shortcut is implemented in content using only letter (including upper- and lower-case letters), punctuation, number, or symbol characters, then at least one of the following is true:\n\nSection: benefits\n\nBenefits\nSpeech users will be able to turn off single-key shortcuts so they can avoid accidentally firing batches of them at once. This will allow speech users to make full use of programs that offer single-key shortcuts to keyboard users.\nKeyboard-only users who have dexterity challenges can also be prone to accidentally hitting keys. Those users would be able to avoid problematic single character shortcuts by turning them off or modifying them to include at least one non-character key.\nAllowing\nall\nshortcut keys to be remapped can help users with some cognitive disabilities, since the same shortcuts can be assigned to perform the same actions across different applications.",
    "principle": "Operable",
    "guideline": "2.1 Keyboard Accessible"
  },
  {
    "id": "2.1.4_examples",
    "type": "sc",
    "sc_id": "2.1.4",
    "section": "examples",
    "text": "[2.1.4 Character Key Shortcuts] (Level A)\nDescription: If a keyboard shortcut is implemented in content using only letter (including upper- and lower-case letters), punctuation, number, or symbol characters, then at least one of the following is true:\n\nSection: examples\n\nExamples\nDisable Shortcuts\nA mechanism is provided to allow users to disable character-key shortcuts. The character key shortcuts are not the only way to carry out these commands. A speech user disables the shortcuts and can prevent words that are picked up by the microphone from triggering single-key shortcuts.\nAlternate Control\nKeyboard-only users are in a long issues thread. While reading the thread they accidentally hit the S key, which moves focus to the search bar at the top of the document. This causes them to lose their place and train of thought. However, a mechanism is provided to allow users to change character-key shortcuts. They change the shortcut to include another key so they can avoid future interruptions.",
    "principle": "Operable",
    "guideline": "2.1 Keyboard Accessible"
  },
  {
    "id": "2.1.4_brief",
    "type": "sc",
    "sc_id": "2.1.4",
    "section": "brief",
    "text": "[2.1.4 Character Key Shortcuts] (Level A)\nDescription: If a keyboard shortcut is implemented in content using only letter (including upper- and lower-case letters), punctuation, number, or symbol characters, then at least one of the following is true:\n\nSection: brief\n\nIn Brief\nGoal\nReduce accidental activation of keyboard shortcuts.\nWhat to do\nEnsure character-only shortcut keys can be turned off or modified.\nWhy it's important\nCharacter-key shortcuts are easy to accidentally trigger, especially with speech input.",
    "principle": "Operable",
    "guideline": "2.1 Keyboard Accessible"
  },
  {
    "id": "2.1.4_resources",
    "type": "sc",
    "sc_id": "2.1.4",
    "section": "resources",
    "text": "[2.1.4 Character Key Shortcuts] (Level A)\nDescription: If a keyboard shortcut is implemented in content using only letter (including upper- and lower-case letters), punctuation, number, or symbol characters, then at least one of the following is true:\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nWeb apps that use character-key shortcuts and allow users to disable and/or change these shortcuts:\nGmail\nWordPress\nVideos of speech user trouble with single character key shortcuts:\nSingle character key shortcuts affecting speech input – example 1\nSingle character key shortcuts affecting speech input – example 2",
    "principle": "Operable",
    "guideline": "2.1 Keyboard Accessible"
  },
  {
    "id": "2.1.4_test_rules",
    "type": "sc",
    "sc_id": "2.1.4",
    "section": "test_rules",
    "text": "[2.1.4 Character Key Shortcuts] (Level A)\nDescription: If a keyboard shortcut is implemented in content using only letter (including upper- and lower-case letters), punctuation, number, or symbol characters, then at least one of the following is true:\n\nSection: test_rules\n\nTest Rules\nThe following are Test Rules\n    for certain aspects of this Success Criterion.\n    It is not necessary to use these particular Test Rules to check for conformance with WCAG, but they are defined and approved test methods.\n    For information on using Test Rules, see\nUnderstanding Test Rules for WCAG Success Criteria\n.\nNo keyboard shortcut uses only printable characters",
    "principle": "Operable",
    "guideline": "2.1 Keyboard Accessible"
  },
  {
    "id": "2.1.4_key_terms",
    "type": "sc",
    "sc_id": "2.1.4",
    "section": "key_terms",
    "text": "[2.1.4 Character Key Shortcuts] (Level A)\nDescription: If a keyboard shortcut is implemented in content using only letter (including upper- and lower-case letters), punctuation, number, or symbol characters, then at least one of the following is true:\n\nSection: key_terms\n\nKey Terms\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\nconformance\nsatisfying all the requirements of a given standard, guideline or specification\nkeyboard shortcut\nalternative means of triggering an action by the pressing of one or more keys\nmechanism\nprocess\nor technique for achieving a result\nNote 1\nThe mechanism may be explicitly provided in the content, or may be\nrelied upon\nto be provided by either the platform or by\nuser agents\n, including\nassistive technologies\n.\nNote 2\nThe mechanism needs to meet all success criteria for the conformance level claimed.\nprocess\nseries of user actions where each action is required in order to complete an activity\nExample 1\nSuccessful use of a series of web pages on a shopping site requires users to view\n      alternative products, prices and offers, select products, submit an order, provide\n      shipping information and provide payment information.\nExample 2\nAn account registration page requires successful completion of a\nTuring test\nbefore\n      the registration form can be accessed.\nrelied upon\nthe content would not\nconform\nif that\ntechnology\nis turned off or is not supported\ntechnology\nmechanism\nfor encoding instructions to be rendered, played or executed by\nuser agents\nNote 1\nAs used in these guidelines \"web technology\" and the word \"technology\" (when used\n      alone) both refer to web content technologies.\nNote 2\nWeb content technologies may include markup languages, data formats, or programming\n      languages that authors may use alone or in combination to create end-user experiences\n      that range from static web pages to synchronized media presentations to dynamic Web\n      applications.\nExample\nSome common examples of web content technologies include HTML, CSS, SVG, PNG, PDF,\n      Flash, and JavaScript.\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.\nuser interface component\na part of the content that is perceived by users as a single control for a distinct\n      function\nNote 1\nMultiple user interface components may be implemented as a single programmatic element.\n      \"Components\" here is not tied to programming techniques, but rather to what the user\n      perceives as separate controls.\nNote 2\nUser interface components include form elements and links as well as components generated\n      by scripts.\nNote 3\nWhat is meant by \"component\" or \"user interface component\" here is also sometimes\n      called \"user interface element\".\nExample\nAn applet has a \"control\" that can be used to move through content by line or page\n      or random access. Since each of these would need to have a name and be settable independently,\n      they would each be a \"user interface component.\"",
    "principle": "Operable",
    "guideline": "2.1 Keyboard Accessible"
  },
  {
    "id": "2.1.4_sufficient",
    "type": "sc_sufficient",
    "sc_id": "2.1.4",
    "techniques": [
      "G217"
    ],
    "text": "[2.1.4 Character Key Shortcuts] (Level A)\nDescription: If a keyboard shortcut is implemented in content using only letter (including upper- and lower-case letters), punctuation, number, or symbol characters, then at least one of the following is true:\n\nSufficient techniques for SC 2.1.4 (no situation): G217",
    "principle": "Operable",
    "guideline": "2.1 Keyboard Accessible"
  },
  {
    "id": "2.1.4_failures",
    "type": "sc_failures",
    "sc_id": "2.1.4",
    "techniques": [
      "F99"
    ],
    "text": "[2.1.4 Character Key Shortcuts] (Level A)\nDescription: If a keyboard shortcut is implemented in content using only letter (including upper- and lower-case letters), punctuation, number, or symbol characters, then at least one of the following is true:\n\nCommon failures for SC 2.1.4: F99",
    "principle": "Operable",
    "guideline": "2.1 Keyboard Accessible"
  },
  {
    "id": "2.2.1_intent",
    "type": "sc",
    "sc_id": "2.2.1",
    "section": "intent",
    "text": "[2.2.1 Timing Adjustable] (Level A)\nDescription: For each time limit that is set by the content, at least one of the following is true:\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to ensure that users with disabilities are\n         given adequate time to interact with web content whenever possible. People with disabilities\n         such as blindness, low vision, dexterity impairments, and cognitive limitations may\n         require more time to read content or to perform functions such as filling out on-line\n         forms. If Web functions are time-dependent, it will be difficult for some users to\n         perform the required action before a time limit occurs. This may render the service\n         inaccessible to them. Designing functions that are not time-dependent will help people\n         with disabilities succeed at completing these functions. Providing options to disable\n         time limits, customize the length of time limits, or request more time before a time\n         limit occurs helps those users who require more time than expected to successfully\n         complete tasks. These options are listed in the order that will be most helpful for\n         the user. Disabling time limits is better than customizing the length of time limits,\n         which is better than requesting more time before a time limit occurs.\nAny process that happens without user initiation after a set time or on a periodic\n         basis is a time limit. This includes partial or full updates of content (for example,\n         page refresh), changes to content, or the expiration of a window of opportunity for\n         a user to react to a request for input.\nIt also includes content that is advancing or updating at a rate beyond the user's ability to read and/or understand it. In other words, animated, moving or scrolling content introduces a time limit on a users ability to read content.\nThis success criterion is generally not applicable when the content repeats or is synchronized with other content, so long as the information and data is adjustable or otherwise under the control of the end user.  Examples of time limits for which this success criterion is not applicable include scrolling text that repeats, captioning, and\ncarousels\n.  These are situations which do include time limits, but the content is still available to the user because it has controls for accessing it, as specified in\n2.2.2 Pause, Stop, Hide\n.\nIn some cases, however, it is not possible to change the time limit (for example, for an auction or other real-time event) and exceptions are therefore provided for those cases.\nContent that operates on a timer does not need to be time adjustable if there is an alternative that does not rely on a timer. For example, a web application such as an email client provides notification of new email arriving with a temporary message (such as a 'toast' message) in the lower right-hand side of the interface, and the message disappears after 5 seconds. Users are able to identify the arrival of email through other means, such as viewing the Inbox, so the disappearance of the message does not set a time limit on the their ability to determine if new mail has arrived. If the user has no other means of discovering the same information (or performing the same function), then each message would need to meet this success criterion in order to provide users with sufficient time to access the information.\nNotes regarding server time limits\nTimed server redirects can be found below under Common Failures.\nNon-timed server redirects (e.g., 3xx response codes) are not applicable because there\n            is no time limit: they work instantly.\nThis success criterion applies only to time limits that are set by the content itself.\n            For example, if a time limit is included in order to address security concerns, it\n            would be considered to have been set by the content because it  is designed to be\n            part of the presentation and interaction experience for that content. Time limits\n            set externally to content, such as by the user agent or by factors intrinsic to the\n            Internet are not under the author's control and not subject to WCAG conformance requirements.\n            Time limits set by web servers should be under the author's/organization's control\n            and are covered. (Success Criteria\n2.2.3\n,\n2.2.4\nand\n2.2.5\nmay also apply.)\nTen times the default was chosen based on clinical experience and other guidelines.\n            For example, if 15 seconds is allowed for a user to respond and hit a switch, 150\n            seconds would be sufficient to allow almost all users to hit a switch even if they\n            had trouble.\n20 seconds was also based on clinical experience and other guidelines. 20 seconds\n            to hit 'any switch' is sufficient for almost all users including those with spasticity.\n            Some would fail, but some would fail all lengths of time. A reasonable period for\n            requesting more time is required since an arbitrarily long time can provide security\n            risks to all users, including those with disabilities, for some applications. For\n            example, with kiosks or terminals that are used for financial transactions, it is\n            quite common for people to walk away without signing off. This leaves them vulnerable\n            to those walking up behind them. Providing a long period of inactivity before asking,\n            and then providing a long period for the person to indicate that they are present\n            can leave terminals open for abuse. If there is no activity the system should ask\n            if the user is there. It should then ask for an indication that a person is there\n            ('hit any key') and then wait long enough for almost anyone to respond. For \"hit any\n            key,\" 20 seconds would meet this. If the person indicates that they are still present,\n            the device should return the user to the exact condition that existed before it asked\n            the question.\n20 hours was chosen as an upper limit because it is longer than a full waking day.\nIn cases where timing is not an intrinsic requirement but giving users control over\n         timed events would invalidate the outcome, a third party can control the time limits\n         for the user (for example, granting double time on a test).\nSee also\n2.2.3: No Timing\n.",
    "principle": "Operable",
    "guideline": "2.2 Enough Time"
  },
  {
    "id": "2.2.1_success_criterion",
    "type": "sc",
    "sc_id": "2.2.1",
    "section": "success_criterion",
    "text": "[2.2.1 Timing Adjustable] (Level A)\nDescription: For each time limit that is set by the content, at least one of the following is true:\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nFor each time limit that is set by the content, at least one of the following is true:\nTurn off\nThe user is allowed to turn off the time limit before encountering it; or\nAdjust\nThe user is allowed to adjust the time limit before encountering it over a wide range\n            that is at least ten times the length of the default setting; or\nExtend\nThe user is warned before time expires and given at least 20 seconds to extend the\n            time limit with a simple action (for example, \"press the space bar\"), and the user\n            is allowed to extend the time limit at least ten times; or\nReal-time Exception\nThe time limit is a required part of a\nreal-time event\n(for example, an auction),\n            and no alternative to the time limit is possible; or\nEssential Exception\nThe time limit is\nessential\nand extending it would invalidate the activity; or\n20 Hour Exception\nThe time limit is longer than 20 hours.\nNote\nThis success criterion helps ensure that users can complete tasks without unexpected\n      changes in content or context that are a result of a time limit. This success criterion\n      should be considered in conjunction with\nSuccess Criterion 3.2.1\n, which puts limits on changes of content or context as a result of user action.",
    "principle": "Operable",
    "guideline": "2.2 Enough Time"
  },
  {
    "id": "2.2.1_benefits",
    "type": "sc",
    "sc_id": "2.2.1",
    "section": "benefits",
    "text": "[2.2.1 Timing Adjustable] (Level A)\nDescription: For each time limit that is set by the content, at least one of the following is true:\n\nSection: benefits\n\nBenefits\nPeople with physical disabilities often need more time to react, to type and to complete\n            activities.  People with low vision need more time to locate things on screen and\n            to read.   People who are blind and using screen readers may need more time to understand\n            screen layouts, to find information and to operate controls.  People who have cognitive\n            or language limitations need more time to read and to understand.  People who are\n            deaf and communicate in sign language may need more time to read information printed\n            in text (which may be a second language for some).\nIn circumstances where a sign-language interpreter may be relating audio content to\n            a user who is deaf, control over time limits is also important.\nPeople with reading disabilities, cognitive limitations, and learning disabilities\n            who may need more time to read or comprehend information can have additional time\n            to read the information by pausing the content.",
    "principle": "Operable",
    "guideline": "2.2 Enough Time"
  },
  {
    "id": "2.2.1_examples",
    "type": "sc",
    "sc_id": "2.2.1",
    "section": "examples",
    "text": "[2.2.1 Timing Adjustable] (Level A)\nDescription: For each time limit that is set by the content, at least one of the following is true:\n\nSection: examples\n\nExamples\nA website uses a client side time limit to help protect users who may step away from\n            their computer.   After a period of inactivity the web page asks if the user needs\n            more time.  If it doesn't get a response – it times out.\nA web page has a field that automatically updates with the latest headlines in a rotating\n            fashion. There is an interactive control that allows the user to extend the length\n            of time between each update to as much as ten times the default. The control can be\n            operated with either a mouse or a keyboard.\nA web page includes an animation which includes text that appears and disappears throughout.\n            In some cases, the text is scrolling across the screen and in others, it is only displayed\n            for a short time before it fades into the background. The page includes a pause button\n            so that users who have trouble reading the text before it disappears can read it.\nIn an auction, there is a time limit on the amount of time a user has to submit a\n            bid. Since the time limit applies to all users who want to bid on a particular item,\n            it would be unfair to extend the time limit for any one particular user. Therefore,\n            a time limit is required for this type of activity and no extension, adjustment, or\n            deactivation of the time limit is required by this success criterion.\nAn on-line ticket-purchasing site gives the user two minutes to confirm a purchase\n            before the seats are returned to the general pool. Because tickets on such sites can\n            sell out quickly, holding a ticket longer than that may invalidate the nature of the\n            site, so this is a case in which the timing is essential and cannot be extended without\n            invalidating the activity. However, the site does move as much of the process out\n            of the time-critical period as possible, for instance allowing users to provide necessary\n            information like name, payment method, etc., before entering the time-critical stage.\nA ticket-purchasing site allows the user two minutes to confirm purchase of selected\n            seats, but warns the user when their time is almost out and allows the user to extend\n            this time limit some number of times with a simple action such as clicking a \"Extend\n            time limit\" button.",
    "principle": "Operable",
    "guideline": "2.2 Enough Time"
  },
  {
    "id": "2.2.1_brief",
    "type": "sc",
    "sc_id": "2.2.1",
    "section": "brief",
    "text": "[2.2.1 Timing Adjustable] (Level A)\nDescription: For each time limit that is set by the content, at least one of the following is true:\n\nSection: brief\n\nIn Brief\nGoal\nUsers have adequate time to complete tasks.\nWhat to do\nLet users turn off, adjust, or extend time limits.\nWhy it's important\nPeople with disabilities may need more time to complete activities.",
    "principle": "Operable",
    "guideline": "2.2 Enough Time"
  },
  {
    "id": "2.2.1_test_rules",
    "type": "sc",
    "sc_id": "2.2.1",
    "section": "test_rules",
    "text": "[2.2.1 Timing Adjustable] (Level A)\nDescription: For each time limit that is set by the content, at least one of the following is true:\n\nSection: test_rules\n\nTest Rules\nThe following are Test Rules\n    for certain aspects of this Success Criterion.\n    It is not necessary to use these particular Test Rules to check for conformance with WCAG, but they are defined and approved test methods.\n    For information on using Test Rules, see\nUnderstanding Test Rules for WCAG Success Criteria\n.\nMeta element has no refresh delay\nMeta element has no refresh delay (no exception)",
    "principle": "Operable",
    "guideline": "2.2 Enough Time"
  },
  {
    "id": "2.2.1_key_terms",
    "type": "sc",
    "sc_id": "2.2.1",
    "section": "key_terms",
    "text": "[2.2.1 Timing Adjustable] (Level A)\nDescription: For each time limit that is set by the content, at least one of the following is true:\n\nSection: key_terms\n\nKey Terms\nessential\nif removed, would fundamentally change the information or functionality of the content,\nand\ninformation and functionality cannot be achieved in another way that would conform\nreal-time event\nevent that a) occurs at the same time as the viewing and b) is not completely generated\n      by the content\nExample 1\nA Webcast of a live performance (occurs at the same time as the viewing and is not\n      prerecorded).\nExample 2\nAn on-line auction with people bidding (occurs at the same time as the viewing).\nExample 3\nLive humans interacting in a virtual world using avatars (is not completely generated\n      by the content and occurs at the same time as the viewing).",
    "principle": "Operable",
    "guideline": "2.2 Enough Time"
  },
  {
    "id": "2.2.1_situation_A",
    "type": "sc_situation",
    "sc_id": "2.2.1",
    "situation_id": "A",
    "techniques": [
      "G133",
      "G198"
    ],
    "text": "[2.2.1 Timing Adjustable] (Level A)\nDescription: For each time limit that is set by the content, at least one of the following is true:\n\nSituation A: If there are session time limits:\n\nRelated techniques: G133, G198",
    "principle": "Operable",
    "guideline": "2.2 Enough Time"
  },
  {
    "id": "2.2.1_situation_B",
    "type": "sc_situation",
    "sc_id": "2.2.1",
    "situation_id": "B",
    "techniques": [
      "G198",
      "G180",
      "SCR16"
    ],
    "text": "[2.2.1 Timing Adjustable] (Level A)\nDescription: For each time limit that is set by the content, at least one of the following is true:\n\nSituation B: If a time limit is controlled by a script on the page:\n\nRelated techniques: G198, G180, SCR16",
    "principle": "Operable",
    "guideline": "2.2 Enough Time"
  },
  {
    "id": "2.2.1_situation_C",
    "type": "sc_situation",
    "sc_id": "2.2.1",
    "situation_id": "C",
    "techniques": [
      "G4",
      "G198",
      "SCR33",
      "SCR36"
    ],
    "text": "[2.2.1 Timing Adjustable] (Level A)\nDescription: For each time limit that is set by the content, at least one of the following is true:\n\nSituation C: If there are time limits on reading:\n\nRelated techniques: G4, G198, SCR33, SCR36",
    "principle": "Operable",
    "guideline": "2.2 Enough Time"
  },
  {
    "id": "2.2.1_failures",
    "type": "sc_failures",
    "sc_id": "2.2.1",
    "techniques": [
      "F40",
      "F41",
      "F58"
    ],
    "text": "[2.2.1 Timing Adjustable] (Level A)\nDescription: For each time limit that is set by the content, at least one of the following is true:\n\nCommon failures for SC 2.2.1: F40, F41, F58",
    "principle": "Operable",
    "guideline": "2.2 Enough Time"
  },
  {
    "id": "2.2.2_intent",
    "type": "sc",
    "sc_id": "2.2.2",
    "section": "intent",
    "text": "[2.2.2 Pause, Stop, Hide] (Level A)\nDescription: For moving, blinking, scrolling, or auto-updating information, all of the following are true:\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to avoid distracting users during their interaction\n         with a web page.\nIn the context of this Success Criterion, \"starts automatically\" broadly refers to animations/updates\n         that are not the direct result of a user's intentional activation, for example, selecting a link or button.\n\"Moving, blinking and scrolling\" refers to content in which the visible content conveys\n         a sense of motion. Common examples include motion pictures, synchronized media presentations,\n         animations, real-time games, and scrolling stock tickers. \"Auto-updating\" refers to\n         content that updates or disappears based on a preset time interval. Common time-based\n         content includes automatically updated weather information, news, stock price\n         updates, and auto-advancing presentations and messages. The requirements for moving,\n         blinking and scrolling content and for auto-updating content are the same except that:\nauthors have the option of providing the user with a means to control the frequency of updates when content is auto-updating and\nthere is no five second exception for auto-updating since it makes little sense to auto-update for a few seconds and then stop\nContent that moves or auto-updates can be a barrier to anyone who has trouble reading\n         stationary text quickly as well as anyone who has trouble tracking moving objects.\n         It can also cause problems for screen readers.\nMoving content can also be a severe distraction for some people. Certain groups, particularly\n         those with attention deficit disorders, find blinking content distracting, making\n         it difficult for them to concentrate on other parts of the web page. Five seconds\n         was chosen because it is long enough to get a user's attention, but not so long that\n         a user cannot wait out the distraction if necessary to use the page.\nContent that is paused can either resume in real-time or continue playing from the\n         point in the presentation where the user left off.\nPausing and resuming where the user left off is best for users who want to pause to\n               read content and works best when the content is not associated with a real-time event\n               or status.\nNote\nSee\n2.2.1: Timing Adjustable\nfor additional requirements related to time-limits for reading and interactions.\nPausing and jumping to current display (when pause is released) is better for information\n               that is real-time or \"status\" in nature. For example, weather radar, a stock ticker,\n               a traffic camera, or an auction timer, would present misleading information if a pause\n               caused it to display old information when the content was restarted.\nNote\nHiding content would have the same result as pausing and jumping to current display (when pause is released).\nFor a mechanism to be considered \"a mechanism for the user to pause,\" it must provide\n         the user with a means to pause that does not tie up the user or the focus so that\n         the page cannot be used.  The word \"pause\" here is meant in the sense of a \"pause\n         button\" although other mechanisms than a button can be used.   Having an animation\n         stop only so long as a user has focus on it (where it restarts as soon as the user\n         moves the focus away) would not be considered a \"mechanism for the user to pause\"\n         because it makes the page unusable in the process and would not meet this SC.\nNote\nThis success criterion is specifically concerned with moving, blinking, scrolling, and\n            auto-updating visual content. For audio content that starts automatically, refer to\n1.4.2 Audio Control\n.\nMoving, blinking, scrolling content that starts automatically because of a general user interaction (such as focusing/hovering over an element,\n            or scrolling the page), rather than as a result of an intentional\nactivation\n(such as activating a button),\n            and which doesn't provide provide a way to Pause, Stop, or Hide, will fail this Criterion, and potentially\n2.3.3 Animation from Interaction\n.\nIt is important to note that the terms \"blinking\" and \"flashing\" can sometimes refer to the same content.\n\"Blinking\" refers to content that causes a distraction problem. Blinking can be allowed\n            for a short time as long as it stops (or can be stopped)\n\"Flashing\" refers to content that can trigger a seizure (if it is more than 3 per\n            second and large and bright enough). This cannot be allowed even for a second or it\n            could cause a seizure. And turning the flash off is also not an option since the seizure\n            could occur faster than most users could turn it off.\nBlinking usually does not occur at speeds of 3 per second or more, but it can. If\n            blinking occurs faster than 3 per second, it would also be considered a flash.\nNote\n\"Flashing\" content that starts automatically will need to be evaluated against\n2.3.2 Three Flashes\nand\n2.3.1 Three Flashes or Below Threshold\n.",
    "principle": "Operable",
    "guideline": "2.2 Enough Time"
  },
  {
    "id": "2.2.2_success_criterion",
    "type": "sc",
    "sc_id": "2.2.2",
    "section": "success_criterion",
    "text": "[2.2.2 Pause, Stop, Hide] (Level A)\nDescription: For moving, blinking, scrolling, or auto-updating information, all of the following are true:\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nFor moving,\nblinking\n, scrolling, or auto-updating information, all of the following are true:\nMoving, blinking, scrolling\nFor any moving, blinking or scrolling information that (1) starts automatically, (2)\n            lasts more than five seconds, and (3) is presented in parallel with other content,\n           there is a\nmechanism\nfor the user to\npause\n, stop, or hide it unless the movement, blinking, or scrolling is part of an activity\n            where it is\nessential\n; and\nAuto-updating\nFor any auto-updating information that (1) starts automatically and (2) is presented\n            in parallel with other content, there is a mechanism for the user to pause, stop,\n            or hide it or to control the frequency of the update unless the auto-updating is part\n            of an activity where it is essential.\nNote 1\nFor requirements related to flickering or flashing content, refer to\nGuideline 2.3\n.\nNote 2\nSince any content that does not meet this success criterion can interfere with a user's\n      ability to use the whole page, all content on the web page (whether it is used to\n      meet other success criteria or not) must meet this success criterion. See\nConformance Requirement 5: Non-Interference\n.\nNote 3\nContent that is updated periodically by software or that is streamed to the user agent\n      is not required to preserve or present information that is generated or received between\n      the initiation of the pause and resuming presentation, as this may not be technically\n      possible, and in many situations could be misleading to do so.\nNote 4\nAn animation that occurs as part of a preload phase or similar situation can be considered\n      essential if interaction cannot occur during that phase for all users and if not indicating\n      progress could confuse users or cause them to think that content was frozen or broken.",
    "principle": "Operable",
    "guideline": "2.2 Enough Time"
  },
  {
    "id": "2.2.2_benefits",
    "type": "sc",
    "sc_id": "2.2.2",
    "section": "benefits",
    "text": "[2.2.2 Pause, Stop, Hide] (Level A)\nDescription: For moving, blinking, scrolling, or auto-updating information, all of the following are true:\n\nSection: benefits\n\nBenefits\nProviding content that stops blinking after five seconds or providing a mechanism\n            for users to stop blinking content allows people with certain disabilities to interact\n            with the web page.\nOne use of content that blinks is to draw the visitor's attention to that content.\n            Although this is an effective technique for all users with vision, it can be a problem\n            for some users if it persists. For certain groups, including people with low literacy,\n            reading and intellectual disabilities, and people with attention deficit disorders,\n            content that blinks may make it difficult or even impossible to interact with the\n            rest of the web page.",
    "principle": "Operable",
    "guideline": "2.2 Enough Time"
  },
  {
    "id": "2.2.2_examples",
    "type": "sc",
    "sc_id": "2.2.2",
    "section": "examples",
    "text": "[2.2.2 Pause, Stop, Hide] (Level A)\nDescription: For moving, blinking, scrolling, or auto-updating information, all of the following are true:\n\nSection: examples\n\nExamples\nAn essential animation can be paused without affecting the activity\nA website helps users understand 'how things work' through animations that demonstrate\n               processes. Animations have \"pause\" and \"restart\" buttons.\nA stock ticker\nA stock ticker has \"pause\" and \"restart\" buttons. Pausing the ticker causes it to\n               pause on the currently displayed stock. Restarting causes the ticker to resume from\n               the stopped point but with a notice that the display is delayed. Since the intent\n               of the stock ticker is usually to provide realtime information, there might also be\n               a button that would advance the ticker to the most recently traded stock.\nA game is designed so that users take turns rather than competing in real-time\nOne party can pause the game without invalidating the competitive aspect of it.\nA web advertisement\nAn advertisement blinks to get viewers attention but stops after 5 seconds\nA form prompt\nA form blinks an arrow near the submit button if a user finishes filling out the form\n               but does not activate the submit button. The blinking stops after 5 seconds.\nAn animation\nAn animation runs in the upper portion of the page but has a \"freeze animation\" button\n               near the bottom of the animation.\nA \"loading\" animation\nA preloader animation is shown on a page which requires a certain percentage of a\n               large file to be downloaded before playback can begin. The animation is the only content\n               on the page and instructs the user to please wait while the video loads. Because the\n               moving content is not presented in parallel with other content, no mechanism to pause,\n               stop or hide it needs to be provided, even though the animation may run for more than\n               5 seconds for users with slower connections.\nA full-page advertisement\nA site requires that all users view a 15 second advertisement before they can access\n               free content available from their site. Because viewing the advertisement is a requirement\n               for all users and because it is not presented in parallel with other content, no mechanism\n               to pause, stop or hide it needs to be provided.",
    "principle": "Operable",
    "guideline": "2.2 Enough Time"
  },
  {
    "id": "2.2.2_brief",
    "type": "sc",
    "sc_id": "2.2.2",
    "section": "brief",
    "text": "[2.2.2 Pause, Stop, Hide] (Level A)\nDescription: For moving, blinking, scrolling, or auto-updating information, all of the following are true:\n\nSection: brief\n\nIn Brief\nGoal\nFewer users are distracted by content that updates or moves.\nWhat to do\nLet users control content changes that occur in parallel with other content.\nWhy it's important\nSome people with cognitive disabilities and attention deficits are distracted by continuous movement.",
    "principle": "Operable",
    "guideline": "2.2 Enough Time"
  },
  {
    "id": "2.2.2_test_rules",
    "type": "sc",
    "sc_id": "2.2.2",
    "section": "test_rules",
    "text": "[2.2.2 Pause, Stop, Hide] (Level A)\nDescription: For moving, blinking, scrolling, or auto-updating information, all of the following are true:\n\nSection: test_rules\n\nTest Rules\nThe following are Test Rules\n    for certain aspects of this Success Criterion.\n    It is not necessary to use these particular Test Rules to check for conformance with WCAG, but they are defined and approved test methods.\n    For information on using Test Rules, see\nUnderstanding Test Rules for WCAG Success Criteria\n.\nText content that changes automatically can be paused, stopped or hidden",
    "principle": "Operable",
    "guideline": "2.2 Enough Time"
  },
  {
    "id": "2.2.2_key_terms",
    "type": "sc",
    "sc_id": "2.2.2",
    "section": "key_terms",
    "text": "[2.2.2 Pause, Stop, Hide] (Level A)\nDescription: For moving, blinking, scrolling, or auto-updating information, all of the following are true:\n\nSection: key_terms\n\nKey Terms\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\nblinking\nswitch back and forth between two visual states in a way that is meant to draw attention\nNote\nSee also\nflash\n. It is possible for something to be large enough and blink brightly enough at the\n      right frequency to be also classified as a flash.\nconformance\nsatisfying all the requirements of a given standard, guideline or specification\nessential\nif removed, would fundamentally change the information or functionality of the content,\nand\ninformation and functionality cannot be achieved in another way that would conform\nflash\na pair of opposing changes in\nrelative luminance\nthat can cause seizures in some people if it is large enough and in the right frequency\n      range\nNote 1\nSee\ngeneral flash and red flash thresholds\nfor information about types of flash that are not allowed.\nNote 2\nSee also\nblinking\n.\ngeneral flash and red flash thresholds\na\nflash\nor rapidly changing image sequence is below the threshold (i.e., content\npasses\n) if any of the following are true:\nthere are no more than three\ngeneral flashes\nand / or no more than three\nred flashes\nwithin any one-second period; or\nthe combined area of flashes occurring concurrently occupies no more than a total\n         of .006 steradians within any 10 degree visual field on the screen (25% of any 10\n         degree visual field on the screen) at typical viewing distance\nwhere:\nA\ngeneral flash\nis defined as a pair of opposing changes in\nrelative luminance\nof 10% or more of the maximum relative luminance (1.0) where the relative luminance of\n         the darker image is below 0.80; and where \"a pair of opposing changes\" is an increase\n         followed by a decrease, or a decrease followed by an increase, and\nA\nred flash\nis defined as any pair of opposing transitions involving a saturated red\nException:\nFlashing that is a fine, balanced, pattern such as white noise or an alternating\n      checkerboard pattern with \"squares\" smaller than 0.1 degree (of visual field at typical\n      viewing distance) on a side does not violate the thresholds.\nNote 1\nFor general software or web content, using a 341 x 256 pixel rectangle anywhere on the displayed screen area when the content is viewed at 1024 x 768 pixels will provide a good estimate of a 10 degree visual field for standard screen sizes and viewing distances (e.g., 15-17 inch screen at 22-26 inches). This resolution of 75 - 85 ppi is known to be lower, and thus more conservative than the nominal CSS pixel resolution of 96 ppi in CSS specifications. Higher resolutions displays showing the same rendering of the content yield smaller and safer images so it is lower resolutions that are used to define the thresholds.\nNote 2\nA transition is the change in relative luminance (or relative luminance/color for\n      red flashing) between adjacent peaks and valleys in a plot of relative luminance (or\n      relative luminance/color for red flashing) measurement against time. A flash consists\n      of two opposing transitions.\nNote 3\nThe new working definition in the field for\n\"pair of opposing transitions involving a saturated red\"\n(from WCAG 2.2) is a pair of opposing transitions where, one transition is either to or from a state with a value R/(R + G + B) that is greater than or equal to 0.8, and the difference between states is more than 0.2 (unitless) in the CIE 1976 UCS chromaticity diagram. [\nISO_9241-391\n]\nNote 4\nTools are available that will carry out analysis from video screen capture. However,\n      no tool is necessary to evaluate for this condition if flashing is less than or equal\n      to 3 flashes in any one second. Content automatically passes (see #1 and #2 above).\nmechanism\nprocess\nor technique for achieving a result\nNote 1\nThe mechanism may be explicitly provided in the content, or may be\nrelied upon\nto be provided by either the platform or by\nuser agents\n, including\nassistive technologies\n.\nNote 2\nThe mechanism needs to meet all success criteria for the conformance level claimed.\npaused\nstopped by user request and not resumed until requested by user\nprocess\nseries of user actions where each action is required in order to complete an activity\nExample 1\nSuccessful use of a series of web pages on a shopping site requires users to view\n      alternative products, prices and offers, select products, submit an order, provide\n      shipping information and provide payment information.\nExample 2\nAn account registration page requires successful completion of a\nTuring test\nbefore\n      the registration form can be accessed.\nrelative luminance\nthe relative brightness of any point in a colorspace, normalized to 0 for darkest\n      black and 1 for lightest white\nNote 1\nFor the sRGB colorspace, the relative luminance of a color is defined as L = 0.2126\n      *\nR\n+ 0.7152 *\nG\n+ 0.0722 *\nB\nwhere\nR\n,\nG\nand\nB\nare defined as:\nif RsRGB <= 0.04045 then\nR\n= RsRGB/12.92 else\nR\n= ((RsRGB+0.055)/1.055) ^ 2.4\nif GsRGB <= 0.04045 then\nG\n= GsRGB/12.92 else\nG\n= ((GsRGB+0.055)/1.055) ^ 2.4\nif BsRGB <= 0.04045 then\nB\n= BsRGB/12.92 else\nB\n= ((BsRGB+0.055)/1.055) ^ 2.4\nand RsRGB, GsRGB, and BsRGB are defined as:\nRsRGB = R8bit/255\nGsRGB = G8bit/255\nBsRGB = B8bit/255\nThe \"^\" character is the exponentiation operator. (Formula taken from \n      [\nSRGB\n].)\nNote 2\nBefore May 2021 the value of 0.04045 in the definition was different (0.03928). It was taken from an older version of the specification and has been updated. It has no practical effect on the calculations in the context of these guidelines.\nNote 3\nAlmost all systems used today to view web content assume sRGB encoding. Unless it\n      is known that another color space will be used to process and display the content,\n      authors should evaluate using sRGB colorspace. If using other color spaces, see\nUnderstanding Success Criterion 1.4.3\n.\nNote 4\nIf dithering occurs after delivery, then the source color value is used. For colors\n      that are dithered at the source, the average values of the colors that are dithered\n      should be used (average R, average G, and average B).\nNote 5\nTools are available that automatically do the calculations when testing contrast and\n      flash.\nNote 6\nA\nseparate page giving the relative luminance definition using MathML\nto display the formulas is available.\nrelied upon\nthe content would not\nconform\nif that\ntechnology\nis turned off or is not supported\ntechnology\nmechanism\nfor encoding instructions to be rendered, played or executed by\nuser agents\nNote 1\nAs used in these guidelines \"web technology\" and the word \"technology\" (when used\n      alone) both refer to web content technologies.\nNote 2\nWeb content technologies may include markup languages, data formats, or programming\n      languages that authors may use alone or in combination to create end-user experiences\n      that range from static web pages to synchronized media presentations to dynamic Web\n      applications.\nExample\nSome common examples of web content technologies include HTML, CSS, SVG, PNG, PDF,\n      Flash, and JavaScript.\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.",
    "principle": "Operable",
    "guideline": "2.2 Enough Time"
  },
  {
    "id": "2.2.2_sufficient",
    "type": "sc_sufficient",
    "sc_id": "2.2.2",
    "techniques": [
      "G4",
      "SCR33",
      "G11",
      "G152",
      "SCR22",
      "G186",
      "G191"
    ],
    "text": "[2.2.2 Pause, Stop, Hide] (Level A)\nDescription: For moving, blinking, scrolling, or auto-updating information, all of the following are true:\n\nSufficient techniques for SC 2.2.2 (no situation): G4, SCR33, G11, G152, SCR22, G186, G191",
    "principle": "Operable",
    "guideline": "2.2 Enough Time"
  },
  {
    "id": "2.2.2_failures",
    "type": "sc_failures",
    "sc_id": "2.2.2",
    "techniques": [
      "F16",
      "F112",
      "F50",
      "F7"
    ],
    "text": "[2.2.2 Pause, Stop, Hide] (Level A)\nDescription: For moving, blinking, scrolling, or auto-updating information, all of the following are true:\n\nCommon failures for SC 2.2.2: F16, F112, F50, F7",
    "principle": "Operable",
    "guideline": "2.2 Enough Time"
  },
  {
    "id": "2.2.3_intent",
    "type": "sc",
    "sc_id": "2.2.3",
    "section": "intent",
    "text": "[2.2.3 No Timing] (Level AAA)\nDescription: Timing is not an essential part of the event or activity presented by the content, except for non-interactive\n      synchronized media and real-time events.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to minimize the occurrence of content that\n         requires timed interaction. This enables people with blindness, low vision, cognitive\n         limitations, or motor impairments to interact with content. This differs from the\n         Level A success criterion in that the only exception is for real-time events.\nNote\nVideo only, such as sign language, is covered in\nGuideline 1.1\n.",
    "principle": "Operable",
    "guideline": "2.2 Enough Time"
  },
  {
    "id": "2.2.3_success_criterion",
    "type": "sc",
    "sc_id": "2.2.3",
    "section": "success_criterion",
    "text": "[2.2.3 No Timing] (Level AAA)\nDescription: Timing is not an essential part of the event or activity presented by the content, except for non-interactive\n      synchronized media and real-time events.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nTiming is not an\nessential\npart of the event or activity presented by the content, except for non-interactive\nsynchronized media\nand\nreal-time events\n.",
    "principle": "Operable",
    "guideline": "2.2 Enough Time"
  },
  {
    "id": "2.2.3_benefits",
    "type": "sc",
    "sc_id": "2.2.3",
    "section": "benefits",
    "text": "[2.2.3 No Timing] (Level AAA)\nDescription: Timing is not an essential part of the event or activity presented by the content, except for non-interactive\n      synchronized media and real-time events.\n\nSection: benefits\n\nBenefits\nPeople with physical disabilities often need more time to react, to type and to complete\n            activities.  People with low vision need more time to locate things on screen and\n            to read.   People who are blind and using screen readers may need more time to understand\n            screen layouts, to find information and to operate controls.  People who have cognitive\n            or language limitations need more time to read and to understand.  People who are\n            deaf and communicate in sign language may need more time to read information printed\n            in text (which may be a second language for some).\nIn circumstances where a sign-language interpreter may be relating audio content to\n            a user who is deaf, control over time limits is also important.",
    "principle": "Operable",
    "guideline": "2.2 Enough Time"
  },
  {
    "id": "2.2.3_examples",
    "type": "sc",
    "sc_id": "2.2.3",
    "section": "examples",
    "text": "[2.2.3 No Timing] (Level AAA)\nDescription: Timing is not an essential part of the event or activity presented by the content, except for non-interactive\n      synchronized media and real-time events.\n\nSection: examples\n\nExamples\nA test is designed so that time to complete the test does not affect the scoring\nRather than calibrating an on-line test using a time limit, the test is calibrated\n               based on scores when users have no time limits.\nA game is designed so that users take turns rather than competing in real-time\nOne party can pause the game without invalidating the competitive aspect of it.",
    "principle": "Operable",
    "guideline": "2.2 Enough Time"
  },
  {
    "id": "2.2.3_brief",
    "type": "sc",
    "sc_id": "2.2.3",
    "section": "brief",
    "text": "[2.2.3 No Timing] (Level AAA)\nDescription: Timing is not an essential part of the event or activity presented by the content, except for non-interactive\n      synchronized media and real-time events.\n\nSection: brief\n\nIn Brief\nGoal\nUsers do not face time limits.\nWhat to do\nDo not use time limits, except for video and live events.\nWhy it's important\nPeople with disabilities often need more time to complete actions.",
    "principle": "Operable",
    "guideline": "2.2 Enough Time"
  },
  {
    "id": "2.2.3_key_terms",
    "type": "sc",
    "sc_id": "2.2.3",
    "section": "key_terms",
    "text": "[2.2.3 No Timing] (Level AAA)\nDescription: Timing is not an essential part of the event or activity presented by the content, except for non-interactive\n      synchronized media and real-time events.\n\nSection: key_terms\n\nKey Terms\naudio\nthe technology of sound reproduction\nNote\nAudio can be created synthetically (including speech synthesis), recorded from real\n      world sounds, or both.\nessential\nif removed, would fundamentally change the information or functionality of the content,\nand\ninformation and functionality cannot be achieved in another way that would conform\nmedia alternative for text\nmedia that presents no more information than is already presented in text (directly\n      or via text alternatives)\nNote\nA media alternative for text is provided for those who benefit from alternate representations\n      of text. Media alternatives for text may be audio-only, video-only (including sign-language\n      video), or audio-video.\nreal-time event\nevent that a) occurs at the same time as the viewing and b) is not completely generated\n      by the content\nExample 1\nA Webcast of a live performance (occurs at the same time as the viewing and is not\n      prerecorded).\nExample 2\nAn on-line auction with people bidding (occurs at the same time as the viewing).\nExample 3\nLive humans interacting in a virtual world using avatars (is not completely generated\n      by the content and occurs at the same time as the viewing).\nsynchronized media\naudio\nor\nvideo\nsynchronized with another format for presenting information and/or with time-based\n      interactive components, unless the media is a\nmedia alternative for text\nthat is clearly labeled as such\nvideo\nthe technology of moving or sequenced pictures or images\nNote\nVideo can be made up of animated or photographic images, or both.",
    "principle": "Operable",
    "guideline": "2.2 Enough Time"
  },
  {
    "id": "2.2.3_sufficient",
    "type": "sc_sufficient",
    "sc_id": "2.2.3",
    "techniques": [
      "G5"
    ],
    "text": "[2.2.3 No Timing] (Level AAA)\nDescription: Timing is not an essential part of the event or activity presented by the content, except for non-interactive\n      synchronized media and real-time events.\n\nSufficient techniques for SC 2.2.3 (no situation): G5",
    "principle": "Operable",
    "guideline": "2.2 Enough Time"
  },
  {
    "id": "2.2.4_intent",
    "type": "sc",
    "sc_id": "2.2.4",
    "section": "intent",
    "text": "[2.2.4 Interruptions] (Level AAA)\nDescription: Interruptions can be postponed or suppressed by the user, except interruptions involving\n      an emergency.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to allow users to turn off updates from the\n         author/server except in emergencies. Emergencies would include civil emergency alert\n         messages or any other messages that warn of danger to health, safety, or property,\n         including data loss, loss of connection, etcetera.\nThis allows access by people with cognitive limitations or attention disorders by\n         enabling them to focus on the content. It also allows users who are blind or have\n         low vision to keep their \"viewing\" focus on the content they are currently reading.",
    "principle": "Operable",
    "guideline": "2.2 Enough Time"
  },
  {
    "id": "2.2.4_success_criterion",
    "type": "sc",
    "sc_id": "2.2.4",
    "section": "success_criterion",
    "text": "[2.2.4 Interruptions] (Level AAA)\nDescription: Interruptions can be postponed or suppressed by the user, except interruptions involving\n      an emergency.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nInterruptions can be postponed or suppressed by the user, except interruptions involving\n      an\nemergency\n.",
    "principle": "Operable",
    "guideline": "2.2 Enough Time"
  },
  {
    "id": "2.2.4_benefits",
    "type": "sc",
    "sc_id": "2.2.4",
    "section": "benefits",
    "text": "[2.2.4 Interruptions] (Level AAA)\nDescription: Interruptions can be postponed or suppressed by the user, except interruptions involving\n      an emergency.\n\nSection: benefits\n\nBenefits\nIndividuals with attention deficit disorders can focus on content without distraction.\nIndividuals with low vision or who use screen readers will not have content updated\n            while they are viewing it (which can lead to discontinuity and misunderstanding if\n            they start reading in one topic and finish in another).",
    "principle": "Operable",
    "guideline": "2.2 Enough Time"
  },
  {
    "id": "2.2.4_examples",
    "type": "sc",
    "sc_id": "2.2.4",
    "section": "examples",
    "text": "[2.2.4 Interruptions] (Level AAA)\nDescription: Interruptions can be postponed or suppressed by the user, except interruptions involving\n      an emergency.\n\nSection: examples\n\nExamples\nExample 1. Setting user preferences\nThe preferences page of a web portal includes an option to postpone all updates and\n               alerts until the end of the current session, except for alerts concerning emergencies.",
    "principle": "Operable",
    "guideline": "2.2 Enough Time"
  },
  {
    "id": "2.2.4_brief",
    "type": "sc",
    "sc_id": "2.2.4",
    "section": "brief",
    "text": "[2.2.4 Interruptions] (Level AAA)\nDescription: Interruptions can be postponed or suppressed by the user, except interruptions involving\n      an emergency.\n\nSection: brief\n\nIn Brief\nGoal\nUsers are not interrupted.\nWhat to do\nLet people delay or turn off updates, except in emergencies.\nWhy it's important\nUpdates distract and disrupt assistive technology users and people with attention deficits.",
    "principle": "Operable",
    "guideline": "2.2 Enough Time"
  },
  {
    "id": "2.2.4_test_rules",
    "type": "sc",
    "sc_id": "2.2.4",
    "section": "test_rules",
    "text": "[2.2.4 Interruptions] (Level AAA)\nDescription: Interruptions can be postponed or suppressed by the user, except interruptions involving\n      an emergency.\n\nSection: test_rules\n\nTest Rules\nThe following are Test Rules\n    for certain aspects of this Success Criterion.\n    It is not necessary to use these particular Test Rules to check for conformance with WCAG, but they are defined and approved test methods.\n    For information on using Test Rules, see\nUnderstanding Test Rules for WCAG Success Criteria\n.\nMeta element has no refresh delay\nMeta element has no refresh delay (no exception)",
    "principle": "Operable",
    "guideline": "2.2 Enough Time"
  },
  {
    "id": "2.2.4_key_terms",
    "type": "sc",
    "sc_id": "2.2.4",
    "section": "key_terms",
    "text": "[2.2.4 Interruptions] (Level AAA)\nDescription: Interruptions can be postponed or suppressed by the user, except interruptions involving\n      an emergency.\n\nSection: key_terms\n\nKey Terms\nemergency\na sudden, unexpected situation or occurrence that requires immediate action to preserve\n      health, safety, or property",
    "principle": "Operable",
    "guideline": "2.2 Enough Time"
  },
  {
    "id": "2.2.4_sufficient",
    "type": "sc_sufficient",
    "sc_id": "2.2.4",
    "techniques": [
      "G75",
      "G76",
      "SCR14"
    ],
    "text": "[2.2.4 Interruptions] (Level AAA)\nDescription: Interruptions can be postponed or suppressed by the user, except interruptions involving\n      an emergency.\n\nSufficient techniques for SC 2.2.4 (no situation): G75, G76, SCR14",
    "principle": "Operable",
    "guideline": "2.2 Enough Time"
  },
  {
    "id": "2.2.4_failures",
    "type": "sc_failures",
    "sc_id": "2.2.4",
    "techniques": [
      "F40",
      "F41"
    ],
    "text": "[2.2.4 Interruptions] (Level AAA)\nDescription: Interruptions can be postponed or suppressed by the user, except interruptions involving\n      an emergency.\n\nCommon failures for SC 2.2.4: F40, F41",
    "principle": "Operable",
    "guideline": "2.2 Enough Time"
  },
  {
    "id": "2.2.5_intent",
    "type": "sc",
    "sc_id": "2.2.5",
    "section": "intent",
    "text": "[2.2.5 Re-authenticating] (Level AAA)\nDescription: When an authenticated session expires, the user can continue the activity without\n      loss of data after re-authenticating.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to allow all users to complete authenticated\n         transactions that have inactivity time limits or other circumstances that would cause\n         a user to be logged out while in the midst of completing the transaction.\nFor security reasons, many sites implement an authentication time limit after a certain\n         period of inactivity. These time limits may cause problems for persons with disabilities\n         because it may take longer for them to complete the activity.\nOther sites will log a person out of a session if a person logs in on the website\n         from another computer or if other activities arise that make the site suspicious of\n         whether the person is still the same legitimate person who logged in originally. When\n         users are logged out while still in the midst of a transaction - it is important that\n         they be given the ability to re-authenticate and continue with the transaction without\n         the loss of any data already entered.",
    "principle": "Operable",
    "guideline": "2.2 Enough Time"
  },
  {
    "id": "2.2.5_success_criterion",
    "type": "sc",
    "sc_id": "2.2.5",
    "section": "success_criterion",
    "text": "[2.2.5 Re-authenticating] (Level AAA)\nDescription: When an authenticated session expires, the user can continue the activity without\n      loss of data after re-authenticating.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nWhen an authenticated session expires, the user can continue the activity without\n      loss of data after re-authenticating.",
    "principle": "Operable",
    "guideline": "2.2 Enough Time"
  },
  {
    "id": "2.2.5_benefits",
    "type": "sc",
    "sc_id": "2.2.5",
    "section": "benefits",
    "text": "[2.2.5 Re-authenticating] (Level AAA)\nDescription: When an authenticated session expires, the user can continue the activity without\n      loss of data after re-authenticating.\n\nSection: benefits\n\nBenefits\nThis success criterion benefits people who may require additional time to complete\n            an activity. People with cognitive limitations may read slowly and require additional\n            time to read and respond to a questionnaire. Users interacting via a screen reader\n            may need extra time to navigate and complete a complicated form. \n            A person with motor impairments or who navigates with an alternative input device\n            may require additional time to navigate through or complete input within a form.\nIn circumstances where a sign-language interpreter may be relating audio content to\n            a user who is deaf, control over time limits is also important.",
    "principle": "Operable",
    "guideline": "2.2 Enough Time"
  },
  {
    "id": "2.2.5_examples",
    "type": "sc",
    "sc_id": "2.2.5",
    "section": "examples",
    "text": "[2.2.5 Re-authenticating] (Level AAA)\nDescription: When an authenticated session expires, the user can continue the activity without\n      loss of data after re-authenticating.\n\nSection: examples\n\nExamples\nA shopping site checkout\nA user with extremely limited use of the hands is logged into a shopping site. It\n               takes so long to enter credit card information into the application that a time limit\n               occurs while the user is performing the checkout process. When the user returns to\n               the checkout process and submits the form, the site returns a login screen to re-authenticate.\n               After the user logs in, the check out process is restored with the same information\n               and at the same stage. The user did not lose any data because the server had temporarily\n               accepted and stored the submission even though the session had timed out and restored\n               the user to the same state after re-authentication was completed.\nAuthentication in an email program\nAn email program has an authentication time-out after 30 minutes. The program prompts\n               the user several minutes before the time-out occurs and provides a link to open a\n               new window in order to re-authenticate. The original window with the in-progress email\n               remains intact and, after re-authentication, the user may send that data.\nA questionnaire with a time limit\nA long questionnaire provided within a single web page has information at the beginning\n               that indicates that the session will time out after 15 minutes. The user is also informed\n               that the questionnaire can be saved at any point and completed at a later time. Within\n               the web page there are several buttons provided to save the partially completed form.\n               In addition, with JavaScript in the list of accessibility-supported content technologies\n               that are relied upon, the user can elect to be alerted via a pop-up if the session\n               is close to timing out.",
    "principle": "Operable",
    "guideline": "2.2 Enough Time"
  },
  {
    "id": "2.2.5_brief",
    "type": "sc",
    "sc_id": "2.2.5",
    "section": "brief",
    "text": "[2.2.5 Re-authenticating] (Level AAA)\nDescription: When an authenticated session expires, the user can continue the activity without\n      loss of data after re-authenticating.\n\nSection: brief\n\nIn Brief\nGoal\nUsers do not lose information or context due to reauthentication.\nWhat to do\nPreserve users' prior activity and data through reauthentication.\nWhy it's important\nSome people may require additional time to complete an activity.",
    "principle": "Operable",
    "guideline": "2.2 Enough Time"
  },
  {
    "id": "2.2.5_sufficient",
    "type": "sc_sufficient",
    "sc_id": "2.2.5",
    "techniques": [
      "G105",
      "G105",
      "G181"
    ],
    "text": "[2.2.5 Re-authenticating] (Level AAA)\nDescription: When an authenticated session expires, the user can continue the activity without\n      loss of data after re-authenticating.\n\nSufficient techniques for SC 2.2.5 (no situation): G105, G105, G181",
    "principle": "Operable",
    "guideline": "2.2 Enough Time"
  },
  {
    "id": "2.2.5_failures",
    "type": "sc_failures",
    "sc_id": "2.2.5",
    "techniques": [
      "F12"
    ],
    "text": "[2.2.5 Re-authenticating] (Level AAA)\nDescription: When an authenticated session expires, the user can continue the activity without\n      loss of data after re-authenticating.\n\nCommon failures for SC 2.2.5: F12",
    "principle": "Operable",
    "guideline": "2.2 Enough Time"
  },
  {
    "id": "2.2.6_intent",
    "type": "sc",
    "sc_id": "2.2.6",
    "section": "intent",
    "text": "[2.2.6 Timeouts] (Level AAA)\nDescription: Users are warned of the duration of any user inactivity that could cause data loss, unless the data is preserved for more than 20 hours when the user does not take any actions.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to ensure that when a timeout is used, users know what duration of inactivity will cause the page to time out and result in lost data. The use of timed events can present significant barriers for users with cognitive disabilities, as these users may require more time to read content or to perform functions, such as completing an online form.\nDuring the completion of an online process, such as to reserve a hotel room or purchase a plane ticket, a user with a cognitive impairment may become overwhelmed with lengthy instructions and data input required to complete the process. The user may not be able to complete the process in one sitting and may need to take a break. Users should be able to leave a process without losing their current place within the process, and without losing information that has already been entered. If users cannot take a break and check their work, many will often be unable to complete a task correctly.\nThis success criterion works in tandem with Success Criterion 2.2.1 Timing Adjustable, but is specifically focused on notification of timeouts related to user inactivity.\nThe best way to conform to this success criterion is to keep the user data for at least 20 hours. This enables the user with disabilities and the aging community to start and finish a task, taking breaks as needed. However, when it is not practical to save the user data the author must warn the user about the duration of inactivity which will result in a timeout. Timeouts should be displayed to the user once at the beginning of the related task or process and not at each step.\nThis success criterion only applies to timeouts that are within the content provider's knowledge or control. For example, if the user closes a web browser or device and loses content in an open page that has not yet been submitted, the success criterion has not been violated.\nExamples of privacy regulations mentioned in the success criterion note, and related compliance standards, are PCI DSS (Payment Card Industry Data Security Standard) and HIPAA (Health Insurance Portability and Accountability Act of 1996).",
    "principle": "Operable",
    "guideline": "2.2 Enough Time"
  },
  {
    "id": "2.2.6_success_criterion",
    "type": "sc",
    "sc_id": "2.2.6",
    "section": "success_criterion",
    "text": "[2.2.6 Timeouts] (Level AAA)\nDescription: Users are warned of the duration of any user inactivity that could cause data loss, unless the data is preserved for more than 20 hours when the user does not take any actions.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nUsers are warned of the duration of any\nuser inactivity\nthat could cause data loss, unless the data is preserved for more than 20 hours when the user does not take any actions.\nNote\nPrivacy regulations may require explicit user consent before user identification has been authenticated and before user data is preserved. In cases where the user is a minor, explicit consent may not be solicited in most jurisdictions, countries or regions. Consultation with privacy professionals and legal counsel is advised when considering data preservation as an approach to satisfy this success criterion.",
    "principle": "Operable",
    "guideline": "2.2 Enough Time"
  },
  {
    "id": "2.2.6_benefits",
    "type": "sc",
    "sc_id": "2.2.6",
    "section": "benefits",
    "text": "[2.2.6 Timeouts] (Level AAA)\nDescription: Users are warned of the duration of any user inactivity that could cause data loss, unless the data is preserved for more than 20 hours when the user does not take any actions.\n\nSection: benefits\n\nBenefits\nThis success criterion helps users by ensuring they are notified about timeouts related to inactivity.\nWhen a user knows how much time they are allowed for a task, they will know whether they can take a needed break and resume their work without needing to start again. This enables many users to complete tasks online that they otherwise could not do. If a situation exists where a timeout is necessary, the user is warned at the start of the task about the length of inactivity that would generate a timeout. The user can then decide if they can manage this task or not in the given time, or if they need to prepare materials in advance of starting a process. This will reduce the frustration of losing work due to a timeout.\nThis success criterion helps people with many different cognitive disabilities, including people with:\nlanguage-related disabilities;\nmemory-related disabilities;\nfocus-and-attention-related disabilities; and\ndisabilities that affect executive function and decision making.",
    "principle": "Operable",
    "guideline": "2.2 Enough Time"
  },
  {
    "id": "2.2.6_examples",
    "type": "sc",
    "sc_id": "2.2.6",
    "section": "examples",
    "text": "[2.2.6 Timeouts] (Level AAA)\nDescription: Users are warned of the duration of any user inactivity that could cause data loss, unless the data is preserved for more than 20 hours when the user does not take any actions.\n\nSection: examples\n\nExamples\nWhile making a purchase on an e-commerce website, the information input by the user is stored for more than 20 hours. This helps ensure that if they need to stop working for a while that they are more likely to be able to continue the purchase when they return.\nA web application allowing people to file tax returns provides a notice that the application will time out for security purposes. The notice indicates that a lack of activity for a continuous period of time that is greater than an hour will trigger initiate the time out process.\nAn online contact form does not implement any type of time out process. Information entered into the contact form can be submitted at any time and would only be lost if the user closes their browser window.",
    "principle": "Operable",
    "guideline": "2.2 Enough Time"
  },
  {
    "id": "2.2.6_brief",
    "type": "sc",
    "sc_id": "2.2.6",
    "section": "brief",
    "text": "[2.2.6 Timeouts] (Level AAA)\nDescription: Users are warned of the duration of any user inactivity that could cause data loss, unless the data is preserved for more than 20 hours when the user does not take any actions.\n\nSection: brief\n\nIn Brief\nGoal\nUsers do not lose data due to unknown timeouts.\nAuthor task\nTell users how long their session can be inactive before they may lose information.\nWhy it's important\nPeople with disabilities may need more time to complete actions.",
    "principle": "Operable",
    "guideline": "2.2 Enough Time"
  },
  {
    "id": "2.2.6_resources",
    "type": "sc",
    "sc_id": "2.2.6",
    "section": "resources",
    "text": "[2.2.6 Timeouts] (Level AAA)\nDescription: Users are warned of the duration of any user inactivity that could cause data loss, unless the data is preserved for more than 20 hours when the user does not take any actions.\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nUser Needs Table 3: Entering data, error prevention & recovery\nSSA Best Practices Library: Timeouts",
    "principle": "Operable",
    "guideline": "2.2 Enough Time"
  },
  {
    "id": "2.2.6_key_terms",
    "type": "sc",
    "sc_id": "2.2.6",
    "section": "key_terms",
    "text": "[2.2.6 Timeouts] (Level AAA)\nDescription: Users are warned of the duration of any user inactivity that could cause data loss, unless the data is preserved for more than 20 hours when the user does not take any actions.\n\nSection: key_terms\n\nKey Terms\nuser inactivity\nany continuous period of time where no user actions occur\nThe method of tracking will be determined by the website or application.",
    "principle": "Operable",
    "guideline": "2.2 Enough Time"
  },
  {
    "id": "2.3.1_intent",
    "type": "sc",
    "sc_id": "2.3.1",
    "section": "intent",
    "text": "[2.3.1 Three Flashes or Below Threshold] (Level A)\nDescription: Web pages do not contain anything that flashes more than three times in any one second period,\n      or the flash is below the general flash and red flash thresholds.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to allow users to access the full content\n         of a site without inducing seizures due to photosensitivity.\nIndividuals who have photosensitive seizure disorders can have a seizure triggered\n         by content that flashes at certain frequencies for more than a few flashes. People\n         are even more sensitive to red flashing than to other colors, so a special test is\n         provided for saturated red flashing. These guidelines were originally based on guidelines for\n         the broadcasting industry as adapted for desktop monitors, where content is viewed\n         from a closer distance (using a larger angle of vision).\nFlashing can be caused by the display, the computer rendering the image or by the\n         content being rendered. The author has no control of the first two. They can be addressed\n         by the design and speed of the display and computer. The intent of this criterion\n         is to ensure that flicker that violates the flash thresholds is not caused by the\n         content itself. For example, the content could contain a video clip or animated image\n         of a series of strobe flashes, or close-ups of rapid-fire explosions.\nThis success criterion replaces a much more restrictive criterion in WCAG 1.0 that\n         did not allow any flashing (even of a single pixel) within a broad frequency range\n         (3 to 50 Hz). This success criterion is based on existing specifications in use in\n         the UK and by others for television broadcast and has been adapted for computer display\n         viewing. In WCAG 2.0, a 1024 x 768 screen was used as the reference screen resolution for the\n         evaluation. The 341 x 256 pixel block represents a 10 degree viewport at a typical\n         viewing distance. (The 10 degree field is taken from the original specifications and\n         represents the central vision portion of the eye, where people are most susceptible\n         to photo stimuli.)\nWith the proliferation of devices of varying screen sizes (from small hand-helds to large living room displays), as well as the adoption of\nCSS pixels\nas a density-independent unit of measurement, the prior assessment criteria may seem outdated. However, an image of a consistent size uses up relatively the same percentage of a user's visual field on any device. On a large screen, the image takes up less size, but the large screen takes up a larger part of the visual field. On a mobile screen, the image may take up most or all of the screen; however, the mobile screen itself takes up a smaller portion of the user's visual field. So the same dimension of the flashing content, represented in CSS pixels can still provide a consistent means of assessment. Substituting CSS pixels for the original pixel block means that the combined area of flashing becomes 341 x 256 CSS pixels, or a flashing area of 87,296 CSS pixels.\nContent should be analyzed at the largest scale at which a user may view the content, and at the standard zoom level of the user agent. For example, with a video that may play in an area of a web page and also at full screen, the video should be analyzed for risks at full screen.\nWhere video content is provided in color spaces other than sRGB, the version provided with the highest dynamic range should be tested. In such cases the industry standard definition of a general flash is a change in luminance of 20 cd/m2 or more where the darker image is below 160 cd/m2. (\nITU-R BT.1702\n.) This is applicable for standard dynamic range (SDR) and high dynamic range (HDR) content. For HDR content when the darker state is 160 cd/m2 or more, a general flash is one where the Michelson contrast is 1/17 or greater — where the Michelson contrast is calculated as (LHigh - LLow) / (LHigh + LLow), and where LHigh and LLow are the luminance of the high and low luminance states, respectively.\nFor short clips that might be looped (such as GIF animations), the content should be analyzed while looping.\nNote\nThe specification cannot account for the actual viewing distance that a person chooses. Users that are closer to their screens than the idealized viewing distance will be affected by flashing areas that normatively pass. The same problem applies to users who rely on zoom or screen magnification. Conversely, users who are further away from the screen than the idealized distance should be able to tolerate flashing areas that are larger than the threshold.\nThe combined area of flashes occurring concurrently and contiguously means the total\n         area that is actually flashing at the same time. It is calculated by adding up the\n         contiguous area that is flashing simultaneously within any 10 degree angle of view.\nNote\nThe terms \"blinking\" and \"flashing\" can sometimes refer to the same content.\n\"Blinking\" refers to content that causes a distraction problem. Blinking can be allowed\n               for a short time as long as it stops (or can be stopped)\n\"Flashing\" refers to content that can trigger a seizure (if it is more than 3 per\n               second and large and bright enough). This cannot be allowed even for a second or it\n               could cause a seizure. And turning the flash off is also not an option since the seizure\n               could occur faster than most users could turn it off.\nBlinking usually does not occur at speeds of 3 per second or more, but it can. If\n               blinking occurs faster than 3 per second, it would also be considered a flash.\nNote (new in WCAG 2.2)\nThe new working definition in the field for\n\"pair of opposing transitions involving a saturated red\"\nis a pair of opposing transitions where, one transition is either to or from a state with a value R/(R + G + B) that is greater than or equal to 0.8, and the difference between states is more than 0.2 (unitless) in the CIE 1976 UCS chromaticity diagram. [ISO 9241-391]\nThe chromaticity difference is calculated as:\nSQRT( (u'1 - u'2)^2 + (v'1 - v'2)^2 )\nwhere u'1 and v'1 are chromaticity coordinates of State 1 and u'2 and v'2 are chromaticity coordinates of State 2. The 1976 UCS chromaticity coordinates of u' and v' are calculated as:\nu' = 4 * X / (X + 15 * Y + 3 * Z)\nv' = 9 * Y / (X + 15 * Y + 3 * Z)\nwhere X, Y, and Z are the tristimulus values of a color in the CIE XYZ colorspace, which can be calculated as:\nX = 0.4124564 * R + 0.3575761 * G + 0.1804375 * B\nY = 0.2126729 * R + 0.7151522 * G + 0.0721750 * B\nZ = 0.0193339 * R + 0.1191920 * G + 0.9503041 * B\nwhere R, G, & B are values that range from 0-1 as specified in “relative luminance” definition.",
    "principle": "Operable",
    "guideline": "2.3 Seizures and Physical Reactions"
  },
  {
    "id": "2.3.1_success_criterion",
    "type": "sc",
    "sc_id": "2.3.1",
    "section": "success_criterion",
    "text": "[2.3.1 Three Flashes or Below Threshold] (Level A)\nDescription: Web pages do not contain anything that flashes more than three times in any one second period,\n      or the flash is below the general flash and red flash thresholds.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nWeb pages\ndo not contain anything that flashes more than three times in any one second period,\n      or the\nflash\nis below the\ngeneral flash and red flash thresholds\n.\nNote\nSince any content that does not meet this success criterion can interfere with a user's\n      ability to use the whole page, all content on the web page (whether it is used to\n      meet other success criteria or not) must meet this success criterion. See\nConformance Requirement 5: Non-Interference\n.",
    "principle": "Operable",
    "guideline": "2.3 Seizures and Physical Reactions"
  },
  {
    "id": "2.3.1_benefits",
    "type": "sc",
    "sc_id": "2.3.1",
    "section": "benefits",
    "text": "[2.3.1 Three Flashes or Below Threshold] (Level A)\nDescription: Web pages do not contain anything that flashes more than three times in any one second period,\n      or the flash is below the general flash and red flash thresholds.\n\nSection: benefits\n\nBenefits\nIndividuals who have seizures when viewing flashing material will be able to view\n            all of the material on a site without having a seizure and without having to miss\n            the full experience of the content by being limited to text alternatives. This includes\n            people with photosensitive epilepsy as well as other photosensitive seizure disorders.",
    "principle": "Operable",
    "guideline": "2.3 Seizures and Physical Reactions"
  },
  {
    "id": "2.3.1_examples",
    "type": "sc",
    "sc_id": "2.3.1",
    "section": "examples",
    "text": "[2.3.1 Three Flashes or Below Threshold] (Level A)\nDescription: Web pages do not contain anything that flashes more than three times in any one second period,\n      or the flash is below the general flash and red flash thresholds.\n\nSection: examples\n\nExamples\nA website has video of muzzle flash of machine gun fire, but limits the size of the\n            flashing image to a small portion of the screen below the flash threshold size.\nA movie with a scene involving very bright lightning flashes is edited so that the\n            lightning only flashes three times in any one second period.",
    "principle": "Operable",
    "guideline": "2.3 Seizures and Physical Reactions"
  },
  {
    "id": "2.3.1_brief",
    "type": "sc",
    "sc_id": "2.3.1",
    "section": "brief",
    "text": "[2.3.1 Three Flashes or Below Threshold] (Level A)\nDescription: Web pages do not contain anything that flashes more than three times in any one second period,\n      or the flash is below the general flash and red flash thresholds.\n\nSection: brief\n\nIn Brief\nGoal\nContent does not trigger seizures.\nWhat to do\nAvoid content that flashes, or keep it under thresholds.\nWhy it's important\nFlashing content can cause migraines, dizziness, nausea, and seizures.",
    "principle": "Operable",
    "guideline": "2.3 Seizures and Physical Reactions"
  },
  {
    "id": "2.3.1_resources",
    "type": "sc",
    "sc_id": "2.3.1",
    "section": "resources",
    "text": "[2.3.1 Three Flashes or Below Threshold] (Level A)\nDescription: Web pages do not contain anything that flashes more than three times in any one second period,\n      or the flash is below the general flash and red flash thresholds.\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nHarding FPA Web Site\nTrace Center Photosensitive Epilepsy Analysis Tool (PEAT)\nInformation about Photosensitive Seizure Disorders\nEpilepsy Action\nEpilepsy Foundation - Photosensitivity and Seizures",
    "principle": "Operable",
    "guideline": "2.3 Seizures and Physical Reactions"
  },
  {
    "id": "2.3.1_key_terms",
    "type": "sc",
    "sc_id": "2.3.1",
    "section": "key_terms",
    "text": "[2.3.1 Three Flashes or Below Threshold] (Level A)\nDescription: Web pages do not contain anything that flashes more than three times in any one second period,\n      or the flash is below the general flash and red flash thresholds.\n\nSection: key_terms\n\nKey Terms\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\nblinking\nswitch back and forth between two visual states in a way that is meant to draw attention\nNote\nSee also\nflash\n. It is possible for something to be large enough and blink brightly enough at the\n      right frequency to be also classified as a flash.\nCSS pixel\nvisual angle of about 0.0213 degrees\nA CSS pixel is the canonical unit of measure for all lengths and measurements in CSS.\n      This unit is density-independent, and distinct from actual hardware pixels present\n      in a display. User agents and operating systems should ensure that a CSS pixel is\n      set as closely as possible to the\nCSS Values and Units Module Level 3 reference pixel\n[\ncss3-values\n], which takes into account the physical dimensions of the display\n      and the assumed viewing distance (factors that cannot be determined by content authors).\nflash\na pair of opposing changes in\nrelative luminance\nthat can cause seizures in some people if it is large enough and in the right frequency\n      range\nNote 1\nSee\ngeneral flash and red flash thresholds\nfor information about types of flash that are not allowed.\nNote 2\nSee also\nblinking\n.\ngeneral flash and red flash thresholds\na\nflash\nor rapidly changing image sequence is below the threshold (i.e., content\npasses\n) if any of the following are true:\nthere are no more than three\ngeneral flashes\nand / or no more than three\nred flashes\nwithin any one-second period; or\nthe combined area of flashes occurring concurrently occupies no more than a total\n         of .006 steradians within any 10 degree visual field on the screen (25% of any 10\n         degree visual field on the screen) at typical viewing distance\nwhere:\nA\ngeneral flash\nis defined as a pair of opposing changes in\nrelative luminance\nof 10% or more of the maximum relative luminance (1.0) where the relative luminance of\n         the darker image is below 0.80; and where \"a pair of opposing changes\" is an increase\n         followed by a decrease, or a decrease followed by an increase, and\nA\nred flash\nis defined as any pair of opposing transitions involving a saturated red\nException:\nFlashing that is a fine, balanced, pattern such as white noise or an alternating\n      checkerboard pattern with \"squares\" smaller than 0.1 degree (of visual field at typical\n      viewing distance) on a side does not violate the thresholds.\nNote 1\nFor general software or web content, using a 341 x 256 pixel rectangle anywhere on the displayed screen area when the content is viewed at 1024 x 768 pixels will provide a good estimate of a 10 degree visual field for standard screen sizes and viewing distances (e.g., 15-17 inch screen at 22-26 inches). This resolution of 75 - 85 ppi is known to be lower, and thus more conservative than the nominal CSS pixel resolution of 96 ppi in CSS specifications. Higher resolutions displays showing the same rendering of the content yield smaller and safer images so it is lower resolutions that are used to define the thresholds.\nNote 2\nA transition is the change in relative luminance (or relative luminance/color for\n      red flashing) between adjacent peaks and valleys in a plot of relative luminance (or\n      relative luminance/color for red flashing) measurement against time. A flash consists\n      of two opposing transitions.\nNote 3\nThe new working definition in the field for\n\"pair of opposing transitions involving a saturated red\"\n(from WCAG 2.2) is a pair of opposing transitions where, one transition is either to or from a state with a value R/(R + G + B) that is greater than or equal to 0.8, and the difference between states is more than 0.2 (unitless) in the CIE 1976 UCS chromaticity diagram. [\nISO_9241-391\n]\nNote 4\nTools are available that will carry out analysis from video screen capture. However,\n      no tool is necessary to evaluate for this condition if flashing is less than or equal\n      to 3 flashes in any one second. Content automatically passes (see #1 and #2 above).\nrelative luminance\nthe relative brightness of any point in a colorspace, normalized to 0 for darkest\n      black and 1 for lightest white\nNote 1\nFor the sRGB colorspace, the relative luminance of a color is defined as L = 0.2126\n      *\nR\n+ 0.7152 *\nG\n+ 0.0722 *\nB\nwhere\nR\n,\nG\nand\nB\nare defined as:\nif RsRGB <= 0.04045 then\nR\n= RsRGB/12.92 else\nR\n= ((RsRGB+0.055)/1.055) ^ 2.4\nif GsRGB <= 0.04045 then\nG\n= GsRGB/12.92 else\nG\n= ((GsRGB+0.055)/1.055) ^ 2.4\nif BsRGB <= 0.04045 then\nB\n= BsRGB/12.92 else\nB\n= ((BsRGB+0.055)/1.055) ^ 2.4\nand RsRGB, GsRGB, and BsRGB are defined as:\nRsRGB = R8bit/255\nGsRGB = G8bit/255\nBsRGB = B8bit/255\nThe \"^\" character is the exponentiation operator. (Formula taken from \n      [\nSRGB\n].)\nNote 2\nBefore May 2021 the value of 0.04045 in the definition was different (0.03928). It was taken from an older version of the specification and has been updated. It has no practical effect on the calculations in the context of these guidelines.\nNote 3\nAlmost all systems used today to view web content assume sRGB encoding. Unless it\n      is known that another color space will be used to process and display the content,\n      authors should evaluate using sRGB colorspace. If using other color spaces, see\nUnderstanding Success Criterion 1.4.3\n.\nNote 4\nIf dithering occurs after delivery, then the source color value is used. For colors\n      that are dithered at the source, the average values of the colors that are dithered\n      should be used (average R, average G, and average B).\nNote 5\nTools are available that automatically do the calculations when testing contrast and\n      flash.\nNote 6\nA\nseparate page giving the relative luminance definition using MathML\nto display the formulas is available.\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.\nweb page\na non-embedded resource obtained from a single URI using HTTP plus any other resources\n      that are used in the rendering or intended to be rendered together with it by a\nuser agent\nNote 1\nAlthough any \"other resources\" would be rendered together with the primary resource,\n      they would not necessarily be rendered simultaneously with each other.\nNote 2\nFor the purposes of conformance with these guidelines, a resource must be \"non-embedded\"\n      within the scope of conformance to be considered a web page.\nExample 1\nA web resource including all embedded images and media.\nExample 2\nA web mail program built using Asynchronous JavaScript and XML (AJAX). The program\n      lives entirely at http://example.com/mail, but includes an inbox, a contacts area\n      and a calendar. Links or buttons are provided that cause the inbox, contacts, or calendar\n      to display, but do not change the URI of the page as a whole.\nExample 3\nA customizable portal site, where users can choose content to display from a set of\n      different content modules.\nExample 4\nWhen you enter \"http://shopping.example.com/\" in your browser, you enter a movie-like\n      interactive shopping environment where you visually move around in a store dragging\n      products off of the shelves around you and into a visual shopping cart in front of\n      you. Clicking on a product causes it to be demonstrated with a specification sheet\n      floating alongside. This might be a single-page website or just one page within a\n      website.",
    "principle": "Operable",
    "guideline": "2.3 Seizures and Physical Reactions"
  },
  {
    "id": "2.3.1_sufficient",
    "type": "sc_sufficient",
    "sc_id": "2.3.1",
    "techniques": [
      "G19",
      "G176",
      "G15"
    ],
    "text": "[2.3.1 Three Flashes or Below Threshold] (Level A)\nDescription: Web pages do not contain anything that flashes more than three times in any one second period,\n      or the flash is below the general flash and red flash thresholds.\n\nSufficient techniques for SC 2.3.1 (no situation): G19, G176, G15",
    "principle": "Operable",
    "guideline": "2.3 Seizures and Physical Reactions"
  },
  {
    "id": "2.3.2_intent",
    "type": "sc",
    "sc_id": "2.3.2",
    "section": "intent",
    "text": "[2.3.2 Three Flashes] (Level AAA)\nDescription: Web pages do not contain anything that flashes more than three times in any one second period.\n\nSection: intent\n\nIntent\nThe purpose of this success criterion is to further reduce the chance of seizures.\n         Seizures cannot be completely eliminated since some people are so sensitive.  However,\n         by eliminating all 3-per-second flashing over any area of the screen, the chances\n         of a person having a seizure are further reduced than when just meeting the measures\n         ordinarily used today in standards internationally, as we do at Level A.\nWhereas\nSuccess Criterion 2.3.1\nallows flashing if it is dim enough or has a small enough area, Success Criterion\n         2.3.2 does not allow flashing greater than 3 per second, regardless of brightness\n         or size. As a result, even a single flashing pixel would violate this criterion. The\n         intent is to guard against flashing larger than a single pixel, but since an unknown\n         amount of magnification or high contrast setting may be applied, the prohibition is\n         against any flashing.\nNote\nIn some cases, what we refer to as \"blinking\" and what we refer to as \"flashing\" may\n            overlap slightly.  We are using different terms for the two because \"blinking\" causes\n            a distraction problem which you can allow for a short time as long as it stops (or\n            can be stopped) whereas \"flashing\" is a seizure trigger and cannot be allowed or it\n            will cause a seizure. The seizure would occur faster than most users could turn it\n            off.  \"Blink\" therefore refers to slow repeating changes that would distract.  \"Flash\"\n            refers to changes that could cause a seizure if they were bright enough or persisted\n            long enough. Blinking usually doesn't occur at speeds of 3 per second or more so blink\n            and flash do not overlap. However, blinking can occur faster than 3 per second so\n            there could be an overlap. See\n2.2.2: Pause, Stop, Hide\nfor more information on blink.",
    "principle": "Operable",
    "guideline": "2.3 Seizures and Physical Reactions"
  },
  {
    "id": "2.3.2_success_criterion",
    "type": "sc",
    "sc_id": "2.3.2",
    "section": "success_criterion",
    "text": "[2.3.2 Three Flashes] (Level AAA)\nDescription: Web pages do not contain anything that flashes more than three times in any one second period.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nWeb pages\ndo not contain anything that\nflashes\nmore than three times in any one second period.",
    "principle": "Operable",
    "guideline": "2.3 Seizures and Physical Reactions"
  },
  {
    "id": "2.3.2_benefits",
    "type": "sc",
    "sc_id": "2.3.2",
    "section": "benefits",
    "text": "[2.3.2 Three Flashes] (Level AAA)\nDescription: Web pages do not contain anything that flashes more than three times in any one second period.\n\nSection: benefits\n\nBenefits\nIndividuals who have seizures when viewing flashing material will be able to view\n            all of the material on a site without having a seizure and without having to miss\n            the full experience of the content by being limited to text alternatives. This includes\n            people with photosensitive epilepsy as well as other photosensitive seizure disorders.",
    "principle": "Operable",
    "guideline": "2.3 Seizures and Physical Reactions"
  },
  {
    "id": "2.3.2_examples",
    "type": "sc",
    "sc_id": "2.3.2",
    "section": "examples",
    "text": "[2.3.2 Three Flashes] (Level AAA)\nDescription: Web pages do not contain anything that flashes more than three times in any one second period.\n\nSection: examples\n\nExamples\nA movie with a scene involving very bright lightning flashes is edited so that the\n            lightning only flashes three times in any one second period.",
    "principle": "Operable",
    "guideline": "2.3 Seizures and Physical Reactions"
  },
  {
    "id": "2.3.2_brief",
    "type": "sc",
    "sc_id": "2.3.2",
    "section": "brief",
    "text": "[2.3.2 Three Flashes] (Level AAA)\nDescription: Web pages do not contain anything that flashes more than three times in any one second period.\n\nSection: brief\n\nIn Brief\nGoal\nContent does not trigger seizures.\nWhat to do\nDo not flash content more than 3 times a second.\nWhy it's important\nFlashing content can cause migraines, dizziness, nausea, and seizures.",
    "principle": "Operable",
    "guideline": "2.3 Seizures and Physical Reactions"
  },
  {
    "id": "2.3.2_resources",
    "type": "sc",
    "sc_id": "2.3.2",
    "section": "resources",
    "text": "[2.3.2 Three Flashes] (Level AAA)\nDescription: Web pages do not contain anything that flashes more than three times in any one second period.\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nHarding FPA Web Site\nTrace Center Photosensitive Epilepsy Analysis Tool (PEAT)\nInformation about Photosensitive Seizure Disorders\nEpilepsy Action\nEpilepsy Foundation - Photosensitivity and Seizures",
    "principle": "Operable",
    "guideline": "2.3 Seizures and Physical Reactions"
  },
  {
    "id": "2.3.2_key_terms",
    "type": "sc",
    "sc_id": "2.3.2",
    "section": "key_terms",
    "text": "[2.3.2 Three Flashes] (Level AAA)\nDescription: Web pages do not contain anything that flashes more than three times in any one second period.\n\nSection: key_terms\n\nKey Terms\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\nblinking\nswitch back and forth between two visual states in a way that is meant to draw attention\nNote\nSee also\nflash\n. It is possible for something to be large enough and blink brightly enough at the\n      right frequency to be also classified as a flash.\nflash\na pair of opposing changes in\nrelative luminance\nthat can cause seizures in some people if it is large enough and in the right frequency\n      range\nNote 1\nSee\ngeneral flash and red flash thresholds\nfor information about types of flash that are not allowed.\nNote 2\nSee also\nblinking\n.\ngeneral flash and red flash thresholds\na\nflash\nor rapidly changing image sequence is below the threshold (i.e., content\npasses\n) if any of the following are true:\nthere are no more than three\ngeneral flashes\nand / or no more than three\nred flashes\nwithin any one-second period; or\nthe combined area of flashes occurring concurrently occupies no more than a total\n         of .006 steradians within any 10 degree visual field on the screen (25% of any 10\n         degree visual field on the screen) at typical viewing distance\nwhere:\nA\ngeneral flash\nis defined as a pair of opposing changes in\nrelative luminance\nof 10% or more of the maximum relative luminance (1.0) where the relative luminance of\n         the darker image is below 0.80; and where \"a pair of opposing changes\" is an increase\n         followed by a decrease, or a decrease followed by an increase, and\nA\nred flash\nis defined as any pair of opposing transitions involving a saturated red\nException:\nFlashing that is a fine, balanced, pattern such as white noise or an alternating\n      checkerboard pattern with \"squares\" smaller than 0.1 degree (of visual field at typical\n      viewing distance) on a side does not violate the thresholds.\nNote 1\nFor general software or web content, using a 341 x 256 pixel rectangle anywhere on the displayed screen area when the content is viewed at 1024 x 768 pixels will provide a good estimate of a 10 degree visual field for standard screen sizes and viewing distances (e.g., 15-17 inch screen at 22-26 inches). This resolution of 75 - 85 ppi is known to be lower, and thus more conservative than the nominal CSS pixel resolution of 96 ppi in CSS specifications. Higher resolutions displays showing the same rendering of the content yield smaller and safer images so it is lower resolutions that are used to define the thresholds.\nNote 2\nA transition is the change in relative luminance (or relative luminance/color for\n      red flashing) between adjacent peaks and valleys in a plot of relative luminance (or\n      relative luminance/color for red flashing) measurement against time. A flash consists\n      of two opposing transitions.\nNote 3\nThe new working definition in the field for\n\"pair of opposing transitions involving a saturated red\"\n(from WCAG 2.2) is a pair of opposing transitions where, one transition is either to or from a state with a value R/(R + G + B) that is greater than or equal to 0.8, and the difference between states is more than 0.2 (unitless) in the CIE 1976 UCS chromaticity diagram. [\nISO_9241-391\n]\nNote 4\nTools are available that will carry out analysis from video screen capture. However,\n      no tool is necessary to evaluate for this condition if flashing is less than or equal\n      to 3 flashes in any one second. Content automatically passes (see #1 and #2 above).\nrelative luminance\nthe relative brightness of any point in a colorspace, normalized to 0 for darkest\n      black and 1 for lightest white\nNote 1\nFor the sRGB colorspace, the relative luminance of a color is defined as L = 0.2126\n      *\nR\n+ 0.7152 *\nG\n+ 0.0722 *\nB\nwhere\nR\n,\nG\nand\nB\nare defined as:\nif RsRGB <= 0.04045 then\nR\n= RsRGB/12.92 else\nR\n= ((RsRGB+0.055)/1.055) ^ 2.4\nif GsRGB <= 0.04045 then\nG\n= GsRGB/12.92 else\nG\n= ((GsRGB+0.055)/1.055) ^ 2.4\nif BsRGB <= 0.04045 then\nB\n= BsRGB/12.92 else\nB\n= ((BsRGB+0.055)/1.055) ^ 2.4\nand RsRGB, GsRGB, and BsRGB are defined as:\nRsRGB = R8bit/255\nGsRGB = G8bit/255\nBsRGB = B8bit/255\nThe \"^\" character is the exponentiation operator. (Formula taken from \n      [\nSRGB\n].)\nNote 2\nBefore May 2021 the value of 0.04045 in the definition was different (0.03928). It was taken from an older version of the specification and has been updated. It has no practical effect on the calculations in the context of these guidelines.\nNote 3\nAlmost all systems used today to view web content assume sRGB encoding. Unless it\n      is known that another color space will be used to process and display the content,\n      authors should evaluate using sRGB colorspace. If using other color spaces, see\nUnderstanding Success Criterion 1.4.3\n.\nNote 4\nIf dithering occurs after delivery, then the source color value is used. For colors\n      that are dithered at the source, the average values of the colors that are dithered\n      should be used (average R, average G, and average B).\nNote 5\nTools are available that automatically do the calculations when testing contrast and\n      flash.\nNote 6\nA\nseparate page giving the relative luminance definition using MathML\nto display the formulas is available.\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.\nweb page\na non-embedded resource obtained from a single URI using HTTP plus any other resources\n      that are used in the rendering or intended to be rendered together with it by a\nuser agent\nNote 1\nAlthough any \"other resources\" would be rendered together with the primary resource,\n      they would not necessarily be rendered simultaneously with each other.\nNote 2\nFor the purposes of conformance with these guidelines, a resource must be \"non-embedded\"\n      within the scope of conformance to be considered a web page.\nExample 1\nA web resource including all embedded images and media.\nExample 2\nA web mail program built using Asynchronous JavaScript and XML (AJAX). The program\n      lives entirely at http://example.com/mail, but includes an inbox, a contacts area\n      and a calendar. Links or buttons are provided that cause the inbox, contacts, or calendar\n      to display, but do not change the URI of the page as a whole.\nExample 3\nA customizable portal site, where users can choose content to display from a set of\n      different content modules.\nExample 4\nWhen you enter \"http://shopping.example.com/\" in your browser, you enter a movie-like\n      interactive shopping environment where you visually move around in a store dragging\n      products off of the shelves around you and into a visual shopping cart in front of\n      you. Clicking on a product causes it to be demonstrated with a specification sheet\n      floating alongside. This might be a single-page website or just one page within a\n      website.",
    "principle": "Operable",
    "guideline": "2.3 Seizures and Physical Reactions"
  },
  {
    "id": "2.3.2_sufficient",
    "type": "sc_sufficient",
    "sc_id": "2.3.2",
    "techniques": [
      "G19"
    ],
    "text": "[2.3.2 Three Flashes] (Level AAA)\nDescription: Web pages do not contain anything that flashes more than three times in any one second period.\n\nSufficient techniques for SC 2.3.2 (no situation): G19",
    "principle": "Operable",
    "guideline": "2.3 Seizures and Physical Reactions"
  },
  {
    "id": "2.3.3_intent",
    "type": "sc",
    "sc_id": "2.3.3",
    "section": "intent",
    "text": "[2.3.3 Animation from Interactions] (Level AAA)\nDescription: Motion animation triggered by interaction can be disabled, unless the animation is essential to the functionality or the information being conveyed.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to allow users to prevent animation from being displayed on web pages. Some users experience distraction or nausea from animated content. For example, if scrolling a page causes elements to move (other than the essential movement associated with scrolling) it can trigger vestibular disorders. Vestibular (inner ear) disorder reactions include dizziness, nausea and headaches. Another animation that is often non-essential is parallax scrolling. Parallax scrolling occurs when backgrounds move at a different rate to foregrounds. Animation that is essential to the functionality or information of a web page is allowed by this success criterion.\n\"Animation from interactions\" applies when a user’s interaction initiates non-essential animation. In contrast,\n2.2.2 Pause, Stop, Hide\napplies when the web page initiates animation \"automatically\" that is not in response to an intentional user activation. There may be situations where a particular animation may fail\nboth\nsuccess criteria.\nNote\nThe impact of animation on people with vestibular disorders can be quite severe. Triggered reactions include nausea, migraine headaches, and potentially needing bed rest to recover.\nHow can a website reduce the chances of triggering a vestibular disorder?\nChoose any one of the following solutions. Avoid using unnecessary animation. Provide a control for users to turn off non-essential animations from user interaction. Take advantage of the reduce motion feature in the user agent or operating system.\nWhat about movement caused by a user scrolling a page?\nMoving new content into the viewport is essential for scrolling. The user controls the essential scrolling movement so it is allowed. Only add non-essential animation to the scrolling interaction in a responsible way. Always give users the ability to turn off unnecessary movement.",
    "principle": "Operable",
    "guideline": "2.3 Seizures and Physical Reactions"
  },
  {
    "id": "2.3.3_success_criterion",
    "type": "sc",
    "sc_id": "2.3.3",
    "section": "success_criterion",
    "text": "[2.3.3 Animation from Interactions] (Level AAA)\nDescription: Motion animation triggered by interaction can be disabled, unless the animation is essential to the functionality or the information being conveyed.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nMotion animation\ntriggered by interaction can be disabled, unless the animation is\nessential\nto the functionality or the information being conveyed.",
    "principle": "Operable",
    "guideline": "2.3 Seizures and Physical Reactions"
  },
  {
    "id": "2.3.3_benefits",
    "type": "sc",
    "sc_id": "2.3.3",
    "section": "benefits",
    "text": "[2.3.3 Animation from Interactions] (Level AAA)\nDescription: Motion animation triggered by interaction can be disabled, unless the animation is essential to the functionality or the information being conveyed.\n\nSection: benefits\n\nBenefits\nVestibular Disorder\nPeople with vestibular disorders need control over movement triggered by interactions. Non-essential movement can trigger vestibular disorder reactions. Vestibular (inner ear) disorder reactions include distraction, dizziness, headaches and nausea.\nPersona Quote: \"Stop that extra movement! You are making me so dizzy I cannot concentrate. Now I have to turn off my computer and go lie down.\"",
    "principle": "Operable",
    "guideline": "2.3 Seizures and Physical Reactions"
  },
  {
    "id": "2.3.3_examples",
    "type": "sc",
    "sc_id": "2.3.3",
    "section": "examples",
    "text": "[2.3.3 Animation from Interactions] (Level AAA)\nDescription: Motion animation triggered by interaction can be disabled, unless the animation is essential to the functionality or the information being conveyed.\n\nSection: examples\n\nExamples\nParallax scrolling with option to turn off unnecessary motion globally\nA site includes extra animations when the user scrolls. Decorative elements move in and out of view\n\t\t\t\t\thorizontally when the essential page content is scrolled vertically. A control at the top of each page\n\t\t\t\t\tallows the user to turn off unnecessary animations. The ability to turn off non-essential animations is a site-wide setting.\nTransitions that support the reduce motion preference\nA site includes a non-essential transition when loading new content. The transition is a page-flipping\n\t\t\t\t\tanimation that respects the reduce-motion CSS media query. When the user enables the reduce motion preference,\n\t\t\t\t\tthe page-flipping animation is turned off.\nEssential animation\nA web application provides a feature to author animated sequences. As part of this tool the author needs to preview the animation.",
    "principle": "Operable",
    "guideline": "2.3 Seizures and Physical Reactions"
  },
  {
    "id": "2.3.3_brief",
    "type": "sc",
    "sc_id": "2.3.3",
    "section": "brief",
    "text": "[2.3.3 Animation from Interactions] (Level AAA)\nDescription: Motion animation triggered by interaction can be disabled, unless the animation is essential to the functionality or the information being conveyed.\n\nSection: brief\n\nIn Brief\nGoal\nUsers are not harmed or distracted by motion.\nWhat to do\nSupport user preferences for motion, and eliminate unnecessary motion effects.\nWhy it's important\nPeople can get sick from motion effects.",
    "principle": "Operable",
    "guideline": "2.3 Seizures and Physical Reactions"
  },
  {
    "id": "2.3.3_resources",
    "type": "sc",
    "sc_id": "2.3.3",
    "section": "resources",
    "text": "[2.3.3 Animation from Interactions] (Level AAA)\nDescription: Motion animation triggered by interaction can be disabled, unless the animation is essential to the functionality or the information being conveyed.\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nMozilla documentation for 'prefers-reduced-motion'\nDemonstration of 'prefers-reduced-motion' in Webkit\nAn Introduction to the Reduced Motion Media Query\nDesigning Safer Web Animations for Motion Sensitivity\niOS:\nReduce Motion on iPhone, iPad or iPod touch\nMac:\nReduce Motion\nWindows 10:\nReduce motion",
    "principle": "Operable",
    "guideline": "2.3 Seizures and Physical Reactions"
  },
  {
    "id": "2.3.3_key_terms",
    "type": "sc",
    "sc_id": "2.3.3",
    "section": "key_terms",
    "text": "[2.3.3 Animation from Interactions] (Level AAA)\nDescription: Motion animation triggered by interaction can be disabled, unless the animation is essential to the functionality or the information being conveyed.\n\nSection: key_terms\n\nKey Terms\nessential\nif removed, would fundamentally change the information or functionality of the content,\nand\ninformation and functionality cannot be achieved in another way that would conform\nmotion animation\naddition of steps between conditions to create the illusion of movement or to give a sense of a smooth transition\nExample\nFor example, an element which moves into place or changes size while appearing is considered to be animated. An element which appears instantly without transitioning is not using animation. Motion animation does not include changes of color, blurring, or opacity which do not change the perceived size, shape, or position of the element.",
    "principle": "Operable",
    "guideline": "2.3 Seizures and Physical Reactions"
  },
  {
    "id": "2.3.3_sufficient",
    "type": "sc_sufficient",
    "sc_id": "2.3.3",
    "techniques": [
      "C39"
    ],
    "text": "[2.3.3 Animation from Interactions] (Level AAA)\nDescription: Motion animation triggered by interaction can be disabled, unless the animation is essential to the functionality or the information being conveyed.\n\nSufficient techniques for SC 2.3.3 (no situation): C39",
    "principle": "Operable",
    "guideline": "2.3 Seizures and Physical Reactions"
  },
  {
    "id": "2.4.1_intent",
    "type": "sc",
    "sc_id": "2.4.1",
    "section": "intent",
    "text": "[2.4.1 Bypass Blocks] (Level A)\nDescription: A mechanism is available to bypass blocks of content that are repeated on multiple web pages.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to allow people who navigate sequentially\n         through content more direct access to the primary content of the web page. web pages\n         and applications often have content that appears on other pages or screens. Examples\n         of repeated blocks of content include but are not limited to navigation links, header\n         content, and advertising frames. Small repeated sections such as individual words,\n         phrases or single links are not considered blocks for the purposes of this provision.\nUsers who navigate sequentially through content will generally have to navigate through\n         repeated content on each page. This is in contrast to a sighted user's ability to ignore\n         the repeated material either by focusing on the center of the screen (where main content\n         usually appears) or a mouse user's ability to select a link with a single mouse click\n         rather than encountering every link or form control that comes before the item they want.\nIt is not the intent of this success criterion to require authors to provide methods\n         that are redundant to functionality provided by the user agent. Most web browsers\n         provide keyboard shortcuts to move the user focus to the top of the page, so if a\n         set of navigation links is provided at the bottom of a web page providing a \"skip\"\n         link may be unnecessary.\nNote\nAlthough this success criterion deals with blocks of content that are repeated on\n            multiple pages, we also strongly promote structural markup on individual pages as\n            per Success Criteria 1.3.1.\nAlthough the success criterion does not specifically use the term “within a set of\n         web pages”, the concept of the pages belonging to a set is implied.  An author would\n         not be expected to avoid any possible duplication of content in any two pages that\n         are not in some way related to each other, and are not \"web pages that share a common\n         purpose and that are created by the same author, group or organization” (the definition\n         of set of web pages).\nNote\nEven for web pages that are not in a set, if a web page has blocks of text that are\n            repeated within the page it may be helpful (but not required) to provide a means to\n            skip over them.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.1_success_criterion",
    "type": "sc",
    "sc_id": "2.4.1",
    "section": "success_criterion",
    "text": "[2.4.1 Bypass Blocks] (Level A)\nDescription: A mechanism is available to bypass blocks of content that are repeated on multiple web pages.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nA\nmechanism\nis available to bypass blocks of content that are repeated on multiple\nweb pages\n.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.1_benefits",
    "type": "sc",
    "sc_id": "2.4.1",
    "section": "benefits",
    "text": "[2.4.1 Bypass Blocks] (Level A)\nDescription: A mechanism is available to bypass blocks of content that are repeated on multiple web pages.\n\nSection: benefits\n\nBenefits\nWhen this success criterion is not satisfied, it may be difficult for people with\n         some disabilities to reach the main content of a web page quickly and easily:\nScreen reader users who visit several pages on the same site can avoid having to hear\n            all header content and dozens of navigation links on every page before the main\n            content is spoken.\nPeople who use only the keyboard or a keyboard interface can reach content with fewer\n            keystrokes. Otherwise, they might have to make dozens of keystrokes before reaching\n            a link in the main content area. This can take a long time and may cause severe physical\n            pain for some users.\nPeople who use screen magnifiers do not have to search through the same header content or\n            other blocks of information to find where the main content begins each time they enter\n            a new page.\nPeople with cognitive limitations as well as people who use screen readers may benefit\n            when links are grouped into lists",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.1_examples",
    "type": "sc",
    "sc_id": "2.4.1",
    "section": "examples",
    "text": "[2.4.1 Bypass Blocks] (Level A)\nDescription: A mechanism is available to bypass blocks of content that are repeated on multiple web pages.\n\nSection: examples\n\nExamples\nA news organization's home page contains a main story in the middle of the page, surrounded\n            by many blocks and sidebars for advertising, searching, and other services. There\n            is a link at the top of the page that jumps to the main story. Without using this\n            link, a keyboard user needs to tab through approximately 40 links to reach the main\n            story; the screen reader user has to listen to 200 words; and the screen magnifier\n            user must search around for the location of the main body.\nAn e-commerce website includes a long list of filters prior to the search results listing. \n            A link above the list enables users to skip the filters and get to the product results quickly.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.1_brief",
    "type": "sc",
    "sc_id": "2.4.1",
    "section": "brief",
    "text": "[2.4.1 Bypass Blocks] (Level A)\nDescription: A mechanism is available to bypass blocks of content that are repeated on multiple web pages.\n\nSection: brief\n\nIn Brief\nGoal\nUsers can more easily navigate by keyboard.\nWhat to do\nProvide a means of skipping repeating content.\nWhy it's important\nUsers reliant on the keyboard interface can move around pages efficiently.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.1_resources",
    "type": "sc",
    "sc_id": "2.4.1",
    "section": "resources",
    "text": "[2.4.1 Bypass Blocks] (Level A)\nDescription: A mechanism is available to bypass blocks of content that are repeated on multiple web pages.\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nWebAIM: Semantic Structure\nHeading Tags",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.1_test_rules",
    "type": "sc",
    "sc_id": "2.4.1",
    "section": "test_rules",
    "text": "[2.4.1 Bypass Blocks] (Level A)\nDescription: A mechanism is available to bypass blocks of content that are repeated on multiple web pages.\n\nSection: test_rules\n\nTest Rules\nThe following are Test Rules\n    for certain aspects of this Success Criterion.\n    It is not necessary to use these particular Test Rules to check for conformance with WCAG, but they are defined and approved test methods.\n    For information on using Test Rules, see\nUnderstanding Test Rules for WCAG Success Criteria\n.\nBypass Blocks of Repeated Content",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.1_key_terms",
    "type": "sc",
    "sc_id": "2.4.1",
    "section": "key_terms",
    "text": "[2.4.1 Bypass Blocks] (Level A)\nDescription: A mechanism is available to bypass blocks of content that are repeated on multiple web pages.\n\nSection: key_terms\n\nKey Terms\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\nconformance\nsatisfying all the requirements of a given standard, guideline or specification\nmechanism\nprocess\nor technique for achieving a result\nNote 1\nThe mechanism may be explicitly provided in the content, or may be\nrelied upon\nto be provided by either the platform or by\nuser agents\n, including\nassistive technologies\n.\nNote 2\nThe mechanism needs to meet all success criteria for the conformance level claimed.\nprocess\nseries of user actions where each action is required in order to complete an activity\nExample 1\nSuccessful use of a series of web pages on a shopping site requires users to view\n      alternative products, prices and offers, select products, submit an order, provide\n      shipping information and provide payment information.\nExample 2\nAn account registration page requires successful completion of a\nTuring test\nbefore\n      the registration form can be accessed.\nrelied upon\nthe content would not\nconform\nif that\ntechnology\nis turned off or is not supported\ntechnology\nmechanism\nfor encoding instructions to be rendered, played or executed by\nuser agents\nNote 1\nAs used in these guidelines \"web technology\" and the word \"technology\" (when used\n      alone) both refer to web content technologies.\nNote 2\nWeb content technologies may include markup languages, data formats, or programming\n      languages that authors may use alone or in combination to create end-user experiences\n      that range from static web pages to synchronized media presentations to dynamic Web\n      applications.\nExample\nSome common examples of web content technologies include HTML, CSS, SVG, PNG, PDF,\n      Flash, and JavaScript.\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.\nweb page\na non-embedded resource obtained from a single URI using HTTP plus any other resources\n      that are used in the rendering or intended to be rendered together with it by a\nuser agent\nNote 1\nAlthough any \"other resources\" would be rendered together with the primary resource,\n      they would not necessarily be rendered simultaneously with each other.\nNote 2\nFor the purposes of conformance with these guidelines, a resource must be \"non-embedded\"\n      within the scope of conformance to be considered a web page.\nExample 1\nA web resource including all embedded images and media.\nExample 2\nA web mail program built using Asynchronous JavaScript and XML (AJAX). The program\n      lives entirely at http://example.com/mail, but includes an inbox, a contacts area\n      and a calendar. Links or buttons are provided that cause the inbox, contacts, or calendar\n      to display, but do not change the URI of the page as a whole.\nExample 3\nA customizable portal site, where users can choose content to display from a set of\n      different content modules.\nExample 4\nWhen you enter \"http://shopping.example.com/\" in your browser, you enter a movie-like\n      interactive shopping environment where you visually move around in a store dragging\n      products off of the shelves around you and into a visual shopping cart in front of\n      you. Clicking on a product causes it to be demonstrated with a specification sheet\n      floating alongside. This might be a single-page website or just one page within a\n      website.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.1_sufficient",
    "type": "sc_sufficient",
    "sc_id": "2.4.1",
    "techniques": [
      "G1",
      "G1",
      "G123",
      "G124",
      "ARIA11",
      "ARIA11",
      "H69",
      "PDF9",
      "H64",
      "SCR28"
    ],
    "text": "[2.4.1 Bypass Blocks] (Level A)\nDescription: A mechanism is available to bypass blocks of content that are repeated on multiple web pages.\n\nSufficient techniques for SC 2.4.1 (no situation): G1, G1, G123, G124, ARIA11, ARIA11, H69, PDF9, H64, SCR28",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.1_advisory",
    "type": "sc_advisory",
    "sc_id": "2.4.1",
    "techniques": [
      "C6",
      "H97"
    ],
    "text": "[2.4.1 Bypass Blocks] (Level A)\nDescription: A mechanism is available to bypass blocks of content that are repeated on multiple web pages.\n\nAdvisory techniques for SC 2.4.1: C6, H97",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.2_intent",
    "type": "sc",
    "sc_id": "2.4.2",
    "section": "intent",
    "text": "[2.4.2 Page Titled] (Level A)\nDescription: Web pages have titles that describe topic or purpose.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to help users find content and orient themselves\n         within it by ensuring that each web page has a descriptive title. Titles identify\n         the current location without requiring users to read or interpret page content. When\n         titles appear in site maps or lists of search results, users can more quickly identify\n         the content they need. User agents make the title of the page easily available to\n         the user for identifying the page. For instance, a user agent may display the page\n         title in the  window title bar or as the name of the tab containing the page.\nIn cases where the page is a document or a web application, the name of the document\n         or web application would be sufficient to describe the purpose of the page. Note that\n         it is not required to use the name of the document or web application; other things\n         may also describe the purpose or the topic of the page.\nIn cases such as Single Page Applications (SPAs), where various distinct pages/views are\n         all nominally served from the same URI and the content of the page is changed dynamically,\n         the title of the page should also be changed dynamically to reflect the content or topic of\n         the current view.\nSuccess Criteria 2.4.4\nand\n2.4.9\ndeal with the purpose of links, many of which are links to web pages. Here also,\n         the name of a document or web application being linked to would be sufficient to describe\n         the purpose of the link. Having the link and the title agree, or be very similar,\n         is good practice and provides continuity between the link 'clicked on' and the web\n         page that the user lands on.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.2_success_criterion",
    "type": "sc",
    "sc_id": "2.4.2",
    "section": "success_criterion",
    "text": "[2.4.2 Page Titled] (Level A)\nDescription: Web pages have titles that describe topic or purpose.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nWeb pages\nhave titles that describe topic or purpose.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.2_benefits",
    "type": "sc",
    "sc_id": "2.4.2",
    "section": "benefits",
    "text": "[2.4.2 Page Titled] (Level A)\nDescription: Web pages have titles that describe topic or purpose.\n\nSection: benefits\n\nBenefits\nThis criterion benefits all users in allowing users to quickly and easily identify\n            whether the information contained in the web page is relevant to their needs.\nPeople with visual disabilities will benefit from being able to differentiate content\n            when multiple web pages are open.\nPeople with cognitive disabilities, limited short-term memory and reading disabilities\n            also benefit from the ability to identify content by its title.\nThis criterion also benefits people with severe mobility impairments whose mode of\n            operation relies on audio when navigating between web pages.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.2_examples",
    "type": "sc",
    "sc_id": "2.4.2",
    "section": "examples",
    "text": "[2.4.2 Page Titled] (Level A)\nDescription: Web pages have titles that describe topic or purpose.\n\nSection: examples\n\nExamples\nAn HTML web page\nThe descriptive title of an HTML web page is marked up with the <title> element so\n               that it will be displayed in the title bar of the user agent.\nA document collection\nThe title of\nUnderstanding WCAG 2.2\nis \"Understanding WCAG 2.2\".\nThe\nIntroduction to Understanding WCAG\npage has the title \"Introduction to Understanding WCAG\".\nMajor sections of the document collection are pages titled \"Understanding Guideline X\" and \"Understanding Success Criterion X.\"\nAppendix A has the title \"Glossary.\"\nAppendix B has the title \"Acknowledgements.\"\nAppendix C has the title \"References.\"\nA web application\nA banking application lets users inspect their bank accounts, view past statements,\n               and perform transactions. The web application dynamically generates titles for each\n               web page, e.g., \"Bank XYZ, accounts for Alex Smith\" \"Bank XYZ, December 2005 statement\n               for Account 1234-5678\".",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.2_brief",
    "type": "sc",
    "sc_id": "2.4.2",
    "section": "brief",
    "text": "[2.4.2 Page Titled] (Level A)\nDescription: Web pages have titles that describe topic or purpose.\n\nSection: brief\n\nIn Brief\nGoal\nEach web page has a meaningful title.\nWhat to do\nProvide a descriptive page title using appropriate technology.\nWhy it's important\nPage titles help users identify and distinguish different pages.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.2_resources",
    "type": "sc",
    "sc_id": "2.4.2",
    "section": "resources",
    "text": "[2.4.2 Page Titled] (Level A)\nDescription: Web pages have titles that describe topic or purpose.\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nWriting Better Web Page Titles\n. How to write titles for web pages that will enhance search engine effectiveness.\nGuidelines for Accessible and Usable Web Sites: Observing Users Who Work With Screen\n               Readers (PDF)\n. Theofanos, M.F., and Redish, J. (2003).  Interactions, Volume X, Issue 6, November-December\n            2003, pages 38-51,\nhttps://dl.acm.org/doi/10.1145/947226.947227",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.2_test_rules",
    "type": "sc",
    "sc_id": "2.4.2",
    "section": "test_rules",
    "text": "[2.4.2 Page Titled] (Level A)\nDescription: Web pages have titles that describe topic or purpose.\n\nSection: test_rules\n\nTest Rules\nThe following are Test Rules\n    for certain aspects of this Success Criterion.\n    It is not necessary to use these particular Test Rules to check for conformance with WCAG, but they are defined and approved test methods.\n    For information on using Test Rules, see\nUnderstanding Test Rules for WCAG Success Criteria\n.\nHTML page has non-empty title\nHTML page title is descriptive",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.2_key_terms",
    "type": "sc",
    "sc_id": "2.4.2",
    "section": "key_terms",
    "text": "[2.4.2 Page Titled] (Level A)\nDescription: Web pages have titles that describe topic or purpose.\n\nSection: key_terms\n\nKey Terms\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.\nweb page\na non-embedded resource obtained from a single URI using HTTP plus any other resources\n      that are used in the rendering or intended to be rendered together with it by a\nuser agent\nNote 1\nAlthough any \"other resources\" would be rendered together with the primary resource,\n      they would not necessarily be rendered simultaneously with each other.\nNote 2\nFor the purposes of conformance with these guidelines, a resource must be \"non-embedded\"\n      within the scope of conformance to be considered a web page.\nExample 1\nA web resource including all embedded images and media.\nExample 2\nA web mail program built using Asynchronous JavaScript and XML (AJAX). The program\n      lives entirely at http://example.com/mail, but includes an inbox, a contacts area\n      and a calendar. Links or buttons are provided that cause the inbox, contacts, or calendar\n      to display, but do not change the URI of the page as a whole.\nExample 3\nA customizable portal site, where users can choose content to display from a set of\n      different content modules.\nExample 4\nWhen you enter \"http://shopping.example.com/\" in your browser, you enter a movie-like\n      interactive shopping environment where you visually move around in a store dragging\n      products off of the shelves around you and into a visual shopping cart in front of\n      you. Clicking on a product causes it to be demonstrated with a specification sheet\n      floating alongside. This might be a single-page website or just one page within a\n      website.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.2_sufficient",
    "type": "sc_sufficient",
    "sc_id": "2.4.2",
    "techniques": [
      "G88",
      "H25",
      "PDF18"
    ],
    "text": "[2.4.2 Page Titled] (Level A)\nDescription: Web pages have titles that describe topic or purpose.\n\nSufficient techniques for SC 2.4.2 (no situation): G88, H25, PDF18",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.2_advisory",
    "type": "sc_advisory",
    "sc_id": "2.4.2",
    "techniques": [
      "G127"
    ],
    "text": "[2.4.2 Page Titled] (Level A)\nDescription: Web pages have titles that describe topic or purpose.\n\nAdvisory techniques for SC 2.4.2: G127",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.2_failures",
    "type": "sc_failures",
    "sc_id": "2.4.2",
    "techniques": [
      "F25"
    ],
    "text": "[2.4.2 Page Titled] (Level A)\nDescription: Web pages have titles that describe topic or purpose.\n\nCommon failures for SC 2.4.2: F25",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.3_intent",
    "type": "sc",
    "sc_id": "2.4.3",
    "section": "intent",
    "text": "[2.4.3 Focus Order] (Level A)\nDescription: If a web page can be navigated sequentially and the navigation sequences affect meaning or operation, focusable components receive\n      focus in an order that preserves meaning and operability.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to ensure that when users navigate sequentially\n         through content, they encounter information in an order that is consistent with the\n         meaning of the content and can be operated from the keyboard. This reduces confusion\n         by letting users form a consistent mental model of the content. There may be different\n         orders that reflect logical relationships in the content. For example, moving through\n         components in a table one row at a time or one column at a time both reflect the logical\n         relationships in the content. Either order may satisfy this success criterion.\nThe way that sequential navigation order is determined in web content is defined by\n         the technology of the content. For example, simple HTML defines sequential navigation\n         via the notion of tabbing order. Dynamic HTML may modify the navigation sequence using\n         scripting along with the addition of a\ntabindex\nattribute to allow focus to additional\n         elements. If no scripting or\ntabindex\nattributes are used, the navigation order is\n         the order that components appear in the content stream. (See\nFocus\nin the HTML Living Standard\n).\nAn example of keyboard navigation that is not the sequential navigation addressed\n         by this success criterion is using arrow key navigation to traverse a tree component.\n         The user can use the up and down arrow keys to move from tree node to tree node. Pressing\n         the right arrow key may expand a node, then using the down arrow key, will move into\n         the newly expanded nodes. This navigation sequence follows the expected sequence for\n         a tree control - as additional items get expanded or collapsed, they are added or\n         removed from the navigation sequence.\nThe focus order may not be identical to the programmatically determined reading order\n         (see\nSuccess Criterion 1.3.2\n) as long as the user can still understand and operate\n         the web page. Since there may be several possible logical reading orders for the content,\n         the focus order may match any of them. However, when the order of a particular presentation\n         differs from the programmatically determined reading order, users of one of these\n         presentations may find it difficult to understand or operate the web page. Authors\n         should carefully consider all these users as they design their web pages.\nFor example, a screen reader user interacts with the programmatically determined reading\n         order, while a sighted keyboard user interacts with the visual presentation of the\n         web page. Care should be taken so that the focus order makes sense to both of these\n         sets of users and does not appear to either of them to jump around randomly.\nFor clarity:\nFocusable components need to receive focus in an order that preserves meaning and\n            operability only when navigation sequences affect meaning and operability.\nIn those cases where it is required, there may be more than one order that will preserve\n            meaning and operability.\nIf there is more than one order that preserves meaning and operability, only one of\n            them needs to be provided.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.3_success_criterion",
    "type": "sc",
    "sc_id": "2.4.3",
    "section": "success_criterion",
    "text": "[2.4.3 Focus Order] (Level A)\nDescription: If a web page can be navigated sequentially and the navigation sequences affect meaning or operation, focusable components receive\n      focus in an order that preserves meaning and operability.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nIf a\nweb page\ncan be\nnavigated sequentially\nand the navigation sequences affect meaning or operation, focusable components receive\n      focus in an order that preserves meaning and operability.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.3_benefits",
    "type": "sc",
    "sc_id": "2.4.3",
    "section": "benefits",
    "text": "[2.4.3 Focus Order] (Level A)\nDescription: If a web page can be navigated sequentially and the navigation sequences affect meaning or operation, focusable components receive\n      focus in an order that preserves meaning and operability.\n\nSection: benefits\n\nBenefits\nThese techniques benefit keyboard users who navigate documents sequentially and expect\n         the focus order to be consistent with the sequential reading order.\nPeople with mobility impairments who must rely on keyboard access for operating a\n            page benefit from a logical, usable focus order.\nPeople with disabilities that make reading difficult can become disoriented when tabbing\n            takes focus someplace unexpected. They benefit from a logical focus order.\nPeople with visual impairments can become disoriented when tabbing takes focus someplace\n            unexpected or when they cannot easily find the content surrounding an interactive\n            element.\nOnly a small portion of the page may be visible to an individual using a screen magnifier\n            at a high level of magnification. Such a user may interpret a field in the wrong context\n            if the focus order is not logical.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.3_examples",
    "type": "sc",
    "sc_id": "2.4.3",
    "section": "examples",
    "text": "[2.4.3 Focus Order] (Level A)\nDescription: If a web page can be navigated sequentially and the navigation sequences affect meaning or operation, focusable components receive\n      focus in an order that preserves meaning and operability.\n\nSection: examples\n\nExamples\nOn a web page that contains a tree of interactive controls, the user can use the up\n            and down arrow keys to move from tree node to tree node. Pressing the right arrow\n            key expands a node, then using the down arrow key moves into the newly expanded nodes.\nA web page implements modeless dialogs via scripting. When the trigger button is activated,\n            a dialog opens. The interactive elements in the dialog are inserted in the focus order\n            immediately after the button. When the dialog is open, the focus order goes from the\n            button to the elements of the dialog, then to the interactive element following the\n            button. When the dialog is closed, the focus order goes from the button to the following\n            element.\nA web page implements modal dialogs via scripting. When the trigger button is activated,\n            a dialog opens and focus is set within the dialog. As\n            long as the dialog is open, focus is limited to the elements of the dialog. When the\n            dialog is dismissed, focus returns to the button or the element following the button.\nAn HTML web page is created with the left hand navigation occurring in the HTML after\n               the main body content, and styled with CSS to appear on the left hand side of the\n               page. This is done to allow focus to move to the main body content first without requiring\ntabindex\nattributes or JavaScript.\nNote\nWhile this example passes the Success Criterion, it is not necessarily true that all\n                  CSS positioning would. More complex positioning examples may or may not preserve meaning\n                  and operability\nThe following example\nfails to meet the Success Criterion\n:\nA company's website includes a form that collects marketing data and allows users\n               to subscribe to several newsletters published by the company. The section of the form\n               for collecting marketing data includes fields such as name, street address, city,\n               state or province, and postal code. Another section of the form includes several checkboxes\n               so that users can indicate newsletters they want to receive. However, the tab order\n               for the form skips between fields in different sections of the form, so that focus\n               moves from the name field to a checkbox, then to the street address, then to another\n               checkbox.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.3_brief",
    "type": "sc",
    "sc_id": "2.4.3",
    "section": "brief",
    "text": "[2.4.3 Focus Order] (Level A)\nDescription: If a web page can be navigated sequentially and the navigation sequences affect meaning or operation, focusable components receive\n      focus in an order that preserves meaning and operability.\n\nSection: brief\n\nIn Brief\nGoal\nKeyboard users navigate content in a correct order.\nWhat to do\nElements receive focus in an order that preserves meaning.\nWhy it's important\nNavigating a site or application with only the keyboard will make sense.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.3_key_terms",
    "type": "sc",
    "sc_id": "2.4.3",
    "section": "key_terms",
    "text": "[2.4.3 Focus Order] (Level A)\nDescription: If a web page can be navigated sequentially and the navigation sequences affect meaning or operation, focusable components receive\n      focus in an order that preserves meaning and operability.\n\nSection: key_terms\n\nKey Terms\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\nkeyboard interface\ninterface used by software to obtain keystroke input\nNote 1\nA keyboard interface allows users to provide keystroke input to programs even if the\n        native technology does not contain a keyboard.\nExample\nA touchscreen PDA has a keyboard interface built into its operating system as well\n        as a connector for external keyboards. Applications on the PDA can use the interface\n        to obtain keyboard input either from an external keyboard or from other applications\n        that provide simulated keyboard output, such as handwriting interpreters or speech-to-text\n        applications with \"keyboard emulation\" functionality.\nNote 2\nOperation of the application (or parts of the application) through a keyboard-operated\n      mouse emulator, such as MouseKeys, does not qualify as operation through a keyboard\n      interface because operation of the program is through its pointing device interface,\n      not through its keyboard interface.\nnavigated sequentially\nnavigated in the order defined for advancing focus (from one element to the next)\n      using a\nkeyboard interface\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.\nweb page\na non-embedded resource obtained from a single URI using HTTP plus any other resources\n      that are used in the rendering or intended to be rendered together with it by a\nuser agent\nNote 1\nAlthough any \"other resources\" would be rendered together with the primary resource,\n      they would not necessarily be rendered simultaneously with each other.\nNote 2\nFor the purposes of conformance with these guidelines, a resource must be \"non-embedded\"\n      within the scope of conformance to be considered a web page.\nExample 1\nA web resource including all embedded images and media.\nExample 2\nA web mail program built using Asynchronous JavaScript and XML (AJAX). The program\n      lives entirely at http://example.com/mail, but includes an inbox, a contacts area\n      and a calendar. Links or buttons are provided that cause the inbox, contacts, or calendar\n      to display, but do not change the URI of the page as a whole.\nExample 3\nA customizable portal site, where users can choose content to display from a set of\n      different content modules.\nExample 4\nWhen you enter \"http://shopping.example.com/\" in your browser, you enter a movie-like\n      interactive shopping environment where you visually move around in a store dragging\n      products off of the shelves around you and into a visual shopping cart in front of\n      you. Clicking on a product causes it to be demonstrated with a specification sheet\n      floating alongside. This might be a single-page website or just one page within a\n      website.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.3_sufficient",
    "type": "sc_sufficient",
    "sc_id": "2.4.3",
    "techniques": [
      "G59",
      "C27",
      "C27",
      "PDF3",
      "SCR26",
      "SCR26",
      "H102",
      "SCR27"
    ],
    "text": "[2.4.3 Focus Order] (Level A)\nDescription: If a web page can be navigated sequentially and the navigation sequences affect meaning or operation, focusable components receive\n      focus in an order that preserves meaning and operability.\n\nSufficient techniques for SC 2.4.3 (no situation): G59, C27, C27, PDF3, SCR26, SCR26, H102, SCR27",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.3_failures",
    "type": "sc_failures",
    "sc_id": "2.4.3",
    "techniques": [
      "F44",
      "F85"
    ],
    "text": "[2.4.3 Focus Order] (Level A)\nDescription: If a web page can be navigated sequentially and the navigation sequences affect meaning or operation, focusable components receive\n      focus in an order that preserves meaning and operability.\n\nCommon failures for SC 2.4.3: F44, F85",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.4_intent",
    "type": "sc",
    "sc_id": "2.4.4",
    "section": "intent",
    "text": "[2.4.4 Link Purpose (In Context)] (Level A)\nDescription: The purpose of each link can be determined from the link text alone or from the link text together with its\n      programmatically determined link context, except where the purpose of the link would be ambiguous to users in general.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to help users understand the purpose of each\n         link so they can decide whether they want to follow the link. Whenever possible, provide\n         link text that identifies the purpose of the link without needing additional context.\n         Assistive technology has the ability to provide users with a list of links that are\n         on the web page. Link text that is as meaningful as possible will aid users who want\n         to choose from this list of links. Meaningful link text also helps those who wish\n         to tab from link to link. Meaningful links help users choose which links to follow\n         without requiring complicated strategies to understand the page.\nThe text of, or associated with, the link is intended to describe the purpose of the\n         link. In cases where the link takes one to a document or a web application, the name\n         of the document or web application would be sufficient to describe the purpose of\n         the link (which is to take you to the document or web application). Note that it is\n         not required to use the name of the document or web application; other things may\n         also describe the purpose of the link.\nSuccess Criterion 2.4.2\ndeals with the titles of pages. Here also, the name of a document or web application\n         being presented on the page would be sufficient to describe the purpose of the page.\n         Having the link and the title agree, or be very similar, is good practice and provides\n         continuity between the link 'clicked on' and the web page that the user lands on.\nIn some situations, authors may want to provide part of the description of the link\n         in logically related text that provides the context for the link. In this case the\n         user should be able to identify the purpose of the link without moving focus from\n         the link. In other words, they can arrive on a link and find out more about it without\n         losing their place. This can be achieved by putting the description of the link in\n         the same sentence, paragraph, list item, or table cell as the link, or in the table header cell for a link in a data table, because these are directly associated with the link itself. Alternatively, authors may choose to use an ARIA technique to associate additional\n         text on the page with the link.\nThis context will be most usable if it precedes the link. (For instance, if you must\n         use ambiguous link text, it is better to put it at the end of the sentence that describes\n         its destination, rather than putting the ambiguous phrase at the beginning of the\n         sentence.) If the description follows the link, there can be confusion and difficulty\n         for screen reader users who are reading through the page in order (top to bottom).\nIt is a best practice for links with the same destination to have consistent text\n         (and this is a requirement per\nSuccess Criterion 3.2.4\nfor pages in a set). It is also a best practice for links with different purposes\n         and destinations to have different link text.\nA best practice for links to\nconforming alternate versions\nis to ensure that the link text to the conforming alternate version indicates in link text that the page it leads to represents the more accessible version. This information may also be provided in text - the goal is to ensure that the end user knows what the purpose of the link is.\nThe success criterion includes an exception for links for which the purpose of the\n         link cannot be determined from the information on the web page. In this situation,\n         the person with the disability is not at a disadvantage; there is no additional context\n         available to understand the link purpose. However, whatever amount of context is available\n         on the web page that can be used to interpret the purpose of the link must be made\n         available in the link text or programmatically associated with the link to satisfy\n         the success criterion.\nNote\nThere may be situations where the purpose of the link is is supposed to be unknown\n            or obscured. For instance, a game may have links identified only as door #1, door\n            #2, and door #3. This link text would be sufficient because the purpose of the links\n            is to create suspense for all users.\nSee also\n2.4.9: Link Purpose (Link Only)\n.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.4_success_criterion",
    "type": "sc",
    "sc_id": "2.4.4",
    "section": "success_criterion",
    "text": "[2.4.4 Link Purpose (In Context)] (Level A)\nDescription: The purpose of each link can be determined from the link text alone or from the link text together with its\n      programmatically determined link context, except where the purpose of the link would be ambiguous to users in general.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nThe\npurpose of each link\ncan be determined from the link text alone or from the link text together with its\nprogrammatically determined link context\n, except where the purpose of the link would be\nambiguous to users in general\n.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.4_benefits",
    "type": "sc",
    "sc_id": "2.4.4",
    "section": "benefits",
    "text": "[2.4.4 Link Purpose (In Context)] (Level A)\nDescription: The purpose of each link can be determined from the link text alone or from the link text together with its\n      programmatically determined link context, except where the purpose of the link would be ambiguous to users in general.\n\nSection: benefits\n\nBenefits\nThis success criterion helps people with motion impairment by letting them skip links\n            that they are not interested in, avoiding the keystrokes needed to visit the referenced\n            content and then returning to the current content.\nPeople with cognitive limitations will not become disoriented by multiple means of\n            navigation to and from content they are not interested in.\nPeople with visual disabilities will be able to determine the purpose of a link by\n            exploring the link's context.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.4_examples",
    "type": "sc",
    "sc_id": "2.4.4",
    "section": "examples",
    "text": "[2.4.4 Link Purpose (In Context)] (Level A)\nDescription: The purpose of each link can be determined from the link text alone or from the link text together with its\n      programmatically determined link context, except where the purpose of the link would be ambiguous to users in general.\n\nSection: examples\n\nExamples\nA link contains text that gives a description of the information at that URI\nA page contains the sentence \"There was much bloodshed during the Medieval period\n               of history.\" Where \"Medieval period of history\" is a link.\nA link is preceded by a text description of the information at that URI\nA page contains the sentence \"Learn more about the Government of Ireland's Commission\n               on Electronic Voting at Go Vote!\" where \"Go Vote!\" is a link.\nBoth an icon and text are included in the same link\nAn icon of a voting machine and the text \"Government of Ireland's Commission of Electronic\n               Voting\" are combined to make a single link. The alt text for the icon is null, since\n               the purpose of the link is already described by the text of the link next to the icon.\nA list of book titles\nA list of books is available in three formats: HTML, PDF, and mp3 (a recording of\n               a person reading the book). To avoid hearing the title of each book three times (once\n               for each format), the first link for each book is the title of the book, the second\n               link says \"PDF\" and the third says, \"mp3.\"\nNews article summaries\nA web page contains a collection of news articles. The main page lists the first few\n               sentences of each article, followed by a \"Read more\" link. A screen reader command\n               to read the current paragraph provides the context to interpret the purpose of the\n               link.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.4_brief",
    "type": "sc",
    "sc_id": "2.4.4",
    "section": "brief",
    "text": "[2.4.4 Link Purpose (In Context)] (Level A)\nDescription: The purpose of each link can be determined from the link text alone or from the link text together with its\n      programmatically determined link context, except where the purpose of the link would be ambiguous to users in general.\n\nSection: brief\n\nIn Brief\nGoal\nUsers understand what each link will do.\nWhat to do\nProvide descriptive names or context for all links.\nWhy it's important\nPeople with visual and cognitive disabilities can navigate more easily.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.4_resources",
    "type": "sc",
    "sc_id": "2.4.4",
    "section": "resources",
    "text": "[2.4.4 Link Purpose (In Context)] (Level A)\nDescription: The purpose of each link can be determined from the link text alone or from the link text together with its\n      programmatically determined link context, except where the purpose of the link would be ambiguous to users in general.\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nUsing Link Titles to Help Users Predict Where They Are Going\nWebAIM Techniques for Hypertext Links",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.4_test_rules",
    "type": "sc",
    "sc_id": "2.4.4",
    "section": "test_rules",
    "text": "[2.4.4 Link Purpose (In Context)] (Level A)\nDescription: The purpose of each link can be determined from the link text alone or from the link text together with its\n      programmatically determined link context, except where the purpose of the link would be ambiguous to users in general.\n\nSection: test_rules\n\nTest Rules\nThe following are Test Rules\n    for certain aspects of this Success Criterion.\n    It is not necessary to use these particular Test Rules to check for conformance with WCAG, but they are defined and approved test methods.\n    For information on using Test Rules, see\nUnderstanding Test Rules for WCAG Success Criteria\n.\nLink has non-empty accessible name\nLink in context is descriptive\nLinks with identical accessible names and same context serve equivalent purpose",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.4_key_terms",
    "type": "sc",
    "sc_id": "2.4.4",
    "section": "key_terms",
    "text": "[2.4.4 Link Purpose (In Context)] (Level A)\nDescription: The purpose of each link can be determined from the link text alone or from the link text together with its\n      programmatically determined link context, except where the purpose of the link would be ambiguous to users in general.\n\nSection: key_terms\n\nKey Terms\naccessibility supported\nsupported by users'\nassistive technologies\nas well as the accessibility features in browsers and other\nuser agents\nTo qualify as an accessibility-supported use of a web content technology (or feature\n      of a technology), both 1 and 2 must be satisfied for a web content technology (or\n      feature):\nThe way that the\nweb content technology\nis used must be supported by users' assistive technology (AT).\nThis means that the way that the technology is used has been tested for interoperability\n            with users' assistive technology in the\nhuman language(s)\nof the content,\nAND\nThe web content technology must have accessibility-supported user agents that are\n               available to users.\nThis means that at least one of the following four statements is true:\nThe technology is supported natively in widely-distributed user agents that are also\n                  accessibility supported (such as HTML and CSS);\nOR\nThe technology is supported in a widely-distributed plug-in that is also accessibility\n                  supported;\nOR\nThe content is available in a closed environment, such as a university or corporate\n                  network, where the user agent required by the technology and used by the organization\n                  is also accessibility supported;\nOR\nThe user agent(s) that support the technology are accessibility supported and are\n                  available for download or purchase in a way that:\ndoes not cost a person with a disability any more than a person without a disability\nand\nis as easy to find and obtain for a person with a disability as it is for a person\n                     without disabilities.\nNote 1\nThe Accessibility Guidelines Working Group and the W3C do not specify which or how much support by assistive\n      technologies there must be for a particular use of a web technology in order for it\n      to be classified as accessibility supported. (See\nLevel of Assistive Technology Support Needed for \"Accessibility Support\"\n.)\nNote 2\nWeb technologies can be used in ways that are not accessibility supported as long\n      as they are not\nrelied upon\nand the page as a whole meets the conformance requirements, including\nConformance Requirement 4\nand\nConformance Requirement 5\n.\nNote 3\nWhen a\nweb technology\nis used in a way that is \"accessibility supported,\" it does not imply that the entire\n      technology or all uses of the technology are supported. Most technologies, including\n      HTML, lack support for at least one feature or use. Pages conform to WCAG only if\n      the uses of the technology that are accessibility supported can be relied upon to\n      meet WCAG requirements.\nNote 4\nWhen citing web content technologies that have multiple versions, the version(s) supported\n      should be specified.\nNote 5\nOne way for authors to locate uses of a technology that are accessibility supported\n      would be to consult compilations of uses that are documented to be accessibility supported.\n      (See\nUnderstanding Accessibility-Supported Web Technology Uses\n.) Authors, companies, technology vendors, or others may document accessibility-supported\n      ways of using web content technologies. However, all ways of using technologies in\n      the documentation would need to meet the definition of accessibility-supported Web\n      content technologies above.\nambiguous to users in general\nthe purpose cannot be determined from the link and all information of the web page\n      presented to the user simultaneously with the link (i.e., readers without disabilities\n      would not know what a link would do until they activated it)\nExample\nThe word guava in the following sentence \"One of the notable exports is guava\" is\n      a link. The link could lead to a definition of guava, a chart listing the quantity\n      of guava exported or a photograph of people harvesting guava. Until the link is activated,\n      all readers are unsure and the person with a disability is not at any disadvantage.\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\nconformance\nsatisfying all the requirements of a given standard, guideline or specification\nconforming alternate version\nversion that\nconforms at the designated level, and\nprovides all of the same information and\nfunctionality\nin the same\nhuman language\n, and\nis as up to date as the non-conforming content, and\nfor which at least one of the following is true:\nthe conforming version can be reached from the non-conforming page via an\naccessibility-supported\nmechanism\n, or\nthe non-conforming version can only be reached from the conforming version, or\nthe non-conforming version can only be reached from a conforming page that also provides\n               a mechanism to reach the conforming version\nNote 1\nIn this definition, \"can only be reached\" means that there is some mechanism, such\n      as a conditional redirect, that prevents a user from \"reaching\" (loading) the non-conforming\n      page unless the user had just come from the conforming version.\nNote 2\nThe alternate version does not need to be matched page for page with the original\n      (e.g., the conforming alternate version may consist of multiple pages).\nNote 3\nIf multiple language versions are available, then conforming alternate versions are\n      required for each language offered.\nNote 4\nAlternate versions may be provided to accommodate different technology environments\n      or user groups. Each version should be as conformant as possible. One version would\n      need to be fully conformant in order to meet\nconformance requirement 1\n.\nNote 5\nThe conforming alternative version does not need to reside within the scope of conformance,\n      or even on the same website, as long as it is as freely available as the non-conforming\n      version.\nNote 6\nAlternate versions should not be confused with\nsupplementary content\n, which support the original page and enhance comprehension.\nNote 7\nSetting user preferences within the content to produce a conforming version is an\n      acceptable mechanism for reaching another version as long as the method used to set\n      the preferences is accessibility supported.\nSee\nUnderstanding Conforming Alternate Versions\ncontent\ninformation and sensory experience to be communicated to the user by means of a\nuser agent\n, including code or markup that defines the content's\nstructure\n,\npresentation\n, and interactions\nfunctionality\nprocesses\nand outcomes achievable through user action\nhuman language\nlanguage that is spoken, written or signed (through visual or tactile means) to communicate\n      with humans\nNote\nSee also\nsign language\n.\nlink purpose\nnature of the result obtained by activating a hyperlink\nmechanism\nprocess\nor technique for achieving a result\nNote 1\nThe mechanism may be explicitly provided in the content, or may be\nrelied upon\nto be provided by either the platform or by\nuser agents\n, including\nassistive technologies\n.\nNote 2\nThe mechanism needs to meet all success criteria for the conformance level claimed.\npresentation\nrendering of the\ncontent\nin a form to be perceived by users\nprocess\nseries of user actions where each action is required in order to complete an activity\nExample 1\nSuccessful use of a series of web pages on a shopping site requires users to view\n      alternative products, prices and offers, select products, submit an order, provide\n      shipping information and provide payment information.\nExample 2\nAn account registration page requires successful completion of a\nTuring test\nbefore\n      the registration form can be accessed.\nprogrammatically determined\ndetermined by software from author-supplied data provided in a way that different\nuser agents\n, including\nassistive technologies\n, can extract and present this information to users in different modalities\nExample 1\nDetermined in a markup language from elements and attributes that are accessed directly\n      by commonly available assistive technology.\nExample 2\nDetermined from technology-specific data structures in a non-markup language and exposed\n      to assistive technology via an accessibility API that is supported by commonly available\n      assistive technology.\nprogrammatically determined link context\nadditional information that can be\nprogrammatically determined\nfrom\nrelationships\nwith a link, combined with the link text, and presented to users in different modalities\nExample\nIn HTML, information that is programmatically determinable from a link in English\n      includes text that is in the same\nparagraph\n, \n      list item, or table cell as the link or in a table header cell that is associated with the table cell that contains the link.\nNote\nSince screen readers interpret punctuation, they can also provide the context from\n      the current sentence, when the focus is on a link in that sentence.\nrelationships\nmeaningful associations between distinct pieces of content\nrelied upon\nthe content would not\nconform\nif that\ntechnology\nis turned off or is not supported\nsign language\na language using combinations of movements of the hands and arms, facial expressions,\n      or body positions to convey meaning\nstructure\nThe way the parts of a\nweb page\nare organized in relation to each other; and\nThe way a collection of\nweb pages\nis organized\nsupplemental content\nadditional\ncontent\nthat illustrates or clarifies the primary content\nExample 1\nAn audio version of a\nweb page\n.\nExample 2\nAn illustration of a complex\nprocess\n.\nExample 3\nA paragraph summarizing the major outcomes and recommendations made in a research\n      study.\ntechnology\nmechanism\nfor encoding instructions to be rendered, played or executed by\nuser agents\nNote 1\nAs used in these guidelines \"web technology\" and the word \"technology\" (when used\n      alone) both refer to web content technologies.\nNote 2\nWeb content technologies may include markup languages, data formats, or programming\n      languages that authors may use alone or in combination to create end-user experiences\n      that range from static web pages to synchronized media presentations to dynamic Web\n      applications.\nExample\nSome common examples of web content technologies include HTML, CSS, SVG, PNG, PDF,\n      Flash, and JavaScript.\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.\nweb page\na non-embedded resource obtained from a single URI using HTTP plus any other resources\n      that are used in the rendering or intended to be rendered together with it by a\nuser agent\nNote 1\nAlthough any \"other resources\" would be rendered together with the primary resource,\n      they would not necessarily be rendered simultaneously with each other.\nNote 2\nFor the purposes of conformance with these guidelines, a resource must be \"non-embedded\"\n      within the scope of conformance to be considered a web page.\nExample 1\nA web resource including all embedded images and media.\nExample 2\nA web mail program built using Asynchronous JavaScript and XML (AJAX). The program\n      lives entirely at http://example.com/mail, but includes an inbox, a contacts area\n      and a calendar. Links or buttons are provided that cause the inbox, contacts, or calendar\n      to display, but do not change the URI of the page as a whole.\nExample 3\nA customizable portal site, where users can choose content to display from a set of\n      different content modules.\nExample 4\nWhen you enter \"http://shopping.example.com/\" in your browser, you enter a movie-like\n      interactive shopping environment where you visually move around in a store dragging\n      products off of the shelves around you and into a visual shopping cart in front of\n      you. Clicking on a product causes it to be demonstrated with a specification sheet\n      floating alongside. This might be a single-page website or just one page within a\n      website.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.4_sufficient",
    "type": "sc_sufficient",
    "sc_id": "2.4.4",
    "techniques": [
      "G91",
      "H30",
      "H24",
      "G189",
      "G189",
      "SCR30",
      "G53",
      "H33",
      "H33",
      "C7",
      "ARIA7",
      "ARIA7",
      "ARIA8",
      "H77",
      "H78",
      "H79",
      "H81",
      "G91",
      "PDF11",
      "PDF13"
    ],
    "text": "[2.4.4 Link Purpose (In Context)] (Level A)\nDescription: The purpose of each link can be determined from the link text alone or from the link text together with its\n      programmatically determined link context, except where the purpose of the link would be ambiguous to users in general.\n\nSufficient techniques for SC 2.4.4 (no situation): G91, H30, H24, G189, G189, SCR30, G53, H33, H33, C7, ARIA7, ARIA7, ARIA8, H77, H78, H79, H81, G91, PDF11, PDF13",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.4_advisory",
    "type": "sc_advisory",
    "sc_id": "2.4.4",
    "techniques": [
      "H2",
      "H80"
    ],
    "text": "[2.4.4 Link Purpose (In Context)] (Level A)\nDescription: The purpose of each link can be determined from the link text alone or from the link text together with its\n      programmatically determined link context, except where the purpose of the link would be ambiguous to users in general.\n\nAdvisory techniques for SC 2.4.4: H2, H80",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.4_failures",
    "type": "sc_failures",
    "sc_id": "2.4.4",
    "techniques": [
      "F63",
      "F89"
    ],
    "text": "[2.4.4 Link Purpose (In Context)] (Level A)\nDescription: The purpose of each link can be determined from the link text alone or from the link text together with its\n      programmatically determined link context, except where the purpose of the link would be ambiguous to users in general.\n\nCommon failures for SC 2.4.4: F63, F89",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.5_intent",
    "type": "sc",
    "sc_id": "2.4.5",
    "section": "intent",
    "text": "[2.4.5 Multiple Ways] (Level AA)\nDescription: More than one way is available to locate a web page within a set of web pages except where the web page is the result of, or a step in, a process.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to make it possible for users to locate content\n         in a manner that best meets their needs. Users may find one technique easier or more\n         comprehensible to use than another.\nEven small sites should provide users some means of orientation. For a three or four\n         page site, with all pages linked from the home page, it may be sufficient simply to\n         provide links from and to the home page where the links on the home page can also\n         serve as a site map.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.5_success_criterion",
    "type": "sc",
    "sc_id": "2.4.5",
    "section": "success_criterion",
    "text": "[2.4.5 Multiple Ways] (Level AA)\nDescription: More than one way is available to locate a web page within a set of web pages except where the web page is the result of, or a step in, a process.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nMore than one way is available to locate a\nweb page\nwithin a\nset of web pages\nexcept where the web page is the result of, or a step in, a\nprocess\n.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.5_benefits",
    "type": "sc",
    "sc_id": "2.4.5",
    "section": "benefits",
    "text": "[2.4.5 Multiple Ways] (Level AA)\nDescription: More than one way is available to locate a web page within a set of web pages except where the web page is the result of, or a step in, a process.\n\nSection: benefits\n\nBenefits\nProviding an opportunity to navigate sites in more than one manner can help people\n            find information faster. Users with visual impairments may find it easier to navigate\n            to the correct part of the site by using a search, rather than scrolling through a\n            large navigation bar using a screen magnifier or screen reader. A person with cognitive\n            disabilities may prefer a table of contents or site map that provides an overview\n            of the site rather than reading and traversing through several web pages. Some users\n            may prefer to explore the site in a sequential manner, moving from web page to Web\n            page in order to best understand the concepts and layout.\nIndividuals with cognitive limitations may find it easier to use search features than\n            to use a hierarchical navigation scheme that may be difficult to understand.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.5_examples",
    "type": "sc",
    "sc_id": "2.4.5",
    "section": "examples",
    "text": "[2.4.5 Multiple Ways] (Level AA)\nDescription: More than one way is available to locate a web page within a set of web pages except where the web page is the result of, or a step in, a process.\n\nSection: examples\n\nExamples\nA search mechanism\nA large food processing company provides a site containing recipes created using its\n               products. The site provides a search mechanism to search for recipes using a particular\n               ingredient. In addition, it provides a list box that lists several categories of foods.\n               A user may type \"soup\" in to the search engine or may select \"soup\" from the list\n               box to go to a page with a list of recipes made from the company's soup products.\nLinks between web pages\nA local hair salon has created a website to promote its services. The site contains\n               only five web pages. There are links on each web page to sequentially move forward\n               or backward through the web pages. In addition, each web page contains a list of links\n               to reach each of the other web pages.\nWhere content is a result of a process or task - Funds transfer confirmation\nAn on-line banking site allows fund transfer between accounts via the Web. There is\n               no other way to locate the confirmation of fund transfer until the account owner completes\n               the transfer.\nWhere content is a result of a process or task - Search engine results\nA search engine provides the search results based on user input. There is no other\n               way to locate the search results except to perform the search process itself.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.5_brief",
    "type": "sc",
    "sc_id": "2.4.5",
    "section": "brief",
    "text": "[2.4.5 Multiple Ways] (Level AA)\nDescription: More than one way is available to locate a web page within a set of web pages except where the web page is the result of, or a step in, a process.\n\nSection: brief\n\nIn Brief\nGoal\nUsers can get to content in multiple ways.\nWhat to do\nProvide at least two options for reaching the same content.\nWhy it's important\nNot everyone can navigate content in the same way.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.5_key_terms",
    "type": "sc",
    "sc_id": "2.4.5",
    "section": "key_terms",
    "text": "[2.4.5 Multiple Ways] (Level AA)\nDescription: More than one way is available to locate a web page within a set of web pages except where the web page is the result of, or a step in, a process.\n\nSection: key_terms\n\nKey Terms\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\nprocess\nseries of user actions where each action is required in order to complete an activity\nExample 1\nSuccessful use of a series of web pages on a shopping site requires users to view\n      alternative products, prices and offers, select products, submit an order, provide\n      shipping information and provide payment information.\nExample 2\nAn account registration page requires successful completion of a\nTuring test\nbefore\n      the registration form can be accessed.\nset of web pages\ncollection of\nweb pages\nthat share a common purpose and that are created by the same author, group or organization\nExample\nExamples include:\na publication which is split across multiple web pages, where each page contains one chapter or other significant section of the work. The publication is logically a single contiguous unit, and contains navigation features that enable access to the full set of pages.\nan e-commerce website shows products in a set of web pages that all share the same navigation and identification. However, when progressing to the checkout process, the template changes; the navigation and other elements are removed, so the pages in that process are functionally and visually different. The checkout pages are not part of the set of product pages.\na blog on a sub-domain (e.g. blog.example.com) which has a different navigation and is authored by a distinct set of people from the pages on the primary domain (example.com).\nNote\nDifferent language versions would be considered different sets of web pages.\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.\nweb page\na non-embedded resource obtained from a single URI using HTTP plus any other resources\n      that are used in the rendering or intended to be rendered together with it by a\nuser agent\nNote 1\nAlthough any \"other resources\" would be rendered together with the primary resource,\n      they would not necessarily be rendered simultaneously with each other.\nNote 2\nFor the purposes of conformance with these guidelines, a resource must be \"non-embedded\"\n      within the scope of conformance to be considered a web page.\nExample 1\nA web resource including all embedded images and media.\nExample 2\nA web mail program built using Asynchronous JavaScript and XML (AJAX). The program\n      lives entirely at http://example.com/mail, but includes an inbox, a contacts area\n      and a calendar. Links or buttons are provided that cause the inbox, contacts, or calendar\n      to display, but do not change the URI of the page as a whole.\nExample 3\nA customizable portal site, where users can choose content to display from a set of\n      different content modules.\nExample 4\nWhen you enter \"http://shopping.example.com/\" in your browser, you enter a movie-like\n      interactive shopping environment where you visually move around in a store dragging\n      products off of the shelves around you and into a visual shopping cart in front of\n      you. Clicking on a product causes it to be demonstrated with a specification sheet\n      floating alongside. This might be a single-page website or just one page within a\n      website.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.5_sufficient",
    "type": "sc_sufficient",
    "sc_id": "2.4.5",
    "techniques": [
      "G125",
      "G125",
      "G64",
      "G63",
      "G161",
      "G126",
      "G185"
    ],
    "text": "[2.4.5 Multiple Ways] (Level AA)\nDescription: More than one way is available to locate a web page within a set of web pages except where the web page is the result of, or a step in, a process.\n\nSufficient techniques for SC 2.4.5 (no situation): G125, G125, G64, G63, G161, G126, G185",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.5_advisory",
    "type": "sc_advisory",
    "sc_id": "2.4.5",
    "techniques": [
      "PDF2"
    ],
    "text": "[2.4.5 Multiple Ways] (Level AA)\nDescription: More than one way is available to locate a web page within a set of web pages except where the web page is the result of, or a step in, a process.\n\nAdvisory techniques for SC 2.4.5: PDF2",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.6_intent",
    "type": "sc",
    "sc_id": "2.4.6",
    "section": "intent",
    "text": "[2.4.6 Headings and Labels] (Level AA)\nDescription: Headings and labels describe topic or purpose.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to help users understand what information\n         is contained in web pages and how that information is organized. When headings are\n         clear and descriptive, users can find the information they seek more easily, and they\n         can understand the relationships between different parts of the content more easily.\n         Descriptive labels help users identify specific components within the content.\nLabels and headings do not need to be lengthy. A word, or even a single character,\n         may suffice if it provides an appropriate cue to finding and navigating content.\nLabels of form controls are usually text-based. In some cases, images can serve as descriptive labels without additional text. In these cases, authors should ensure that the image and its use as a label (in context) are widely understood.\nNote that the same image can be interpreted differently in different contexts. However, it can still be considered descriptive if its use is commonly understood in each context. For example, when accompanying a text field, a loupe or magnifying glass icon with text alternative of \"Search\" is commonly interpreted as indicating the field is for entering and submitting a search query.\nPlaced on or near another image, a loupe or magnifying glass icon is commonly interpreted as a means to view a magnified version of the image (for instance, acting as a mechanism to zoom into the image, or opening a full-sized image in a new window).\nThis success criterion requires that if headings or labels are provided, they be descriptive. This success criterion does not require headings or labels; labels for inputs are covered separately by\n3.3.2 Labels or Instructions\n.  This success criterion also\n         does not require that content acting as a heading or label be correctly marked up or\n         identified — that aspect is covered separately by\n1.3.1: Info and Relationships\n. It is possible for content\n         to pass this success criterion (providing descriptive content that acts as headings or labels) while failing\n         Success Criterion 1.3.1 (if the headings or labels aren't correctly marked up/identified). Conversely,\n         it is also possible for content to pass Success Criterion 1.3.1 (with headings or labels correctly\n         marked up or identified), while failing this success criterion (if those headings or labels are inaccurate or insufficiently clear).\nFurther, in the case of labels, this success criterion does not take into consideration whether or not\n         alternative methods of providing an accessible name for form controls and inputs have been\n         used — that aspect is covered separately by\n4.1.2: Name, Role and Value\n. It is possible\n         for controls and inputs to have an appropriate accessible name (e.g. using\naria-label=\"…\"\n)\n         and therefore pass Success Criterion 4.1.2, but to still fail this success criterion (if the label is inaccurate or insufficiently clear or descriptive).\nThis success criterion does not require the use of labels; however, it does require that if labels are present, they must be accurate and sufficiently clear or descriptive. Please see\n3.3.2: Labels or Instructions\nfor more information on the use of labels.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.6_success_criterion",
    "type": "sc",
    "sc_id": "2.4.6",
    "section": "success_criterion",
    "text": "[2.4.6 Headings and Labels] (Level AA)\nDescription: Headings and labels describe topic or purpose.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nHeadings and\nlabels\ndescribe topic or purpose.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.6_benefits",
    "type": "sc",
    "sc_id": "2.4.6",
    "section": "benefits",
    "text": "[2.4.6 Headings and Labels] (Level AA)\nDescription: Headings and labels describe topic or purpose.\n\nSection: benefits\n\nBenefits\nDescriptive headings are especially helpful for users who have disabilities that make\n            reading slow and for people with limited short-term memory. These people benefit when\n            section titles make it possible to predict what each section contains.\nForm input controls with labels that clearly and accurately describe the content that is expected to be\n            entered helps users know how to successfully complete the form.\nWhen headings and labels are also correctly marked up and identified in accordance with\n1.3.1: Info and Relationships\n, this success criterion\n            helps people who use screen readers by ensuring that labels and headings are clearer when\n            presented in a different format — for example, in an automatically generated list of\n            headings, a table of contents, or when jumping from heading to heading within a page.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.6_examples",
    "type": "sc",
    "sc_id": "2.4.6",
    "section": "examples",
    "text": "[2.4.6 Headings and Labels] (Level AA)\nDescription: Headings and labels describe topic or purpose.\n\nSection: examples\n\nExamples\nA news site\nThe home page of a news site lists the headlines for the top stories of the hour.\n               Under each heading are the first 35 words of the story and a link to the full article.\n               Each headline gives a clear and accurate idea of the article's subject.\nA guide on how to write well\nA guide on writing contains the following section titles:\nHow To Write Well\n,\nCut Out Useless Words\n,\nIdentify Unnecessary Words\n, and so on.\n               The section headings are clear and concise and the structure of the information is\n               accurately reflected in the structure of the headings.\nConsistent headings in different articles\nA website contains papers from a conference. Submissions to the conference are required\n               to have the following organization:\nSummary\n,\nIntroduction\n, [other sections unique\n               to this article],\nConclusion\n,\nAuthor Biography\n,\nGlossary\n, and\nBibliography\n.\n               The title of each web page clearly identifies the article it contains, creating a useful balance\n               between the uniqueness of the articles and the consistency of the section headings.\nA form asking for the name of the user\nA form asks for the name of the user. It consists of two input fields to ask for the first\n               and last name. The first field is labeled\nFirst name\n, the second is labeled\nLast name\n.\nA search field labeled by a magnifying glass icon\nA search text input is followed by a button containing a magnifying glass icon that activates the search function. \n               The icon has the string \"search\" as programmatically determinable label.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.6_brief",
    "type": "sc",
    "sc_id": "2.4.6",
    "section": "brief",
    "text": "[2.4.6 Headings and Labels] (Level AA)\nDescription: Headings and labels describe topic or purpose.\n\nSection: brief\n\nIn Brief\nGoal\nA page's content is described in headings and labels\nWhat to do\nProvide descriptive headings and labels\nWhy it's important\nPeople can orient themselves, especially those with cognitive or visual disabilities.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.6_resources",
    "type": "sc",
    "sc_id": "2.4.6",
    "section": "resources",
    "text": "[2.4.6 Headings and Labels] (Level AA)\nDescription: Headings and labels describe topic or purpose.\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nHow Users Read on the Web\nA study showing that most users scan web pages rather than reading them word by word.\nApplying Writing Guidelines to Web Pages\nA report on the effects of making websites concise, easy to scan, and objective.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.6_test_rules",
    "type": "sc",
    "sc_id": "2.4.6",
    "section": "test_rules",
    "text": "[2.4.6 Headings and Labels] (Level AA)\nDescription: Headings and labels describe topic or purpose.\n\nSection: test_rules\n\nTest Rules\nThe following are Test Rules\n    for certain aspects of this Success Criterion.\n    It is not necessary to use these particular Test Rules to check for conformance with WCAG, but they are defined and approved test methods.\n    For information on using Test Rules, see\nUnderstanding Test Rules for WCAG Success Criteria\n.\nForm field label is descriptive\nHeading is descriptive",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.6_key_terms",
    "type": "sc",
    "sc_id": "2.4.6",
    "section": "key_terms",
    "text": "[2.4.6 Headings and Labels] (Level AA)\nDescription: Headings and labels describe topic or purpose.\n\nSection: key_terms\n\nKey Terms\nASCII art\npicture created by a spatial arrangement of characters or glyphs (typically from the\n      95 printable characters defined by ASCII)\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\ncontent\ninformation and sensory experience to be communicated to the user by means of a\nuser agent\n, including code or markup that defines the content's\nstructure\n,\npresentation\n, and interactions\nhuman language\nlanguage that is spoken, written or signed (through visual or tactile means) to communicate\n      with humans\nNote\nSee also\nsign language\n.\nlabel\ntext\nor other component with a\ntext alternative\nthat is presented to a user to identify a component within web\ncontent\nNote 1\nA label is presented to all users whereas the\nname\nmay be hidden and only exposed by assistive technology. In many (but not all) cases\n      the name and the label are the same.\nNote 2\nThe term label is not limited to the label element in HTML.\nname\ntext by which software can identify a component within web content to the user\nNote 1\nThe name may be hidden and only exposed by assistive technology, whereas a\nlabel\nis presented to all users. In many (but not all) cases, the label and the name are\n      the same.\nNote 2\nThis is unrelated to the name attribute in HTML.\nnon-text content\nany content that is not a sequence of characters that can be\nprogrammatically determined\nor where the sequence is not expressing something in\nhuman language\nNote\nThis includes\nASCII art\n(which is a pattern of characters), emoticons, leetspeak (which uses character substitution),\n      and images representing text\npresentation\nrendering of the\ncontent\nin a form to be perceived by users\nprogrammatically determined\ndetermined by software from author-supplied data provided in a way that different\nuser agents\n, including\nassistive technologies\n, can extract and present this information to users in different modalities\nExample 1\nDetermined in a markup language from elements and attributes that are accessed directly\n      by commonly available assistive technology.\nExample 2\nDetermined from technology-specific data structures in a non-markup language and exposed\n      to assistive technology via an accessibility API that is supported by commonly available\n      assistive technology.\nsign language\na language using combinations of movements of the hands and arms, facial expressions,\n      or body positions to convey meaning\nstructure\nThe way the parts of a\nweb page\nare organized in relation to each other; and\nThe way a collection of\nweb pages\nis organized\ntext\nsequence of characters that can be\nprogrammatically determined\n, where the sequence is expressing something in\nhuman language\ntext alternative\nText\nthat is programmatically associated with\nnon-text content\nor referred to from text that is programmatically associated with non-text content.\n      Programmatically associated text is text whose location can be\nprogrammatically determined\nfrom the non-text content.\nExample\nAn image of a chart is described in text in the paragraph after the chart. The short\n      text alternative for the chart indicates that a description follows.\nNote\nRefer to\nUnderstanding Text Alternatives\nfor more information.\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.\nweb page\na non-embedded resource obtained from a single URI using HTTP plus any other resources\n      that are used in the rendering or intended to be rendered together with it by a\nuser agent\nNote 1\nAlthough any \"other resources\" would be rendered together with the primary resource,\n      they would not necessarily be rendered simultaneously with each other.\nNote 2\nFor the purposes of conformance with these guidelines, a resource must be \"non-embedded\"\n      within the scope of conformance to be considered a web page.\nExample 1\nA web resource including all embedded images and media.\nExample 2\nA web mail program built using Asynchronous JavaScript and XML (AJAX). The program\n      lives entirely at http://example.com/mail, but includes an inbox, a contacts area\n      and a calendar. Links or buttons are provided that cause the inbox, contacts, or calendar\n      to display, but do not change the URI of the page as a whole.\nExample 3\nA customizable portal site, where users can choose content to display from a set of\n      different content modules.\nExample 4\nWhen you enter \"http://shopping.example.com/\" in your browser, you enter a movie-like\n      interactive shopping environment where you visually move around in a store dragging\n      products off of the shelves around you and into a visual shopping cart in front of\n      you. Clicking on a product causes it to be demonstrated with a specification sheet\n      floating alongside. This might be a single-page website or just one page within a\n      website.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.6_sufficient",
    "type": "sc_sufficient",
    "sc_id": "2.4.6",
    "techniques": [
      "G130",
      "G131"
    ],
    "text": "[2.4.6 Headings and Labels] (Level AA)\nDescription: Headings and labels describe topic or purpose.\n\nSufficient techniques for SC 2.4.6 (no situation): G130, G131",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.7_intent",
    "type": "sc",
    "sc_id": "2.4.7",
    "section": "intent",
    "text": "[2.4.7 Focus Visible] (Level AA)\nDescription: Any keyboard operable user interface has a mode of operation where the keyboard focus indicator is visible.\n\nSection: intent\n\nIntent\nThe purpose of this success criterion is to help a person know which element has the\n         keyboard focus.\n“Mode of operation” accounts for user agents which may not always show a focus indicator, or only show the focus indicator when the keyboard is used. User agents may optimise when the focus indicator is shown, such as only showing it when a keyboard is used. Authors are responsible for providing at least one mode of operation where the focus is visible. In most cases there is only one mode of operation so this success criterion applies. The focus indicator must not be time limited, when the keyboard focus is shown it must remain.\nNote\nThere may be situations where mouse/pointer users could also benefit from having a visible focus indicator, even though they did not set focus to an element using the keyboard. As a best practice, consider still providing an explicit focus indicator for these cases.\nNote that a keyboard focus indicator can take different forms.\nNew in WCAG 2.2:\nWhile Focus Visible does not specify what that form is,\n2.4.13 Focus Appearance (Level AAA)\nprovides guidance on creating a consistent, visible indicator.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.7_success_criterion",
    "type": "sc",
    "sc_id": "2.4.7",
    "section": "success_criterion",
    "text": "[2.4.7 Focus Visible] (Level AA)\nDescription: Any keyboard operable user interface has a mode of operation where the keyboard focus indicator is visible.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nAny keyboard operable user interface has a mode of operation where the keyboard\nfocus indicator\nis visible.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.7_benefits",
    "type": "sc",
    "sc_id": "2.4.7",
    "section": "benefits",
    "text": "[2.4.7 Focus Visible] (Level AA)\nDescription: Any keyboard operable user interface has a mode of operation where the keyboard focus indicator is visible.\n\nSection: benefits\n\nBenefits\nThis success criterion helps anyone who relies on the keyboard to operate the page,\n            by letting them visually determine the component on which keyboard operations will\n            interact at any point in time.\nPeople with attention limitations, short term memory limitations, or limitations in\n            executive processes benefit by being able to discover where the focus is located.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.7_examples",
    "type": "sc",
    "sc_id": "2.4.7",
    "section": "examples",
    "text": "[2.4.7 Focus Visible] (Level AA)\nDescription: Any keyboard operable user interface has a mode of operation where the keyboard focus indicator is visible.\n\nSection: examples\n\nExamples\nWhen text fields receive focus, a vertical bar is displayed in the field, indicating\n            that the user can insert text, OR all of the text is highlighted, indicating that\n            the user can type over the text.\nWhen a user interface control receives focus, a visible border is displayed around\n            it.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.7_brief",
    "type": "sc",
    "sc_id": "2.4.7",
    "section": "brief",
    "text": "[2.4.7 Focus Visible] (Level AA)\nDescription: Any keyboard operable user interface has a mode of operation where the keyboard focus indicator is visible.\n\nSection: brief\n\nIn Brief\nGoal\nUsers know which element has keyboard focus.\nWhat to do\nEnsure each item receiving focus has a visible indicator.\nWhy it's important\nWithout a focus indicator, sighted keyboard users cannot operate the page.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.7_resources",
    "type": "sc",
    "sc_id": "2.4.7",
    "section": "resources",
    "text": "[2.4.7 Focus Visible] (Level AA)\nDescription: Any keyboard operable user interface has a mode of operation where the keyboard focus indicator is visible.\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nStyling form controls with CSS, revisited",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.7_test_rules",
    "type": "sc",
    "sc_id": "2.4.7",
    "section": "test_rules",
    "text": "[2.4.7 Focus Visible] (Level AA)\nDescription: Any keyboard operable user interface has a mode of operation where the keyboard focus indicator is visible.\n\nSection: test_rules\n\nTest Rules\nThe following are Test Rules\n    for certain aspects of this Success Criterion.\n    It is not necessary to use these particular Test Rules to check for conformance with WCAG, but they are defined and approved test methods.\n    For information on using Test Rules, see\nUnderstanding Test Rules for WCAG Success Criteria\n.\nElement in sequential focus order has visible focus",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.7_key_terms",
    "type": "sc",
    "sc_id": "2.4.7",
    "section": "key_terms",
    "text": "[2.4.7 Focus Visible] (Level AA)\nDescription: Any keyboard operable user interface has a mode of operation where the keyboard focus indicator is visible.\n\nSection: key_terms\n\nKey Terms\nfocus indicator\npixels that are changed to visually indicate when a\nuser interface component\nis in a focused\nstate\nstate\ndynamic property expressing characteristics of a\nuser interface component\nthat may change in response to user action or automated processes\nStates do not affect the nature of the component, but represent data associated with the component or user interaction possibilities. Examples include focus, hover, select, press, check, visited/unvisited, and expand/collapse.\nuser interface component\na part of the content that is perceived by users as a single control for a distinct\n      function\nNote 1\nMultiple user interface components may be implemented as a single programmatic element.\n      \"Components\" here is not tied to programming techniques, but rather to what the user\n      perceives as separate controls.\nNote 2\nUser interface components include form elements and links as well as components generated\n      by scripts.\nNote 3\nWhat is meant by \"component\" or \"user interface component\" here is also sometimes\n      called \"user interface element\".\nExample\nAn applet has a \"control\" that can be used to move through content by line or page\n      or random access. Since each of these would need to have a name and be settable independently,\n      they would each be a \"user interface component.\"",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.7_sufficient",
    "type": "sc_sufficient",
    "sc_id": "2.4.7",
    "techniques": [
      "G149",
      "C15",
      "G165",
      "G195",
      "C40",
      "C45",
      "SCR31"
    ],
    "text": "[2.4.7 Focus Visible] (Level AA)\nDescription: Any keyboard operable user interface has a mode of operation where the keyboard focus indicator is visible.\n\nSufficient techniques for SC 2.4.7 (no situation): G149, C15, G165, G195, C40, C45, SCR31",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.7_failures",
    "type": "sc_failures",
    "sc_id": "2.4.7",
    "techniques": [
      "F55",
      "F78"
    ],
    "text": "[2.4.7 Focus Visible] (Level AA)\nDescription: Any keyboard operable user interface has a mode of operation where the keyboard focus indicator is visible.\n\nCommon failures for SC 2.4.7: F55, F78",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.8_intent",
    "type": "sc",
    "sc_id": "2.4.8",
    "section": "intent",
    "text": "[2.4.8 Location] (Level AAA)\nDescription: Information about the user's location within a set of web pages is available.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to provide a way for the user to orient herself\n         within a set of web pages, a website, or a web application and find related information.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.8_success_criterion",
    "type": "sc",
    "sc_id": "2.4.8",
    "section": "success_criterion",
    "text": "[2.4.8 Location] (Level AAA)\nDescription: Information about the user's location within a set of web pages is available.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nInformation about the user's location within a\nset of web pages\nis available.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.8_benefits",
    "type": "sc",
    "sc_id": "2.4.8",
    "section": "benefits",
    "text": "[2.4.8 Location] (Level AAA)\nDescription: Information about the user's location within a set of web pages is available.\n\nSection: benefits\n\nBenefits\nThis success criterion is helpful for people with a short attention span who may become\n            confused when following a long series of navigation steps to a web page. It is also\n            helpful when a user follows a link directly to a page deep within a set of web pages\n            and needs to navigate that website to understand the content of that page or to find\n            more related information.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.8_examples",
    "type": "sc",
    "sc_id": "2.4.8",
    "section": "examples",
    "text": "[2.4.8 Location] (Level AAA)\nDescription: Information about the user's location within a set of web pages is available.\n\nSection: examples\n\nExamples\nLinks to help user determine their location in a site\nA research group is part of an educational department at a university. The group's\n               home page links to the department home page and the university's home page.\nA breadcrumb trail\nA portal website organizes topics into categories. As the user navigates through\n               categories and subcategories, a breadcrumb trail shows the current location in the\n               hierarchy of categories. Each page also contains a link to the portal home page.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.8_brief",
    "type": "sc",
    "sc_id": "2.4.8",
    "section": "brief",
    "text": "[2.4.8 Location] (Level AAA)\nDescription: Information about the user's location within a set of web pages is available.\n\nSection: brief\n\nIn Brief\nGoal\nUsers know where they are in a set of pages.\nWhat to do\nUse breadcrumbs, site maps, or other indicators to give context.\nWhy it's important\nLocation indicators reduce confusion for people with cognitive disabilities.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.8_resources",
    "type": "sc",
    "sc_id": "2.4.8",
    "section": "resources",
    "text": "[2.4.8 Location] (Level AAA)\nDescription: Information about the user's location within a set of web pages is available.\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nThe Sound of the Accessible Title Tag Separator",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.8_key_terms",
    "type": "sc",
    "sc_id": "2.4.8",
    "section": "key_terms",
    "text": "[2.4.8 Location] (Level AAA)\nDescription: Information about the user's location within a set of web pages is available.\n\nSection: key_terms\n\nKey Terms\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\nset of web pages\ncollection of\nweb pages\nthat share a common purpose and that are created by the same author, group or organization\nExample\nExamples include:\na publication which is split across multiple web pages, where each page contains one chapter or other significant section of the work. The publication is logically a single contiguous unit, and contains navigation features that enable access to the full set of pages.\nan e-commerce website shows products in a set of web pages that all share the same navigation and identification. However, when progressing to the checkout process, the template changes; the navigation and other elements are removed, so the pages in that process are functionally and visually different. The checkout pages are not part of the set of product pages.\na blog on a sub-domain (e.g. blog.example.com) which has a different navigation and is authored by a distinct set of people from the pages on the primary domain (example.com).\nNote\nDifferent language versions would be considered different sets of web pages.\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.\nweb page\na non-embedded resource obtained from a single URI using HTTP plus any other resources\n      that are used in the rendering or intended to be rendered together with it by a\nuser agent\nNote 1\nAlthough any \"other resources\" would be rendered together with the primary resource,\n      they would not necessarily be rendered simultaneously with each other.\nNote 2\nFor the purposes of conformance with these guidelines, a resource must be \"non-embedded\"\n      within the scope of conformance to be considered a web page.\nExample 1\nA web resource including all embedded images and media.\nExample 2\nA web mail program built using Asynchronous JavaScript and XML (AJAX). The program\n      lives entirely at http://example.com/mail, but includes an inbox, a contacts area\n      and a calendar. Links or buttons are provided that cause the inbox, contacts, or calendar\n      to display, but do not change the URI of the page as a whole.\nExample 3\nA customizable portal site, where users can choose content to display from a set of\n      different content modules.\nExample 4\nWhen you enter \"http://shopping.example.com/\" in your browser, you enter a movie-like\n      interactive shopping environment where you visually move around in a store dragging\n      products off of the shelves around you and into a visual shopping cart in front of\n      you. Clicking on a product causes it to be demonstrated with a specification sheet\n      floating alongside. This might be a single-page website or just one page within a\n      website.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.8_sufficient",
    "type": "sc_sufficient",
    "sc_id": "2.4.8",
    "techniques": [
      "G65",
      "G63",
      "G128",
      "G127"
    ],
    "text": "[2.4.8 Location] (Level AAA)\nDescription: Information about the user's location within a set of web pages is available.\n\nSufficient techniques for SC 2.4.8 (no situation): G65, G63, G128, G127",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.8_advisory",
    "type": "sc_advisory",
    "sc_id": "2.4.8",
    "techniques": [
      "PDF14",
      "PDF17"
    ],
    "text": "[2.4.8 Location] (Level AAA)\nDescription: Information about the user's location within a set of web pages is available.\n\nAdvisory techniques for SC 2.4.8: PDF14, PDF17",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.9_intent",
    "type": "sc",
    "sc_id": "2.4.9",
    "section": "intent",
    "text": "[2.4.9 Link Purpose (Link Only)] (Level AAA)\nDescription: A mechanism is available to allow the purpose of each link to be identified from link text alone,\n      except where the purpose of the link would be ambiguous to users in general.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to help users understand the purpose of each\n         link in the content, so they can decide whether they want to follow it. Best practice\n         is that links with the same destination would have the same descriptions, but links\n         with different purposes and destinations would have different descriptions (see also\nSuccess Criterion 3.2.4\nwhich calls for consistency in identifying components that have the same functionality).\n         Because the purpose of a link can be identified from its link text, links can be understood\n         when they are out of context, such as when the user agent provides a list of all the\n         links on a page.\nThe text in the link is intended to describe the purpose of the link. In cases where\n         the link takes one to a document or a web application, the name of the document or\n         web application would be sufficient to describe the purpose of the link (which is\n         to take you to the document or web application). Note that it is not required to use\n         the name of the document or web application; other things may also describe the purpose\n         of the link.\nSuccess Criterion 2.4.2\ndeals with the titles of pages. Here also, the name of a document or web application\n         being presented on the page would be sufficient to describe the purpose of the page.\n         Having the link and the title agree, or be very similar, is good practice and provides\n         continuity between the link 'clicked on' and the web page that the user lands on.\nThe success criterion includes an exception for links for which the purpose of the\n         link cannot be determined from the information on the web page. In this situation,\n         the person with the disability is not at a disadvantage; there is no additional context\n         available to understand the link purpose. However, whatever amount of context is available\n         on the web page that can be used to interpret the purpose of the link must be made\n         available in the link text to satisfy the success criterion.\nThe word \"mechanism\" is used to allow authors to either make all links fully understandable\n         out of context by default or to provide a way to make them this way. This is done\n         because for some pages, making the links all unambiguous by themselves makes the pages\n         easier for some users and harder for others. Providing the ability to make the links\n         unambiguous (by them selves) or not provides both users with disabilities with the\n         ability to use the page in the format that best meets their needs.\nFor example: A page listing 100 book titles along with links to download the books\n         in HTML, PDF, DOC, TXT, MP3, or AAC might ordinarily be viewed as the title of the\n         book as a link with the words \"in HTML\" after it. then the sentence \"Also available\n         in: \" followed by a series of short links with text of \"HTML\", \"PDF\", \"DOC\", \"TXT\",\n         \"MP3\", and \"AAC\". At Level 3, some users could opt to view the page this way - because\n         they would find the page harder to understand or slower to use if the full title of\n         the book were included in each of the links. Others could opt to view the page with\n         the full title as part of each of the links so that each link was understandable in\n         itself. Both the former and the latter groups could include people with visual or\n         cognitive disabilities that used different techniques to browse or that had different\n         types or severities of disability.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.9_success_criterion",
    "type": "sc",
    "sc_id": "2.4.9",
    "section": "success_criterion",
    "text": "[2.4.9 Link Purpose (Link Only)] (Level AAA)\nDescription: A mechanism is available to allow the purpose of each link to be identified from link text alone,\n      except where the purpose of the link would be ambiguous to users in general.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nA\nmechanism\nis available to allow the\npurpose of each link\nto be identified from link text alone,\n      except where the purpose of the link would be\nambiguous to users in general\n.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.9_benefits",
    "type": "sc",
    "sc_id": "2.4.9",
    "section": "benefits",
    "text": "[2.4.9 Link Purpose (Link Only)] (Level AAA)\nDescription: A mechanism is available to allow the purpose of each link to be identified from link text alone,\n      except where the purpose of the link would be ambiguous to users in general.\n\nSection: benefits\n\nBenefits\nThis success criterion helps people with motion impairment by letting them skip Web\n            pages that they are not interested in, avoiding the keystrokes needed to visit the\n            referenced content and then return to the current content.\nPeople with cognitive limitations will not become disoriented by extra navigation\n            to and from content they are not interested in.\nPeople with visual disabilities will benefit from not losing their place in the content\n            when they return to the original page. The screen reader's list of links is more useful\n            for finding information because the target of the links are described.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.9_examples",
    "type": "sc",
    "sc_id": "2.4.9",
    "section": "examples",
    "text": "[2.4.9 Link Purpose (Link Only)] (Level AAA)\nDescription: A mechanism is available to allow the purpose of each link to be identified from link text alone,\n      except where the purpose of the link would be ambiguous to users in general.\n\nSection: examples\n\nExamples\nBoth an icon and text are included in the same link\nAn icon of a voting machine and the text \"Government of Ireland's Commission of Electronic\n               Voting\" are combined to make a single link.\nA list of book titles\nA list of books is available in three formats: HTML, PDF, and mp3 (a recording of\n               a person reading the book). The title of the book is followed by links to the different\n               formats. The rendered text for each link is just the format type, but the text associated\n               with each link includes the title as well as the format; for instance, \"Gulliver's\n               Travels, MP3.\"",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.9_brief",
    "type": "sc",
    "sc_id": "2.4.9",
    "section": "brief",
    "text": "[2.4.9 Link Purpose (Link Only)] (Level AAA)\nDescription: A mechanism is available to allow the purpose of each link to be identified from link text alone,\n      except where the purpose of the link would be ambiguous to users in general.\n\nSection: brief\n\nIn Brief\nGoal\nUsers understand what each link will do.\nWhat to do\nProvide descriptive names for all links.\nWhy it's important\nDescriptive link text is more understandable for all users, especially when using assistive technology.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.9_resources",
    "type": "sc",
    "sc_id": "2.4.9",
    "section": "resources",
    "text": "[2.4.9 Link Purpose (Link Only)] (Level AAA)\nDescription: A mechanism is available to allow the purpose of each link to be identified from link text alone,\n      except where the purpose of the link would be ambiguous to users in general.\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nUsing Link Titles to Help Users Predict Where They Are Going\nWebAIM Techniques for Hypertext Links",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.9_test_rules",
    "type": "sc",
    "sc_id": "2.4.9",
    "section": "test_rules",
    "text": "[2.4.9 Link Purpose (Link Only)] (Level AAA)\nDescription: A mechanism is available to allow the purpose of each link to be identified from link text alone,\n      except where the purpose of the link would be ambiguous to users in general.\n\nSection: test_rules\n\nTest Rules\nThe following are Test Rules\n    for certain aspects of this Success Criterion.\n    It is not necessary to use these particular Test Rules to check for conformance with WCAG, but they are defined and approved test methods.\n    For information on using Test Rules, see\nUnderstanding Test Rules for WCAG Success Criteria\n.\nLink has non-empty accessible name\nLink in context is descriptive\nLink is descriptive\nLinks with identical accessible names and same context serve equivalent purpose\nLinks with identical accessible names have equivalent purpose",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.9_key_terms",
    "type": "sc",
    "sc_id": "2.4.9",
    "section": "key_terms",
    "text": "[2.4.9 Link Purpose (Link Only)] (Level AAA)\nDescription: A mechanism is available to allow the purpose of each link to be identified from link text alone,\n      except where the purpose of the link would be ambiguous to users in general.\n\nSection: key_terms\n\nKey Terms\nambiguous to users in general\nthe purpose cannot be determined from the link and all information of the web page\n      presented to the user simultaneously with the link (i.e., readers without disabilities\n      would not know what a link would do until they activated it)\nExample\nThe word guava in the following sentence \"One of the notable exports is guava\" is\n      a link. The link could lead to a definition of guava, a chart listing the quantity\n      of guava exported or a photograph of people harvesting guava. Until the link is activated,\n      all readers are unsure and the person with a disability is not at any disadvantage.\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\nconformance\nsatisfying all the requirements of a given standard, guideline or specification\nlink purpose\nnature of the result obtained by activating a hyperlink\nmechanism\nprocess\nor technique for achieving a result\nNote 1\nThe mechanism may be explicitly provided in the content, or may be\nrelied upon\nto be provided by either the platform or by\nuser agents\n, including\nassistive technologies\n.\nNote 2\nThe mechanism needs to meet all success criteria for the conformance level claimed.\nprocess\nseries of user actions where each action is required in order to complete an activity\nExample 1\nSuccessful use of a series of web pages on a shopping site requires users to view\n      alternative products, prices and offers, select products, submit an order, provide\n      shipping information and provide payment information.\nExample 2\nAn account registration page requires successful completion of a\nTuring test\nbefore\n      the registration form can be accessed.\nrelied upon\nthe content would not\nconform\nif that\ntechnology\nis turned off or is not supported\ntechnology\nmechanism\nfor encoding instructions to be rendered, played or executed by\nuser agents\nNote 1\nAs used in these guidelines \"web technology\" and the word \"technology\" (when used\n      alone) both refer to web content technologies.\nNote 2\nWeb content technologies may include markup languages, data formats, or programming\n      languages that authors may use alone or in combination to create end-user experiences\n      that range from static web pages to synchronized media presentations to dynamic Web\n      applications.\nExample\nSome common examples of web content technologies include HTML, CSS, SVG, PNG, PDF,\n      Flash, and JavaScript.\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.9_sufficient",
    "type": "sc_sufficient",
    "sc_id": "2.4.9",
    "techniques": [
      "ARIA8",
      "G91",
      "H30",
      "H24",
      "G189",
      "G189",
      "SCR30",
      "C7",
      "C7",
      "PDF11",
      "PDF11",
      "PDF13"
    ],
    "text": "[2.4.9 Link Purpose (Link Only)] (Level AAA)\nDescription: A mechanism is available to allow the purpose of each link to be identified from link text alone,\n      except where the purpose of the link would be ambiguous to users in general.\n\nSufficient techniques for SC 2.4.9 (no situation): ARIA8, G91, H30, H24, G189, G189, SCR30, C7, C7, PDF11, PDF11, PDF13",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.9_advisory",
    "type": "sc_advisory",
    "sc_id": "2.4.9",
    "techniques": [
      "H2",
      "H33"
    ],
    "text": "[2.4.9 Link Purpose (Link Only)] (Level AAA)\nDescription: A mechanism is available to allow the purpose of each link to be identified from link text alone,\n      except where the purpose of the link would be ambiguous to users in general.\n\nAdvisory techniques for SC 2.4.9: H2, H33",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.9_failures",
    "type": "sc_failures",
    "sc_id": "2.4.9",
    "techniques": [
      "F84",
      "F89"
    ],
    "text": "[2.4.9 Link Purpose (Link Only)] (Level AAA)\nDescription: A mechanism is available to allow the purpose of each link to be identified from link text alone,\n      except where the purpose of the link would be ambiguous to users in general.\n\nCommon failures for SC 2.4.9: F84, F89",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.10_intent",
    "type": "sc",
    "sc_id": "2.4.10",
    "section": "intent",
    "text": "[2.4.10 Section Headings] (Level AAA)\nDescription: Section headings are used to organize the content.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to provide headings for sections of a Web\n         page, when the page is organized into sections. For instance, long documents are often\n         divided into a variety of chapters, chapters have subtopics, etc. When such sections exist,\n         they need to have headings that introduce them. This clearly indicates the organization\n         of the content, facilitates navigation within the content, and provides mental \"handles\"\n         that aid in comprehension of the content. Other page elements may complement headings\n         to improve presentation (e.g., horizontal rules and boxes), but visual presentation\n         is not sufficient to identify document sections.\nThis provision is included at Level AAA because it cannot be applied to all types\n         of content and it may not always be possible to insert headings. For example, when\n         posting a pre-existing document to the Web, headings that an author did not include\n         in the original document cannot be inserted. Or, a long letter would often cover different\n         topics, but putting headings into a letter would be very strange. However, if a document\n         can be broken up into sections with headings, it facilitates both understanding and\n         navigation.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.10_success_criterion",
    "type": "sc",
    "sc_id": "2.4.10",
    "section": "success_criterion",
    "text": "[2.4.10 Section Headings] (Level AAA)\nDescription: Section headings are used to organize the content.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nSection\nheadings are used to organize the content.\nNote 1\n\"Heading\" is used in its general sense and includes titles and other ways to add a\n      heading to different types of content.\nNote 2\nThis success criterion covers sections within writing, not\nuser interface components\n. User interface components are covered under\nSuccess Criterion 4.1.2\n.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.10_benefits",
    "type": "sc",
    "sc_id": "2.4.10",
    "section": "benefits",
    "text": "[2.4.10 Section Headings] (Level AAA)\nDescription: Section headings are used to organize the content.\n\nSection: benefits\n\nBenefits\nPeople who are blind will know when they have moved from one section of a web page\n            to another and will know the purpose of each section.\nPeople with some learning disabilities will be able to use the headings to understand\n            the overall organization of the page content more easily.\nPeople who navigate content by keyboard will be able to jump the focus from heading\n            to heading, enabling them to find quickly content of interest.\nIn pages where content in part of the page updates, headings can be used to quickly\n            access updated content.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.10_examples",
    "type": "sc",
    "sc_id": "2.4.10",
    "section": "examples",
    "text": "[2.4.10 Section Headings] (Level AAA)\nDescription: Section headings are used to organize the content.\n\nSection: examples\n\nExamples\nA menu contains different sections for different courses. Each section has a heading:\n            Appetizers, Salad, Soup, Entree, Dessert.\nA web application contains a settings page that is divided into groups of related\n            settings. Each section contains a heading describing the class of settings.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.10_brief",
    "type": "sc",
    "sc_id": "2.4.10",
    "section": "brief",
    "text": "[2.4.10 Section Headings] (Level AAA)\nDescription: Section headings are used to organize the content.\n\nSection: brief\n\nIn Brief\nGoal\nUsers understand how content is organized in sections.\nWhat to do\nWhere content is organized in sections, provide section headings.\nWhy it's important\nPeople can orient themselves, especially those with cognitive or visual disabilities.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.10_resources",
    "type": "sc",
    "sc_id": "2.4.10",
    "section": "resources",
    "text": "[2.4.10 Section Headings] (Level AAA)\nDescription: Section headings are used to organize the content.\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nWebAIM: Semantic Structure\nHeading Tags",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.10_key_terms",
    "type": "sc",
    "sc_id": "2.4.10",
    "section": "key_terms",
    "text": "[2.4.10 Section Headings] (Level AAA)\nDescription: Section headings are used to organize the content.\n\nSection: key_terms\n\nKey Terms\nsection\na self-contained portion of written content that deals with one or more related topics\n      or thoughts\nNote\nA section may consist of one or more paragraphs and include graphics, tables, lists\n      and sub-sections.\nuser interface component\na part of the content that is perceived by users as a single control for a distinct\n      function\nNote 1\nMultiple user interface components may be implemented as a single programmatic element.\n      \"Components\" here is not tied to programming techniques, but rather to what the user\n      perceives as separate controls.\nNote 2\nUser interface components include form elements and links as well as components generated\n      by scripts.\nNote 3\nWhat is meant by \"component\" or \"user interface component\" here is also sometimes\n      called \"user interface element\".\nExample\nAn applet has a \"control\" that can be used to move through content by line or page\n      or random access. Since each of these would need to have a name and be settable independently,\n      they would each be a \"user interface component.\"",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.11_intent",
    "type": "sc",
    "sc_id": "2.4.11",
    "section": "intent",
    "text": "[2.4.11 Focus Not Obscured (Minimum)] (Level AA)\nDescription: New\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to ensure that the item receiving keyboard focus is always partially visible in the user's viewport. For sighted people who rely on a keyboard (or on a device that operates through the keyboard interface, such as a switch or voice input), knowing the current point of focus is critical. The component with focus signals the interaction point on the page. Where users cannot see the item with focus, they may not know how to proceed, or may even think the system has become unresponsive.\nIn recognition of the complex responsive designs common today, this AA criterion allows for the component receiving focus to be\npartially\nobscured by other author-created content. A partly obscured component can still be very visible, although the more of it that is obscured, the less easy it is to see. For that reason, authors should attempt to design interactions to reduce the degree and frequency with which the item receiving focus is partly obscured. For best visibility,\nnone\nof the component receiving focus should be obscured. This preferred outcome is covered by the AAA criterion\nFocus Not Obscured (Enhanced)\n.\nTypical types of content that can overlap focused items are sticky footers, sticky headers, and non-modal dialogs. As a user tabs through the page, these layers of content can obscure the item receiving focus, along with its focus indicator.\nA notification implemented as sticky content, such as a cookie banner, will fail this success criterion if it entirely obscures a component receiving focus. Ways of passing include making the banner modal so the user has to dismiss the banner before navigating through the page, or using\nscroll padding\nso the banner does not overlap other content. Notifications that do not require user action could also meet this criterion by closing on loss of focus.\nAnother form of obscuring can occur where light boxes or other semi-opaque effects overlap the item with focus. While less than 100 percent opacity is not causing the component to be\nentirely obscured\n, such semi-opaque overlaps may cause a failure of\n1.4.11 Non-text Contrast\n. When a focus indicator can be covered by a semi-opaque component, the ability of the focus indicator to pass 1.4.11 should be evaluated (and pass) while the focus indicator is under the semi-opaque component. The intention in both situations is that the component receiving focus should never be obscured to the point a user cannot tell which item has focus.\nNote\nThis criterion evaluates the focused\ncomponent\n, rather than the focus\nindicator\n. The component itself does not include the focus indicator when checking that \"the component is not entirely hidden\" - unless the focus indicator is inside the component, or focus is indicated by a change to the component itself. Although users benefit from both the component and the focus indicator (if external to the component) not being obscured when tracking the focus, for the purposes of this criterion only checking the component provides a clearer metric. However, if the focus indicator is fully obscured, it would likely fail\n2.4.7 Focus Visible\n.\nUser-movable content\nThis SC contains a note regarding content that can be repositioned. If users can move content regions, then they can potentially position the movable content such that it obscures other content that may receive focus. In such a case, the author is only responsible for ensuring that the movable content\nin its initial position\ndoes not obscure the item receiving focus.\nThis note is intended to accommodate a common interaction in complex applications such as authoring tools, where the main editing region (also called a canvas) can be enhanced by displaying toolbars or other panels, which can be repositioned around the canvas. It is possible to design such toolbars so they do\nnot\nobscure focus. Authors are encouraged to do so, as well as pursue techniques which ensure equitable keyboard use of such toolbars. However, in recognition of the complexities involved in responsive design as well as in supporting the ability to transform the text size and spacing of content, only the starting position of such movable panels is assessed.\nUser-opened content\nThis SC contains a note regarding content that is opened or disclosed by the user. One example of such content is a menu button opened by a user that opens a list of choices over pre-existing content on the screen. Such content can obscure other information on the screen, but it does not obscure an item receiving keyboard focus, because the new content doesn't stay open through a change of focus. However, authors may create user-opened content that is intentionally designed to persist until closed by the user, such as a chat window. Such persistent content has the potential to fail Focus Not Obscured (Minimum). Various types are described in this section. All can be designed so that they pass this success criterion.\nThis section only applies to content that the user actively discloses. Content pre-positioned by the author (such as a sticky footer), or content that appears without direct user initiation, such as system warnings, must not prevent the item receiving focus from being immediately visible in the viewport. Also, this note is not intended to apply to disclosures that are by convention non-persistent. As discussed in the following sub-section, an open dropdown that does not close when no longer focused is not following this convention.\nNon-persistent opened information\nA number of components on the web open (or disclose) additional content (on activation or on focus) intended for immediate user interaction or information. This new content is often on top of other content, obscuring it. Examples of such components are menu items, select element items, combobox lists (and other dropdown items), date picker calendars, and tooltips. The common trait of all these components is that they are not expected to persist after being acted on or once they are no longer the primary point of user interaction. Such non-persistent disclosures do not fail this SC since they do not obscure the item with focus. However, if an author allows such components to\npersist\nafter the user has 1) activated one of the opened items or 2) moved the focus away from the triggering item and the additional content, it is at risk of failing this criterion by obscuring the item with focus.\nUser openable, persistent disclosures\nSome disclosure patterns provide a mechanism for the user to open additional content that remains open until intentionally closed by the user. Accordions are a simple example of such a pattern. Chatbots and expandable side navigation are more complex examples. All of these patterns can be implemented so they are not at risk of failing this SC. Some possible approaches are:\nWhen the additional content appears, it displaces existing content.\nAn accordion is an example of this. When an accordion is opened, the disclosed content shifts existing content further down the page. Since the new content does not obscure existing content, it cannot obscure the item with focus.\nWhen the additional content appears, existing content reflows.\nThe popout sidebar on the\nWCAG standard\nis an example of this pattern. When the side menu is activated, it opens a new section of information along the left side of the page. The main content area is reduced horizontally to accommodate the new content, and the existing content reflows to fit in the thinner space. As a result, there is no overlapping content between the two sections; the item receiving focus, whether in the left navigation or in the main content, will not be obscured by the other section.\nWhen the additional content is opened, it takes focus and the tab ring is constrained to the new content until it is dismissed.\nThis modality is somewhat like a dialog, in that a user cannot navigate beyond the opened content by keyboard without dismissing it first (typically by pressing Esc). However, unlike in a modal dialog, in some implementations a pointer user may be able to interact with content outside the opened section without dismissing it. Since this pattern potentially creates an inequitable experience between keyboard and pointer users, it should be used cautiously. That said, it does prevent the opened content from obscuring the keyboard focus in the main content, and thus should pass this SC. This is described and demonstrated in a short video in the Knowbility article in the reference section, under the section heading\nKeep keyboard focus in the slide-out navigation until it's closed\n.\nThe disclosure expands into an area of the page containing no other content.\nMany pages are designed with wide margins, providing significant white space into which new content can be opened. Many chatbots and toast notifications are designed to 'slide up' into the right unpopulated side of a page. Where authors are careful to ensure content is not obscured at each breakpoint in a responsive design, no obscuring of other operable content need occur.\nWhen focus leaves the additional content, the additional content is automatically hidden or collapsed, or the content can be hidden or collapsed by use of a dedicated keyboard command (for example, the\nEscape\nkey\n.) This is very similar to patterns discussed previously under Non-persistent opened information. A distinguishing factor can be that the user's last point of interaction in the disclosure is preserved (it persists) even though it may be hidden until a user returns. Some trees and side navigation patterns behave this way.\nIn recognition of more complex interfaces and user needs there is a note:\nContent opened by the user may obscure the component receiving focus\n. If the user can bring the item with focus into view using a method without having to navigate back to the user-opened content to dismiss it, this criterion would be passed. For example, keyboard actions that may allow the item with focus to be revealed include:\nusing the\nEscape\nkey to dismiss the obscuring content;\nusing keys to scroll the content in the viewport to reveal the item with focus;\nissuing a key to move between overlays.\nFor example:\nA user opens a chat interface, which is a popover non-modal dialog. This results in some content of the underlying page being fully obscured. The user navigates away from the chat interface by use of the\ntab\nkey, focusing onto a link that has been fully obscured by the dialog. The user presses the\nEscape\nkey to close the chat interface, which un-obscures the link.\nA user expands a fixed-position page feedback component at the bottom of a web page. They then use their keyboard to navigate to a link that's fully obscured by the expanded component and press the\ndown arrow\nor\nspace\nkey on their keyboard to scroll the content on the page, un-obscuring the link.\nA user opens a web-based multi-user authoring application. An overlay appears displaying a list of people who have contributed to the document. The user tabs through the list of contributors and activates one of them. The application displays a new overlay, which obscures the first one, that displays that person's recent contributions. The user presses the\nF6\nkey to toggle the stacking order of the two overlays.\nModal dialogs\nA properly constructed modal dialog will always pass this SC. Even if it appears directly on top of an item with focus, the dialog takes focus on appearance, and thus the item receiving focus -- the dialog or one of its components -- is visible. A properly constructed modal maintains that focus and prevents interaction outside the modal until it is dismissed.\nA dialog-like overlay that does not take focus on appearance and does not either constrain interaction to the overlay or dismiss itself on loss of focus (thus allowing focus to exit into the content behind it) will be at risk of failing this SC, where it is positioned such that it can obscure other focusable items.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.11_success_criterion",
    "type": "sc",
    "sc_id": "2.4.11",
    "section": "success_criterion",
    "text": "[2.4.11 Focus Not Obscured (Minimum)] (Level AA)\nDescription: New\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nWhen a\nuser interface component\nreceives keyboard focus, the component is not entirely hidden due to author-created content.\nNote 1\nWhere content in a configurable interface can be repositioned by the user, then only the initial positions of user-movable content are considered for testing and conformance of this success criterion.\nNote 2\nContent opened by the\nuser\nmay obscure the component receiving focus. If the user can reveal the focused component without advancing the keyboard focus, the component with focus is not considered visually hidden due to author-created content.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.11_benefits",
    "type": "sc",
    "sc_id": "2.4.11",
    "section": "benefits",
    "text": "[2.4.11 Focus Not Obscured (Minimum)] (Level AA)\nDescription: New\n\nSection: benefits\n\nBenefits\nSighted users who rely on a keyboard interface to operate the page will be able to see the component which gets keyboard focus. Such users include those who rely on a keyboard or on devices which use the keyboard interface, including speech input, sip-and-puff software, onscreen keyboards, scanning software, and a variety of assistive technologies and alternate keyboards.\nPeople with limited or low vision, who may primarily user a pointer for screen orientation and repositioning, nonetheless benefit from a visible indication of the current point of keyboard interaction, especially where magnification reduces the overall viewing portion of the screen.\nPeople with attention limitations, short term memory limitations, or limitations in executive processes benefit by being able to discover where the focus is located.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.11_examples",
    "type": "sc",
    "sc_id": "2.4.11",
    "section": "examples",
    "text": "[2.4.11 Focus Not Obscured (Minimum)] (Level AA)\nDescription: New\n\nSection: examples\n\nExamples\nA page has a sticky footer (attached to the bottom of the viewport). When tabbing down the page the focused item is not completely visually obscured by the footer because content in the viewport scrolls up to always display the item with keyboard focus using\nscroll padding\n.\nA page has a full-width cookie approval dialog. The dialog is modal, preventing access to the other controls in the page until it has been dismissed. Focus is not obscured because the major portion of the cookie approval dialog remains on screen (until selections are made and submitted),  and so the major portion of the keyboard focus indicator remains visible.\nA notification is implemented as a sticky header and the keyboard focus is moved to the notification so at least part of the focus indicator is in view. The notification disappears when it loses focus so it does not obscure any other controls, and part of the prior keyboard focus indicator is visible.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.11_brief",
    "type": "sc",
    "sc_id": "2.4.11",
    "section": "brief",
    "text": "[2.4.11 Focus Not Obscured (Minimum)] (Level AA)\nDescription: New\n\nSection: brief\n\nIn Brief\nGoal\nKeep the focused item visible.\nWhat to do\nEnsure when an item gets keyboard focus, it is at least partially visible.\nWhy it's important\nPeople who can't use a mouse need to see what has keyboard focus.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.11_resources",
    "type": "sc",
    "sc_id": "2.4.11",
    "section": "resources",
    "text": "[2.4.11 Focus Not Obscured (Minimum)] (Level AA)\nDescription: New\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nLet's Focus on Slide-Out Navigation",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.11_key_terms",
    "type": "sc",
    "sc_id": "2.4.11",
    "section": "key_terms",
    "text": "[2.4.11 Focus Not Obscured (Minimum)] (Level AA)\nDescription: New\n\nSection: key_terms\n\nKey Terms\nuser interface component\na part of the content that is perceived by users as a single control for a distinct\n      function\nNote 1\nMultiple user interface components may be implemented as a single programmatic element.\n      \"Components\" here is not tied to programming techniques, but rather to what the user\n      perceives as separate controls.\nNote 2\nUser interface components include form elements and links as well as components generated\n      by scripts.\nNote 3\nWhat is meant by \"component\" or \"user interface component\" here is also sometimes\n      called \"user interface element\".\nExample\nAn applet has a \"control\" that can be used to move through content by line or page\n      or random access. Since each of these would need to have a name and be settable independently,\n      they would each be a \"user interface component.\"",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.12_intent",
    "type": "sc",
    "sc_id": "2.4.12",
    "section": "intent",
    "text": "[2.4.12 Focus Not Obscured (Enhanced)] (Level AAA)\nDescription: New\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to ensure that the item receiving keyboard focus is always visible in the user's viewport. For sighted people who rely on a keyboard (or on a device that operates through the keyboard interface, such as a switch or voice input), knowing the current point of focus is critical. The component with focus signals the interaction point on the page. Where users cannot see the item with focus, they may not know how to proceed, or may even think the system has become unresponsive.\nTypical types of content that can overlap focused items are sticky footers, sticky headers, and non-modal dialogs. As a user tabs through the page, these layers of content can hide the item receiving focus, along with its focus indicator.\nA notification implemented as sticky content, such as a cookie banner, will fail this success criterion if it partially covers a component receiving focus. Ways of passing include making the banner modal so the user has to dismiss the banner before navigating through the page, or using\nscroll padding\nso the banner does not overlap other content. Notifications that do not require user action could also meet this criterion by closing on loss of focus.\nAnother form of obscuring can occur where light boxes or other semi-opaque effects overlap the item with focus. This form of obscuring is\nnot\nin scope for this success criterion. While less than 100 percent opacity is not causing the component to be\nvisually hidden\n, such semi-opaque overlaps may cause a failure of\n1.4.11 Non-text Contrast\nand/or\n2.4.13 Focus Appearance\n. When a focus indicator can be covered by a semi-opaque component, the focus indicator should be assessed against 1.4.11 and 2.4.13. The intention in both situations is that the component receiving focus should never be obscured to the point a user cannot tell which item has focus.\nNote\nThis criterion evaluates the focused\ncomponent\n, rather than the focus\nindicator\n. The component itself does not include the focus indicator when checking that \"no part of the component is hidden\" - unless the focus indicator is inside the component, or focus is indicated by a change to the component itself. Although users benefit from both the component and the focus indicator (if external to the component) not being obscured when tracking the focus, for the purposes of this criterion only checking the component provides a clearer metric. However, if the focus indicator is fully obscured, it would likely fail\n2.4.7 Focus Visible\n.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.12_success_criterion",
    "type": "sc",
    "sc_id": "2.4.12",
    "section": "success_criterion",
    "text": "[2.4.12 Focus Not Obscured (Enhanced)] (Level AAA)\nDescription: New\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nWhen a\nuser interface component\nreceives keyboard focus, no part of the component is hidden by author-created content.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.12_benefits",
    "type": "sc",
    "sc_id": "2.4.12",
    "section": "benefits",
    "text": "[2.4.12 Focus Not Obscured (Enhanced)] (Level AAA)\nDescription: New\n\nSection: benefits\n\nBenefits\nSighted users who rely on a keyboard interface to operate the page will be able to see the component which gets keyboard focus. Such users include those who rely on devices which use the keyboard interface, including speech input, sip-and-puff software, on-screen keyboards, scanning software, and a variety of assistive technologies and alternate keyboards.\nPeople with limited or low vision but who rely upon a pointing device (for viewport orientation and repositioning) benefit from a clearly visible indication of the current point of keyboard interaction, especially where magnification reduces the overall useable portion of content.\nPeople with attention limitations, short term memory limitations, or limitations in executive processes benefit by being able to more easily discover where the focus is located.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.12_examples",
    "type": "sc",
    "sc_id": "2.4.12",
    "section": "examples",
    "text": "[2.4.12 Focus Not Obscured (Enhanced)] (Level AAA)\nDescription: New\n\nSection: examples\n\nExamples\nA page has a sticky footer (attached to the bottom of the viewport). When tabbing down the page the focused item is not at all obscured by the footer because content in the viewport scrolls up to always display the item with keyboard focus using\nscroll padding\n.\nA page has a large (30% wide) cookie approval dialog. The dialog is modal, preventing access to the other controls in the page until it has been dismissed. Focus is not obscured because the cookie approval dialog (including the focus indicator) remains on screen until selections are made and submitted.\nA notification is implemented as a sticky header and the keyboard focus is moved to the notification. The notification disappears when it loses focus, and does not obscure any other controls (including the focus indicator visible prior to the notification).",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.12_brief",
    "type": "sc",
    "sc_id": "2.4.12",
    "section": "brief",
    "text": "[2.4.12 Focus Not Obscured (Enhanced)] (Level AAA)\nDescription: New\n\nSection: brief\n\nIn Brief\nGoal\nDon't cover any part of the item with focus.\nWhat to do\nEnsure when an item gets keyboard focus, it is fully visible.\nWhy it's important\nPeople who can't use a mouse need to see what has keyboard focus.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.12_key_terms",
    "type": "sc",
    "sc_id": "2.4.12",
    "section": "key_terms",
    "text": "[2.4.12 Focus Not Obscured (Enhanced)] (Level AAA)\nDescription: New\n\nSection: key_terms\n\nKey Terms\nuser interface component\na part of the content that is perceived by users as a single control for a distinct\n      function\nNote 1\nMultiple user interface components may be implemented as a single programmatic element.\n      \"Components\" here is not tied to programming techniques, but rather to what the user\n      perceives as separate controls.\nNote 2\nUser interface components include form elements and links as well as components generated\n      by scripts.\nNote 3\nWhat is meant by \"component\" or \"user interface component\" here is also sometimes\n      called \"user interface element\".\nExample\nAn applet has a \"control\" that can be used to move through content by line or page\n      or random access. Since each of these would need to have a name and be settable independently,\n      they would each be a \"user interface component.\"",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.13_intent",
    "type": "sc",
    "sc_id": "2.4.13",
    "section": "intent",
    "text": "[2.4.13 Focus Appearance] (Level AAA)\nDescription: New\n\nSection: intent\n\nIntent\nThe purpose of this success criterion is to ensure a keyboard focus indicator is clearly visible and\n            discernible. Focus Appearance is closely related to\n2.4.7 Focus Visible\nand\n1.4.11 Non-text Contrast\n.\n            Focus Visible requires that a visible focus indicator exists while a component has keyboard focus; Focus\n            Appearance defines a minimum level of visibility. Where Non-text Contrast requires a component to have\n            adequate contrast against the background in each of its states, Focus Appearance requires sufficient\n            contrast for the focus indicator itself.\nFor sighted people with mobility impairments who use a keyboard or a device that utilizes the\nkeyboard interface\n(such as a switch or voice input), knowing the current point of focus is very important. Visible focus must also meet the needs\n            of users with low vision, who may also rely on the keyboard.\nA keyboard focus indicator can take different forms. This Success Criterion encourages the use of a solid\n            outline around the focused user interface component, but allows other types of indicators that are at least\n            as large.\nThis Understanding document will elaborate on the minimum area requirement, color contrast requirements, and\n            finally list some user agent exceptions.\nMinimum area\nThe first part of the success criterion specifies a minimum area for the focus indicator:\nis at least as large as the area of a 2\nCSS pixel\nthick\nperimeter\nof the unfocused\n                        component or sub-component\nThis only specifies a minimum area for the focus indicator. It does not require that the focus indicator\n                literally be a 2 CSS pixel thick outline, only that the indicator be at least that large.\nHowever, the simplest way to meet the size requirement is to use a focus indicator which\nis\na\n                solid 2 CSS pixel thick perimeter.\nNote\nA\nCSS pixel\nis what developers use in CSS declarations like “width: 200px”. It is\n                device-independent and not to be confused with device pixels which vary depending on the physical pixel\n                density.\nThe rest of this document notates CSS pixels as “px”.\nUsing a solid outline\nThe easiest and most common way to meet this requirement is to use a solid outline around the\n                    component. The outline must be at least 2px thick. The following illustration shows a\nminimally\nthick focus indicator, where a 2px thick band of white pixels making up\n                    the page background around an example button have been altered to black.\nFigure 1.\nPasses: The focus indicator is a solid 2px thick outline.\nFor non-rectangular components, the \"perimeter\" definition allows authors to use either of the\n                    following types of outline:\na line which solidly encloses a shape, or\na line which solidly encloses the\nminimum bounding box\nof a shape\nFor example, a star-shaped button may use either a focus indicator that follows the shape of the star\n                    or a focus indicator that follows the bounding box of the star. In the following examples, the same\n                    three stars have already been selected, and focus is on the third star. The first example uses a\n                    focus indicator which matches the star shape of the focused star. The second uses a rectangular\n                    indicator.\nFigure 2.\nPasses: a solid outline indicator surrounds the third of five stars.\nFigure 3.\nPasses: a solidly bound focus rectangle encloses the third of five stars.\nOffsetting indicators slightly from the focused component, as in the examples above, is not required\n                    to meet the minimum area requirement of the success criterion, but it can help make indicators more\n                    visible. In CSS, the\noutline\nand\noutline-offset\nproperties are commonly\n                    used to achieve this.\nThe smallest possible 2 CSS pixel thick indicator that is still a \"perimeter\" is a solid line that\n                    appears inside the component against the component's outer edge, for example by using a CSS\nborder\nproperty. Indicators that are inset further within the component (not directly\n                    against the component's outer edge) need to be thicker than 2 CSS pixels to meet the minimum size\n                    requirement.\nFigure 4.\nAll four of these example focus indicators are 2px solid lines. The \"outset\", \"outline\",\n                        and \"border\" indicators pass. The \"inset\" indicator does not meet the minimum area requirement\n                        and fails; it would need to be at least 3px thick to pass.\nNote that different Non-text Contrast requirements may apply depending on whether the focus indicator\n                    is offset from, inset into, or against the edge of the component. See the\nRelationship with Non-text Contrast\nsection\n                    below.\nOther indicator shapes\nThis success criterion does not require that focus indicators be solid outlines. Other shapes may be\n                    used so long as they meet the minimum area requirement.\nThe minimum area of the focus indicator for a control is the area of a 2 CSS pixel thick perimeter of\n                    the control (or its minimum bounding box) in the control's unfocused state. For example, if a\n                    control is a rectangle 90px wide and 30px tall, the area of a 2 CSS pixel thick perimeter is\n                    difference between the areas of:\nA 92px by 32px rectangle (1px larger on all sides), and\nA 88px by 28px rectangle (1px smaller on all sides)\nThis results in a minimum area of (92px * 32px) - (88px * 28px) = 480px\n2\n.\nSome general formulas for 2 CSS pixel thick perimeters of common shapes are:\nRectangle with width\nw\nand height\nh\n4\nh\n+ 4\nw\nCircle with radius\nr\n4𝜋\nr\nRounded rectangle with width\nw\n, height\nh\n, and border radius\nr\n4\nh\n+ 4\nw\n- (16 - 4𝜋)\nr\nNote\nIf you need to use complex mathematics to work out if a focus indicator is large enough,\n                    it is probably a sign that you should use a larger indicator instead. The bigger the visible change\n                    when an item receives focus, the easier it is for someone to see.\nThe following 2 examples use a 90px wide by 30px tall button, with a minimum area requirement of\n                    480px\n2\n:\nFigure 5.\nPasses: the inner outline is inset slightly from the outer edge of the component, but\n                        compensates for this by being 3px thick. It has an area of 612px\n2\n, which exceeds the\n                        480px\n2\nminimum.\nFigure 6.\nPasses: the indicator rectangles on either side of the focused button are each 9px wide\n                        by 28px tall. In total, they are 504px\n2\n, which just barely meets the\n                        480px\n2\nminimum.\nNote\nPrefer using focus indicator techniques that scale with both the width and height of the\n                    focused control. Otherwise, if controls change size across different variations of a page (for\n                    example, in a responsive design), the indicator might meet the area requirement in some variations\n                    but not others. For example, in the above figure, if the width of the two highlight rectangles did\n                    not scale as the button grew wider, it would stop meeting the minimum area requirement if the button\n                    needed to grow any wider to accomodate a longer button label.\nAnother way of achieving the area requirement is to alter the appearance of the entire component, for\n                    instance by changing its color – provided that the new color has a contrast ratio of at least 3:1\n                    against the original color. This can be effective in a set of closely placed buttons. The following\n                    example demonstrates this with 5 rating stars; the center star is filled in with a darker color to\n                    indicate focus. However, it is much more difficult to detect such a focus indicator when components\n                    are not near each other and so cannot be easily compared. For users using magnification, even\n                    components relatively close together may be difficult to compare, so it is not considered a best\n                    practice.\nFigure 7.\nPasses: a color change applies to the whole third star to indicate focus.\nInline links\nIf an inline link is broken over multiple lines, some methods of creating a focus indicator create\n                    different results by browsers. CSS\noutline\nseparately surrounds each part of a link\n                    that breaks across multiple lines. It is by far the most common CSS technique for focus indication,\n                    and produces a result that satisfies the minimum bounding box definition since each part is solidly\n                    bound. CSS\nborder\nwill split the perimeter across the parts of the link, which results\n                    in an unenclosed border for each line of the link. The minimum bounding box definition states that\n                    link focus can be assessed as if the link was all on one line, so a 2px thick border is also\n                    considered to meet the minimum area requirement. Therefore, where the contrast requirements are met,\n                    each of these methods can produce a sufficient focus indicator.\nFigure 8.\nPasses: the CSS\noutline\nproperty solidly bounds each part of the link\n                        completely, so it meets the definition of a perimeter.\nFigure 9.\nPasses: Although the CSS\nborder\non a multi-line link does not enclose the\n                        separate parts of the link, the minimum bounding box definition allows it to be assessed as if\n                        it was on a single line, so it also qualifies as a perimeter.\nChange of contrast\nThe second part of the Success Criterion's indicator requirements states that an area of the indicator:\nhas a contrast ratio of at least 3:1 between the same pixels in the focused and unfocused states\nThis requirement measures the change of contrast between the same pixels in different states. This is\n                different from the Text Contrast and Non-text Contrast Success Criteria, which measure the contrast\n                between different adjacent pixels in a single state at a time.\n3:1 is the\nminimum\nallowable change-of-contrast ratio, but the greater the change of\n                contrast between states, the easier it is for users to see the focus indicator. Authors are encouraged\n                to make the change-of-contrast ratio as great as possible.\nThe following illustration shows a\nminimally\ncontrasting focus indicator, where some of\n                the white pixels making up the page background have been altered to a mid-grey that has a 3:1 contrast\n                ratio with the original white. Authors are encouraged to exceed the minimum focus appearance. For\n                instance, the dark blue lines in figures 2 and 3 are much more visible.\nFigure 10.\nPasses: Two buttons in the shape of a star, with the second surrounded by a focus indicator\n                    whose pixels contrast 3:1 between focused (light grey) and unfocused (white) states.\nWhen a component changes to include a focus indicator, that change can be measured as a change of color\n                contrast. For example, if a yellow outline is added to a button on a blue background, the change of\n                color is from blue to yellow. This change can be measured whether the focus indicator is on the\n                background around the component, or the background within the component.\nFigure 11.\nPasses: adding a yellow outline to a link is a change of color from blue to yellow. That\n                    change has a contrast ratio of 12:1.\nIf a control receiving focus changes its background (fill color) to a color that contrasts less than 3:1\n                with the original background, that would not pass the change of contrast.\nFigure 12.\nFails: the second link has a dark-grey (#555) which\nfails\nthis Success\n                    Criterion because the change from black-background to dark-grey background does not meet 3:1.\nIf the background change is sufficient, it is a method of passing the criterion.\nFigure 13.\nPasses: the second link has a white background (#fff) which\npasses\nthis\n                    success criterion because the change from black-background to white-background meets 3:1.\nPartially contrasting indicators\nIt is not necessary for the\nentire\nfocus indicator to have a 3:1 change of contrast. It is\n                    sufficient for just a part of the indicator to meet the change of contrast requirement, so long as\n                    the contrasting part of the indicator meets the minimum area requirement.\nFigure 14.\nPasses: The black part of the indicator meets 3:1 contrast with the white background,\n                        but the gray part does not. The black part is 2px thick, so it meets the minimum area\n                        requirement on its own and the gray part can be ignored.\nFigure 15.\nFails: The indicator as a whole is 2px thick, but the part of it that has sufficient\n                        change-of-contrast is only 1px thick. The part of the indicator with sufficient\n                        change-of-contrast does not meet the minimum area requirement.\nWhen calculating whether a focus indicator meets the minimum area requirement, only the part of the\n                    indicator which meets the change-of-contrast requirement should be included in the calculation.\nGradients\nIf a focus indicator has a gradient, the principle is to measure the contrast of the changed area,\n                    and ignore any part of the gradient which has less than a 3:1 change-of-contrast ratio.\nFigure 16.\nWhen a gradient is used on a focus indicator, the measure of surface area should only\n                        include the area that has changed enough to meet the 3:1 contrast ratio.\nIf you eliminate the area which has less than 3:1 change-of-contrast, you can calculate the area of\n                    the remaining parts of the indicator to determine whether the indicator meets the minimum area\n                    requirement.\nFigure 17.\nPasses: the same focused button with the non-contrasting areas removed. The contrasting\n                        area is 6px thick along most of the bottom edge and 3-4px thick on the left and right edges,\n                        which is enough to meet the minimum area requirement.\nNote\nSome of the examples in this document are screen-captured images of elements. Due to\n                    loss of resolution in these images, the actual pixel color may not match the original. As such, they\n                    are intended to be used for illustrative purposes, and should not be inspected on a pixel-by-pixel\n                    basis for sufficient contrast.\nSome designs have pages with a non-solid background image covering the whole (or part) of the page or\n                    make use of parallax scrolling effects which result in a near-infinite number of color combinations\n                    if a page is scrolled and/or changes are made to the viewport size.\nIf the contrast of background colors that change are close enough to need to be tested for each\n                    combination then they would likely not meet the user need of people with low vision in certain\n                    scroll combinations and would likely fail in certain combinations as well. In these cases it would\n                    be an easy solution to use a\nC40: Creating a two-color focus indicator to ensure sufficient contrast with all components\nor some other mechanism to indicate focus such as a solid box with a border\n                    to guarantee there is sufficient contrast across variations of background images or background\n                    gradients.\nIt is possible to use visual patterns such as strips switching places to disguise a change of focus\n                    indicator. However, this is not considered a visible indicator.\nRelationship with Non-text Contrast\nFocus indicators are visual information required to identify a state of a user interface component. That\n                means that they are subject to\n1.4.11 Non-text Contrast\n, in\n                addition to 2.4.13 Focus Appearance.\nIn combination with\n2.4.7 Focus Visible\n,\n1.4.11 Non-text Contrast\nrequires that the visual focus indicator for a component\n                must have sufficient contrast against the adjacent colors when the component is focused, except where\n                the appearance of the component is determined by the user agent and not modified by the author.\nThe difference between the contrast requirements in Focus Appearance and Non-text Contrast is:\nFocus Appearance requires that focus indicators have a\nchange of contrast\nbetween focused\n                    and non-focused states.\nNon-text Contrast requires that focus indicators have\nadjacent contrast\nbetween the\n                    indicator (in the focused state) and adjacent non-indicator colors.\nFigure 18.\nThis example passes Focus Appearance but fails Non-text Contrast; there is insufficient\nadjacent contrast\nbetween the focus indicator and the adjacent colors.\nFigure 19.\nThis example passes Non-text Contrast but fails Focus Appearance; there is insufficient\nchange of contrast\nbetween the focused and unfocused states.\nAdditionally, Non-text Contrast does not establish any size requirement and has slightly different rules\n                for when exceptions are allowed.\nSee the Relationship with Focus Visible section of\nUnderstanding 1.4.11\n                    Non-text Contrast\nfor more details and examples.\nComponent keyboard focus\nThe preamble to this success criterion is \"When a user interface component has keyboard focus...\" The\nkeyboard focus\nis the point of interaction for someone using a keyboard. For environments with\n                a keyboard-operable interface, the keyboard focus can be moved around the interface in order to interact\n                with different components. Whichever component is being interacted with has focus.\nWCAG defines\nuser interface component\nas \"a part of the content that is perceived by users as a\n                single control for a distinct function.\" Because different users may perceive controls differently,\n                there is a potential for some variation when interpreting what constitutes both a\nsingle\n                    control\nand a\ndistinct function\n. This is particularly the case when something visually\n                presents in a way that may differ from how it is programmatically created under the covers. Where there\n                is not a native HTML component upon which to base designs, there can be great variations in how the\n                components and their focus indicators are portrayed. Further, some components have sub-components that\n                can take focus, such as the menu items on a menu.\nNonetheless, consistent results from different testers were obtained for this success criterion by using\n                the focus indicator itself as the gauge of what constitutes the component being interacted with. For\n                complex components, the three typical focus indicators are as follows:\nFocus indicator around only the whole component\nFocus indicators around both the component and subcomponent\nFocus indicator around only the subcomponent\nEach of these will be discussed, using a tablist as a familiar complex component.\nFocus indicator around only the whole component\nFigure 20.\nA tablist with a focus indicator around only the whole.\nWhen the focus indicator is shown only around the whole tablist, the user is guided to considering the\n                tablist as a single user component. The tab items within it are visually distinguished between selected\n                and unselected states (and visual indicators of selection state must meet the criteria given in\n1.4.11 Non-text\n                    Contrast\n).\nHaving a focus indicator\nonly\naround the whole is possible where there is no need to have a\n                selected sub-component while another sub-component has focus. For a tablist which synchronizes its tab\n                panel content with whatever tab is active, only one tab item can be selected at a time, and since\n                whatever tab is selected is considered active, a separate focus indicator is redundant.\nResult: the group focus indicator must meet the requirements of this success criterion.\nA\nradio button group\nand a\nstar-rating\n                    widget\n, which each use only a whole-component focus indicator, provide working examples of\n                different complex components that pass the primary requirements of this success criterion. In the star\n                ratings example, users can increment the rating by 1/2 stars. Not only is a focus indicator for each 1/2\n                star unnecessary, but it would actually be difficult to achieve without making the interaction\n                confusing.\nFocus indicators around both the component and subcomponent\nFigure 21.\nThe same tablist in two states. In the first, focus is around both the tablist and the\n                    currently selected tab; in the second, focus is around both the tablist and an unselected tab.\nFor a tablist which does not keep its tab panel content synchronized with whatever tab is selected, there\n                needs to be a focus indicator for the tab item subcomponent. This is because the tab item with focus may\n                be different than the selected item.\nThe user can navigate to the tablist, which in this implementation has a focus rectangle around the whole\n                tablist as well as one around a tab item (conventionally the item that is currently selected). The focus\n                around the whole is helpful in cueing a keyboard user that this is a complex component that has its own\n                interaction. The user can then move focus between the unselected and selected tab items -- each of which\n                in turn has its own focus indicator -- before activating one, which then makes it selected as well as\n                focused, and updates the tab panel to match.\nIn this scenario, either the group focus indicator or the sub-component indicator must meet the\n                requirements of this success criterion. To avoid being overly prescriptive, the success criterion allows\n                authors to choose which makes the most sense. Generally, if a sub-component focus is necessary, it\n                should be assessed instead of the group indicator.\nResult: the focus indicator for the tab item meets the requirements of this success criterion. The\n                tablist focus indicator does not need to meet the requirements.\nA\nslider to pick\n                    colors\nprovides a working example of a different complex component that predominantly shows\n                focus for the subcomponent. In this case, the thumb slider sub-component has a focus indicator of\n                sufficient size and contrast to pass the sufficient area calculation. There is also a subtle focus\n                around the whole slider component, but it does not need to be assessed to pass this success criterion.\nFocus indicator around only the subcomponent\nFigure 22.\nThe same tabs as in the prior set, but the focus indicator around the whole is removed.\nThe same unsynchronized tablist can also be implemented as something which only shows focus on the tab\n                items and not on the whole. The behaviour is the same as in the prior example, but there is never a\n                focus indicator placed around the tablist. This interaction is acceptable, but it is not best practice\n                since it demands more understanding from the user with less information. For example, some visual cues\n                for the tablist and tab items (and tab panel) may not be clear. As well, keyboard users may not\n                initially understand the expected keyboard interaction.\nResult: the focus indicator for the tab item must meet the requirements of this Success Criterion,\n                judging focus with both selected and unselected tab items.\nA\nfunctional example of sub-component-only tab focus\nhas an indicator that is large enough (at\n                least four times the shortest side) with sufficient contrast to pass the focus area language of this\n                success criterion.\nWhere something with focus is not a user interface component\nSome pages contain very large editing regions, such as web implementations of word processors and code\n                editors. Unlike a\ntextarea\nelement, which is a user interface component, these large\n                editing regions do not typically meet the definition of\nuser interface components\n;\n                they are not \"perceived by users as a single control for a distinct function.\"\n                Providing focus indicators around such editing regions may still be beneficial to some; however, where\n                the region is not perceived as a single control, it is not covered by this success criterion. The web\n                page will still need to provide a insertion point (caret indicator) in such editing regions in order to\n                meet the requirements of\n2.4.7\n                    Focus Visible\n.\nSome non-operable elements can take focus (such as a heading element that is the target of a skip link).\n                However, the preamble of this success criterion refers to user interface components; it is only when the\n                element with focus is operable by keyboard that this success criterion applies.\nExceptions\nThere are two situations where the focus appearance does not need to be assessed:\nthe focus indicator cannot be adjusted by the author\nthe author has not modified the effects of the user agent default\nFirst exception: the focus indicator cannot be adjusted by the author\nThe focus indicator is determined by the user agent and cannot be adjusted by the author\nSome components or technologies may not allow the author to adjust the focus indicator. This is the\n                    case with HTML\nselect\nelements (both single and multi-select), where the visual\n                    treatments for selection and focus cannot be adjusted by the author. In this case the Success\n                    Criterion does not apply.\nFigure 23.\nPasses: The user agent's default\nselect\nelement presentation cannot be\n                        modified by the author, so it passes regardless of the quality of the focus indicator\nSecond exception: the default indicator and background are not modified\nThe focus indicator and the indicator's background color are not modified by the author\nIf the focus indicator and the background behind the focus indicator are not modified by the author,\n                    the success criterion does not apply.\nThe intent of this exception is to reduce burden on authors by allowing them to rely on the default\n                    indicators provided by user agents (browsers). If all user agents provided good focus indicators,\n                    authors would be able to concentrate efforts on other accessibility considerations. Unfortunately,\n                    browser default focus indicators vary by component, browser, and across devices and operating\n                    systems, and the default focus indicators in some browsers can be difficult to see (such as a 1px\n                    dotted outline). For this reason, most authors override browser defaults in order to overcome these\n                    deficiencies and create a more uniform user experience, regardless of browser.\nSome browser makers are improving their default focus indicators to make them more visible. As more\n                    browsers adopt defaults that meet the primary bullets of this Success Criterion, authors will be\n                    able to achieve improved focus indicators without customization.\nModifying the focus indicator background\nBrowser default focus indicators can be made\nmore\ndifficult to see if the author modifies\n                    the pixels directly adjacent to the indicator (commonly referred to as its background), such as by\n                    positioning a component on top of an image or gradient background, or altering the page's default\n                    white background color, for instance using a blue background in combination with a browser's blue\n                    default indicator. For this reason, where the author alters the pixels directly adjacent to the\n                    default focus indicator, the user agent exception does not apply, and the author will need to verify\n                    they meet the size and contrast requirements of this success criterion.\nNote\nAltering the\nbody\nelement's\nbackground-color\nattribute\nis\none way of altering the pixels directly adjacent to the indicator in most\n                    implementations. However, specifying a value of white (\n#FFFFFF\n) does not nullify this\n                    exception since, as established in the third note of the\ncontrast ratio\ndefinition, the\n                    default (\"unspecified\") color is assumed to be white.\nAs well, if the browser provides an indicator\nwithin\na component by default, then authors\n                    can potentially reduce the visibility by changing the component color (which in such a scenario is\n                    the background color for the focus indicator). For example, if the default indicator on a button\n                    uses a colored inner border, authors can negatively affect the focus appearance by making the button\n                    or its unfocused border color a similar-luminosity color. For this reason, this user agent exception\n                    can only be met if the author both does not modify the default focus indicator\nand\ndoes not\n                    modify its background.\nFigure 24.\nFails: The middle button is focused using a browser's default focus indicator, but it is\n                        very difficult to tell which button is focused because the custom blue border on the unfocused\n                        button uses a similar color.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.13_success_criterion",
    "type": "sc",
    "sc_id": "2.4.13",
    "section": "success_criterion",
    "text": "[2.4.13 Focus Appearance] (Level AAA)\nDescription: New\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nWhen the keyboard\nfocus indicator\nis visible, an area of the focus indicator meets all the following:\nis at least as large as the area of a 2\nCSS pixel\nthick\nperimeter\nof the unfocused component or sub-component, and\nhas a contrast ratio of at least 3:1 between the same pixels in the focused and unfocused states.\nExceptions:\nThe focus indicator is determined by the\nuser agent\nand cannot be adjusted by the author, or\nThe focus indicator and the indicator's background color are not modified by the author.\nNote 1\nWhat is perceived as the user interface component or sub-component (to determine the perimeter) depends on its visual\npresentation\n. The visual presentation includes the component's visible\ncontent\n, border, and component-specific background. It does not include shadow and glow effects outside the component's content, background, or border.\nNote 2\nExamples of sub-components that may receive a focus indicator are menu items in an opened drop-down menu, or focusable cells in a grid.\nNote 3\nContrast calculations can be based on colors defined within the\ntechnology\n(such as\nHTML\n, CSS, and SVG). Pixels modified by user agent resolution enhancements and anti-aliasing can be ignored.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.13_benefits",
    "type": "sc",
    "sc_id": "2.4.13",
    "section": "benefits",
    "text": "[2.4.13 Focus Appearance] (Level AAA)\nDescription: New\n\nSection: benefits\n\nBenefits\nThis success criterion helps anyone who relies on the keyboard to operate the page, by letting them\n                visually determine the component on which keyboard operations will interact at any point in time.\nPeople with attention limitations, short term memory limitations, or limitations in executive processes\n                benefit by being able to discover where the focus is located.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.13_examples",
    "type": "sc",
    "sc_id": "2.4.13",
    "section": "examples",
    "text": "[2.4.13 Focus Appearance] (Level AAA)\nDescription: New\n\nSection: examples\n\nExamples\nWhen links receive focus, an outline is displayed around the link that contrasts with the background\n                adjacent to the link.\nWhen buttons receive focus, an outline is displayed within the button (around the text) that contrasts\n                with the button's background.\nWhen text fields receive focus, an outline is displayed around the field, indicating that the input has\n                focus.\nWhen radio buttons receive focus, an outline is displayed around the control, indicating that the input\n                has focus.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.13_brief",
    "type": "sc",
    "sc_id": "2.4.13",
    "section": "brief",
    "text": "[2.4.13 Focus Appearance] (Level AAA)\nDescription: New\n\nSection: brief\n\nIn Brief\nGoal\nMake it easier to spot the keyboard focus.\nWhat to do\nUse a focus indicator of sufficient size and contrast.\nWhy it's important\nMany people can't see small changes in visual appearance, including older people.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.13_resources",
    "type": "sc",
    "sc_id": "2.4.13",
    "section": "resources",
    "text": "[2.4.13 Focus Appearance] (Level AAA)\nDescription: New\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nA guide to designing accessible focus\n                    indicators\nby Sara Soueidan\nFocus appearance -\n                    testing version 3\nFocus visible testing\n                    (Feb 2022)\nAvoid Default\n                    Browser Focus Styles\nby Adrian Roselli",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.4.13_key_terms",
    "type": "sc",
    "sc_id": "2.4.13",
    "section": "key_terms",
    "text": "[2.4.13 Focus Appearance] (Level AAA)\nDescription: New\n\nSection: key_terms\n\nKey Terms\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\nblocks of text\nmore than one sentence of text\nconformance\nsatisfying all the requirements of a given standard, guideline or specification\ncontent\ninformation and sensory experience to be communicated to the user by means of a\nuser agent\n, including code or markup that defines the content's\nstructure\n,\npresentation\n, and interactions\ncontrast ratio\n(L1 + 0.05) / (L2 + 0.05), where\nL1 is the\nrelative luminance\nof the lighter of the colors, and\nL2 is the\nrelative luminance\nof the darker of the colors.\nNote 1\nContrast ratios can range from 1 to 21 (commonly written 1:1 to 21:1).\nNote 2\nBecause authors do not have control over user settings as to how text is rendered\n      (for example font smoothing or anti-aliasing), the contrast ratio for text can be\n      evaluated with anti-aliasing turned off.\nNote 3\nFor the purpose of Success Criteria 1.4.3 and 1.4.6, contrast is measured with respect\n      to the specified background over which the text is rendered in normal usage. If no\n      background color is specified, then white is assumed.\nNote 4\nBackground color is the specified color of content over which the text is to be rendered\n      in normal usage. It is a failure if no background color is specified when the text\n      color is specified, because the user's default background color is unknown and cannot\n      be evaluated for sufficient contrast. For the same reason, it is a failure if no text\n      color is specified when a background color is specified.\nNote 5\nWhen there is a border around the letter, the border can add contrast and would be\n      used in calculating the contrast between the letter and its background. A narrow border\n      around the letter would be used as the letter. A wide border around the letter that\n      fills in the inner details of the letters acts as a halo and would be considered background.\nNote 6\nWCAG conformance should be evaluated for color pairs specified in the content that\n      an author would expect to appear adjacent in typical presentation. Authors need not\n      consider unusual presentations, such as color changes made by the user agent, except\n      where caused by authors' code.\nCSS pixel\nvisual angle of about 0.0213 degrees\nA CSS pixel is the canonical unit of measure for all lengths and measurements in CSS.\n      This unit is density-independent, and distinct from actual hardware pixels present\n      in a display. User agents and operating systems should ensure that a CSS pixel is\n      set as closely as possible to the\nCSS Values and Units Module Level 3 reference pixel\n[\ncss3-values\n], which takes into account the physical dimensions of the display\n      and the assumed viewing distance (factors that cannot be determined by content authors).\nfocus indicator\npixels that are changed to visually indicate when a\nuser interface component\nis in a focused\nstate\nkeyboard interface\ninterface used by software to obtain keystroke input\nNote 1\nA keyboard interface allows users to provide keystroke input to programs even if the\n        native technology does not contain a keyboard.\nExample\nA touchscreen PDA has a keyboard interface built into its operating system as well\n        as a connector for external keyboards. Applications on the PDA can use the interface\n        to obtain keyboard input either from an external keyboard or from other applications\n        that provide simulated keyboard output, such as handwriting interpreters or speech-to-text\n        applications with \"keyboard emulation\" functionality.\nNote 2\nOperation of the application (or parts of the application) through a keyboard-operated\n      mouse emulator, such as MouseKeys, does not qualify as operation through a keyboard\n      interface because operation of the program is through its pointing device interface,\n      not through its keyboard interface.\nmechanism\nprocess\nor technique for achieving a result\nNote 1\nThe mechanism may be explicitly provided in the content, or may be\nrelied upon\nto be provided by either the platform or by\nuser agents\n, including\nassistive technologies\n.\nNote 2\nThe mechanism needs to meet all success criteria for the conformance level claimed.\nminimum bounding box\nthe smallest enclosing rectangle aligned to the horizontal axis within which all the points of a shape lie. For components which wrap onto multiple lines as part of a sentence or\nblock of text\n(such as hypertext links), the bounding box is based on how the component would appear on a single line.\nperimeter\ncontinuous line forming the boundary of a shape not including shared pixels, or the\nminimum bounding box\n, whichever is shortest.\nExample\nThe perimeter calculation for a 2 CSS pixel perimeter around a rectangle is 4\nh\n+4\nw\n, where\nh\nis the height and\nw\nis the width. For a 2 CSS pixel perimeter around a circle it is 4𝜋\nr\n.\npresentation\nrendering of the\ncontent\nin a form to be perceived by users\nprocess\nseries of user actions where each action is required in order to complete an activity\nExample 1\nSuccessful use of a series of web pages on a shopping site requires users to view\n      alternative products, prices and offers, select products, submit an order, provide\n      shipping information and provide payment information.\nExample 2\nAn account registration page requires successful completion of a\nTuring test\nbefore\n      the registration form can be accessed.\nrelative luminance\nthe relative brightness of any point in a colorspace, normalized to 0 for darkest\n      black and 1 for lightest white\nNote 1\nFor the sRGB colorspace, the relative luminance of a color is defined as L = 0.2126\n      *\nR\n+ 0.7152 *\nG\n+ 0.0722 *\nB\nwhere\nR\n,\nG\nand\nB\nare defined as:\nif RsRGB <= 0.04045 then\nR\n= RsRGB/12.92 else\nR\n= ((RsRGB+0.055)/1.055) ^ 2.4\nif GsRGB <= 0.04045 then\nG\n= GsRGB/12.92 else\nG\n= ((GsRGB+0.055)/1.055) ^ 2.4\nif BsRGB <= 0.04045 then\nB\n= BsRGB/12.92 else\nB\n= ((BsRGB+0.055)/1.055) ^ 2.4\nand RsRGB, GsRGB, and BsRGB are defined as:\nRsRGB = R8bit/255\nGsRGB = G8bit/255\nBsRGB = B8bit/255\nThe \"^\" character is the exponentiation operator. (Formula taken from \n      [\nSRGB\n].)\nNote 2\nBefore May 2021 the value of 0.04045 in the definition was different (0.03928). It was taken from an older version of the specification and has been updated. It has no practical effect on the calculations in the context of these guidelines.\nNote 3\nAlmost all systems used today to view web content assume sRGB encoding. Unless it\n      is known that another color space will be used to process and display the content,\n      authors should evaluate using sRGB colorspace. If using other color spaces, see\nUnderstanding Success Criterion 1.4.3\n.\nNote 4\nIf dithering occurs after delivery, then the source color value is used. For colors\n      that are dithered at the source, the average values of the colors that are dithered\n      should be used (average R, average G, and average B).\nNote 5\nTools are available that automatically do the calculations when testing contrast and\n      flash.\nNote 6\nA\nseparate page giving the relative luminance definition using MathML\nto display the formulas is available.\nrelied upon\nthe content would not\nconform\nif that\ntechnology\nis turned off or is not supported\nstate\ndynamic property expressing characteristics of a\nuser interface component\nthat may change in response to user action or automated processes\nStates do not affect the nature of the component, but represent data associated with the component or user interaction possibilities. Examples include focus, hover, select, press, check, visited/unvisited, and expand/collapse.\nstructure\nThe way the parts of a\nweb page\nare organized in relation to each other; and\nThe way a collection of\nweb pages\nis organized\ntechnology\nmechanism\nfor encoding instructions to be rendered, played or executed by\nuser agents\nNote 1\nAs used in these guidelines \"web technology\" and the word \"technology\" (when used\n      alone) both refer to web content technologies.\nNote 2\nWeb content technologies may include markup languages, data formats, or programming\n      languages that authors may use alone or in combination to create end-user experiences\n      that range from static web pages to synchronized media presentations to dynamic Web\n      applications.\nExample\nSome common examples of web content technologies include HTML, CSS, SVG, PNG, PDF,\n      Flash, and JavaScript.\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.\nuser interface component\na part of the content that is perceived by users as a single control for a distinct\n      function\nNote 1\nMultiple user interface components may be implemented as a single programmatic element.\n      \"Components\" here is not tied to programming techniques, but rather to what the user\n      perceives as separate controls.\nNote 2\nUser interface components include form elements and links as well as components generated\n      by scripts.\nNote 3\nWhat is meant by \"component\" or \"user interface component\" here is also sometimes\n      called \"user interface element\".\nExample\nAn applet has a \"control\" that can be used to move through content by line or page\n      or random access. Since each of these would need to have a name and be settable independently,\n      they would each be a \"user interface component.\"\nweb page\na non-embedded resource obtained from a single URI using HTTP plus any other resources\n      that are used in the rendering or intended to be rendered together with it by a\nuser agent\nNote 1\nAlthough any \"other resources\" would be rendered together with the primary resource,\n      they would not necessarily be rendered simultaneously with each other.\nNote 2\nFor the purposes of conformance with these guidelines, a resource must be \"non-embedded\"\n      within the scope of conformance to be considered a web page.\nExample 1\nA web resource including all embedded images and media.\nExample 2\nA web mail program built using Asynchronous JavaScript and XML (AJAX). The program\n      lives entirely at http://example.com/mail, but includes an inbox, a contacts area\n      and a calendar. Links or buttons are provided that cause the inbox, contacts, or calendar\n      to display, but do not change the URI of the page as a whole.\nExample 3\nA customizable portal site, where users can choose content to display from a set of\n      different content modules.\nExample 4\nWhen you enter \"http://shopping.example.com/\" in your browser, you enter a movie-like\n      interactive shopping environment where you visually move around in a store dragging\n      products off of the shelves around you and into a visual shopping cart in front of\n      you. Clicking on a product causes it to be demonstrated with a specification sheet\n      floating alongside. This might be a single-page website or just one page within a\n      website.",
    "principle": "Operable",
    "guideline": "2.4 Navigable"
  },
  {
    "id": "2.5.1_intent",
    "type": "sc",
    "sc_id": "2.5.1",
    "section": "intent",
    "text": "[2.5.1 Pointer Gestures] (Level A)\nDescription: All functionality that uses multipoint or path-based gestures for operation can be operated with a single pointer without a path-based gesture, unless a multipoint or path-based gesture is essential.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to ensure that content can be controlled with a range of pointing devices, abilities, and assistive technologies. Some people  cannot perform gestures in a precise manner, or they may use a specialized or adapted input device such as a head pointer, eye-gaze system, or speech-controlled mouse emulator. Some pointing methods lack the capability or accuracy to perform multipoint or path-based gestures.\nA\npath-based gesture\ninvolves an interaction where not just the endpoints matter, but how the pointer moves between these points.\nSwiping is an example of a\npath-based gesture\n, which is only recognized when the user moves in a (mostly) straight line from the start point to the end point.\nFigure 1.\nA\npath-based gesture\nwhere pointer movement is only allowed in a straight line from the start-point to the end-point. If the user strays from the straight directional path, the gesture is not recognised, has no effect, or is aborted.\nIf going through an intermediate point (usually near the start of the gesture) affects its meaning, then it is a\npath-based gesture\n. The user engages a pointer (starting point), carries out a movement that goes through at least one intermediate-point before disengaging the pointer (end point). The intermediate point defines the gesture as requiring a specific path, even if the complete path is not defined.\nFigure 2.\nA\npath-based gesture\ninvolves starting a pointer movement that goes through at least one intermediate point before the end-point. The end-point may be a continuation, or allow for various movements.\nExamples of path-based gestures include swiping, sliders and carousels dependent on the direction of interaction, and other gestures which trace a prescribed path such as drawing a specific shape. Such paths may be drawn with a finger or stylus on a touchscreen, graphics tablet, or trackpad, or with a mouse, joystick, or similar pointer device.\nThe difference between Pointer Gestures and Dragging\nDragging is a movement where the user picks up an object with a pointer (such as mouse cursor or a finger) and moves it to some other position. This movement from start point to end point does not require the user to follow any particular path or direction. Dragging is therefore not path-based. In contrast, a path-based pointer gesture requires the traversal of an intermediate point, which is a technical way of expressing that the directionality and possibly speed of the gesture communicates a particular command to the system.\nNew in WCAG 2.2:\nDragging motions are covered in\nSuccess Criterion 2.5.7: Dragging Movements\n.\nFigure 3.\nA\nfree-form gesture\ndoes\nnot\nrequire any particular path before the end-point, only the start and (optionally) the end point matter. This is\nnot path-based\nChallenges for people with disabilities\nNote\nAny movement of a pointer could be difficult or impossible to use for someone who cannot perform precise movements, therefore alternative forms of interaction are always recommended. This success criterion is scoped to\npath-based gestures\nas it may be difficult or impossible to provide an alternative for\nfree-form gestures\n.\nExamples of\nmultipoint\ngestures include a two-finger pinch zoom, a split tap where one finger rests on the screen and a second finger taps, or a two- or three-finger tap or swipe. Users may find it difficult or impossible to accomplish these if they type and point with a single finger or stick.\nAuthors must ensure that their content can be operated without multipoint or path-based gestures. Multipoint or path-based gestures can be used so long as the functionality can also be operated by another method, such as a tap, click, double tap, double click, long press, or click & hold.\nThis success criterion applies to gestures in the author-provided content, not gestures defined by the operating system, user agent, or assistive technology. Examples of operating system gestures would be swiping down to see system notifications and gestures for built-in assistive technologies (AT). Examples of user agent-implemented gestures would be horizontal swiping implemented by browsers for navigating within the page history, or vertical swiping to scroll page content.\nThere are times when a component requires a path-based gesture for touch screen devices but not with a mouse. Taking an example of a generic slider:\nUsing a mouse:\nIf the user clicks on the thumb control of the slider and moves vertically, the slider will respond by moving to the right or left, even if the movement is mostly upwards. There will be no page scrolling as a result of the vertical movement as long as they drag with focus on the slider. Therefore, the slider does not require a path-based gesture with mouse pointer.\nUsing a touch-screen:\nIf the user puts their finger on the thumb control of the slider and moves upwards more than sideways, the slider may not respond because the browser takes control of the swipe and interprets it as a scroll, and will move the page up and down. Moving left or right on the slider thumb engages the slider and then the user can vary their vertical movement. This implementation has the 3-point requirement to work with a finger on a touch screen device so is a path-based gesture.\nAs touch screen devices can apply default gestures it is important to test with them if you are unsure whether a particular component does require a path-based gesture.\nBrowsers on a touch screen device generally provide some default gestures that impact whether a path-based gesture is needed. For example, a web browser on a touch-screen devices might detect a vertical gesture and scroll the page. If a user places their finger on a slider thumb and moves up (to scroll down) that might not activate the slider (depending on implementation). If the user moves horizontally first then the slider could capture that gesture and ignore vertical movement, resulting in a path-based gesture. If you include touch-screen devices as accessibility supported then these types of interaction need testing with a touch screen as using a mouse in a similar way would not trigger the same browser behavior.\nThis success criterion does not require all functionality to be available through pointing devices, but if it is available to pointer devices then it should not require path-based gestures. While content authors generally need to provide keyboard commands or other non-pointer mechanisms that perform actions equivalent to complex gestures (see Success Criterion 2.1.1 Keyboard), this is not sufficient to conform to this success criterion. That is because some users rely entirely on pointing devices, or find simple pointer inputs much easier to perform and understand than alternatives. For example, a user relying on a head-pointer would find clicking a control to be much more convenient than activating an on-screen keyboard to emulate a keyboard shortcut, and a person who has difficulty memorizing a series of keys (or gestures) may find it much easier to simply click on a labeled control. Therefore, if one or more pointer-based mechanisms are supported, then their benefits should be afforded to users through simple, single-point actions alone.\nSingle pointer operations include taps and clicks, double-taps and double-clicks, long presses, swiping, dragging, and path-based gestures. Gestures such as \"pinch to zoom\" or two-finger swipes are\nmultipoint\ngestures, as they require two or more pointer inputs - in this case, two fingers on a touchscreen.\nAn exception is made for functionality that is inherently and necessarily based on complex paths or multipoint gestures. For example, entering your signature may be inherently path-based (although acknowledging something or confirming your identity need not be).\nThis success criterion\ndoes not apply\nto gestures that involve dragging in any direction because only the start and end points matter in a dragging operation. However, such gestures do require fine motor control. Authors are encouraged to provide non-dragging methods, for instance, a drag and drop operation could also be achieved by selecting an item (with a tap or keyboard interaction) and then selecting its destination as a second step.",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.1_success_criterion",
    "type": "sc",
    "sc_id": "2.5.1",
    "section": "success_criterion",
    "text": "[2.5.1 Pointer Gestures] (Level A)\nDescription: All functionality that uses multipoint or path-based gestures for operation can be operated with a single pointer without a path-based gesture, unless a multipoint or path-based gesture is essential.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nAll\nfunctionality\nthat uses multipoint or path-based gestures for operation can be operated with a\nsingle pointer\nwithout a path-based gesture, unless a multipoint or path-based gesture is\nessential\n.\nNote\nThis requirement applies to web content that interprets pointer actions (i.e., this does not apply to actions that are required to operate the user agent or assistive technology).",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.1_benefits",
    "type": "sc",
    "sc_id": "2.5.1",
    "section": "benefits",
    "text": "[2.5.1 Pointer Gestures] (Level A)\nDescription: All functionality that uses multipoint or path-based gestures for operation can be operated with a single pointer without a path-based gesture, unless a multipoint or path-based gesture is essential.\n\nSection: benefits\n\nBenefits\nUsers who cannot (accurately) perform path-based pointer gestures - on a touchscreen, or with a mouse - will have alternative means for operating the content.\nUsers who cannot perform multi-pointer gestures on a touchscreen (for instance, because they are operating the touchscreen with an alternative input such as a head pointer) will have a single-pointer alternative for operating the content.\nUsers who may not understand the custom gesture interaction intended by the author will be able to rely on simple, frequently used gestures to interact. This can be especially beneficial for users with cognitive or learning disabilities.",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.1_examples",
    "type": "sc",
    "sc_id": "2.5.1",
    "section": "examples",
    "text": "[2.5.1 Pointer Gestures] (Level A)\nDescription: All functionality that uses multipoint or path-based gestures for operation can be operated with a single pointer without a path-based gesture, unless a multipoint or path-based gesture is essential.\n\nSection: examples\n\nExamples\nA website includes a map view that supports the pinch gesture to zoom into the map content. User interface controls offer the operation using plus and minus buttons to zoom in and out.\nA website includes a map view that supports the pinch gesture to zoom into the map content. As an single-pointer alternative, the map also allows users to double-tap, hold, and then move the pointer up or down to zoom in or out.\nA news site has a horizontal content slider with hidden news teasers that can moved into the viewport via a fast horizontal swipe/flicking motion. It also offers forward and backward arrow buttons for single-point activation to navigate to adjacent slider content.\nA kanban widget with several vertical areas representing states in a defined process allows the user to right- or left-swipe elements to move them to an adjacent silo. The user can also accomplish this by selecting the element with a single tap or click, and then activating an arrow button to move the selected element.\nA custom slider requires movement in a strict left/right direction when operated by dragging the thumb control. Buttons on both sides of the slider increment and decrement the selected value and update the thumb position.",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.1_brief",
    "type": "sc",
    "sc_id": "2.5.1",
    "section": "brief",
    "text": "[2.5.1 Pointer Gestures] (Level A)\nDescription: All functionality that uses multipoint or path-based gestures for operation can be operated with a single pointer without a path-based gesture, unless a multipoint or path-based gesture is essential.\n\nSection: brief\n\nIn Brief\nGoal\nLet users operate touchscreens with one finger and reduced gestures.\nWhat to do\nProvide single-point operation for all functions.\nWhy it's important\nNot everyone can perform complex and multi-touch gestures.",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.1_key_terms",
    "type": "sc",
    "sc_id": "2.5.1",
    "section": "key_terms",
    "text": "[2.5.1 Pointer Gestures] (Level A)\nDescription: All functionality that uses multipoint or path-based gestures for operation can be operated with a single pointer without a path-based gesture, unless a multipoint or path-based gesture is essential.\n\nSection: key_terms\n\nKey Terms\nessential\nif removed, would fundamentally change the information or functionality of the content,\nand\ninformation and functionality cannot be achieved in another way that would conform\nfunctionality\nprocesses\nand outcomes achievable through user action\nprocess\nseries of user actions where each action is required in order to complete an activity\nExample 1\nSuccessful use of a series of web pages on a shopping site requires users to view\n      alternative products, prices and offers, select products, submit an order, provide\n      shipping information and provide payment information.\nExample 2\nAn account registration page requires successful completion of a\nTuring test\nbefore\n      the registration form can be accessed.\nsingle pointer\nan input modality that only targets a single point on the page/screen at a time – such as a mouse, single finger on a touch screen, or stylus.\nNote\nSingle pointer interactions include clicks, double clicks, taps, dragging motions, and single-finger swipe gestures. In contrast, multipoint interactions involve the use of two or more pointers at the same time, such as two-finger interactions on a touchscreen, or the simultaneous use of a mouse and stylus.",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.1_sufficient",
    "type": "sc_sufficient",
    "sc_id": "2.5.1",
    "techniques": [
      "G215",
      "G216"
    ],
    "text": "[2.5.1 Pointer Gestures] (Level A)\nDescription: All functionality that uses multipoint or path-based gestures for operation can be operated with a single pointer without a path-based gesture, unless a multipoint or path-based gesture is essential.\n\nSufficient techniques for SC 2.5.1 (no situation): G215, G216",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.1_failures",
    "type": "sc_failures",
    "sc_id": "2.5.1",
    "techniques": [
      "F105"
    ],
    "text": "[2.5.1 Pointer Gestures] (Level A)\nDescription: All functionality that uses multipoint or path-based gestures for operation can be operated with a single pointer without a path-based gesture, unless a multipoint or path-based gesture is essential.\n\nCommon failures for SC 2.5.1: F105",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.2_intent",
    "type": "sc",
    "sc_id": "2.5.2",
    "section": "intent",
    "text": "[2.5.2 Pointer Cancellation] (Level A)\nDescription: For functionality that can be operated using a single pointer, at least one of the following is true:\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to make it easier for users to prevent accidental or erroneous pointer input. People with various disabilities can inadvertently initiate touch or mouse events with unwanted results. Each of the following subsections roughly aligns with the bullets of this Success Criterion, and outlines a means of allowing users to cancel pointer operations.\nUp-Event activation or completion\nThe most accessible way to incorporate pointer cancellation is to make activation occur on the up-event.\nUp-event activation refers to the activation of a target when the pointer is released. In a touchscreen interaction, when the finger touches a target, the up-event activation only occurs when the finger is lifted while still being within the target boundary. Similarly in mouse interaction, the up-event occurs when the mouse button is released while the cursor is still within the boundary of the initial target set when the mouse button was pressed.\nAuthors can reduce the problem of users inadvertently triggering an action by using generic platform activation/click events that activate functionality on the up-event. For example, the\nclick\nevent in JavaScript triggers on release of the primary mouse button, and is an example of an implicit up-event. Despite its name, the\nclick\nevent is device-independent and also works for touch and keyboard interaction.\nThe preference for up-events is implicit in the success criterion wording of the first bullet:\nThe down-event of the pointer is not used to execute any part of the function.\nAuthors meet the first bullet by using only the up-event.\nUp-Event Abort or Undo\nWhere the interaction is equivalent to a simple \"click\", up-event activation has a built-in ability to cancel. There is a distinction between when someone touches a screen and when they remove their finger. Similarly, in mouse interaction, there is a difference between pressing and releasing the mouse button. When activation occurs only as the pointer is released, users have the opportunity to Abort (cancel) the activation. Users who have difficulty accurately using a mouse or touchscreen benefit greatly from this basic behaviour. They normally receive visual feedback when an item is pressed. If they discover they have selected the wrong item, they can cancel the action by moving their pointer or finger away from the target before releasing.\nFor more complex interactions, such as drag and drop, the down- and up-events may initiate and end a series of actions to complete a process. For example, with drag and drop, the item may be:\nselected with a press (down-event),\nmoved to a new location, while still being depressed, and\nreleased (up-event) to conclude the drop action.\nIn such a complex action, the need for an Abort or Undo function increases. Designers may elect to confirm the move through something like a confirmation dialog or an undo button, giving the user the ability to Undo the process just completed. Alternatively, the ability to Abort the action can be achieved if, before completing step 3, the user returns the selected item to its original location and concludes the process there. If other parts of the screen disallow a move, the user can conclude the drag and drop there, effectively nullifying the operation.\nUp Reversal\nIn other interactions, the down-event may trigger a behaviour which can be reversed when the up-event concludes. Examples of this include press-and-hold actions such as where a transient popup appears (or a video plays) when the user presses on an object (down-event), but the popup (or video) disappears as soon as the user releases the pointer (up-event). Since the up-event reverses the preceding down event, the user is returned to their prior point, and has effectively cancelled the operation.\nDown-Event\nCompleting the function on the down-event is only permitted when it is essential that the up-event not be used.\nThe most prevalent essential down-event activation occurs in keyboard emulation. On a physical keyboard, keys by default activate on the down-event -- a letter appears when the key is pressed. If a software keyboard emulator tried to override this expected behaviour by making letters appear when the key is released, the behaviour would be unexpected and would adversely affect expected interaction.\nNote that a keyboard has a built-in Backspace or Delete button, which effectively provides an Undo option. Undo is not a requirement of the down-event Essential exception; however, providing an easy way for users to undo any action is a recommended practice (and may be a functional necessity), even where it is not a requirement of this success criterion.\nOther examples where the timing of an activation is essential and requires the down-event would be:\nAn activity that emulates a physical on-press trigger, such as when playing an on-screen piano keyboard. Activation on the up-event would significantly alter the desired behaviour.\nA program for shooting skeets where waiting for the \"up\" event would invalidate the precise timing necessary for the activation.",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.2_success_criterion",
    "type": "sc",
    "sc_id": "2.5.2",
    "section": "success_criterion",
    "text": "[2.5.2 Pointer Cancellation] (Level A)\nDescription: For functionality that can be operated using a single pointer, at least one of the following is true:\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nFor\nfunctionality\nthat can be operated using a\nsingle pointer\n, at least one of the following is true:\nNo Down-Event\nThe\ndown-event\nof the pointer is not used to execute any part of the function;\nAbort or Undo\nCompletion of the function is on the\nup-event\n, and a\nmechanism\nis available to abort the function before completion or to undo the function after completion;\nUp Reversal\nThe up-event reverses any outcome of the preceding down-event;\nEssential\nCompleting the function on the down-event is\nessential\n.\nNote 1\nFunctions that emulate a keyboard or numeric keypad key press are considered essential.\nNote 2\nThis requirement applies to web content that interprets pointer actions (i.e., this does not apply to actions that are required to operate the user agent or assistive technology).",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.2_benefits",
    "type": "sc",
    "sc_id": "2.5.2",
    "section": "benefits",
    "text": "[2.5.2 Pointer Cancellation] (Level A)\nDescription: For functionality that can be operated using a single pointer, at least one of the following is true:\n\nSection: benefits\n\nBenefits\nMakes it easier for all users to recover from hitting the wrong target.\nHelps people with visual disabilities, cognitive limitations, and motor impairments by reducing the chance that a control will be accidentally activated or an action will occur unexpectedly, and also ensures that where complex controls are activated, a means of Undoing or Aborting the action is available.\nIndividuals who are unable to detect changes of context are less likely to become disoriented while navigating a site.",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.2_examples",
    "type": "sc",
    "sc_id": "2.5.2",
    "section": "examples",
    "text": "[2.5.2 Pointer Cancellation] (Level A)\nDescription: For functionality that can be operated using a single pointer, at least one of the following is true:\n\nSection: examples\n\nExamples\nFor interface elements that have a single tap or long press as input, the corresponding event is triggered when the finger is lifted inside that element.\nA drag-and-drop interface allows users to sort vertically stacked cards by picking up one card with the pointer (down-event), move it to a new position, and insert it at the new location when the pointer is released (up-event). Releasing the pointer outside the drop target area reverts the action, i.e., it moves the card back to the old position before the interaction started.",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.2_brief",
    "type": "sc",
    "sc_id": "2.5.2",
    "section": "brief",
    "text": "[2.5.2 Pointer Cancellation] (Level A)\nDescription: For functionality that can be operated using a single pointer, at least one of the following is true:\n\nSection: brief\n\nIn Brief\nGoal\nReduce accidental activation of controls by mouse or touch.\nWhat to do\nMake pointer cancellation predictable and consistent.\nWhy it's important\nMake it easier for anyone to recover from something they didn’t mean to do.",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.2_key_terms",
    "type": "sc",
    "sc_id": "2.5.2",
    "section": "key_terms",
    "text": "[2.5.2 Pointer Cancellation] (Level A)\nDescription: For functionality that can be operated using a single pointer, at least one of the following is true:\n\nSection: key_terms\n\nKey Terms\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\nconformance\nsatisfying all the requirements of a given standard, guideline or specification\ndown-event\nplatform event that occurs  when the trigger stimulus of a pointer is depressed\nThe down-event may have different names on different platforms, such as \"touchstart\" or \"mousedown\".\nessential\nif removed, would fundamentally change the information or functionality of the content,\nand\ninformation and functionality cannot be achieved in another way that would conform\nfunctionality\nprocesses\nand outcomes achievable through user action\nmechanism\nprocess\nor technique for achieving a result\nNote 1\nThe mechanism may be explicitly provided in the content, or may be\nrelied upon\nto be provided by either the platform or by\nuser agents\n, including\nassistive technologies\n.\nNote 2\nThe mechanism needs to meet all success criteria for the conformance level claimed.\nprocess\nseries of user actions where each action is required in order to complete an activity\nExample 1\nSuccessful use of a series of web pages on a shopping site requires users to view\n      alternative products, prices and offers, select products, submit an order, provide\n      shipping information and provide payment information.\nExample 2\nAn account registration page requires successful completion of a\nTuring test\nbefore\n      the registration form can be accessed.\nrelied upon\nthe content would not\nconform\nif that\ntechnology\nis turned off or is not supported\nsingle pointer\nan input modality that only targets a single point on the page/screen at a time – such as a mouse, single finger on a touch screen, or stylus.\nNote\nSingle pointer interactions include clicks, double clicks, taps, dragging motions, and single-finger swipe gestures. In contrast, multipoint interactions involve the use of two or more pointers at the same time, such as two-finger interactions on a touchscreen, or the simultaneous use of a mouse and stylus.\ntechnology\nmechanism\nfor encoding instructions to be rendered, played or executed by\nuser agents\nNote 1\nAs used in these guidelines \"web technology\" and the word \"technology\" (when used\n      alone) both refer to web content technologies.\nNote 2\nWeb content technologies may include markup languages, data formats, or programming\n      languages that authors may use alone or in combination to create end-user experiences\n      that range from static web pages to synchronized media presentations to dynamic Web\n      applications.\nExample\nSome common examples of web content technologies include HTML, CSS, SVG, PNG, PDF,\n      Flash, and JavaScript.\nup-event\nplatform event that occurs  when the trigger stimulus of a pointer is released\nThe up-event may have different names on different platforms, such as \"touchend\" or \"mouseup\".\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.2_sufficient",
    "type": "sc_sufficient",
    "sc_id": "2.5.2",
    "techniques": [
      "G210",
      "G212"
    ],
    "text": "[2.5.2 Pointer Cancellation] (Level A)\nDescription: For functionality that can be operated using a single pointer, at least one of the following is true:\n\nSufficient techniques for SC 2.5.2 (no situation): G210, G212",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.2_failures",
    "type": "sc_failures",
    "sc_id": "2.5.2",
    "techniques": [
      "F101"
    ],
    "text": "[2.5.2 Pointer Cancellation] (Level A)\nDescription: For functionality that can be operated using a single pointer, at least one of the following is true:\n\nCommon failures for SC 2.5.2: F101",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.3_intent",
    "type": "sc",
    "sc_id": "2.5.3",
    "section": "intent",
    "text": "[2.5.3 Label in Name] (Level A)\nDescription: For user interface components with labels that include text or images of text, the name contains the text that is presented visually.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to ensure that the words which visually label a component are also the words associated with the component programmatically. This helps ensure that people with disabilities can rely on visible labels as a means to interact with the components.\nMost controls are accompanied by a visible text\nlabel\n. Those same controls have a programmatic\nname\n, also known as the\naccessible name\n. Users typically have a much better experience if the words and characters in the visible label of a control match or are contained within the accessible name. When these match, speech-input users (i.e., users of speech recognition applications) can navigate by speaking the visible text labels of components, such as menus, links, and buttons, that appear on the screen. Sighted users who use text-to-speech (e.g., screen readers) will also have a better experience if the text they hear matches the text they see on the screen.\nNote that where a visible text label does not exist for a component, this success criterion does not apply to that component.\nWhere text labels exist and are properly linked to the user interface components through established authoring practices, the label and name will normally match. When they don't match, speech-input users who attempt to use the visible text label as a means of navigation or selection (e.g., \"move to Password\") will be unsuccessful.  The speech-based navigation fails because the visible label spoken by the users does not match (or is not part of) the accessible name that is enabled as a speech-input command. In addition, when the accessible name is different from the visible label, it may function as a hidden command that can be accidentally activated by speech-input users.\nMismatches between visible labels and programmatic names for controls are even more of an issue for speech-input and text-to-speech users who also have cognitive challenges. Mismatches create an extra cognitive load for speech-input users, who must remember to say a speech command that is different from the visible label they see on a control. It also creates extra cognitive load for a text-to-speech user to absorb and understand speech output that does not match the visible label.\nNote that when a\nuser interface component\nlacks an\naccessible name\n— a failure of\n4.1.2 Name, Role, Value\n— and has a visible text label, then it also fails this success criterion.\nIdentifying label text for components\nIn order for the label text and accessible name to be matched, it is first necessary to determine which text on the screen should be considered a label for any given control. There are often multiple text strings in a user interface that may be relevant to a control. However, there are reasons why it is best to conservatively interpret the label as being only the text in close proximity.\nConventionally the label for user interface components is the adjacent text string. The typical positioning for left to right languages is:\nimmediately to the left of comboboxes, dropdown lists, text inputs, and other widgets (or in the absence of left-side labels, immediately above and aligned with the left edge of each input)\nimmediately to the right of checkboxes and radio buttons\ninside buttons and tabs or immediately below icons serving as buttons\nThe rationale for some of these conventions is explained in\nG162: Positioning labels to maximize predictability of relationships\n.\nIt is important to bias towards treating only the adjacent text as a label because liberal interpretations of what constitutes a text label can jeopardize the value of this success criterion (SC) by lessening predictability. Isolating the label to the single string in close proximity to the component makes it easier for developers, testers, and end users to identify the label targeted for evaluation in this SC. Predictable interpretation of labeling allows users of speech recognition technologies to interact with the element via its conventionally positioned label, and allows users of screen reading technologies to enjoy consistency between the nearby visible label and the announced name of the component.\nNote that placeholder text within an input field is not considered an appropriate means of providing a label. The\nHTML Standard\nstates\nThe placeholder attribute should not be used as an alternative to a\nlabel\n.\nHowever, it is worth noting that \"label\" in that statement is in code brackets and links to the\nlabel\nelement. For the purposes of this Label in Name Success Criterion, \"label\" is not used in such a programmatic sense but is simply referring to a text string in close visual proximity to a component. As such, in the absence of any other nearby text string (as described in the preceding list), if an input contains placeholder text, such text may be a candidate for Label in Name. This is supported both through the accessible name calculation (discussed later) and from the practical sense that where a visible label is not otherwise provided, it is likely that a speech-input user may attempt to use the placeholder text value as a means of interacting with the input.\nText labels \"express something in human language\"\nSymbolic text characters\nFor the purposes of this SC, text should not be considered a visible label if it is used in a symbolic manner, rather than directly\nexpressing something in human language\nas per the definition of\ntext\nin WCAG. For example,\n1.4.5 Images of Text\ndescribes considerations for \"symbolic text characters.\" In the images of text example \"B\", \"I\", and \"ABC\" appear on icons in a text editor, where they are meant to symbolize the functions for Bold, Italics, and Spelling, respectively. In such a case, the accessible name should be the function the button serves (e.g., \"Spell check\" or \"Check spelling\"), not the visible symbolic characters. A similar text editor is shown in the figure below.\nFigure 1.\nA detail of the rich text editor in Github, showing a variety of unlabeled icons, including icons resembling text characters.\nLikewise, where an author has used a greater-than symbol (\">\") to mimic the appearance of the right-facing arrow, the text does not convey something in human language. It is a symbol, in this scenario likely meant to mimic the icons used for a \"Play\" button or a \"Next\" arrow.\nPunctuation and capitalization\nThe use of punctuation and capitalization in labels\nmay\nalso be considered optional for the same reason. For example, the colon conventionally added at the end of input labels does not express something in human language, and capitals on the first letter of each word in a label do not normally alter the words' meaning. This is particularly relevant in the context of this SC, since it is primarily aimed at users of speech recognition; capitals and most punctuation are frequently ignored when a user speaks a label as a means of interacting with a control.\nWhile it is certainly not an error to include the colon and capitalization in the accessible name, a computed name of \"First name\" should not be considered a failure of \"First Name:\".\nFirst Name:\nLikewise, \"Next…\" visibly shown on a button could have \"Next\" as the accessible name.\n. When in doubt, where a meaningful visible label exists, match the string exactly for the accessible name.\nMathematical expressions and formulae\nMathematical expressions are an exception to the previous subsection about symbolic characters. Math symbols can be used as labels; for example \"11×3=33\" and \"A>B\" convey meaning.\nA>B\n11×3=33\nThe label should not be overwritten in the accessible name, and substitutions of words where a formula is used should be avoided since there are multiple ways to express the same equation. For example, making the name \"eleven multiplied by three is equivalent to thirty-three\" might mean a user who said \"eleven times three equals thirty-three\" may not match. It is best to leave the formulas as used in the label and count on the user's familiarity with their speech software to achieve a match. Further, converting a mathematical formula label into an accessible name that is a spelled-out equivalent may create issues for translation. The name should match the label's formula text. Note that a consideration for authors is to use the proper symbol in the formula. For instance 11x3 (with a lower or upper case letter X), 11*3 (with the asterisk symbol), and 11×3 (with the\n&\ntimes\n;\nsymbol) are all easy for sighted users to interpret as meaning the same formula, but may not all be matched to \"11 times 3\" by the speech recognition software. The proper operator symbol (in this case the times symbol) should be used.\nAccessible Name and Description Computation specification\nIt is important to understand how the accessible name is derived. The\nAccessible Name and Description Computation 1.1\nand the\nHTML Accessibility API Mappings 1.0\ndescribe how the accessible name is computed, including which attributes are considered in its calculation, and in what order of preference. If a component has multiple possible attribute values that could be used for its accessible name, only the most preferred of those values will be computed. None of the other, less preferred values will be part of the name. For the most part, existing established programmatic relationships between labels and controls are reinforced by the specification.\nOther text displayed on the screen that is correctly coded to meet\n1.3.1 Info and Relationships\nis\nnot\nnormally factored into the calculation for the accessible name of a UI component without author intervention (via ARIA labeling techniques). The most common of these are:\nheadings and instructions\ngroup labels for sets of components (i.e., used with\nlegend\n/\nfieldset\nor with role of\ngroup\nor\nradiogroup\n)\nSuch textual information may constitute part of the component's\ndescription\n. So from both a programmatic viewpoint, and from the conservative tactic of only considering a label to be \"adjacent text,\" neither headings, instructions, nor group 'labels' should normally be considered\nlabels\nfor the purpose of this success criterion.\nIt is important to note that the specification allows authors to override the name calculated through native semantics. Both\naria-label\nand\naria-labelledby\ntake precedence in the name calculation, overriding the visible text as the accessible name even when the visible text label is programmatically associated with the control. For this reason, when a visible label already exists,\naria-label\nshould be avoided or used carefully, and\naria-labelledby\nshould be used as a supplement with care.\nFinally,\naria-describedby\nis not included in the Accessible Name computation (instead it is part of the Accessible Description computation). By convention, text associated with a control through\naria-describedby\nis announced immediately after the accessible name by screen readers. Therefore, the context of headings, instructions, and group labels can be provided through the accessible description to assist users of screen readers without affecting the experience of those who navigate using speech recognition software.\nText in parentheses\nNote: The term \"parenthetical\" in this section is describing text that literally appears within a set of round brackets (). It is not used in the more abstract sense of \"information related to\".\nIt is important to mention parenthetical text in labels in the context of accessible name versus description. In common usage, text in parentheses is considered secondary but relevant to meaning. Users of speech recognition would not typically announce text in parentheses as part of the input name. For that reason, parenthetical text may be optionally considered a description and left out of the accessible name.\nHowever, where parenthetical information provides important context, such as indication of a required field or limitations on what is allowed for input, this information must be provided programmatically in some other way to the user if that information is not included as part of the accessible name. For example, \"Name (required)\" and \"Date (YYYY-MM-DD)\" could accept \"Name\" and \"Date\" as the accessible names. However, in order to pass\n1.3.1 Info and Relationships\n, authors would need to programmatically surface both the required state and the limit on the allowed data formatting (in this example, eight integers fitting the YYYY-MM-DD pattern). The \"required\" state could be surfaced through the HTML\nrequired\nattribute or by using\naria-required=\"true\"\n. The allowed data formatting could be surfaced by being referenced using the\naria-describedby\nattribute.",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.3_success_criterion",
    "type": "sc",
    "sc_id": "2.5.3",
    "section": "success_criterion",
    "text": "[2.5.3 Label in Name] (Level A)\nDescription: For user interface components with labels that include text or images of text, the name contains the text that is presented visually.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nFor\nuser interface components\nwith\nlabels\nthat include\ntext\nor\nimages of text\n, the\nname\ncontains the text that is presented visually.\nNote\nA best practice is to have  the text of the label at the start of the name.",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.3_benefits",
    "type": "sc",
    "sc_id": "2.5.3",
    "section": "benefits",
    "text": "[2.5.3 Label in Name] (Level A)\nDescription: For user interface components with labels that include text or images of text, the name contains the text that is presented visually.\n\nSection: benefits\n\nBenefits\nSpeech-input users can directly activate controls on a page with fewer surprising changes of focus.\nText-to-speech users will have a better experience because the labels that they hear match the visible text labels that\n\t\t\t\tthey see on the screen.",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.3_examples",
    "type": "sc",
    "sc_id": "2.5.3",
    "section": "examples",
    "text": "[2.5.3 Label in Name] (Level A)\nDescription: For user interface components with labels that include text or images of text, the name contains the text that is presented visually.\n\nSection: examples\n\nExamples\nAccessible name matches visible label:\nThe accessible name and visible label of a control match.\nAccessible name starts with visible label:\nThe accessible name \"Search for a value\" begins with the text of the visible label, \"Search\".",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.3_brief",
    "type": "sc",
    "sc_id": "2.5.3",
    "section": "brief",
    "text": "[2.5.3 Label in Name] (Level A)\nDescription: For user interface components with labels that include text or images of text, the name contains the text that is presented visually.\n\nSection: brief\n\nIn Brief\nGoal\nThe visual label for controls is a trigger for speech activation.\nWhat to do\nWhere practical, make the control’s text label and name match.\nWhy it's important\nPeople who operate with voice interaction use the visible labels in their commands.",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.3_resources",
    "type": "sc",
    "sc_id": "2.5.3",
    "section": "resources",
    "text": "[2.5.3 Label in Name] (Level A)\nDescription: For user interface components with labels that include text or images of text, the name contains the text that is presented visually.\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nAccessible Name and Description Computation\nAccessible Name and Description Computation in HTML Accessibility API Mappings 1.0",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.3_test_rules",
    "type": "sc",
    "sc_id": "2.5.3",
    "section": "test_rules",
    "text": "[2.5.3 Label in Name] (Level A)\nDescription: For user interface components with labels that include text or images of text, the name contains the text that is presented visually.\n\nSection: test_rules\n\nTest Rules\nThe following are Test Rules\n    for certain aspects of this Success Criterion.\n    It is not necessary to use these particular Test Rules to check for conformance with WCAG, but they are defined and approved test methods.\n    For information on using Test Rules, see\nUnderstanding Test Rules for WCAG Success Criteria\n.\nForm field has non-empty accessible name\nVisible label is part of accessible name",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.3_key_terms",
    "type": "sc",
    "sc_id": "2.5.3",
    "section": "key_terms",
    "text": "[2.5.3 Label in Name] (Level A)\nDescription: For user interface components with labels that include text or images of text, the name contains the text that is presented visually.\n\nSection: key_terms\n\nKey Terms\nASCII art\npicture created by a spatial arrangement of characters or glyphs (typically from the\n      95 printable characters defined by ASCII)\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\ncontent\ninformation and sensory experience to be communicated to the user by means of a\nuser agent\n, including code or markup that defines the content's\nstructure\n,\npresentation\n, and interactions\nhuman language\nlanguage that is spoken, written or signed (through visual or tactile means) to communicate\n      with humans\nNote\nSee also\nsign language\n.\nimage of text\ntext that has been rendered in a non-text form (e.g., an image) in order to achieve\n      a particular visual effect\nNote\nThis does not include text that is part of a picture that contains significant other visual content.\nExample\nA person's name on a nametag in a photograph.\nlabel\ntext\nor other component with a\ntext alternative\nthat is presented to a user to identify a component within web\ncontent\nNote 1\nA label is presented to all users whereas the\nname\nmay be hidden and only exposed by assistive technology. In many (but not all) cases\n      the name and the label are the same.\nNote 2\nThe term label is not limited to the label element in HTML.\nname\ntext by which software can identify a component within web content to the user\nNote 1\nThe name may be hidden and only exposed by assistive technology, whereas a\nlabel\nis presented to all users. In many (but not all) cases, the label and the name are\n      the same.\nNote 2\nThis is unrelated to the name attribute in HTML.\nnon-text content\nany content that is not a sequence of characters that can be\nprogrammatically determined\nor where the sequence is not expressing something in\nhuman language\nNote\nThis includes\nASCII art\n(which is a pattern of characters), emoticons, leetspeak (which uses character substitution),\n      and images representing text\npresentation\nrendering of the\ncontent\nin a form to be perceived by users\nprogrammatically determined\ndetermined by software from author-supplied data provided in a way that different\nuser agents\n, including\nassistive technologies\n, can extract and present this information to users in different modalities\nExample 1\nDetermined in a markup language from elements and attributes that are accessed directly\n      by commonly available assistive technology.\nExample 2\nDetermined from technology-specific data structures in a non-markup language and exposed\n      to assistive technology via an accessibility API that is supported by commonly available\n      assistive technology.\nsign language\na language using combinations of movements of the hands and arms, facial expressions,\n      or body positions to convey meaning\nstructure\nThe way the parts of a\nweb page\nare organized in relation to each other; and\nThe way a collection of\nweb pages\nis organized\ntext\nsequence of characters that can be\nprogrammatically determined\n, where the sequence is expressing something in\nhuman language\ntext alternative\nText\nthat is programmatically associated with\nnon-text content\nor referred to from text that is programmatically associated with non-text content.\n      Programmatically associated text is text whose location can be\nprogrammatically determined\nfrom the non-text content.\nExample\nAn image of a chart is described in text in the paragraph after the chart. The short\n      text alternative for the chart indicates that a description follows.\nNote\nRefer to\nUnderstanding Text Alternatives\nfor more information.\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.\nuser interface component\na part of the content that is perceived by users as a single control for a distinct\n      function\nNote 1\nMultiple user interface components may be implemented as a single programmatic element.\n      \"Components\" here is not tied to programming techniques, but rather to what the user\n      perceives as separate controls.\nNote 2\nUser interface components include form elements and links as well as components generated\n      by scripts.\nNote 3\nWhat is meant by \"component\" or \"user interface component\" here is also sometimes\n      called \"user interface element\".\nExample\nAn applet has a \"control\" that can be used to move through content by line or page\n      or random access. Since each of these would need to have a name and be settable independently,\n      they would each be a \"user interface component.\"\nweb page\na non-embedded resource obtained from a single URI using HTTP plus any other resources\n      that are used in the rendering or intended to be rendered together with it by a\nuser agent\nNote 1\nAlthough any \"other resources\" would be rendered together with the primary resource,\n      they would not necessarily be rendered simultaneously with each other.\nNote 2\nFor the purposes of conformance with these guidelines, a resource must be \"non-embedded\"\n      within the scope of conformance to be considered a web page.\nExample 1\nA web resource including all embedded images and media.\nExample 2\nA web mail program built using Asynchronous JavaScript and XML (AJAX). The program\n      lives entirely at http://example.com/mail, but includes an inbox, a contacts area\n      and a calendar. Links or buttons are provided that cause the inbox, contacts, or calendar\n      to display, but do not change the URI of the page as a whole.\nExample 3\nA customizable portal site, where users can choose content to display from a set of\n      different content modules.\nExample 4\nWhen you enter \"http://shopping.example.com/\" in your browser, you enter a movie-like\n      interactive shopping environment where you visually move around in a store dragging\n      products off of the shelves around you and into a visual shopping cart in front of\n      you. Clicking on a product causes it to be demonstrated with a specification sheet\n      floating alongside. This might be a single-page website or just one page within a\n      website.",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.3_sufficient",
    "type": "sc_sufficient",
    "sc_id": "2.5.3",
    "techniques": [
      "G208",
      "G211"
    ],
    "text": "[2.5.3 Label in Name] (Level A)\nDescription: For user interface components with labels that include text or images of text, the name contains the text that is presented visually.\n\nSufficient techniques for SC 2.5.3 (no situation): G208, G211",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.3_advisory",
    "type": "sc_advisory",
    "sc_id": "2.5.3",
    "techniques": [
      "G162"
    ],
    "text": "[2.5.3 Label in Name] (Level A)\nDescription: For user interface components with labels that include text or images of text, the name contains the text that is presented visually.\n\nAdvisory techniques for SC 2.5.3: G162",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.3_failures",
    "type": "sc_failures",
    "sc_id": "2.5.3",
    "techniques": [
      "F96",
      "F111"
    ],
    "text": "[2.5.3 Label in Name] (Level A)\nDescription: For user interface components with labels that include text or images of text, the name contains the text that is presented visually.\n\nCommon failures for SC 2.5.3: F96, F111",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.4_intent",
    "type": "sc",
    "sc_id": "2.5.4",
    "section": "intent",
    "text": "[2.5.4 Motion Actuation] (Level A)\nDescription: Functionality that can be operated by device motion or user motion can also be operated by user interface components and responding to the motion can be disabled to prevent accidental actuation, except when:\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to ensure that functions triggered by moving a device (for example, shaking or tilting) or by gesturing towards the device (so that sensors like a camera can pick up and interpret the gesturing), can also be operated by more conventional user interface components.\nNote\nThis criterion concerns input through sensors which respond directly to motions such as gesturing towards, tilting or shaking a device. It does not cover the movement of users through space as registered by geolocation sensors or beacons, or events observed by the device other than intentional gesturing by the user. It also does not cover incidental motion associated with operating a keyboard, pointer, or assistive technology.\nDevices often have sensors that can act as inputs, such as accelerometer and gyroscope sensors on a phone or tablet device. These sensors can allow the user to control something by simply changing the orientation or moving the device in particular ways. In other situations, web content can interpret user gestures via the camera or other sensors to actuate functions. For example, shaking the device might issue an \"Undo\" command, or a gentle hand wave might be used to move forward or backward in a sequence of pages. Some users with disabilities are not able to operate these device sensors (either not at all, or not precisely enough) because the device is on a fixed mount (perhaps a wheelchair) or due to motor impairments. Therefore, functionality offered through motion must also be available by another mechanism.\nIn addition, some users may accidentally activate sensors due to tremors or other motor impairments. The user must have the ability to turn off motion actuation to prevent such accidental triggering of functions. Applications may be able to meet this requirement by supporting operating system settings which allow the user to disable motion detection at the system level.\nThere is an exception where motion is essential for the function or not using motions or gestures would invalidate the activity. Some applications are specifically created to use device sensor data. Examples of content that are exempt from this requirement include a pedometer that relies on device motion to count steps.",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.4_success_criterion",
    "type": "sc",
    "sc_id": "2.5.4",
    "section": "success_criterion",
    "text": "[2.5.4 Motion Actuation] (Level A)\nDescription: Functionality that can be operated by device motion or user motion can also be operated by user interface components and responding to the motion can be disabled to prevent accidental actuation, except when:\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nFunctionality\nthat can be operated by device motion or user motion can also be operated by\nuser interface components\nand responding to the motion can be disabled to prevent accidental actuation, except when:\nSupported Interface\nThe motion is used to operate functionality through an\naccessibility supported\ninterface;\nEssential\nThe motion is\nessential\nfor the function and doing so would invalidate the activity.",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.4_benefits",
    "type": "sc",
    "sc_id": "2.5.4",
    "section": "benefits",
    "text": "[2.5.4 Motion Actuation] (Level A)\nDescription: Functionality that can be operated by device motion or user motion can also be operated by user interface components and responding to the motion can be disabled to prevent accidental actuation, except when:\n\nSection: benefits\n\nBenefits\nThis success criterion helps people who may be unable to perform particular motions (such as tilting, shaking, or gesturing) because the device may be mounted or users may be physically unable to perform the necessary movement. This success criterion ensures that users can still operate all functionality by other means such as touch or via assistive technologies.\nOther users will benefit in situations where they are unable to move their devices.",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.4_examples",
    "type": "sc",
    "sc_id": "2.5.4",
    "section": "examples",
    "text": "[2.5.4 Motion Actuation] (Level A)\nDescription: Functionality that can be operated by device motion or user motion can also be operated by user interface components and responding to the motion can be disabled to prevent accidental actuation, except when:\n\nSection: examples\n\nExamples\nA user can choose an application setting which turns off Shake to Undo and other motion-activated features.\nAfter text is input in a field, shaking a device shows a dialog offering users to undo the input. A cancel button next to the text field offers the same functionality.\nA user can tilt a device to advance to the next or a previous page. Buttons are also provided to perform the same function.\nA user can move or pan a device to change the view in an interactive photo. A control is also available to perform these same functions.\nA user can gesture towards the device to navigate content. Controls are also available to navigate.",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.4_brief",
    "type": "sc",
    "sc_id": "2.5.4",
    "section": "brief",
    "text": "[2.5.4 Motion Actuation] (Level A)\nDescription: Functionality that can be operated by device motion or user motion can also be operated by user interface components and responding to the motion can be disabled to prevent accidental actuation, except when:\n\nSection: brief\n\nIn Brief\nGoal\nContent is not dependent on a user's ability to move a device.\nWhat to do\nDon't rely solely on device motion to control page content.\nWhy it's important\nSome people cannot hold or move a device steadily.",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.4_resources",
    "type": "sc",
    "sc_id": "2.5.4",
    "section": "resources",
    "text": "[2.5.4 Motion Actuation] (Level A)\nDescription: Functionality that can be operated by device motion or user motion can also be operated by user interface components and responding to the motion can be disabled to prevent accidental actuation, except when:\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nDetecting device orientation\nDeviceMotionEvent",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.4_test_rules",
    "type": "sc",
    "sc_id": "2.5.4",
    "section": "test_rules",
    "text": "[2.5.4 Motion Actuation] (Level A)\nDescription: Functionality that can be operated by device motion or user motion can also be operated by user interface components and responding to the motion can be disabled to prevent accidental actuation, except when:\n\nSection: test_rules\n\nTest Rules\nThe following are Test Rules\n    for certain aspects of this Success Criterion.\n    It is not necessary to use these particular Test Rules to check for conformance with WCAG, but they are defined and approved test methods.\n    For information on using Test Rules, see\nUnderstanding Test Rules for WCAG Success Criteria\n.\nDevice motion based changes to the content can also be created from the user interface\nDevice motion based changes to the content can be disabled",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.4_key_terms",
    "type": "sc",
    "sc_id": "2.5.4",
    "section": "key_terms",
    "text": "[2.5.4 Motion Actuation] (Level A)\nDescription: Functionality that can be operated by device motion or user motion can also be operated by user interface components and responding to the motion can be disabled to prevent accidental actuation, except when:\n\nSection: key_terms\n\nKey Terms\naccessibility supported\nsupported by users'\nassistive technologies\nas well as the accessibility features in browsers and other\nuser agents\nTo qualify as an accessibility-supported use of a web content technology (or feature\n      of a technology), both 1 and 2 must be satisfied for a web content technology (or\n      feature):\nThe way that the\nweb content technology\nis used must be supported by users' assistive technology (AT).\nThis means that the way that the technology is used has been tested for interoperability\n            with users' assistive technology in the\nhuman language(s)\nof the content,\nAND\nThe web content technology must have accessibility-supported user agents that are\n               available to users.\nThis means that at least one of the following four statements is true:\nThe technology is supported natively in widely-distributed user agents that are also\n                  accessibility supported (such as HTML and CSS);\nOR\nThe technology is supported in a widely-distributed plug-in that is also accessibility\n                  supported;\nOR\nThe content is available in a closed environment, such as a university or corporate\n                  network, where the user agent required by the technology and used by the organization\n                  is also accessibility supported;\nOR\nThe user agent(s) that support the technology are accessibility supported and are\n                  available for download or purchase in a way that:\ndoes not cost a person with a disability any more than a person without a disability\nand\nis as easy to find and obtain for a person with a disability as it is for a person\n                     without disabilities.\nNote 1\nThe Accessibility Guidelines Working Group and the W3C do not specify which or how much support by assistive\n      technologies there must be for a particular use of a web technology in order for it\n      to be classified as accessibility supported. (See\nLevel of Assistive Technology Support Needed for \"Accessibility Support\"\n.)\nNote 2\nWeb technologies can be used in ways that are not accessibility supported as long\n      as they are not\nrelied upon\nand the page as a whole meets the conformance requirements, including\nConformance Requirement 4\nand\nConformance Requirement 5\n.\nNote 3\nWhen a\nweb technology\nis used in a way that is \"accessibility supported,\" it does not imply that the entire\n      technology or all uses of the technology are supported. Most technologies, including\n      HTML, lack support for at least one feature or use. Pages conform to WCAG only if\n      the uses of the technology that are accessibility supported can be relied upon to\n      meet WCAG requirements.\nNote 4\nWhen citing web content technologies that have multiple versions, the version(s) supported\n      should be specified.\nNote 5\nOne way for authors to locate uses of a technology that are accessibility supported\n      would be to consult compilations of uses that are documented to be accessibility supported.\n      (See\nUnderstanding Accessibility-Supported Web Technology Uses\n.) Authors, companies, technology vendors, or others may document accessibility-supported\n      ways of using web content technologies. However, all ways of using technologies in\n      the documentation would need to meet the definition of accessibility-supported Web\n      content technologies above.\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\nconformance\nsatisfying all the requirements of a given standard, guideline or specification\nessential\nif removed, would fundamentally change the information or functionality of the content,\nand\ninformation and functionality cannot be achieved in another way that would conform\nfunctionality\nprocesses\nand outcomes achievable through user action\nhuman language\nlanguage that is spoken, written or signed (through visual or tactile means) to communicate\n      with humans\nNote\nSee also\nsign language\n.\nmechanism\nprocess\nor technique for achieving a result\nNote 1\nThe mechanism may be explicitly provided in the content, or may be\nrelied upon\nto be provided by either the platform or by\nuser agents\n, including\nassistive technologies\n.\nNote 2\nThe mechanism needs to meet all success criteria for the conformance level claimed.\nprocess\nseries of user actions where each action is required in order to complete an activity\nExample 1\nSuccessful use of a series of web pages on a shopping site requires users to view\n      alternative products, prices and offers, select products, submit an order, provide\n      shipping information and provide payment information.\nExample 2\nAn account registration page requires successful completion of a\nTuring test\nbefore\n      the registration form can be accessed.\nrelied upon\nthe content would not\nconform\nif that\ntechnology\nis turned off or is not supported\nsign language\na language using combinations of movements of the hands and arms, facial expressions,\n      or body positions to convey meaning\ntechnology\nmechanism\nfor encoding instructions to be rendered, played or executed by\nuser agents\nNote 1\nAs used in these guidelines \"web technology\" and the word \"technology\" (when used\n      alone) both refer to web content technologies.\nNote 2\nWeb content technologies may include markup languages, data formats, or programming\n      languages that authors may use alone or in combination to create end-user experiences\n      that range from static web pages to synchronized media presentations to dynamic Web\n      applications.\nExample\nSome common examples of web content technologies include HTML, CSS, SVG, PNG, PDF,\n      Flash, and JavaScript.\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.\nuser interface component\na part of the content that is perceived by users as a single control for a distinct\n      function\nNote 1\nMultiple user interface components may be implemented as a single programmatic element.\n      \"Components\" here is not tied to programming techniques, but rather to what the user\n      perceives as separate controls.\nNote 2\nUser interface components include form elements and links as well as components generated\n      by scripts.\nNote 3\nWhat is meant by \"component\" or \"user interface component\" here is also sometimes\n      called \"user interface element\".\nExample\nAn applet has a \"control\" that can be used to move through content by line or page\n      or random access. Since each of these would need to have a name and be settable independently,\n      they would each be a \"user interface component.\"",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.4_sufficient",
    "type": "sc_sufficient",
    "sc_id": "2.5.4",
    "techniques": [
      "G213"
    ],
    "text": "[2.5.4 Motion Actuation] (Level A)\nDescription: Functionality that can be operated by device motion or user motion can also be operated by user interface components and responding to the motion can be disabled to prevent accidental actuation, except when:\n\nSufficient techniques for SC 2.5.4 (no situation): G213",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.4_failures",
    "type": "sc_failures",
    "sc_id": "2.5.4",
    "techniques": [
      "F106"
    ],
    "text": "[2.5.4 Motion Actuation] (Level A)\nDescription: Functionality that can be operated by device motion or user motion can also be operated by user interface components and responding to the motion can be disabled to prevent accidental actuation, except when:\n\nCommon failures for SC 2.5.4: F106",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.5_intent",
    "type": "sc",
    "sc_id": "2.5.5",
    "section": "intent",
    "text": "[2.5.5 Target Size (Enhanced)] (Level AAA)\nDescription: The size of the target for pointer inputs is at least 44 by 44 CSS pixels except when:\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to help users who may have trouble activating a small target because of hand tremors, limited dexterity or other reasons. If the target is too small, it may be difficult to aim at the target. Mice and similar pointing devices can be hard to use for these users, and a larger target will help them greatly in having positive outcomes on the web page.\nTouch is particularly problematic as it is an input mechanism with coarse precision. Users lack the same level of fine control as on inputs such as a mouse or stylus. A finger is larger than a mouse pointer, and generally obstructs the user's view of the precise location on the screen that is being touched/activated.\nThe issue can be further complicated for responsive/mobile sites which need to accommodate different types of fine and coarse inputs (e.g. a site that can be accessed both on a traditional desktop/laptop with a mouse, as well as on a tablet or mobile phone with a touch screen).\nWhile this criterion defines a minimum target size, it is recommended that larger sizes are used to reduce the possibility of unintentional actions. This is particularly relevant if any of the following are true:\nthe control is used frequently;\nthe result of the interaction cannot be easily undone;\nthe control is positioned where it will be difficult to reach, or is near the edge of the screen;\nthe control is part of a sequential task.\nThe targets on a screen can have different purposes and uses, and this success criterion specifies how each is to be handled.\nEquivalent targets:\nIf there is more than one target on a screen that performs the same action, only one of the targets need to meet the target size of 44 by 44 CSS pixels.\nInline:\nContent displayed can often be reflowed based on the screen width available. This is known as responsive design and makes it easier to read since you do not need to scroll both horizontally and vertically. In reflowed content, the targets can appear anywhere on a line and can change position based on the width of the available screen. Since targets can appear anywhere on the line, the size cannot be larger than the available text and spacing between the sentences or paragraphs, otherwise the targets could overlap. It is for this reason targets which are contained within one or more sentences are excluded from the target size requirements.\nNote\nIf the target is the full sentence and the sentence is not in a block of text, then the target needs to be at least 44 by 44 CSS pixels.\nNote\nA footnote or an icon within or at the end of a sentence is considered to be part of a sentence and therefore are excluded from the minimum target size.\nUser Agent Control:\nIf the size of the target is not modified by the author through CSS or other size properties, then the target does not need to meet the target size of 44 by 44 CSS pixels.\nEssential:\nIf the target is required to be a particular target size and cannot be provided in another way, while changing it would essentially change the information or functionality of the content, then the target does not need to meet the target size of 44 by 44 CSS pixels.",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.5_success_criterion",
    "type": "sc",
    "sc_id": "2.5.5",
    "section": "success_criterion",
    "text": "[2.5.5 Target Size (Enhanced)] (Level AAA)\nDescription: The size of the target for pointer inputs is at least 44 by 44 CSS pixels except when:\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nThe size of the\ntarget\nfor\npointer inputs\nis at least 44 by 44\nCSS pixels\nexcept when:\nEquivalent\nThe target is available through an equivalent link or control on the same page that is at least 44 by 44 CSS pixels;\nInline\nThe target is in a sentence or\nblock of text\n;\nUser Agent Control\nThe size of the target is determined by the\nuser agent\nand is not modified by the author;\nEssential\nA particular\npresentation\nof the target is\nessential\nto the information being conveyed.",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.5_benefits",
    "type": "sc",
    "sc_id": "2.5.5",
    "section": "benefits",
    "text": "[2.5.5 Target Size (Enhanced)] (Level AAA)\nDescription: The size of the target for pointer inputs is at least 44 by 44 CSS pixels except when:\n\nSection: benefits\n\nBenefits\nUsers who use a mobile device where touch screen is the primary mode of interaction\nUsers with mobility impairments, such as hand tremors\nUsers who use a mobile device in environments where they are exposed to shaking such as public transportation\nUsers who find fine motor movements difficult\nUsers who access a device using one hand\nUsers with large fingers, or who are operating the device with only a part of their finger or knuckle\nUsers who have low vision may better see the target",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.5_examples",
    "type": "sc",
    "sc_id": "2.5.5",
    "section": "examples",
    "text": "[2.5.5 Target Size (Enhanced)] (Level AAA)\nDescription: The size of the target for pointer inputs is at least 44 by 44 CSS pixels except when:\n\nSection: examples\n\nExamples\nExample 1: Buttons\nThree buttons are on-screen and the touch target area of each button is 44 by 44 CSS pixels.\nExample 2: Equivalent target\nMultiple targets are provided on the page that perform the same function. One of the targets is 44 by 44 CSS pixels. The other targets do not have a minimum touch target of 44 by 44 CSS pixels.\nExample 3: Anchor Link\nThe target is an in-page link and the target is less than 44 by 44 CSS pixels.\nExample 4: Text Link in a paragraph\nLinks within a paragraph of text have varying touch target dimensions. Links within\n           paragraphs of text do no need to meet the 44 by 44 CSS pixels requirements.\nExample 5: Text Link in a sentence\nA text link that is in a sentence is excluded and does not need to meet the 44 by 44 CSS pixel requirement. If the text link is the full sentence, then the text link target touch area does need to meet the 44 by 44 CSS pixels.\nExample 6: Footnote\nA footnote link at the end of a sentence does not need to meet the 44 by 44 CSS pixels requirements. The footnote at the end of the sentence is considered to be part of the sentence.\nExample 7: Help icon\nA help icon within or at the end of a sentence does not need to meet the 44 by 44 CSS pixels requirements. The icon at the end of the sentence is considered to be part of the sentence.",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.5_brief",
    "type": "sc",
    "sc_id": "2.5.5",
    "section": "brief",
    "text": "[2.5.5 Target Size (Enhanced)] (Level AAA)\nDescription: The size of the target for pointer inputs is at least 44 by 44 CSS pixels except when:\n\nSection: brief\n\nIn Brief\nGoal\nControls can be operated more easily, especially on touch screens.\nWhat to do\nMake custom targets at least 44 by 44 pixels.\nWhy it's important\nSome people cannot tap small objects.",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.5_resources",
    "type": "sc",
    "sc_id": "2.5.5",
    "section": "resources",
    "text": "[2.5.5 Target Size (Enhanced)] (Level AAA)\nDescription: The size of the target for pointer inputs is at least 44 by 44 CSS pixels except when:\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nApple touch target size recommendations\nWindows UWP Guidelines for touch targets\nGoogle Material Design Touch targets\nweb.dev Accessible tap targets\nHuman Fingertips to Investigate the Mechanics of Tactile Sense (PDF)\nOne-Handed Thumb Use on Small Touchscreen Devices",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.5_key_terms",
    "type": "sc",
    "sc_id": "2.5.5",
    "section": "key_terms",
    "text": "[2.5.5 Target Size (Enhanced)] (Level AAA)\nDescription: The size of the target for pointer inputs is at least 44 by 44 CSS pixels except when:\n\nSection: key_terms\n\nKey Terms\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\nblocks of text\nmore than one sentence of text\ncontent\ninformation and sensory experience to be communicated to the user by means of a\nuser agent\n, including code or markup that defines the content's\nstructure\n,\npresentation\n, and interactions\nCSS pixel\nvisual angle of about 0.0213 degrees\nA CSS pixel is the canonical unit of measure for all lengths and measurements in CSS.\n      This unit is density-independent, and distinct from actual hardware pixels present\n      in a display. User agents and operating systems should ensure that a CSS pixel is\n      set as closely as possible to the\nCSS Values and Units Module Level 3 reference pixel\n[\ncss3-values\n], which takes into account the physical dimensions of the display\n      and the assumed viewing distance (factors that cannot be determined by content authors).\nessential\nif removed, would fundamentally change the information or functionality of the content,\nand\ninformation and functionality cannot be achieved in another way that would conform\npointer input\ninput from a device that can target a specific coordinate (or set of coordinates) on a screen,\n      such as a mouse, pen, or touch contact\nNote\nSee the\nPointer Events\n      definition for \"pointer\"\n[\npointerevents\n].\npresentation\nrendering of the\ncontent\nin a form to be perceived by users\nstructure\nThe way the parts of a\nweb page\nare organized in relation to each other; and\nThe way a collection of\nweb pages\nis organized\ntarget\nregion of the display that will accept a pointer action, such as the interactive area of a\nuser interface component\nNote\nIf two or more targets are overlapping, the overlapping area should not be included in the measurement of the target size, except when the overlapping targets perform the same action or open the same page.\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.\nuser interface component\na part of the content that is perceived by users as a single control for a distinct\n      function\nNote 1\nMultiple user interface components may be implemented as a single programmatic element.\n      \"Components\" here is not tied to programming techniques, but rather to what the user\n      perceives as separate controls.\nNote 2\nUser interface components include form elements and links as well as components generated\n      by scripts.\nNote 3\nWhat is meant by \"component\" or \"user interface component\" here is also sometimes\n      called \"user interface element\".\nExample\nAn applet has a \"control\" that can be used to move through content by line or page\n      or random access. Since each of these would need to have a name and be settable independently,\n      they would each be a \"user interface component.\"\nweb page\na non-embedded resource obtained from a single URI using HTTP plus any other resources\n      that are used in the rendering or intended to be rendered together with it by a\nuser agent\nNote 1\nAlthough any \"other resources\" would be rendered together with the primary resource,\n      they would not necessarily be rendered simultaneously with each other.\nNote 2\nFor the purposes of conformance with these guidelines, a resource must be \"non-embedded\"\n      within the scope of conformance to be considered a web page.\nExample 1\nA web resource including all embedded images and media.\nExample 2\nA web mail program built using Asynchronous JavaScript and XML (AJAX). The program\n      lives entirely at http://example.com/mail, but includes an inbox, a contacts area\n      and a calendar. Links or buttons are provided that cause the inbox, contacts, or calendar\n      to display, but do not change the URI of the page as a whole.\nExample 3\nA customizable portal site, where users can choose content to display from a set of\n      different content modules.\nExample 4\nWhen you enter \"http://shopping.example.com/\" in your browser, you enter a movie-like\n      interactive shopping environment where you visually move around in a store dragging\n      products off of the shelves around you and into a visual shopping cart in front of\n      you. Clicking on a product causes it to be demonstrated with a specification sheet\n      floating alongside. This might be a single-page website or just one page within a\n      website.",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.6_intent",
    "type": "sc",
    "sc_id": "2.5.6",
    "section": "intent",
    "text": "[2.5.6 Concurrent Input Mechanisms] (Level AAA)\nDescription: Web content does not restrict use of input modalities available on a platform except where the restriction is essential, required to ensure the security of the content, or required to respect user settings.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to ensure that people can use and switch between different modes of input when interacting with web content. Users may employ a variety of input mechanisms when interacting with web content. These may be a combination of mechanisms such as a keyboard or keyboard-like interfaces and pointer devices like a mouse, stylus or touchscreen.\nEven though a device may have a primary input mechanism, the user may choose to employ alternative input mechanisms when interacting with the device. For example, the primary mechanism for mobile phones and tablets is the touchscreen.  The user of these devices may choose to use a paired mouse or external keyboard as an alternative to using the touchscreen.\nUsers should be able to switch input mechanisms at any point should the user determine that certain tasks and interactions are more easily accomplished by using an alternative input mechanism. Content must not limit the user's interaction to any particular input mechanism unless the restriction is essential, or is required to ensure the security of the content or to respect user settings.\nNote: A touch-typing web application, which teaches users how to touch-type on a keyboard and/or measures their proficiency and speed, would be an example of an essential limitation to a particular input mechanism.",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.6_success_criterion",
    "type": "sc",
    "sc_id": "2.5.6",
    "section": "success_criterion",
    "text": "[2.5.6 Concurrent Input Mechanisms] (Level AAA)\nDescription: Web content does not restrict use of input modalities available on a platform except where the restriction is essential, required to ensure the security of the content, or required to respect user settings.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nWeb content does not restrict use of input modalities available on a platform except where the restriction is\nessential\n, required to ensure the security of the content, or required to respect user settings.",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.6_benefits",
    "type": "sc",
    "sc_id": "2.5.6",
    "section": "benefits",
    "text": "[2.5.6 Concurrent Input Mechanisms] (Level AAA)\nDescription: Web content does not restrict use of input modalities available on a platform except where the restriction is essential, required to ensure the security of the content, or required to respect user settings.\n\nSection: benefits\n\nBenefits\nUsers can interact with web content with whichever input mechanism is preferred and available to them.\nUsers may switch between input mechanisms when they desire or the circumstances require it.\nUsers are allowed to add and remove input mechanisms at any point, where supported by the operating system.",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.6_examples",
    "type": "sc",
    "sc_id": "2.5.6",
    "section": "examples",
    "text": "[2.5.6 Concurrent Input Mechanisms] (Level AAA)\nDescription: Web content does not restrict use of input modalities available on a platform except where the restriction is essential, required to ensure the security of the content, or required to respect user settings.\n\nSection: examples\n\nExamples\nA user with mobility impairment pairs a mouse and keyboard to a mobile phone with a touchscreen. The phone can thereafter be operated by those input devices and the content does not accept the touchscreen as the only input mechanism.\nOn a touch-enabled laptop with coarse precision, people who have difficulty activating a small target because of hand tremors, limited dexterity or other reasons are still able to interact with content using their keyboard and trackpad.\nA user starts interacting with a page using a desktop keyboard, and then attaches a secondary touch-enabled monitor. Content can be operated using this newly added input mechanism and does not assume that the keyboard, the first input mechanism it detected, is the only one in use.\nA speech input user navigates content using voice commands which translate to simulate mouse (and keyboard) commands. When talking with a colleague, however, the user turns speech recognition off and uses the mouse instead.\nA user opens a menu with a mouse, and then navigates between the menu items with arrow keys.",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.6_brief",
    "type": "sc",
    "sc_id": "2.5.6",
    "section": "brief",
    "text": "[2.5.6 Concurrent Input Mechanisms] (Level AAA)\nDescription: Web content does not restrict use of input modalities available on a platform except where the restriction is essential, required to ensure the security of the content, or required to respect user settings.\n\nSection: brief\n\nIn Brief\nGoal\nUsers can choose different ways of inputting content.\nWhat to do\nDo not prevent users from switching their mode of input.\nWhy it's important\nPeople may not be able to work using just one input method.",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.6_resources",
    "type": "sc",
    "sc_id": "2.5.6",
    "section": "resources",
    "text": "[2.5.6 Concurrent Input Mechanisms] (Level AAA)\nDescription: Web content does not restrict use of input modalities available on a platform except where the restriction is essential, required to ensure the security of the content, or required to respect user settings.\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nW3C Pointer Events - Level 2\nPatrick H. Lauke - Detecting touch: it's the 'why', not the 'how'\nChris Wilson / Paul Kinlan: Touch And Mouse - Together Again For The First Time\nW3C Touch Events - Level 2: Interaction with Mouse Events and click\nW3C CSS Media Queries Level 4: Interaction Media Features",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.6_key_terms",
    "type": "sc",
    "sc_id": "2.5.6",
    "section": "key_terms",
    "text": "[2.5.6 Concurrent Input Mechanisms] (Level AAA)\nDescription: Web content does not restrict use of input modalities available on a platform except where the restriction is essential, required to ensure the security of the content, or required to respect user settings.\n\nSection: key_terms\n\nKey Terms\nessential\nif removed, would fundamentally change the information or functionality of the content,\nand\ninformation and functionality cannot be achieved in another way that would conform",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.6_sufficient",
    "type": "sc_sufficient",
    "sc_id": "2.5.6",
    "techniques": [
      "Example 1 in Pointer Events Level 2",
      "Example 1 in Pointer Events Level 2"
    ],
    "text": "[2.5.6 Concurrent Input Mechanisms] (Level AAA)\nDescription: Web content does not restrict use of input modalities available on a platform except where the restriction is essential, required to ensure the security of the content, or required to respect user settings.\n\nSufficient techniques for SC 2.5.6 (no situation): Example 1 in Pointer Events Level 2, Example 1 in Pointer Events Level 2",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.6_failures",
    "type": "sc_failures",
    "sc_id": "2.5.6",
    "techniques": [
      "F98"
    ],
    "text": "[2.5.6 Concurrent Input Mechanisms] (Level AAA)\nDescription: Web content does not restrict use of input modalities available on a platform except where the restriction is essential, required to ensure the security of the content, or required to respect user settings.\n\nCommon failures for SC 2.5.6: F98",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.7_intent",
    "type": "sc",
    "sc_id": "2.5.7",
    "section": "intent",
    "text": "[2.5.7 Dragging Movements] (Level AA)\nDescription: New\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to ensure functionality that uses a dragging movement has another\nsingle pointer\nmode of operation without the need for the dexterity required to drag elements.\nSome people cannot perform dragging movements in a precise manner. Others use a specialized or adapted input device, such as a trackball, head pointer, eye-gaze system, or speech-controlled mouse emulator, which may make dragging cumbersome and error-prone.\nWhen an interface implements functionality that uses dragging movements, users perform four discrete actions:\ntap or click to establish a starting point, then\npress and hold that contact while...\nperforming a repositioning of the pointer, before...\nreleasing the pointer at the end point.\nNot all users can accurately press and hold that contact while also repositioning the pointer. An alternative method must be provided so that users with mobility impairments who use a pointer (mouse, pen, or touch contact) can use the functionality.\nThis requirement is separate from keyboard accessibility because people using a touch screen device may not use a physical keyboard. Keyboard specific interactions such as tabbing or arrow keys may not be possible when encountering a drag and drop control. Note, however, that providing a text input can be an acceptable single-pointer alternative to dragging. For example, an input beside a slider could allow any user to enter a precise value for the slider. In such a situation, the on-screen keyboard that appears for touch users offers a single-pointer means of entering an alphanumeric value.\nThis criterion does not apply to scrolling enabled by the user-agent. Scrolling a page is not in scope, nor is using a technique such as\nCSS\noverflow\nto make a section of content scrollable.\nRelationship to other requirements\nSuccess Criteria 2.1.1 Keyboard and 2.1.3 Keyboard (No Exception) require dragging features to be keyboard accessible. However, achieving keyboard equivalence for a dragging operation does not automatically meet this success criterion. It is possible to create an interface that works with dragging and keyboard controls that does not work using only clicks or taps. While many designs can be created for a dragging alternative which address both keyboard accessibility and operability by single pointer operation, the two requirements should be assessed independently.\nThis success criterion applies to dragging movements as opposed to pointer gestures, which are covered in\nSuccess Criterion 2.5.1 Pointer Gestures\n. Pointer gestures include directional path-based as well as multi-point gestures. In contrast, for dragging movements, only the start and end point of the movement matters, not the actual path.\nAdditional examples are selection rectangles that set the first x/y rectangle coordinate at the pointer position via a pointer down-event, and the second x/y coordinate, after a dragging movement, at the next up-event. A similar example is a connecting line drawn between two different items on the screen, as in an allocation test where users are required to draw a line between questions and corresponding answers. In these cases, the dragging movement requires an alternative way to accomplish the same action that does not rely on the dragging movement. For example, two separate single tap or click actions may define the rectangle coordinates or the start and end points of a connecting line.\nAlternatives for dragging movements on the same page\nWhere functionality can be executed via dragging movements and an equivalent option exists that allows for single-pointer access without dragging, this success criterion is passed. It does not have to be the same component, so long as the functionality is equivalent. An example is a color wheel where a color can be changed by dragging an indicator. In addition, text fields for the numerical input of color values allow the definition of a color without requiring dragging movements. (Note that a text input is considered device agnostic; although the purpose is to enter characters, text entry can take place through voice, pointer or keyboard.)\nDistinguishing dragging movements from path-based pointer gestures\nDragging movements covered in this success criterion are pointer interactions where only the start- and endpoints matter. Once the pointer engages with a target, the direction of the dragging movement does not factor into the interaction until the pointer disengages the target. Since the dragging movement does not have an intermediate point, the dragging movement can go in any direction. Path-based gestures are covered in\nSuccess Criterion 2.5.1 Pointer Gestures\n.",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.7_success_criterion",
    "type": "sc",
    "sc_id": "2.5.7",
    "section": "success_criterion",
    "text": "[2.5.7 Dragging Movements] (Level AA)\nDescription: New\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nAll\nfunctionality\nthat uses a\ndragging movement\nfor operation can be achieved by a\nsingle pointer\nwithout dragging, unless dragging is\nessential\nor the functionality is determined by the\nuser agent\nand not modified by the author.\nNote\nThis requirement applies to web content that interprets pointer actions (i.e., this does not apply to actions that are required to operate the user agent or assistive technology).",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.7_benefits",
    "type": "sc",
    "sc_id": "2.5.7",
    "section": "benefits",
    "text": "[2.5.7 Dragging Movements] (Level AA)\nDescription: New\n\nSection: benefits\n\nBenefits\nUsers who struggle with performing dragging movements can still operate an interface with a pointer interface.",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.7_examples",
    "type": "sc",
    "sc_id": "2.5.7",
    "section": "examples",
    "text": "[2.5.7 Dragging Movements] (Level AA)\nDescription: New\n\nSection: examples\n\nExamples\nA map allows users to drag the view of the map around, and the map has up/down/left/right buttons to move the view as well.\nA sortable list of elements may, after tapping or clicking on a list element, provide adjacent controls for moving the element up or down in the list by simply tapping or clicking on those controls.\nA taskboard that allows users to drag and drop items between columns also provides an additional pop-up menu after tapping or clicking on items for moving the selected element to another column by tapping or clicking on pop-up menu entries.\nA radial control widget (color wheel) where the value can be set by dragging the marker for the currently selected color to another position, also allows picking another color value by tapping or clicking on another place in the color wheel.\nA linear slider control widget, where the value can be set by dragging the visual indicator (thumb) showing the current value, allows tapping or clicking on any point of the slider track to change the value and set the thumb to that position.\nA widget where you can drag a gift to one person in a photo of a group of people also has a menu alternative where users can select the person that should receive the gift from the menu.",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.7_brief",
    "type": "sc",
    "sc_id": "2.5.7",
    "section": "brief",
    "text": "[2.5.7 Dragging Movements] (Level AA)\nDescription: New\n\nSection: brief\n\nIn Brief\nGoal\nDon’t rely on dragging for user actions.\nWhat to do\nFor any action that involves dragging, provide a simple pointer alternative.\nWhy it's important\nSome people cannot use a mouse to drag items.",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.7_key_terms",
    "type": "sc",
    "sc_id": "2.5.7",
    "section": "key_terms",
    "text": "[2.5.7 Dragging Movements] (Level AA)\nDescription: New\n\nSection: key_terms\n\nKey Terms\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\ndown-event\nplatform event that occurs  when the trigger stimulus of a pointer is depressed\nThe down-event may have different names on different platforms, such as \"touchstart\" or \"mousedown\".\ndragging movement\nan operation where the pointer engages with an element on the\ndown-event\nand the element (or a representation of its position) follows the pointer until an\nup-event\nNote\nExamples of draggable elements include list items, text elements, and images.\nessential\nif removed, would fundamentally change the information or functionality of the content,\nand\ninformation and functionality cannot be achieved in another way that would conform\nfunctionality\nprocesses\nand outcomes achievable through user action\nprocess\nseries of user actions where each action is required in order to complete an activity\nExample 1\nSuccessful use of a series of web pages on a shopping site requires users to view\n      alternative products, prices and offers, select products, submit an order, provide\n      shipping information and provide payment information.\nExample 2\nAn account registration page requires successful completion of a\nTuring test\nbefore\n      the registration form can be accessed.\nsingle pointer\nan input modality that only targets a single point on the page/screen at a time – such as a mouse, single finger on a touch screen, or stylus.\nNote\nSingle pointer interactions include clicks, double clicks, taps, dragging motions, and single-finger swipe gestures. In contrast, multipoint interactions involve the use of two or more pointers at the same time, such as two-finger interactions on a touchscreen, or the simultaneous use of a mouse and stylus.\nup-event\nplatform event that occurs  when the trigger stimulus of a pointer is released\nThe up-event may have different names on different platforms, such as \"touchend\" or \"mouseup\".\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.7_sufficient",
    "type": "sc_sufficient",
    "sc_id": "2.5.7",
    "techniques": [
      "G219"
    ],
    "text": "[2.5.7 Dragging Movements] (Level AA)\nDescription: New\n\nSufficient techniques for SC 2.5.7 (no situation): G219",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.7_failures",
    "type": "sc_failures",
    "sc_id": "2.5.7",
    "techniques": [
      "F108"
    ],
    "text": "[2.5.7 Dragging Movements] (Level AA)\nDescription: New\n\nCommon failures for SC 2.5.7: F108",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.8_intent",
    "type": "sc",
    "sc_id": "2.5.8",
    "section": "intent",
    "text": "[2.5.8 Target Size (Minimum)] (Level AA)\nDescription: New\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to help ensure targets can be easily activated without accidentally activating an adjacent target.  Users with dexterity limitations and those who have difficulty with fine motor movement find it difficult to accurately activate small targets when there are other targets that are too close.  Providing sufficient size, or sufficient spacing between targets, will reduce the likelihood of accidentally activating the wrong control.\nDisabilities addressed by this requirement include hand tremors, spasticity, and quadriplegia.  Some people with disabilities use specialized input devices instead of a computer mouse or trackpad.  Typically these types of input device do not provide as much accuracy as mainstream pointing devices.  Meeting this requirement also ensures that touchscreen interfaces are easier to use.\nNote\nThis success criterion defines a\nminimum size\nand, if this can't be met, a\nminimum spacing\n. It is still possible to have very small, and difficult to activate, targets and meet the requirements of this Success Criterion, provided that the targets don't have any adjacent targets that are too close. However, using larger target sizes will help many people use targets more easily.\nAs a best practice\nit is recommended to at least meet the\nminimum size\nrequirement of the Success Criterion, regardless of spacing. For important links/controls, consider aiming for the stricter\n2.5.5 Target Size (Enhanced)\n.\nExceptions\nThe requirement is for targets to be at least 24 by 24 CSS pixels in size. There are five exceptions:\nSpacing:\nUndersized targets (those less than 24 by 24 CSS pixels) are positioned so that if a 24 CSS pixel diameter circle is centered on the\nbounding box\nof each, the circles do not intersect another target or the circle for another undersized target.\nEquivalent:\nIn cases where a target does not have a size equivalent to 24 by 24 CSS pixels, but there is another control that can achieve the underlying function that\ndoes\nmeet the requirements of this success criterion, the target can be excepted based on the \"Equivalent\" exception.\nInline:\nThe success criterion does not apply to inline targets in sentences, or where the size of the target is constrained by the line-height of non-target text. This exception is allowed because text reflow based on viewport size makes it impossible for authors to anticipate where links may be positioned relative to one another. Applying this success criterion when multiple links are embedded in blocks of smaller text often results in an undesirable design. It is more important to set the line height to a value that improves readability.\nUser agent control:\nBrowsers have default renderings of some controls, such as the days of the month calendar in an\n<input type=\"date\">\n. As long as the author has not modified the user agent default size, the target size for a\nUser agent control\nis excepted.\nEssential:\nIf the size and spacing of the targets is fundamental to the information being conveyed, the\nEssential\nexception applies. For example, in digital maps, the position of pins is analogous to the position of places shown on the map. If there are many pins close together, the spacing between pins and neighboring pins will often be below 24 CSS pixels. It is essential to show the pins at the correct map location, therefore the Essential exception applies. A similar example is an interactive data visualization where targets are necessarily dense. Another example is where jurisdictions legally require online forms to replicate paper forms, which can impose constraints on the size of targets. In such jurisdictions, any legal requirement to replicate small targets can be considered essential. When the \"Essential\" exception is applicable, authors are strongly encouraged to provide equivalent functionality through alternative means to the extent practical.\nSize requirement\nFor a target to be \"at least 24 by 24 CSS pixels\", it must be conceptually possible to draw a solid 24 by 24 CSS pixel square, aligned to the horizontal and vertical axis such that the square is completely within the target (does not extend outside the target's area).\nFigure 1.\nWhere targets are a 24 by 24px square (and larger is better), they meet the size requirement of the criterion and pass (image shown to scale -\nsee the scalable original version\n)\nThe 24 by 24px square has to be aligned with the page, although the target itself could be skewed.\nFigure 2.\nSo long as there is a solid 24 by 24px square within the target, it meets the size requirement of the criterion and passes (image shown to scale -\nsee the scalable original version\n)\nIf a target is not large enough to allow for a 24 by 24px square to be drawn inside it, it is considered\nundersized\n, and does not pass the size requirement of the success criterion. However, if it has sufficient space around it without adjacent targets, it may still pass the criterion thanks to the spacing exception (below).\nFigure 3.\nThe rounded corners do not leave sufficient space to draw a 24 by 24px square inside the target, making the target\nundersized\n. Depending on the spacing to other targets, it may still pass if it has sufficient clearance (image shown at 1:1 and 2:1 scale -\nsee the scalable original version\n)\nThe requirement is independent of the zoom factor of the page; when users zoom in, the CSS pixel size of elements does not change. This means that authors cannot meet it by claiming that the target will have enough spacing or sufficient size if the user zooms into the page.\nThe requirement does not apply to targets while they are obscured by content displayed as a result of a user interaction or scripted behavior of content, for example:\ninteracting with a combobox shows a dropdown list of suggestions\nactivating a button displays a modal dialog\ncontent displays a cookie banner after page load\ncontent displays a \"Take a survey\" dialog after some period of user inactivity\nThe requirement does however apply to targets in any new content that appears on top of other content.\nWhile the success criterion primarily helps touch users by providing target sizing to prevent accidental triggering of adjacent targets, it is also useful for mouse or pen users. It reduces the chances of erroneous activation due to either a tremor or reduced precision, whether because of reduced fine motor control or input imprecision.\nSpacing\nWhen the minimum size for a target is not met, spacing can at least improve the user experience. There is less chance of accidentally activating a neighboring target if a target is not immediately adjacent to another. Touchscreen devices and user agents generally have internal heuristics to identify which link or control is closest to a user's touch interaction - this means that sufficient spacing between targets can work as effectively as a larger target size itself.\nWhen a target is smaller than 24 by 24 CSS pixels, it is\nundersized\n. In this case, we check if it at least has sufficient\nspacing\nby drawing an imaginary 24 CSS pixel diameter circle over the undersized target, centered on the target's\nbounding box\n. For rectangular targets, the bounding box coincides with the target itself – thus, the circle is placed on the center of the target. If the target is\nnot\nrectangular – for instance, if the target is clipped, has rounded corners, or if it's a more complex clickable SVG shape – we need to first determine the bounding box, and then find the box's center. Note that for concave shapes, the center of the bounding box may be outside of the target itself. Now, we center the circle on the center of the bounding box.\nFigure 4.\nFor a square/rectangular target, the 24 CSS pixel diameter circle is centered on the target itself. For convex and concave targets, it is centered on the bounding box of the shape. Note the concave target, where in this case the center of the bounding box is outside of the actual target (image shown to scale -\nsee the scalable original version\n)\nWe repeat this process for all adjacent undersized targets. To determine if an undersized target has sufficient spacing (to pass this Success Criterion's spacing exception), we check that the 24 CSS pixel diameter circle of the target does not intersect another target or the circle of any other adjacent undersized targets.\nThe following example shows three versions of a horizontal row of six icon-based buttons:\nIn the top row, the dimensions of each target are 24 by 24 CSS pixels, passing this success criterion.\nIn the second row, the same targets are only 20 by 20 CSS pixels, but have a 4 CSS pixel space between them – as the target size is below 24 by 24 CSS pixels, these need to be evaluated against the Success Criterion's spacing exception, and they pass.\nIn the last row, the targets are again 20 by 20 CSS pixels, but have no space between them – these fail the spacing exception. This is because the imaginary 24 CSS pixel diameter circles over the targets would intersect.\nFigure 5.\nThree rows of targets, illustrating two ways of meeting this success criterion and one way of failing it (image shown to scale -\nsee the scalable original version\n)\nThe next two illustrations show sets of buttons which are only 16 CSS pixels tall. In the first set, there are no targets immediately above or below the buttons, so they pass. In the second illustration, there are further buttons, and they have been stacked on top of one another, resulting in a fail.\nFigure 6.\nWhile the height of the targets is only 16 CSS pixels, the lack of adjacent targets above and below means that the targets pass this success criterion (image shown to scale -\nsee the scalable original version\n)\nFigure 7.\nTwo rows of buttons, both with a height of only 16 CSS pixels. The rows are close, with only a 1 CSS pixel gap between them. This means that the 24 CSS pixel spacing circles of the targets in one row will\nintersect\nthe targets (and their circles, depending on their respective widths) in the other line, thus failing the success criterion. Image shown to scale -\nsee the scalable original version\n.\nThe following two illustrations show how menu items can be adjusted to properly meet this requirement. In the first illustration, the\nAbout us\nmenu has been activated, showing that each of the menu item targets has a 24 CSS pixel height (text and padding), and so passes. In the second illustration, the same menu is expanded, but the menu items only achieve 18 CSS pixels in height, and so fail.\nFigure 8.\nThe menu items with a height of 24 CSS pixels pass. For the menu items that are only 18 CSS pixels high, the 24 CSS pixel spacing circles of the targets in one row will intersect the adjacent menu item targets and circles, and fail (image shown to scale -\nsee the scalable original version\n)\nThe following example has one large target (an image that links to a new page related to that image) and a very small second target (a control with a magnifier icon to open a zoomed-in preview, possibly in a modal, of the image).\nIn the top row, the small target overlaps - or, to be more technically accurate,\nclips\n- the large target. The small target itself has a size of 24 by 24 CSS pixels, so passes. In the second row, we see that if the second target is any smaller – in this case 16 by 16 CSS pixels – it fails the criterion, as the imaginary circle with a 24 CSS pixel diameter we draw over the small target will intersect the large target itself.\nFigure 9.\nThe 24 by 24 CSS pixel small target passes, while the 16 by 16 CSS pixel small target fails, since the 24 CSS pixel diameter circle used for undersized targets intersect the large target (image shown to scale -\nsee the scalable original version\n)\nIn the following example, we have the same two targets – a large target and a small target. This time, the small target touches/abuts the large target. If the small target is smaller than 24 by 24 CSS pixels, the imaginary circle with a 24 CSS pixel diameter we draw over the small target will intersect the large target itself, failing the requirement. The undersized target must be spaced further away from the large target until its circle doesn't intersect the large target.\nFigure 10.\nIn the first row, the 16 by 16 CSS pixel target touching/abutting the large target fails, as its 24 CSS pixel diameter circle used for undersized targets intersects the large target. In the second row we see that the only way the undersized target can pass is by adding a 4 CSS pixel spacing gap between the targets (image shown to scale -\nsee the scalable original version\n)\nNote\nUsers with different disabilities have different needs for control sizes. It can be beneficial to provide an option to increase the active target area without increasing the visible target size. Another option is to provide a mechanism to control the density of layout and thereby change target size or spacing, or both. This can be beneficial for a wide range of users. For example, users with visual field loss may prefer a more condensed layout with smaller sized controls while users with other forms of low vision may prefer large controls.\nUser agent control\nThis success criterion has an exception for the size of targets determined by a user agent and not modified by the author. An example of this kind of target is a browser's scrollbars. If a scrollbar's dimensions have been modified by the author then there must be a passing amount of spacing between the scrollbar and the content of the page. The following example shows a passing and a failing design.\nFigure 11.\nThe passing example has enough space between the link and the scrollbar for a 24 CSS pixel diameter circle, placed over the scrollbar, to not overlap the link. The failing example has no space between the link and the scrollbar, which fails the criterion because the 24 CSS pixel diameter circle overlaps the link. (Image shown to scale -\nsee the scalable original version\n)",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.8_success_criterion",
    "type": "sc",
    "sc_id": "2.5.8",
    "section": "success_criterion",
    "text": "[2.5.8 Target Size (Minimum)] (Level AA)\nDescription: New\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nThe size of the\ntarget\nfor\npointer inputs\nis at least 24 by 24\nCSS pixels\n, except when:\nSpacing\nUndersized targets (those less than 24 by 24 CSS pixels) are positioned so that if a 24 CSS pixel diameter circle is centered on the\nbounding box\nof each, the circles do not intersect another target or the circle for another undersized target;\nEquivalent\nThe function can be achieved through a different control on the same page that meets this criterion;\nInline\nThe target is in a sentence or its size is otherwise constrained by the line-height of non-target text;\nUser Agent Control\nThe size of the target is determined by the\nuser agent\nand is not modified by the author;\nEssential\nA particular\npresentation\nof the target is\nessential\nor is legally required for the information being conveyed.\nNote 1\nTargets that allow for values to be selected spatially based on position within the target are considered one target for the purpose of the success criterion. Examples include sliders, color pickers displaying a gradient of colors, or editable areas where you position the cursor.\nNote 2\nFor inline targets the line-height should be interpreted as perpendicular to the flow of text. For example, in a language displayed vertically, the line-height would be horizontal.",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.8_benefits",
    "type": "sc",
    "sc_id": "2.5.8",
    "section": "benefits",
    "text": "[2.5.8 Target Size (Minimum)] (Level AA)\nDescription: New\n\nSection: benefits\n\nBenefits\nHaving targets with sufficient size - or at least sufficient target spacing - can help all users who may have difficulty in confidently targeting or operating small controls. Users who benefit include, but are not limited to:\nPeople who use a mobile device where the touch screen is the primary mode of interaction;\nPeople using mouse, stylus or touch input who have mobility impairments such as hand tremors;\nPeople using a device in environments where they are exposed to shaking such as public transportation;\nMouse users who have difficulty with fine motor movements;\nPeople who access a device using one hand;\nPeople with large fingers, or who are operating the device with only a part of their finger or knuckle.",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.8_examples",
    "type": "sc",
    "sc_id": "2.5.8",
    "section": "examples",
    "text": "[2.5.8 Target Size (Minimum)] (Level AA)\nDescription: New\n\nSection: examples\n\nExamples\nThree buttons are on-screen and the target size of each button is 24 by 24 CSS pixels. Since the target size itself is 24 by 24 CSS pixels, no additional spacing is required, the success criterion passes.\nA row of buttons, each of which has a horizontal width of more than 24 CSS pixels, a height of only 20 CSS pixels, and vertical margin of 4 CSS pixels above and below the row of buttons. Since there is sufficient spacing both above and below the row of buttons, the success criterion passes.\nLinks within a paragraph of text have varying target dimensions. Links within paragraphs of text do not need to meet the 24 by 24 CSS pixels requirements, so the success criterion passes.",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.8_brief",
    "type": "sc",
    "sc_id": "2.5.8",
    "section": "brief",
    "text": "[2.5.8 Target Size (Minimum)] (Level AA)\nDescription: New\n\nSection: brief\n\nIn Brief\nGoal\nMake controls easier to activate.\nWhat to do\nEnsure targets meet a minimum size or have sufficient spacing around them.\nWhy it's important\nSome people with physical impairments cannot click small buttons that are close together.",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.8_resources",
    "type": "sc",
    "sc_id": "2.5.8",
    "section": "resources",
    "text": "[2.5.8 Target Size (Minimum)] (Level AA)\nDescription: New\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nTarget size study for one-handed thumb use on small touchscreen devices",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.8_key_terms",
    "type": "sc",
    "sc_id": "2.5.8",
    "section": "key_terms",
    "text": "[2.5.8 Target Size (Minimum)] (Level AA)\nDescription: New\n\nSection: key_terms\n\nKey Terms\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\nblocks of text\nmore than one sentence of text\ncontent\ninformation and sensory experience to be communicated to the user by means of a\nuser agent\n, including code or markup that defines the content's\nstructure\n,\npresentation\n, and interactions\nCSS pixel\nvisual angle of about 0.0213 degrees\nA CSS pixel is the canonical unit of measure for all lengths and measurements in CSS.\n      This unit is density-independent, and distinct from actual hardware pixels present\n      in a display. User agents and operating systems should ensure that a CSS pixel is\n      set as closely as possible to the\nCSS Values and Units Module Level 3 reference pixel\n[\ncss3-values\n], which takes into account the physical dimensions of the display\n      and the assumed viewing distance (factors that cannot be determined by content authors).\nessential\nif removed, would fundamentally change the information or functionality of the content,\nand\ninformation and functionality cannot be achieved in another way that would conform\nminimum bounding box\nthe smallest enclosing rectangle aligned to the horizontal axis within which all the points of a shape lie. For components which wrap onto multiple lines as part of a sentence or\nblock of text\n(such as hypertext links), the bounding box is based on how the component would appear on a single line.\npointer input\ninput from a device that can target a specific coordinate (or set of coordinates) on a screen,\n      such as a mouse, pen, or touch contact\nNote\nSee the\nPointer Events\n      definition for \"pointer\"\n[\npointerevents\n].\npresentation\nrendering of the\ncontent\nin a form to be perceived by users\nstructure\nThe way the parts of a\nweb page\nare organized in relation to each other; and\nThe way a collection of\nweb pages\nis organized\ntarget\nregion of the display that will accept a pointer action, such as the interactive area of a\nuser interface component\nNote\nIf two or more targets are overlapping, the overlapping area should not be included in the measurement of the target size, except when the overlapping targets perform the same action or open the same page.\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.\nuser interface component\na part of the content that is perceived by users as a single control for a distinct\n      function\nNote 1\nMultiple user interface components may be implemented as a single programmatic element.\n      \"Components\" here is not tied to programming techniques, but rather to what the user\n      perceives as separate controls.\nNote 2\nUser interface components include form elements and links as well as components generated\n      by scripts.\nNote 3\nWhat is meant by \"component\" or \"user interface component\" here is also sometimes\n      called \"user interface element\".\nExample\nAn applet has a \"control\" that can be used to move through content by line or page\n      or random access. Since each of these would need to have a name and be settable independently,\n      they would each be a \"user interface component.\"\nweb page\na non-embedded resource obtained from a single URI using HTTP plus any other resources\n      that are used in the rendering or intended to be rendered together with it by a\nuser agent\nNote 1\nAlthough any \"other resources\" would be rendered together with the primary resource,\n      they would not necessarily be rendered simultaneously with each other.\nNote 2\nFor the purposes of conformance with these guidelines, a resource must be \"non-embedded\"\n      within the scope of conformance to be considered a web page.\nExample 1\nA web resource including all embedded images and media.\nExample 2\nA web mail program built using Asynchronous JavaScript and XML (AJAX). The program\n      lives entirely at http://example.com/mail, but includes an inbox, a contacts area\n      and a calendar. Links or buttons are provided that cause the inbox, contacts, or calendar\n      to display, but do not change the URI of the page as a whole.\nExample 3\nA customizable portal site, where users can choose content to display from a set of\n      different content modules.\nExample 4\nWhen you enter \"http://shopping.example.com/\" in your browser, you enter a movie-like\n      interactive shopping environment where you visually move around in a store dragging\n      products off of the shelves around you and into a visual shopping cart in front of\n      you. Clicking on a product causes it to be demonstrated with a specification sheet\n      floating alongside. This might be a single-page website or just one page within a\n      website.",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "2.5.8_sufficient",
    "type": "sc_sufficient",
    "sc_id": "2.5.8",
    "techniques": [
      "C42"
    ],
    "text": "[2.5.8 Target Size (Minimum)] (Level AA)\nDescription: New\n\nSufficient techniques for SC 2.5.8 (no situation): C42",
    "principle": "Operable",
    "guideline": "2.5 Input Modalities"
  },
  {
    "id": "3.1.1_intent",
    "type": "sc",
    "sc_id": "3.1.1",
    "section": "intent",
    "text": "[3.1.1 Language of Page] (Level A)\nDescription: The default human language of each web page can be programmatically determined.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to ensure that content developers provide\n         information in the web page that user agents need to present text and other linguistic\n         content correctly. Both assistive technologies and conventional user agents can render\n         text more accurately when the language of the web page is identified. Screen readers\n         can load the correct pronunciation rules. Visual browsers can display characters and\n         scripts correctly. Media players can show captions correctly. As a result, users with\n         disabilities will be better able to understand the content.\nThe default human language of the web page is the default text-processing language\n         as discussed in\nInternationalization Best Practices: Specifying Language in XHTML & HTML Content\n. When a web page uses several languages, the default text-processing language is\n         the language which is used most. (If several languages are used equally, the first\n         language used should be chosen as the default human language.)\nNote\nFor multilingual sites targeting Conformance Level A, the Working Group strongly encourages\n            developers to follow Success Criterion 3.1.2 as well even though that is a Level AA\n            success criterion.",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.1_success_criterion",
    "type": "sc",
    "sc_id": "3.1.1",
    "section": "success_criterion",
    "text": "[3.1.1 Language of Page] (Level A)\nDescription: The default human language of each web page can be programmatically determined.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nThe default\nhuman language\nof each\nweb page\ncan be\nprogrammatically determined\n.",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.1_benefits",
    "type": "sc",
    "sc_id": "3.1.1",
    "section": "benefits",
    "text": "[3.1.1 Language of Page] (Level A)\nDescription: The default human language of each web page can be programmatically determined.\n\nSection: benefits\n\nBenefits\nThis success criterion helps:\npeople who use screen readers or other technologies that convert text into synthetic\n            speech;\npeople who find it difficult to read written material with fluency and accuracy, such\n            as recognizing characters and alphabets or decoding words;\npeople with certain cognitive, language and learning disabilities who use text-to-speech\n            software\npeople who rely on captions for synchronized media.",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.1_examples",
    "type": "sc",
    "sc_id": "3.1.1",
    "section": "examples",
    "text": "[3.1.1 Language of Page] (Level A)\nDescription: The default human language of each web page can be programmatically determined.\n\nSection: examples\n\nExamples\nExample 1. A web page with content in two languages\nA web page produced in Germany and written in HTML includes content in both German\n               and English, but most of the content is in German. The default human language is identified\n               as German (de) by the lang attribute on the html element.",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.1_brief",
    "type": "sc",
    "sc_id": "3.1.1",
    "section": "brief",
    "text": "[3.1.1 Language of Page] (Level A)\nDescription: The default human language of each web page can be programmatically determined.\n\nSection: brief\n\nIn Brief\nGoal\nAssistive technology can determine the language of a page.\nWhat to do\nIndicate the predominant language on a page.\nWhy it's important\nPeople using assistive technology get information in the correct language.",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.1_resources",
    "type": "sc",
    "sc_id": "3.1.1",
    "section": "resources",
    "text": "[3.1.1 Language of Page] (Level A)\nDescription: The default human language of each web page can be programmatically determined.\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nInternationalization Best Practices: Specifying Language in XHTML & HTML Content",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.1_test_rules",
    "type": "sc",
    "sc_id": "3.1.1",
    "section": "test_rules",
    "text": "[3.1.1 Language of Page] (Level A)\nDescription: The default human language of each web page can be programmatically determined.\n\nSection: test_rules\n\nTest Rules\nThe following are Test Rules\n    for certain aspects of this Success Criterion.\n    It is not necessary to use these particular Test Rules to check for conformance with WCAG, but they are defined and approved test methods.\n    For information on using Test Rules, see\nUnderstanding Test Rules for WCAG Success Criteria\n.\nHTML page has lang attribute\nHTML page lang attribute has valid language tag\nHTML page lang and xml:lang attributes have matching values\nHTML page language subtag matches default language",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.1_key_terms",
    "type": "sc",
    "sc_id": "3.1.1",
    "section": "key_terms",
    "text": "[3.1.1 Language of Page] (Level A)\nDescription: The default human language of each web page can be programmatically determined.\n\nSection: key_terms\n\nKey Terms\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\nhuman language\nlanguage that is spoken, written or signed (through visual or tactile means) to communicate\n      with humans\nNote\nSee also\nsign language\n.\nprogrammatically determined\ndetermined by software from author-supplied data provided in a way that different\nuser agents\n, including\nassistive technologies\n, can extract and present this information to users in different modalities\nExample 1\nDetermined in a markup language from elements and attributes that are accessed directly\n      by commonly available assistive technology.\nExample 2\nDetermined from technology-specific data structures in a non-markup language and exposed\n      to assistive technology via an accessibility API that is supported by commonly available\n      assistive technology.\nsign language\na language using combinations of movements of the hands and arms, facial expressions,\n      or body positions to convey meaning\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.\nweb page\na non-embedded resource obtained from a single URI using HTTP plus any other resources\n      that are used in the rendering or intended to be rendered together with it by a\nuser agent\nNote 1\nAlthough any \"other resources\" would be rendered together with the primary resource,\n      they would not necessarily be rendered simultaneously with each other.\nNote 2\nFor the purposes of conformance with these guidelines, a resource must be \"non-embedded\"\n      within the scope of conformance to be considered a web page.\nExample 1\nA web resource including all embedded images and media.\nExample 2\nA web mail program built using Asynchronous JavaScript and XML (AJAX). The program\n      lives entirely at http://example.com/mail, but includes an inbox, a contacts area\n      and a calendar. Links or buttons are provided that cause the inbox, contacts, or calendar\n      to display, but do not change the URI of the page as a whole.\nExample 3\nA customizable portal site, where users can choose content to display from a set of\n      different content modules.\nExample 4\nWhen you enter \"http://shopping.example.com/\" in your browser, you enter a movie-like\n      interactive shopping environment where you visually move around in a store dragging\n      products off of the shelves around you and into a visual shopping cart in front of\n      you. Clicking on a product causes it to be demonstrated with a specification sheet\n      floating alongside. This might be a single-page website or just one page within a\n      website.",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.1_sufficient",
    "type": "sc_sufficient",
    "sc_id": "3.1.1",
    "techniques": [
      "H57",
      "PDF16",
      "PDF19"
    ],
    "text": "[3.1.1 Language of Page] (Level A)\nDescription: The default human language of each web page can be programmatically determined.\n\nSufficient techniques for SC 3.1.1 (no situation): H57, PDF16, PDF19",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.1_advisory",
    "type": "sc_advisory",
    "sc_id": "3.1.1",
    "techniques": [
      "SVR5"
    ],
    "text": "[3.1.1 Language of Page] (Level A)\nDescription: The default human language of each web page can be programmatically determined.\n\nAdvisory techniques for SC 3.1.1: SVR5",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.2_intent",
    "type": "sc",
    "sc_id": "3.1.2",
    "section": "intent",
    "text": "[3.1.2 Language of Parts] (Level AA)\nDescription: The human language of each passage or phrase in the content can be programmatically determined except for proper names, technical terms, words of indeterminate language, and words\n      or phrases that have become part of the vernacular of the immediately surrounding\n     text.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to ensure that user agents can correctly present\n          phrases, passages, and in some cases words written in multiple languages. This makes it possible for user agents and\n         assistive technologies to present content according to the  presentation and pronunciation\n         rules for that language. This applies to graphical browsers as well as screen readers,\n         braille displays, and other voice browsers.\nBoth assistive technologies and conventional user agents can render text more accurately\n         if the language of each passage of text is identified. Screen readers can use the\n         pronunciation rules of the language of the text. Visual browsers can display characters\n         and scripts in appropriate ways. This is especially important when switching between\n         languages that read from left to right and languages that read from right to left,\n         or when text is rendered in a language that uses a different alphabet. Users with\n         disabilities who know all the languages used in the web page will be better able to\n         understand the content when each passage is rendered appropriately.\nWhen no other language has been specified for a phrase or passage of text, its human\n         language is the default human language of the web page (see\nSuccess Criterion 3.1.1\n).\n         So the human language of all content in single language documents can be programmatically\n         determined.\nIndividual words or phrases in one language can become part of another language. For\n         example, \"rendezvous\" is a French word that has been adopted in English, appears in\n         English dictionaries, and is properly pronounced by English screen readers. Hence\n         a passage of English text may contain the word \"rendezvous\" without specifying that\n         its human language is French and still satisfy this success criterion. Frequently,\n         when the human language of text appears to be changing for a single word, that word\n         has become part of the language of the surrounding text. Because this is so common\n         in some languages, single words should be considered part of the language of the surrounding\n         text unless it is clear that a change in language was intended. If there is doubt\n         whether a change in language is intended, consider whether the word would be pronounced\n         the same (except for accent or intonation) in the language of the immediately surrounding\n         text.\nMost professions require frequent use of technical terms which may originate from\n         a foreign language. Such terms are usually not translated to all languages. The universal\n         nature of technical terms also facilitate communication between professionals.\nSome common examples of technical terms include: Homo sapiens, Alpha Centauri, hertz,\n         and habeas corpus.\nIdentifying changes in language is important for a number of reasons:\nIt allows braille translation software to follow changes in language, e.g., substitute\n            control codes for accented characters, and insert control codes necessary to prevent\n            erroneous creation of Grade 2 braille contractions.\nSpeech synthesizers that support multiple languages will be able to speak the text\n            in the appropriate accent with proper pronunciation. If changes are not marked, the\n            synthesizer will try its best to speak the words in the  default language it works\n            in. Thus, the French word for car, \"\nvoiture\n\" would be pronounced \"voyture\" by a speech\n            synthesizer that uses English as its default language.\nMarking changes in language can benefit future developments in technology, for example\n            users who are unable to translate between languages themselves will be able to use\n            machines to translate unfamiliar languages.\nMarking changes in language can also assist user agents in providing definitions using\n            a dictionary.",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.2_success_criterion",
    "type": "sc",
    "sc_id": "3.1.2",
    "section": "success_criterion",
    "text": "[3.1.2 Language of Parts] (Level AA)\nDescription: The human language of each passage or phrase in the content can be programmatically determined except for proper names, technical terms, words of indeterminate language, and words\n      or phrases that have become part of the vernacular of the immediately surrounding\n     text.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nThe\nhuman language\nof each passage or phrase in the content can be\nprogrammatically determined\nexcept for proper names, technical terms, words of indeterminate language, and words\n      or phrases that have become part of the vernacular of the immediately surrounding\ntext\n.",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.2_benefits",
    "type": "sc",
    "sc_id": "3.1.2",
    "section": "benefits",
    "text": "[3.1.2 Language of Parts] (Level AA)\nDescription: The human language of each passage or phrase in the content can be programmatically determined except for proper names, technical terms, words of indeterminate language, and words\n      or phrases that have become part of the vernacular of the immediately surrounding\n     text.\n\nSection: benefits\n\nBenefits\nThis success criterion helps:\npeople who use screen readers or other technologies that convert text into synthetic\n            speech;\npeople who find it difficult to read written material with fluency and accuracy, such\n            as recognizing characters and alphabets, decoding words, and understanding words and\n            phrases;\npeople with certain cognitive, language and learning disabilities who use text-to-speech\n            software;\npeople who rely on captions to recognize language changes in the soundtrack of synchronized\n            media content.",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.2_examples",
    "type": "sc",
    "sc_id": "3.1.2",
    "section": "examples",
    "text": "[3.1.2 Language of Parts] (Level AA)\nDescription: The human language of each passage or phrase in the content can be programmatically determined except for proper names, technical terms, words of indeterminate language, and words\n      or phrases that have become part of the vernacular of the immediately surrounding\n     text.\n\nSection: examples\n\nExamples\nA German phrase in an English sentence\nIn the sentence, \"He maintained that the DDR (German Democratic Republic) was just a '\nTreppenwitz der Weltgeschichte\n',\" the German phrase '\nTreppenwitz der Weltgeschichte\n' is marked as German. Depending on the markup language, English may either be marked as the language for the entire document except where specified, or marked at the paragraph level. When a screen reader encounters the German phrase, it changes pronunciation rules from English to German to pronounce the word correctly.\nAlternative language links\nAn HTML web page includes links to versions of the page in other languages (e.g.,\nDeutsch\n,\nFrançais\n,\nNederlands\n,\nCatalan\n, etc.). The text of each link is the name of the language, in that language. The language of each link is indicated via a\nlang\nattribute.\n<ul>\n  <li><a href=\"...\" lang=\"de\">Deutsch</a></li>\n  <li><a href=\"...\" lang=\"it\">Italiano</a></li>\n  <li><a href=\"...\" lang=\"fr\">Français</a></li>\n  ...\n  <li><a href=\"...\" lang=\"zh-hant\">繁體中文</a></li>\n</ul>\n\"Podcast\" used in a French sentence\nBecause \"podcast\" is part of the vernacular of the immediately surrounding text in the following excerpt, \"\nÀ l'occasion de l'exposition \"Energie éternelle. 1500 ans d'art indien\", le Palais des Beaux-Arts de Bruxelles a lancé son premier podcast. Vous pouvez télécharger ce podcast au format M4A et MP3\n\", no indication of language change is required.\nThe element's content and attribute values are in different languages\nThis example assumes that the page's default content is in English. The link's\ntitle\nattribute is in English, but the nested\nspan\nelement that contains the word\nEspañol\nhas a\nlang=\"es\"\nattribute.\n<a title=\"Spanish\" href=\"qa-html-language-declarations-es.html\"><span lang=\"es\">Español</span></a>",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.2_brief",
    "type": "sc",
    "sc_id": "3.1.2",
    "section": "brief",
    "text": "[3.1.2 Language of Parts] (Level AA)\nDescription: The human language of each passage or phrase in the content can be programmatically determined except for proper names, technical terms, words of indeterminate language, and words\n      or phrases that have become part of the vernacular of the immediately surrounding\n     text.\n\nSection: brief\n\nIn Brief\nGoal\nAssistive technology can identify the languages used within a page.\nWhat to do\nIndicate when words are in a different language.\nWhy it's important\nPeople using assistive technology get information in the correct language.",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.2_resources",
    "type": "sc",
    "sc_id": "3.1.2",
    "section": "resources",
    "text": "[3.1.2 Language of Parts] (Level AA)\nDescription: The human language of each passage or phrase in the content can be programmatically determined except for proper names, technical terms, words of indeterminate language, and words\n      or phrases that have become part of the vernacular of the immediately surrounding\n     text.\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nHTML - The\nlang\nand\nxml:lang\nattributes\n.\nLanguage tags in HTML and XML\n.\nAuthoring HTML: Language declarations\n.",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.2_test_rules",
    "type": "sc",
    "sc_id": "3.1.2",
    "section": "test_rules",
    "text": "[3.1.2 Language of Parts] (Level AA)\nDescription: The human language of each passage or phrase in the content can be programmatically determined except for proper names, technical terms, words of indeterminate language, and words\n      or phrases that have become part of the vernacular of the immediately surrounding\n     text.\n\nSection: test_rules\n\nTest Rules\nThe following are Test Rules\n    for certain aspects of this Success Criterion.\n    It is not necessary to use these particular Test Rules to check for conformance with WCAG, but they are defined and approved test methods.\n    For information on using Test Rules, see\nUnderstanding Test Rules for WCAG Success Criteria\n.\nElement with lang attribute has valid language tag\nHTML element language subtag matches language",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.2_key_terms",
    "type": "sc",
    "sc_id": "3.1.2",
    "section": "key_terms",
    "text": "[3.1.2 Language of Parts] (Level AA)\nDescription: The human language of each passage or phrase in the content can be programmatically determined except for proper names, technical terms, words of indeterminate language, and words\n      or phrases that have become part of the vernacular of the immediately surrounding\n     text.\n\nSection: key_terms\n\nKey Terms\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\nhuman language\nlanguage that is spoken, written or signed (through visual or tactile means) to communicate\n      with humans\nNote\nSee also\nsign language\n.\nprogrammatically determined\ndetermined by software from author-supplied data provided in a way that different\nuser agents\n, including\nassistive technologies\n, can extract and present this information to users in different modalities\nExample 1\nDetermined in a markup language from elements and attributes that are accessed directly\n      by commonly available assistive technology.\nExample 2\nDetermined from technology-specific data structures in a non-markup language and exposed\n      to assistive technology via an accessibility API that is supported by commonly available\n      assistive technology.\nsign language\na language using combinations of movements of the hands and arms, facial expressions,\n      or body positions to convey meaning\ntext\nsequence of characters that can be\nprogrammatically determined\n, where the sequence is expressing something in\nhuman language\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.2_sufficient",
    "type": "sc_sufficient",
    "sc_id": "3.1.2",
    "techniques": [
      "H58",
      "PDF19"
    ],
    "text": "[3.1.2 Language of Parts] (Level AA)\nDescription: The human language of each passage or phrase in the content can be programmatically determined except for proper names, technical terms, words of indeterminate language, and words\n      or phrases that have become part of the vernacular of the immediately surrounding\n     text.\n\nSufficient techniques for SC 3.1.2 (no situation): H58, PDF19",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.3_intent",
    "type": "sc",
    "sc_id": "3.1.3",
    "section": "intent",
    "text": "[3.1.3 Unusual Words] (Level AAA)\nDescription: A mechanism is available for identifying specific definitions of words or phrases used in an unusual or restricted way, including idioms and jargon.\n\nSection: intent\n\nIntent\nCertain disabilities make it difficult to understand nonliteral word usage and specialized\n         words or usage. Certain disabilities make it difficult to understand figurative language\n         or specialized usage. Providing such mechanisms is vital for these audiences. Specialized\n         information intended for non-specialist readers is encouraged to satisfy this Success\n         Criterion, even when claiming only Single-A or Double-A conformance.",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.3_success_criterion",
    "type": "sc",
    "sc_id": "3.1.3",
    "section": "success_criterion",
    "text": "[3.1.3 Unusual Words] (Level AAA)\nDescription: A mechanism is available for identifying specific definitions of words or phrases used in an unusual or restricted way, including idioms and jargon.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nA\nmechanism\nis available for identifying specific definitions of words or phrases\nused in an unusual or restricted way\n, including\nidioms\nand\njargon\n.",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.3_benefits",
    "type": "sc",
    "sc_id": "3.1.3",
    "section": "benefits",
    "text": "[3.1.3 Unusual Words] (Level AAA)\nDescription: A mechanism is available for identifying specific definitions of words or phrases used in an unusual or restricted way, including idioms and jargon.\n\nSection: benefits\n\nBenefits\nThis success criterion may help people with cognitive, language and learning disabilities\n         who:\nhave difficulty decoding words\nhave difficulty understanding words and phrases\nhave difficulty using context to aid understanding\nIt would also help people with visual disabilities who:\nlose context when zoomed-in with a screen magnifier",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.3_examples",
    "type": "sc",
    "sc_id": "3.1.3",
    "section": "examples",
    "text": "[3.1.3 Unusual Words] (Level AAA)\nDescription: A mechanism is available for identifying specific definitions of words or phrases used in an unusual or restricted way, including idioms and jargon.\n\nSection: examples\n\nExamples\nText that includes a definition for a word used in an unusual way\nOrganize the list or \"cascade\" of dictionaries and other resources so that the definition\n               search will find the intended definitions instead of displaying definitions from other\n               sources in the \"cascade.\" (The \"cascade\" lists the dictionaries and other reference\n               materials in the order most likely to bring up the right definition. This controls\n               the order to follow when searching for definitions.)\nIncluding definitions in the glossary\nWCAG 2.0 uses the word \"text\" in a specific way. Thus, when the word \"text\" is used\n               within WCAG 2.0 it is linked to the definition of \"text\" provided in a glossary within\n               the same web page.\nThe specific definition of a word is provided at the bottom of the page\nThe internal link from the word to the corresponding definition is also provided within the page.",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.3_brief",
    "type": "sc",
    "sc_id": "3.1.3",
    "section": "brief",
    "text": "[3.1.3 Unusual Words] (Level AAA)\nDescription: A mechanism is available for identifying specific definitions of words or phrases used in an unusual or restricted way, including idioms and jargon.\n\nSection: brief\n\nIn Brief\nGoal\nUsers can identify and learn what unusual words mean.\nWhat to do\nProvide definitions for technical jargon and unusual terms.\nWhy it's important\nMore people, especially those with cognitive disabilities, can understand the meaning of content.",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.3_resources",
    "type": "sc",
    "sc_id": "3.1.3",
    "section": "resources",
    "text": "[3.1.3 Unusual Words] (Level AAA)\nDescription: A mechanism is available for identifying specific definitions of words or phrases used in an unusual or restricted way, including idioms and jargon.\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nNote\nThe inclusion of a product or vendor name in the list below does not constitute an\n            endorsement by the Accessibility Guidelines Working Group or the Web Accessibility\n            Initiative of the World Wide Web Consortium. This list is provided simply for convenience\n            and to give users an idea of what resources may be available\nFree bilingual dictionaries for a number of languages are available from the\nFreedict.org website\n. The dictionaries are of uneven quality and size as noted on the site. Retrieved\n            9 April 2005.\nThe WorldStar Free Dictionaries, Translators and Search Engines\nsite provides access to free on-line dictionaries and search engines in many languages.\n            Retrieved 18 November 2005.\nMore dictionaries are at\nyour dictionary\n,\nfreelang.com\n(in English, Spanish and French!) and many other places.",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.3_key_terms",
    "type": "sc",
    "sc_id": "3.1.3",
    "section": "key_terms",
    "text": "[3.1.3 Unusual Words] (Level AAA)\nDescription: A mechanism is available for identifying specific definitions of words or phrases used in an unusual or restricted way, including idioms and jargon.\n\nSection: key_terms\n\nKey Terms\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\nconformance\nsatisfying all the requirements of a given standard, guideline or specification\nidiom\nphrase whose meaning cannot be deduced from the meaning of the individual words and\n      the specific words cannot be changed without losing the meaning\nNote\nIdioms cannot be translated directly, word for word, without losing their (cultural\n      or language-dependent) meaning.\nExample 1\nIn English, \"spilling the beans\" means \"revealing a secret.\" However, \"knocking over\n      the beans\" or \"spilling the vegetables\" does not mean the same thing.\nExample 2\nIn Japanese, the phrase \"\nさじを投げる\n\" literally translates into \"he throws a spoon,\" but it means that there is nothing\n      he can do and finally he gives up.\nExample 3\nIn Dutch, \"\nHij ging met de kippen op stok\n\" literally translates into \"He went to roost with the chickens,\" but it means that\n      he went to bed early.\njargon\nwords used in a particular way by people in a particular field\nExample\nThe word StickyKeys is jargon from the field of assistive technology/accessibility.\nmechanism\nprocess\nor technique for achieving a result\nNote 1\nThe mechanism may be explicitly provided in the content, or may be\nrelied upon\nto be provided by either the platform or by\nuser agents\n, including\nassistive technologies\n.\nNote 2\nThe mechanism needs to meet all success criteria for the conformance level claimed.\nprocess\nseries of user actions where each action is required in order to complete an activity\nExample 1\nSuccessful use of a series of web pages on a shopping site requires users to view\n      alternative products, prices and offers, select products, submit an order, provide\n      shipping information and provide payment information.\nExample 2\nAn account registration page requires successful completion of a\nTuring test\nbefore\n      the registration form can be accessed.\nrelied upon\nthe content would not\nconform\nif that\ntechnology\nis turned off or is not supported\ntechnology\nmechanism\nfor encoding instructions to be rendered, played or executed by\nuser agents\nNote 1\nAs used in these guidelines \"web technology\" and the word \"technology\" (when used\n      alone) both refer to web content technologies.\nNote 2\nWeb content technologies may include markup languages, data formats, or programming\n      languages that authors may use alone or in combination to create end-user experiences\n      that range from static web pages to synchronized media presentations to dynamic Web\n      applications.\nExample\nSome common examples of web content technologies include HTML, CSS, SVG, PNG, PDF,\n      Flash, and JavaScript.\nused in an unusual or restricted way\nwords used in such a way that requires users to know exactly which definition to apply\n      in order to understand the content correctly\nExample\nThe term \"gig\" means something different if it occurs in a discussion of music concerts\n         than it does in article about computer hard drive space, but the appropriate definition\n         can be determined from context. By contrast, the word \"text\" is used in a very specific\n         way in WCAG 2, so a definition is supplied in the glossary.\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.3_situation_A",
    "type": "sc_situation",
    "sc_id": "3.1.3",
    "situation_id": "A",
    "techniques": [
      "G101",
      "G55",
      "H40",
      "G112",
      "H54",
      "G101",
      "G55",
      "H40",
      "G62",
      "G70"
    ],
    "text": "[3.1.3 Unusual Words] (Level AAA)\nDescription: A mechanism is available for identifying specific definitions of words or phrases used in an unusual or restricted way, including idioms and jargon.\n\nSituation A: If the word or phrase has a unique meaning within the web page:\n\nRelated techniques: G101, G55, H40, G112, H54, G101, G55, H40, G62, G70",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.3_situation_B",
    "type": "sc_situation",
    "sc_id": "3.1.3",
    "situation_id": "B",
    "techniques": [
      "G101",
      "G55",
      "H40",
      "G112",
      "H54"
    ],
    "text": "[3.1.3 Unusual Words] (Level AAA)\nDescription: A mechanism is available for identifying specific definitions of words or phrases used in an unusual or restricted way, including idioms and jargon.\n\nSituation B: If the word or phrase means different things within the same web page:\n\nRelated techniques: G101, G55, H40, G112, H54",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.4_intent",
    "type": "sc",
    "sc_id": "3.1.4",
    "section": "intent",
    "text": "[3.1.4 Abbreviations] (Level AAA)\nDescription: A mechanism for identifying the expanded form or meaning of abbreviations is available.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to ensure that users can access the expanded\n         form of abbreviations.",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.4_success_criterion",
    "type": "sc",
    "sc_id": "3.1.4",
    "section": "success_criterion",
    "text": "[3.1.4 Abbreviations] (Level AAA)\nDescription: A mechanism for identifying the expanded form or meaning of abbreviations is available.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nA\nmechanism\nfor identifying the expanded form or meaning of\nabbreviations\nis available.",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.4_benefits",
    "type": "sc",
    "sc_id": "3.1.4",
    "section": "benefits",
    "text": "[3.1.4 Abbreviations] (Level AAA)\nDescription: A mechanism for identifying the expanded form or meaning of abbreviations is available.\n\nSection: benefits\n\nBenefits\nThis success criterion may help people who:\nhave difficulty decoding words;\nrely on screen magnifiers (magnification may reduce contextual cues);\nhave limited memory;\nhave difficulty using context to aid understanding.\nAbbreviations may confuse some readers in different ways:\nSome abbreviations do not look like normal words and cannot be pronounced according\n            to the usual rules of the language. For example, the English word \"room\" is abbreviated\n            as \"rm,\" which does not correspond to any English word or phoneme. The user has to\n            know that \"rm\" is an abbreviation for the word \"room\" in order to say it correctly.\nSometimes, the same abbreviation means different things in different contexts. For\n            example, in the English sentence \"Dr. Johnson lives on Boswell Dr.,\" the first \"Dr.\"\n            is an abbreviation for \"Doctor\" and the second instance is an abbreviation for the\n            word \"Drive\" (a word that means \"street\"). Users must be able to understand the context\n            in order to know what the abbreviations mean.\nSome acronyms spell common words but are used in different ways. For example, \"JAWS\"\n            is an acronym for a screen reader whose full name is \"Job Access with Speech.\" It\n            is also a common English word referring to the part of the mouth that holds the teeth.\n            The acronym is used differently than the common word.\nSome acronyms sound like common words but are spelled differently. For example, the\n            acronym for Synchronized Multimedia Integration Language, S M I L, is pronounced like\n            the English word \"smile.\"\nIt would also help people with visual disabilities who:\nLose context when zoomed-in with a screen magnifier",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.4_examples",
    "type": "sc",
    "sc_id": "3.1.4",
    "section": "examples",
    "text": "[3.1.4 Abbreviations] (Level AAA)\nDescription: A mechanism for identifying the expanded form or meaning of abbreviations is available.\n\nSection: examples\n\nExamples\nAn abbreviation whose expansion is provided the first time the abbreviation appears\n            in the content\nThe name, \"World Wide Web Consortium,\" appears as the first heading on the organization's\n               home page. The abbreviation, \"W3C,\" is enclosed in parentheses in the same heading.\nA dictionary search form\nA website includes a search form provided by an on-line acronym service. Users enter\n               an acronym and the form returns a list of possible expansions from the sources that\n               it searched.\nA medical website\nA medical website provides information for both doctors and patients. The site includes\n               a set of cascading dictionaries;  a very specialized medical dictionary is first,\n               followed by a second medical dictionary for the general public. The cascade also includes\n               a list of acronyms and abbreviations that are unique to the site, and finally there\n               is a standard dictionary as well. The standard dictionary at the end of the list provides\n               definitions for most words in the text. The specialized medical dictionary yields\n               definitions of unusual medical terms. Definitions for words that appear in more than\n               one dictionary are listed in the order of the cascade. The meaning of acronyms and\n               abbreviations is provided by the list of acronyms and abbreviations.\nExpanded forms of Abbreviations\nThe expanded form of each abbreviation is available in a programmatically determinable\n               manner. User agents that speak the text can use the expanded form to announce the\n               abbreviation. Other user agents might make the expanded form available as a tooltip\n               or as contextual help for the abbreviation.",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.4_brief",
    "type": "sc",
    "sc_id": "3.1.4",
    "section": "brief",
    "text": "[3.1.4 Abbreviations] (Level AAA)\nDescription: A mechanism for identifying the expanded form or meaning of abbreviations is available.\n\nSection: brief\n\nIn Brief\nGoal\nUsers can identify and learn what abbreviations mean.\nWhat to do\nProvide the expanded form of abbreviations to users.\nWhy it's important\nSome people, including those with cognitive disabilities, may not understand the shortened form of words.",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.4_resources",
    "type": "sc",
    "sc_id": "3.1.4",
    "section": "resources",
    "text": "[3.1.4 Abbreviations] (Level AAA)\nDescription: A mechanism for identifying the expanded form or meaning of abbreviations is available.\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nAcronym finder\n- You can search with the exact acronym, the beginning of the acronym, wildcards\n            and reverse lookup.\nAbbreviations.com\n.",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.4_key_terms",
    "type": "sc",
    "sc_id": "3.1.4",
    "section": "key_terms",
    "text": "[3.1.4 Abbreviations] (Level AAA)\nDescription: A mechanism for identifying the expanded form or meaning of abbreviations is available.\n\nSection: key_terms\n\nKey Terms\nabbreviation\nshortened form of a word, phrase, or name where the abbreviation has not become part\n      of the language\nNote 1\nThis includes initialisms and acronyms where:\ninitialisms\nare shortened forms of a name or phrase made from the initial letters of words or\n            syllables contained in that name or phrase\nNote 2\nNot defined in all languages.\nExample 1\nSNCF is a French initialism that contains the initial letters of the\nSociété Nationale des Chemins de Fer\n, the French national railroad.\nExample 2\nESP is an initialism for extrasensory perception.\nacronyms\nare abbreviated forms made from the initial letters or parts of other words (in a\n            name or phrase) which may be pronounced as a word\nExample 3\nNOAA is an acronym made from the initial letters of the National Oceanic and Atmospheric\n            Administration in the United States.\nNote 3\nSome companies have adopted what used to be an initialism as their company name. In\n      these cases, the new name of the company is the letters (for example, Ecma) and the\n      word is no longer considered an abbreviation.\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\nconformance\nsatisfying all the requirements of a given standard, guideline or specification\nmechanism\nprocess\nor technique for achieving a result\nNote 1\nThe mechanism may be explicitly provided in the content, or may be\nrelied upon\nto be provided by either the platform or by\nuser agents\n, including\nassistive technologies\n.\nNote 2\nThe mechanism needs to meet all success criteria for the conformance level claimed.\nprocess\nseries of user actions where each action is required in order to complete an activity\nExample 1\nSuccessful use of a series of web pages on a shopping site requires users to view\n      alternative products, prices and offers, select products, submit an order, provide\n      shipping information and provide payment information.\nExample 2\nAn account registration page requires successful completion of a\nTuring test\nbefore\n      the registration form can be accessed.\nrelied upon\nthe content would not\nconform\nif that\ntechnology\nis turned off or is not supported\ntechnology\nmechanism\nfor encoding instructions to be rendered, played or executed by\nuser agents\nNote 1\nAs used in these guidelines \"web technology\" and the word \"technology\" (when used\n      alone) both refer to web content technologies.\nNote 2\nWeb content technologies may include markup languages, data formats, or programming\n      languages that authors may use alone or in combination to create end-user experiences\n      that range from static web pages to synchronized media presentations to dynamic Web\n      applications.\nExample\nSome common examples of web content technologies include HTML, CSS, SVG, PNG, PDF,\n      Flash, and JavaScript.\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.4_situation_A",
    "type": "sc_situation",
    "sc_id": "3.1.4",
    "situation_id": "A",
    "techniques": [
      "G102",
      "G97",
      "G55",
      "PDF8",
      "G102",
      "G55",
      "G62",
      "G70",
      "PDF8"
    ],
    "text": "[3.1.4 Abbreviations] (Level AAA)\nDescription: A mechanism for identifying the expanded form or meaning of abbreviations is available.\n\nSituation A: If the abbreviation has only one meaning within the web page:\n\nRelated techniques: G102, G97, G55, PDF8, G102, G55, G62, G70, PDF8",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.4_situation_B",
    "type": "sc_situation",
    "sc_id": "3.1.4",
    "situation_id": "B",
    "techniques": [
      "G102",
      "G55",
      "PDF8"
    ],
    "text": "[3.1.4 Abbreviations] (Level AAA)\nDescription: A mechanism for identifying the expanded form or meaning of abbreviations is available.\n\nSituation B: If the abbreviation means different things within the same web page:\n\nRelated techniques: G102, G55, PDF8",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.4_advisory",
    "type": "sc_advisory",
    "sc_id": "3.1.4",
    "techniques": [
      "H28"
    ],
    "text": "[3.1.4 Abbreviations] (Level AAA)\nDescription: A mechanism for identifying the expanded form or meaning of abbreviations is available.\n\nAdvisory techniques for SC 3.1.4: H28",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.5_intent",
    "type": "sc",
    "sc_id": "3.1.5",
    "section": "intent",
    "text": "[3.1.5 Reading Level] (Level AAA)\nDescription: When text requires reading ability more advanced than the lower secondary education level after removal of proper names and titles, supplemental content, or a version that does not require reading ability more advanced than the lower\n      secondary education level, is available.\n\nSection: intent\n\nIntent\nContent should be written as clearly and simply as possible. The intent of this Success\n         Criterion is:\nto ensure that additional content is available to aid the understanding of difficult\n            or complex text;\nto establish a testable measure indicating when such additional content is required.\nThis success criterion helps people with reading disabilities while also allowing\n         authors to publish difficult or complex web content. Text difficulty is described\n         in terms of the level of education required to read the text. Education levels are\n         defined according to the International Standard Classification of Education [\nUNESCO\n], which was created to allow international comparison among systems of education.\nDifficult or complex text may be appropriate for most members of the intended audience\n         (that is, most of the people for whom the content has been created). But there are\n         people with disabilities, including reading disabilities, even among highly educated\n         users with specialized knowledge of the subject matter. It may be possible to accommodate\n         these users by making the text more readable. If the text cannot be made more readable,\n         then supplemental content is needed. Supplemental content is required when text demands\n         reading ability more advanced than the lower secondary education level—that is, more\n         than nine years of school. Such text presents severe obstacles to people with reading\n         disabilities and is considered difficult even for people without disabilities who\n         have completed upper secondary education.\nReading disabilities such as dyslexia make it difficult to recognize written or printed\n         words and associate them with the correct sounds. This is called \"decoding\" the text.\n         Decoding must be automatic in order for people to read fluently. The act of decoding\n         text word by word consumes much of the mental energy that most people are able to\n         use for understanding what they read.\n         Text that uses short, common words and short sentences is easier to decode and usually\n         requires less advanced reading ability than text that uses long sentences and long\n         or unfamiliar words.\nThe education level required to read text content (also called \"readability\") is measured\n         by analyzing selected passages of text from the web page. If the web page includes\n         text written for different purposes or different styles are used, the selected passages\n         include samples of the types of content in the web page and the different styles in\n         which the content is written. (In many cases, the web page contains only one kind\n         of text content—e.g., technical documentation, a legal notice, marketing material,\n         etc.—and all the content uses the same style.)\nEducators can also measure the education level required to read text content. For\n         example, qualified teachers can evaluate text according to local education standards\n         to determine if it requires reading ability beyond what is expected for students in\n         the last year of lower secondary education.\nBecause people's names, the names of cities or other proper names cannot be changed\n         to shorter names with fewer syllables, and because doing so or just referring to everyone\n         by pronouns can make sentences harder to understand, the success criterion specifies\n         that proper names can be ignored or removed from the text before assessing whether\n         it meets the reading ability requirement. Titles refer to the name of documents, books,\n         movies, etc. Titles are removed or ignored for the analysis because changing the words\n         in titles might make the titles easier to read but would make it impossible to understand\n         the item to which the title refers. This would make it harder to read and understand\n         the content. (e.g., a book, academic paper, article, etc.). Therefore, titles are\n         also exempted specifically.\nWhen a web page contains multiple languages, a readability result should be calculated\n         for each language that constitutes at least 5% of the content and that is used in\n         full sentences or paragraphs (not just individual words or phrases). The overall readability\n         of the page should be judged on the language that yields the worst readability results.\nThe readability of content may also be determined by applying a readability formula\n         to the selected passage. Many (though not all) readability formulas base their calculations\n         on passages of 100 words. Such formulas have been developed for many languages.  The\n         number of words in the passage is counted and the length of the words is determined\n         by counting either the number of syllables or the number of characters. Most readability\n         formulas also count the number and length of sentences. The average length of words\n         and sentences in the content is then used to calculate a readability score.  (Some\n         languages, such as Japanese, may include multiple scripts within the same passage.\n         Readability formulas for these languages may use the number and length of such \"runs\"\n         in their calculations.)  The result may be presented as a number (for example, on\n         a scale from 0-100) or as a grade level.   These results can then be interpreted using\n         the education levels described in the International Standard Classification of Education.\n         Readability formulas are available for at least some languages when running the spell\n         checkers in popular software if you specify in the options of this engine that you\n         want to have the statistics when it has finished checking your documents.\nLevels of education\nPrimary education\nFirst 6 years of school\nLower secondary education\n7-9 years of school\nUpper secondary education\n10-12 years of school\nAdvanced education\nMore than 12 years of school\nAdapted from\nInternational Standard Classification of Education (UNESCO)\n.\nNote\nAccording to the Open Society Mental Health Initiative, the concept of Easy to Read\n            cannot be universal, and it will not be possible to write a text that will suit the\n            abilities of all people with literacy and comprehension problems. Using the clearest\n            and simplest language appropriate is highly desirable, but the Accessibility Guidelines Working Group\n            could not find a way to test whether this had been achieved. The use of reading level\n            is a way to introduce testability into a success criterion that encourages clear writing.\n            Supplementary content can be a powerful technique for people with some classes of\n            cognitive disability.",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.5_success_criterion",
    "type": "sc",
    "sc_id": "3.1.5",
    "section": "success_criterion",
    "text": "[3.1.5 Reading Level] (Level AAA)\nDescription: When text requires reading ability more advanced than the lower secondary education level after removal of proper names and titles, supplemental content, or a version that does not require reading ability more advanced than the lower\n      secondary education level, is available.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nWhen text requires reading ability more advanced than the\nlower secondary education level\nafter removal of proper names and titles,\nsupplemental content\n, or a version that does not require reading ability more advanced than the lower\n      secondary education level, is available.",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.5_benefits",
    "type": "sc",
    "sc_id": "3.1.5",
    "section": "benefits",
    "text": "[3.1.5 Reading Level] (Level AAA)\nDescription: When text requires reading ability more advanced than the lower secondary education level after removal of proper names and titles, supplemental content, or a version that does not require reading ability more advanced than the lower\n      secondary education level, is available.\n\nSection: benefits\n\nBenefits\nThis success criterion may help people who:\nHave difficulty comprehending and interpreting written language (e.g., articles, instructions,\n            or newspapers in text or braille), for the purpose of obtaining general knowledge\n            or specific information",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.5_examples",
    "type": "sc",
    "sc_id": "3.1.5",
    "section": "examples",
    "text": "[3.1.5 Reading Level] (Level AAA)\nDescription: When text requires reading ability more advanced than the lower secondary education level after removal of proper names and titles, supplemental content, or a version that does not require reading ability more advanced than the lower\n      secondary education level, is available.\n\nSection: examples\n\nExamples\nA scientific journal including readable summaries of complex research articles\nA scientific journal includes articles written in highly technical language aimed\n               at specialists in the field.  The journal's Table of Contents page includes a plain-language\n               summary of each article. The summaries are intended for a general audience with eight\n               years of school. The metadata for the journal uses the Dublin Core specification to\n               identify the education level of the articles' intended audience as \"advanced,\" and\n               the education level of the intended audience for the summaries as \"lower secondary\n               education.\"\nMedical information for members of the public\nA medical school operates a website that explains recent medical and scientific discoveries.\n               The articles on the site are written for people without medical training. Each article\n               uses the Dublin Core metadata specification to identify the education level of the\n               intended audience as \"lower secondary education\" and includes the Flesch Reading Ease\n               score for the article. A link on each page displays the education level and other\n               metadata. No supplemental content is required because people who read at the lower\n               secondary education level can read the articles.\nAn e-learning application\nAn on-line course about Spanish cultural history includes a unit on Moorish architecture.\n               The unit includes text written for students with different reading abilities. Photographs\n               and drawings of buildings illustrate architectural concepts and styles. Graphic organizers\n               are used to illustrate complex relationships, and an audio version using synthetic\n               speech is available. The metadata for each version describes the academic level of\n               the content and includes a readability score based on formulas developed for Spanish-language\n               text. The learning application uses this metadata and metadata about the students\n               to provide versions of instructional content that match the needs of individual students.\nScience information that requires a reading ability at the lower secondary education level\nThe text below (116 words total) requires a reading ability of grade 4.2 in the United\n               States according to the Flesch-Kincaid formula. In the US, grade 4.2 is at the primary\n               education level.\nScience is about testing — and about looking closely. Some scientists use microscopes\n               to take a close look. We're going to use a simple piece of paper.\nHere's what you do: Print this page and cut out the square to make a \"window\" one\n               inch square. (It's easiest to fold the page in half before you cut.)\nChoose something interesting: a tree trunk, a leaf, flower, the soil surface, or a\n               slice of soil from a shovel.\nPut your window over the thing and look at it closely. Take your time — this is not a race.\nTo help you see more details, draw a picture of what's inside your square.\nNow let's think about what you've found.\n(Source: Howard Hughes Medical Institute \"CoolScience for Kids\" Project)",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.5_brief",
    "type": "sc",
    "sc_id": "3.1.5",
    "section": "brief",
    "text": "[3.1.5 Reading Level] (Level AAA)\nDescription: When text requires reading ability more advanced than the lower secondary education level after removal of proper names and titles, supplemental content, or a version that does not require reading ability more advanced than the lower\n      secondary education level, is available.\n\nSection: brief\n\nIn Brief\nGoal\nUsers can get a simplified version of complex information.\nWhat to do\nWhen text information becomes complex, create a more easily understood version.\nWhy it's important\nMore people, especially those with cognitive disabilities, can understand the meaning of content.",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.5_resources",
    "type": "sc",
    "sc_id": "3.1.5",
    "section": "resources",
    "text": "[3.1.5 Reading Level] (Level AAA)\nDescription: When text requires reading ability more advanced than the lower secondary education level after removal of proper names and titles, supplemental content, or a version that does not require reading ability more advanced than the lower\n      secondary education level, is available.\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nThe\nPlain Language Association International\n(PLAIN) website provides many useful resources to help writers produce documents that communicate clearly in a variety of cultural and rhetorical contexts.\nThe US Government's plain language website\nprovides general information about plain language as well as information about use\n            of plain language in US Government documents, including legal requirements\nThe Plain English Campaign website\nprovides useful information and guidance for authors writing in English.\nJuicy Studio's Readability Test\nanalyzes the readability of all rendered content.\nEntry for Audience Education Level. Using Dublin Core – Dublin Core Qualifiers\nIMS Learner Information Packaging Model Information Specification, Table 6.3  \"accessibility\"\n               learner information data structure detailed description\nLeesbaar Nederlands\n(\"Readable Dutch\") contains guidelines for writing text that is accessible for people\n            with a reading disability. These guidelines address language, content and design.\nEuropean Easy-to-Read Guidelines\nFlesch-Kincaid Readability Test",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.5_key_terms",
    "type": "sc",
    "sc_id": "3.1.5",
    "section": "key_terms",
    "text": "[3.1.5 Reading Level] (Level AAA)\nDescription: When text requires reading ability more advanced than the lower secondary education level after removal of proper names and titles, supplemental content, or a version that does not require reading ability more advanced than the lower\n      secondary education level, is available.\n\nSection: key_terms\n\nKey Terms\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\ncontent\ninformation and sensory experience to be communicated to the user by means of a\nuser agent\n, including code or markup that defines the content's\nstructure\n,\npresentation\n, and interactions\nlower secondary education level\nthe two or three year period of education that begins after completion of six years\n      of school and ends nine years after the beginning of\nprimary education\nNote\nThis definition is based on the International Standard Classification of Education\n      [\nUNESCO\n].\npresentation\nrendering of the\ncontent\nin a form to be perceived by users\nprimary education level\nsix year time period that begins between the ages of five and seven, possibly without\n      any previous education\nNote\nThis definition is based on the International Standard Classification of Education\n      [\nUNESCO\n].\nprocess\nseries of user actions where each action is required in order to complete an activity\nExample 1\nSuccessful use of a series of web pages on a shopping site requires users to view\n      alternative products, prices and offers, select products, submit an order, provide\n      shipping information and provide payment information.\nExample 2\nAn account registration page requires successful completion of a\nTuring test\nbefore\n      the registration form can be accessed.\nstructure\nThe way the parts of a\nweb page\nare organized in relation to each other; and\nThe way a collection of\nweb pages\nis organized\nsupplemental content\nadditional\ncontent\nthat illustrates or clarifies the primary content\nExample 1\nAn audio version of a\nweb page\n.\nExample 2\nAn illustration of a complex\nprocess\n.\nExample 3\nA paragraph summarizing the major outcomes and recommendations made in a research\n      study.\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.\nweb page\na non-embedded resource obtained from a single URI using HTTP plus any other resources\n      that are used in the rendering or intended to be rendered together with it by a\nuser agent\nNote 1\nAlthough any \"other resources\" would be rendered together with the primary resource,\n      they would not necessarily be rendered simultaneously with each other.\nNote 2\nFor the purposes of conformance with these guidelines, a resource must be \"non-embedded\"\n      within the scope of conformance to be considered a web page.\nExample 1\nA web resource including all embedded images and media.\nExample 2\nA web mail program built using Asynchronous JavaScript and XML (AJAX). The program\n      lives entirely at http://example.com/mail, but includes an inbox, a contacts area\n      and a calendar. Links or buttons are provided that cause the inbox, contacts, or calendar\n      to display, but do not change the URI of the page as a whole.\nExample 3\nA customizable portal site, where users can choose content to display from a set of\n      different content modules.\nExample 4\nWhen you enter \"http://shopping.example.com/\" in your browser, you enter a movie-like\n      interactive shopping environment where you visually move around in a store dragging\n      products off of the shelves around you and into a visual shopping cart in front of\n      you. Clicking on a product causes it to be demonstrated with a specification sheet\n      floating alongside. This might be a single-page website or just one page within a\n      website.",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.5_sufficient",
    "type": "sc_sufficient",
    "sc_id": "3.1.5",
    "techniques": [
      "G86",
      "G103",
      "G79",
      "G153",
      "G160"
    ],
    "text": "[3.1.5 Reading Level] (Level AAA)\nDescription: When text requires reading ability more advanced than the lower secondary education level after removal of proper names and titles, supplemental content, or a version that does not require reading ability more advanced than the lower\n      secondary education level, is available.\n\nSufficient techniques for SC 3.1.5 (no situation): G86, G103, G79, G153, G160",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.6_intent",
    "type": "sc",
    "sc_id": "3.1.6",
    "section": "intent",
    "text": "[3.1.6 Pronunciation] (Level AAA)\nDescription: A mechanism is available for identifying specific pronunciation of words where meaning of the\n      words, in context, is ambiguous without knowing the pronunciation.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to help people who are blind, people who have\n         low vision, and people with reading disabilities to understand content in cases where\n         meaning depends on pronunciation. Often words or characters have different meanings,\n         each with its own pronunciation. The meaning of such words or characters can usually\n         be determined from the context of the sentence. However, for more complex or ambiguous\n         sentences, or for some languages, the meaning of the word cannot be easily determined\n         or determined at all without knowing the pronunciation. When the sentence is read\n         aloud and the screen reader reads the word using the wrong pronunciation, it can be\n         even more difficult to understand than when read visually. When words are ambiguous\n         or indeterminate unless the pronunciation is known, then providing some means of determining\n         the pronunciation is needed.\nFor example, in the English language heteronyms are words that are spelled the same\n         but have different pronunciations and meanings, such as the words desert (abandon)\n         and desert (arid region). If the proper pronunciation can be determined from the context\n         of the sentence, then nothing is required.  If it cannot then some mechanism for determining\n         the proper pronunciation would be required. Additionally, in some languages certain\n         characters can be pronounced in different ways. In Japanese, for example, there are\n         characters like Han characters(Kanji) that have multiple pronunciations. Screen readers\n         may speak the characters incorrectly without the information on pronunciation. When\n         read incorrectly, the content will not make sense to users.",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.6_success_criterion",
    "type": "sc",
    "sc_id": "3.1.6",
    "section": "success_criterion",
    "text": "[3.1.6 Pronunciation] (Level AAA)\nDescription: A mechanism is available for identifying specific pronunciation of words where meaning of the\n      words, in context, is ambiguous without knowing the pronunciation.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nA\nmechanism\nis available for identifying specific pronunciation of words where meaning of the\n      words, in context, is ambiguous without knowing the pronunciation.",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.6_benefits",
    "type": "sc",
    "sc_id": "3.1.6",
    "section": "benefits",
    "text": "[3.1.6 Pronunciation] (Level AAA)\nDescription: A mechanism is available for identifying specific pronunciation of words where meaning of the\n      words, in context, is ambiguous without knowing the pronunciation.\n\nSection: benefits\n\nBenefits\nThis success criterion may help people who:\nhave difficulty decoding words\nhave difficulty using context to aid understanding\nuse technologies that read the words aloud",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.6_examples",
    "type": "sc",
    "sc_id": "3.1.6",
    "section": "examples",
    "text": "[3.1.6 Pronunciation] (Level AAA)\nDescription: A mechanism is available for identifying specific pronunciation of words where meaning of the\n      words, in context, is ambiguous without knowing the pronunciation.\n\nSection: examples\n\nExamples\nGiving the reading of a person's name\nWeb content in Japanese provides kana (Japanese phonetic syllabary characters) written\n               next to Han characters (Kanji)  show the pronunciation of a person's name. The kana\n               is provided to users in parentheses right after the word. Giving the reading of the\n               words written in Han characters (Kanji) allows both sighted users and screen readers\n               to read/pronounce the words correctly. Note that screen readers will speak the word\n               twice: the Han characters (Kanji) that can be pronounced in a wrong way are read first\n               and then kana is spoken in order to provide the correct reading.\nShowing the reading of the words by ruby element\nWeb content using HTML provides kana (phonetic syllabary characters) written\n               above the characters to show the reading (pronunciation) of the words by using the\n               ruby element.\nProviding sound files of the pronunciation\nA document includes some words whose meaning cannot be determined without knowing\n               the correct pronunciation. Each word is linked to a sound file that gives the correct\n               pronunciation. Users can select these links to find out how to pronounce the words.\nIncluding pronunciation information in the glossary\nA web page includes a glossary section. Some items in the glossary include pronunciation\n               information as well as definitions. Words in the content whose meaning cannot be determined\n               without knowing their pronunciation are linked to the appropriate entries in the glossary.\nText that includes pronunciation information for characters shared by several languages\n                  but pronounced differently in each language\nA Japanese university website includes several short phrases quoted from scholarly\n               texts in Chinese and Korean. The quotations are written using the same script as the\n               Japanese text. Pronunciation information is provided to show the correct reading of\n               the Chinese and Korean characters.\nNote\nFor Japanese, the ruby element is used for showing the \"reading\" rather than \"pronunciation.\"",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.6_brief",
    "type": "sc",
    "sc_id": "3.1.6",
    "section": "brief",
    "text": "[3.1.6 Pronunciation] (Level AAA)\nDescription: A mechanism is available for identifying specific pronunciation of words where meaning of the\n      words, in context, is ambiguous without knowing the pronunciation.\n\nSection: brief\n\nIn Brief\nGoal\nUsers can identify the pronunciation of ambiguous words.\nWhat to do\nIndicate how to pronounce a word, where its meaning is otherwise unclear.\nWhy it's important\nSome people, including those with cognitive disabilities, may not understand the meaning of content.",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.6_key_terms",
    "type": "sc",
    "sc_id": "3.1.6",
    "section": "key_terms",
    "text": "[3.1.6 Pronunciation] (Level AAA)\nDescription: A mechanism is available for identifying specific pronunciation of words where meaning of the\n      words, in context, is ambiguous without knowing the pronunciation.\n\nSection: key_terms\n\nKey Terms\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\nconformance\nsatisfying all the requirements of a given standard, guideline or specification\nmechanism\nprocess\nor technique for achieving a result\nNote 1\nThe mechanism may be explicitly provided in the content, or may be\nrelied upon\nto be provided by either the platform or by\nuser agents\n, including\nassistive technologies\n.\nNote 2\nThe mechanism needs to meet all success criteria for the conformance level claimed.\nprocess\nseries of user actions where each action is required in order to complete an activity\nExample 1\nSuccessful use of a series of web pages on a shopping site requires users to view\n      alternative products, prices and offers, select products, submit an order, provide\n      shipping information and provide payment information.\nExample 2\nAn account registration page requires successful completion of a\nTuring test\nbefore\n      the registration form can be accessed.\nrelied upon\nthe content would not\nconform\nif that\ntechnology\nis turned off or is not supported\ntechnology\nmechanism\nfor encoding instructions to be rendered, played or executed by\nuser agents\nNote 1\nAs used in these guidelines \"web technology\" and the word \"technology\" (when used\n      alone) both refer to web content technologies.\nNote 2\nWeb content technologies may include markup languages, data formats, or programming\n      languages that authors may use alone or in combination to create end-user experiences\n      that range from static web pages to synchronized media presentations to dynamic Web\n      applications.\nExample\nSome common examples of web content technologies include HTML, CSS, SVG, PNG, PDF,\n      Flash, and JavaScript.\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.1.6_sufficient",
    "type": "sc_sufficient",
    "sc_id": "3.1.6",
    "techniques": [
      "G120",
      "G121",
      "G62",
      "G163",
      "H62"
    ],
    "text": "[3.1.6 Pronunciation] (Level AAA)\nDescription: A mechanism is available for identifying specific pronunciation of words where meaning of the\n      words, in context, is ambiguous without knowing the pronunciation.\n\nSufficient techniques for SC 3.1.6 (no situation): G120, G121, G62, G163, H62",
    "principle": "Understandable",
    "guideline": "3.1 Readable"
  },
  {
    "id": "3.2.1_intent",
    "type": "sc",
    "sc_id": "3.2.1",
    "section": "intent",
    "text": "[3.2.1 On Focus] (Level A)\nDescription: When any user interface component receives focus, it does not initiate a change of context.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to ensure that functionality is predictable\n         as visitors navigate their way through a document. Any component that is able to trigger\n         an event when it receives focus must not change the context.          Examples of\n         changing context when a component receives focus include, but are not limited to:\nforms submitted automatically when a component receives focus;\nnew windows launched when a component receives focus;\nfocus is changed to another component when that component receives focus;\nFocus may be moved to a control either via the keyboard (e.g. tabbing to a control) or the mouse (e.g. clicking on a text field). Moving the mouse over a control does not move the focus\n         unless scripting implements this behavior. Note that for some types of controls, clicking\n         on a control may also activate the control (e.g. button), which may, in turn, initiate a change in context.\nNote\nWhat is meant by \"component\" here is also sometimes called \"user interface element\"\n            or \"user interface component\".",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.1_success_criterion",
    "type": "sc",
    "sc_id": "3.2.1",
    "section": "success_criterion",
    "text": "[3.2.1 On Focus] (Level A)\nDescription: When any user interface component receives focus, it does not initiate a change of context.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nWhen any\nuser interface component\nreceives focus, it does not initiate a\nchange of context\n.",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.1_benefits",
    "type": "sc",
    "sc_id": "3.2.1",
    "section": "benefits",
    "text": "[3.2.1 On Focus] (Level A)\nDescription: When any user interface component receives focus, it does not initiate a change of context.\n\nSection: benefits\n\nBenefits\nThis success criterion helps people with visual disabilities, cognitive limitations,\n            and motor impairments by reducing the chance that a change of context will occur unexpectedly.",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.1_examples",
    "type": "sc",
    "sc_id": "3.2.1",
    "section": "examples",
    "text": "[3.2.1 On Focus] (Level A)\nDescription: When any user interface component receives focus, it does not initiate a change of context.\n\nSection: examples\n\nExamples\nExample 1: A dropdown menu\nA dropdown menu on a page allows users to choose between jump destinations. If the\n               person uses the keyboard to move down to a choice and activates it (with a spacebar\n               or enter key) it will jump to a new page.  However, if the person moves down to a\n               choice and either hits the escape or the tab key to move out of the pulldown menu\n               – it does not jump to a new screen as the focus shifts out of the dropdown menu.\nExample of a Failure: A help dialog\nWhen a field receives focus, a help dialog window describing the field and providing\n               options opens. As a keyboard user tabs through the web page, the dialog opens, moving\n               the keyboard focus away from the control every time the user attempts to tab past\n               the field.",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.1_brief",
    "type": "sc",
    "sc_id": "3.2.1",
    "section": "brief",
    "text": "[3.2.1 On Focus] (Level A)\nDescription: When any user interface component receives focus, it does not initiate a change of context.\n\nSection: brief\n\nIn Brief\nGoal\nContent can be navigated more predictably.\nWhat to do\nDo not change a user's context when items get focus.\nWhy it's important\nContent that behaves predictably is especially important to people with disabilities.",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.1_key_terms",
    "type": "sc",
    "sc_id": "3.2.1",
    "section": "key_terms",
    "text": "[3.2.1 On Focus] (Level A)\nDescription: When any user interface component receives focus, it does not initiate a change of context.\n\nSection: key_terms\n\nKey Terms\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\nchanges of context\nmajor changes that, if made without user awareness, can disorient users who are not able to view\n      the entire page simultaneously\nChanges in context include changes of:\nuser agent\n;\nviewport\n;\nfocus;\ncontent\nthat changes the meaning of the\nweb page\nNote\nA change of content is not always a change of context. Changes in content, such as\n      an expanding outline, dynamic menu, or a tab control do not necessarily change the\n      context, unless they also change one of the above (e.g., focus).\nExample\nOpening a new window, moving focus to a different component, going to a new page (including\n      anything that would look to a user as if they had moved to a new page) or significantly\n      re-arranging the content of a page are examples of changes of context.\ncontent\ninformation and sensory experience to be communicated to the user by means of a\nuser agent\n, including code or markup that defines the content's\nstructure\n,\npresentation\n, and interactions\npresentation\nrendering of the\ncontent\nin a form to be perceived by users\nstructure\nThe way the parts of a\nweb page\nare organized in relation to each other; and\nThe way a collection of\nweb pages\nis organized\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.\nuser interface component\na part of the content that is perceived by users as a single control for a distinct\n      function\nNote 1\nMultiple user interface components may be implemented as a single programmatic element.\n      \"Components\" here is not tied to programming techniques, but rather to what the user\n      perceives as separate controls.\nNote 2\nUser interface components include form elements and links as well as components generated\n      by scripts.\nNote 3\nWhat is meant by \"component\" or \"user interface component\" here is also sometimes\n      called \"user interface element\".\nExample\nAn applet has a \"control\" that can be used to move through content by line or page\n      or random access. Since each of these would need to have a name and be settable independently,\n      they would each be a \"user interface component.\"\nviewport\nobject in which the\nuser agent\npresents content\nNote 1\nThe user agent presents content through one or more viewports. Viewports include windows, frames,\n      loudspeakers, and virtual magnifying glasses. A viewport may contain another viewport\n      (e.g., nested frames). Interface components created by the user agent such as prompts,\n      menus, and alerts are not viewports.\nNote 2\nThis definition is based on\nUser Agent Accessibility Guidelines 1.0 Glossary\n[\nUAAG10\n].\nweb page\na non-embedded resource obtained from a single URI using HTTP plus any other resources\n      that are used in the rendering or intended to be rendered together with it by a\nuser agent\nNote 1\nAlthough any \"other resources\" would be rendered together with the primary resource,\n      they would not necessarily be rendered simultaneously with each other.\nNote 2\nFor the purposes of conformance with these guidelines, a resource must be \"non-embedded\"\n      within the scope of conformance to be considered a web page.\nExample 1\nA web resource including all embedded images and media.\nExample 2\nA web mail program built using Asynchronous JavaScript and XML (AJAX). The program\n      lives entirely at http://example.com/mail, but includes an inbox, a contacts area\n      and a calendar. Links or buttons are provided that cause the inbox, contacts, or calendar\n      to display, but do not change the URI of the page as a whole.\nExample 3\nA customizable portal site, where users can choose content to display from a set of\n      different content modules.\nExample 4\nWhen you enter \"http://shopping.example.com/\" in your browser, you enter a movie-like\n      interactive shopping environment where you visually move around in a store dragging\n      products off of the shelves around you and into a visual shopping cart in front of\n      you. Clicking on a product causes it to be demonstrated with a specification sheet\n      floating alongside. This might be a single-page website or just one page within a\n      website.",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.1_sufficient",
    "type": "sc_sufficient",
    "sc_id": "3.2.1",
    "techniques": [
      "G107"
    ],
    "text": "[3.2.1 On Focus] (Level A)\nDescription: When any user interface component receives focus, it does not initiate a change of context.\n\nSufficient techniques for SC 3.2.1 (no situation): G107",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.1_advisory",
    "type": "sc_advisory",
    "sc_id": "3.2.1",
    "techniques": [
      "G200",
      "G201"
    ],
    "text": "[3.2.1 On Focus] (Level A)\nDescription: When any user interface component receives focus, it does not initiate a change of context.\n\nAdvisory techniques for SC 3.2.1: G200, G201",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.1_failures",
    "type": "sc_failures",
    "sc_id": "3.2.1",
    "techniques": [
      "F55"
    ],
    "text": "[3.2.1 On Focus] (Level A)\nDescription: When any user interface component receives focus, it does not initiate a change of context.\n\nCommon failures for SC 3.2.1: F55",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.2_intent",
    "type": "sc",
    "sc_id": "3.2.2",
    "section": "intent",
    "text": "[3.2.2 On Input] (Level A)\nDescription: Changing the setting of any user interface component does not automatically cause a change of context unless the user has been advised of the behavior before using the component.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to ensure that entering data or selecting\n         a form control has predictable effects. Changing the setting of any user interface\n         component is changing some aspect in the control that will persist when the user is\n         no longer interacting with it. So checking a checkbox, entering text into a text field,\n         or changing the selected option in a list control changes its setting, but activating\n         a link or a button does not. Changes in context can confuse users who do not easily\n         perceive the change or are easily distracted by changes. Changes of context are appropriate\n         only when it is clear that such a change will happen in response to the user's action.\nNote\nThis success criterion covers changes in context due to changing the setting of a\n            control. Clicking on links or buttons is activating a control, not\n            changing the setting of that control.\nNote\nWhat is meant by \"component\" and \"user interface component\" here is also sometimes\n            called \"user interface element\".",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.2_success_criterion",
    "type": "sc",
    "sc_id": "3.2.2",
    "section": "success_criterion",
    "text": "[3.2.2 On Input] (Level A)\nDescription: Changing the setting of any user interface component does not automatically cause a change of context unless the user has been advised of the behavior before using the component.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nChanging the setting of any\nuser interface component\ndoes not automatically cause a\nchange of context\nunless the user has been advised of the behavior before using the component.",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.2_benefits",
    "type": "sc",
    "sc_id": "3.2.2",
    "section": "benefits",
    "text": "[3.2.2 On Input] (Level A)\nDescription: Changing the setting of any user interface component does not automatically cause a change of context unless the user has been advised of the behavior before using the component.\n\nSection: benefits\n\nBenefits\nThis success criterion helps users with disabilities by making interactive content\n            more predictable. Unexpected changes of context can be so disorienting for users with\n            visual disabilities or cognitive limitations that they are unable to use the content.\nIndividuals who are unable to detect changes of context are less likely to become\n               disoriented while navigating a site. For example:\nIndividuals who are blind or have low vision may have difficulty knowing when a visual\n                  context change has occurred, such as a new window popping up. In this case, warning\n                  users of context changes in advance minimizes confusion when the user discovers that\n                  the back button no longer behaves as expected.\nSome individuals with low vision, with reading and intellectual disabilities, and\n            others who have difficulty interpreting visual cues may benefit from additional cues\n            in order to detect changes of context.",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.2_examples",
    "type": "sc",
    "sc_id": "3.2.2",
    "section": "examples",
    "text": "[3.2.2 On Input] (Level A)\nDescription: Changing the setting of any user interface component does not automatically cause a change of context unless the user has been advised of the behavior before using the component.\n\nSection: examples\n\nExamples\nA form is provided for creating calendar entries in a web-based calendaring and scheduling\n            application. Along with the standard fields for subject, time and location, \n            a select dropdown allows the user to choose the type of calendar entry to create. The calendar\n            entry type can be meeting, appointment or reminder.  If the user selects the\n            meeting option, additional fields are displayed on the page for entering the meeting\n            participants. Different fields appear if the reminder option is chosen. Because only\n            parts of the entry change and the overall structure remains the same, the basic context\n            remains for the user.\nA form contains fields representing US phone numbers. All of the numbers have a three\n            digit area code followed by a three digit prefix and finally a four digit number,\n            and each part of the phone number is entered into a separate field. When the user\n            completes the entry of one field the focus automatically moves to the next field of\n            the phone number. This behavior of phone fields is described for the user at the beginning\n            of the form.",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.2_brief",
    "type": "sc",
    "sc_id": "3.2.2",
    "section": "brief",
    "text": "[3.2.2 On Input] (Level A)\nDescription: Changing the setting of any user interface component does not automatically cause a change of context unless the user has been advised of the behavior before using the component.\n\nSection: brief\n\nIn Brief\nGoal\nContent can be operated more predictably.\nWhat to do\nForewarn users if their context will change based on their input.\nWhy it's important\nContent that behaves predictably is especially important to people with disabilities.",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.2_key_terms",
    "type": "sc",
    "sc_id": "3.2.2",
    "section": "key_terms",
    "text": "[3.2.2 On Input] (Level A)\nDescription: Changing the setting of any user interface component does not automatically cause a change of context unless the user has been advised of the behavior before using the component.\n\nSection: key_terms\n\nKey Terms\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\nchanges of context\nmajor changes that, if made without user awareness, can disorient users who are not able to view\n      the entire page simultaneously\nChanges in context include changes of:\nuser agent\n;\nviewport\n;\nfocus;\ncontent\nthat changes the meaning of the\nweb page\nNote\nA change of content is not always a change of context. Changes in content, such as\n      an expanding outline, dynamic menu, or a tab control do not necessarily change the\n      context, unless they also change one of the above (e.g., focus).\nExample\nOpening a new window, moving focus to a different component, going to a new page (including\n      anything that would look to a user as if they had moved to a new page) or significantly\n      re-arranging the content of a page are examples of changes of context.\ncontent\ninformation and sensory experience to be communicated to the user by means of a\nuser agent\n, including code or markup that defines the content's\nstructure\n,\npresentation\n, and interactions\npresentation\nrendering of the\ncontent\nin a form to be perceived by users\nstructure\nThe way the parts of a\nweb page\nare organized in relation to each other; and\nThe way a collection of\nweb pages\nis organized\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.\nuser interface component\na part of the content that is perceived by users as a single control for a distinct\n      function\nNote 1\nMultiple user interface components may be implemented as a single programmatic element.\n      \"Components\" here is not tied to programming techniques, but rather to what the user\n      perceives as separate controls.\nNote 2\nUser interface components include form elements and links as well as components generated\n      by scripts.\nNote 3\nWhat is meant by \"component\" or \"user interface component\" here is also sometimes\n      called \"user interface element\".\nExample\nAn applet has a \"control\" that can be used to move through content by line or page\n      or random access. Since each of these would need to have a name and be settable independently,\n      they would each be a \"user interface component.\"\nviewport\nobject in which the\nuser agent\npresents content\nNote 1\nThe user agent presents content through one or more viewports. Viewports include windows, frames,\n      loudspeakers, and virtual magnifying glasses. A viewport may contain another viewport\n      (e.g., nested frames). Interface components created by the user agent such as prompts,\n      menus, and alerts are not viewports.\nNote 2\nThis definition is based on\nUser Agent Accessibility Guidelines 1.0 Glossary\n[\nUAAG10\n].\nweb page\na non-embedded resource obtained from a single URI using HTTP plus any other resources\n      that are used in the rendering or intended to be rendered together with it by a\nuser agent\nNote 1\nAlthough any \"other resources\" would be rendered together with the primary resource,\n      they would not necessarily be rendered simultaneously with each other.\nNote 2\nFor the purposes of conformance with these guidelines, a resource must be \"non-embedded\"\n      within the scope of conformance to be considered a web page.\nExample 1\nA web resource including all embedded images and media.\nExample 2\nA web mail program built using Asynchronous JavaScript and XML (AJAX). The program\n      lives entirely at http://example.com/mail, but includes an inbox, a contacts area\n      and a calendar. Links or buttons are provided that cause the inbox, contacts, or calendar\n      to display, but do not change the URI of the page as a whole.\nExample 3\nA customizable portal site, where users can choose content to display from a set of\n      different content modules.\nExample 4\nWhen you enter \"http://shopping.example.com/\" in your browser, you enter a movie-like\n      interactive shopping environment where you visually move around in a store dragging\n      products off of the shelves around you and into a visual shopping cart in front of\n      you. Clicking on a product causes it to be demonstrated with a specification sheet\n      floating alongside. This might be a single-page website or just one page within a\n      website.",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.2_sufficient",
    "type": "sc_sufficient",
    "sc_id": "3.2.2",
    "techniques": [
      "G80",
      "H32",
      "H84",
      "PDF15",
      "G13",
      "SCR19"
    ],
    "text": "[3.2.2 On Input] (Level A)\nDescription: Changing the setting of any user interface component does not automatically cause a change of context unless the user has been advised of the behavior before using the component.\n\nSufficient techniques for SC 3.2.2 (no situation): G80, H32, H84, PDF15, G13, SCR19",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.2_advisory",
    "type": "sc_advisory",
    "sc_id": "3.2.2",
    "techniques": [
      "G201"
    ],
    "text": "[3.2.2 On Input] (Level A)\nDescription: Changing the setting of any user interface component does not automatically cause a change of context unless the user has been advised of the behavior before using the component.\n\nAdvisory techniques for SC 3.2.2: G201",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.2_failures",
    "type": "sc_failures",
    "sc_id": "3.2.2",
    "techniques": [
      "F36",
      "F37"
    ],
    "text": "[3.2.2 On Input] (Level A)\nDescription: Changing the setting of any user interface component does not automatically cause a change of context unless the user has been advised of the behavior before using the component.\n\nCommon failures for SC 3.2.2: F36, F37",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.3_intent",
    "type": "sc",
    "sc_id": "3.2.3",
    "section": "intent",
    "text": "[3.2.3 Consistent Navigation] (Level AA)\nDescription: Navigational mechanisms that are repeated on multiple web pages within a set of web pages occur in the same relative order each time they are repeated, unless a change is initiated by the user.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to encourage the use of consistent presentation\n         and layout for users who interact with repeated content within \n         a set of web pages and need to locate specific information or functionality more than\n         once.\n         Individuals with low vision who use screen magnification to display a small portion\n         of the screen at a time often use visual cues and page boundaries to quickly locate\n         repeated content.\n         Presenting repeated content in the same order is also important for visual users who\n         use spatial memory or visual cues within the design to locate repeated content.\nIt is important to note that the use of the phrase \"same order\" in this section is\n         not meant to imply that subnavigation menus cannot be used or that blocks of secondary\n         navigation or page structure cannot be used. Instead, this success criterion is intended\n         to assist users who interact with repeated content across web pages to be able to\n         predict the location of the content they are looking for and find it more quickly\n         when they encounter it again.\nUsers may initiate a change in the order by using adaptive user agents or by setting\n         preferences so that the information is presented in a way that is most useful to them.",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.3_success_criterion",
    "type": "sc",
    "sc_id": "3.2.3",
    "section": "success_criterion",
    "text": "[3.2.3 Consistent Navigation] (Level AA)\nDescription: Navigational mechanisms that are repeated on multiple web pages within a set of web pages occur in the same relative order each time they are repeated, unless a change is initiated by the user.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nNavigational mechanisms that are repeated on multiple\nweb pages\nwithin a\nset of web pages\noccur in the\nsame relative order\neach time they are repeated, unless a change is initiated by the user.",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.3_benefits",
    "type": "sc",
    "sc_id": "3.2.3",
    "section": "benefits",
    "text": "[3.2.3 Consistent Navigation] (Level AA)\nDescription: Navigational mechanisms that are repeated on multiple web pages within a set of web pages occur in the same relative order each time they are repeated, unless a change is initiated by the user.\n\nSection: benefits\n\nBenefits\nEnsuring that repeated components occur in the same order on each page of a site helps\n            users become comfortable that they will able to predict where they can find things\n            on each page. This helps users with\ncognitive limitations\n, users with\nlow vision\n, users with\nintellectual disabilities\n, and also those who are\nblind\n.",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.3_examples",
    "type": "sc",
    "sc_id": "3.2.3",
    "section": "examples",
    "text": "[3.2.3 Consistent Navigation] (Level AA)\nDescription: Navigational mechanisms that are repeated on multiple web pages within a set of web pages occur in the same relative order each time they are repeated, unless a change is initiated by the user.\n\nSection: examples\n\nExamples\nA consistently located control\nA search field is the last item on every web page in a site. Users can quickly locate the search function.\nAn expanding navigation menu\nA navigation menu includes a list of seven items with links to the main sections of a site.\n               When a user selects one of these items, a list of sub-navigation items is inserted\n               into the top-level navigation menu.\nConsistently positioned skip navigation controls\nA \"skip navigation\" (or \"skip to main content\") link is included as the first link\n               on every page in a website. The link allows users to quickly bypass heading information\n               and navigational content and begin interacting with the main content of a page.\nSkip to navigation link\nNavigational content is consistently located at the end of each page in a set of Web\n               pages. A \"skip to navigation\" link is consistently located at the beginning of each\n               page so that keyboard users can easily locate it when needed.",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.3_brief",
    "type": "sc",
    "sc_id": "3.2.3",
    "section": "brief",
    "text": "[3.2.3 Consistent Navigation] (Level AA)\nDescription: Navigational mechanisms that are repeated on multiple web pages within a set of web pages occur in the same relative order each time they are repeated, unless a change is initiated by the user.\n\nSection: brief\n\nIn Brief\nGoal\nContent can be navigated more predictably.\nWhat to do\nConsistently order navigation that repeats across multiple pages.\nWhy it's important\nContent that behaves predictably is especially important to people with disabilities.",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.3_resources",
    "type": "sc",
    "sc_id": "3.2.3",
    "section": "resources",
    "text": "[3.2.3 Consistent Navigation] (Level AA)\nDescription: Navigational mechanisms that are repeated on multiple web pages within a set of web pages occur in the same relative order each time they are repeated, unless a change is initiated by the user.\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nDetweiler, M.C. and Omanson, R.C. (1996), Ameritech Web Page User Interface Standards\n            and Design Guidelines.\nIBM: User experience design - Navigation\n.",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.3_key_terms",
    "type": "sc",
    "sc_id": "3.2.3",
    "section": "key_terms",
    "text": "[3.2.3 Consistent Navigation] (Level AA)\nDescription: Navigational mechanisms that are repeated on multiple web pages within a set of web pages occur in the same relative order each time they are repeated, unless a change is initiated by the user.\n\nSection: key_terms\n\nKey Terms\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\nsame relative order\nsame position relative to other items\nNote\nItems are considered to be in the same relative order even if other items are inserted\n      or removed from the original order. For example, expanding navigation menus may insert\n      an additional level of detail or a secondary navigation section may be inserted into\n      the reading order.\nset of web pages\ncollection of\nweb pages\nthat share a common purpose and that are created by the same author, group or organization\nExample\nExamples include:\na publication which is split across multiple web pages, where each page contains one chapter or other significant section of the work. The publication is logically a single contiguous unit, and contains navigation features that enable access to the full set of pages.\nan e-commerce website shows products in a set of web pages that all share the same navigation and identification. However, when progressing to the checkout process, the template changes; the navigation and other elements are removed, so the pages in that process are functionally and visually different. The checkout pages are not part of the set of product pages.\na blog on a sub-domain (e.g. blog.example.com) which has a different navigation and is authored by a distinct set of people from the pages on the primary domain (example.com).\nNote\nDifferent language versions would be considered different sets of web pages.\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.\nweb page\na non-embedded resource obtained from a single URI using HTTP plus any other resources\n      that are used in the rendering or intended to be rendered together with it by a\nuser agent\nNote 1\nAlthough any \"other resources\" would be rendered together with the primary resource,\n      they would not necessarily be rendered simultaneously with each other.\nNote 2\nFor the purposes of conformance with these guidelines, a resource must be \"non-embedded\"\n      within the scope of conformance to be considered a web page.\nExample 1\nA web resource including all embedded images and media.\nExample 2\nA web mail program built using Asynchronous JavaScript and XML (AJAX). The program\n      lives entirely at http://example.com/mail, but includes an inbox, a contacts area\n      and a calendar. Links or buttons are provided that cause the inbox, contacts, or calendar\n      to display, but do not change the URI of the page as a whole.\nExample 3\nA customizable portal site, where users can choose content to display from a set of\n      different content modules.\nExample 4\nWhen you enter \"http://shopping.example.com/\" in your browser, you enter a movie-like\n      interactive shopping environment where you visually move around in a store dragging\n      products off of the shelves around you and into a visual shopping cart in front of\n      you. Clicking on a product causes it to be demonstrated with a specification sheet\n      floating alongside. This might be a single-page website or just one page within a\n      website.",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.3_sufficient",
    "type": "sc_sufficient",
    "sc_id": "3.2.3",
    "techniques": [
      "G61"
    ],
    "text": "[3.2.3 Consistent Navigation] (Level AA)\nDescription: Navigational mechanisms that are repeated on multiple web pages within a set of web pages occur in the same relative order each time they are repeated, unless a change is initiated by the user.\n\nSufficient techniques for SC 3.2.3 (no situation): G61",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.3_advisory",
    "type": "sc_advisory",
    "sc_id": "3.2.3",
    "techniques": [
      "PDF14",
      "PDF17"
    ],
    "text": "[3.2.3 Consistent Navigation] (Level AA)\nDescription: Navigational mechanisms that are repeated on multiple web pages within a set of web pages occur in the same relative order each time they are repeated, unless a change is initiated by the user.\n\nAdvisory techniques for SC 3.2.3: PDF14, PDF17",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.3_failures",
    "type": "sc_failures",
    "sc_id": "3.2.3",
    "techniques": [
      "F66"
    ],
    "text": "[3.2.3 Consistent Navigation] (Level AA)\nDescription: Navigational mechanisms that are repeated on multiple web pages within a set of web pages occur in the same relative order each time they are repeated, unless a change is initiated by the user.\n\nCommon failures for SC 3.2.3: F66",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.4_intent",
    "type": "sc",
    "sc_id": "3.2.4",
    "section": "intent",
    "text": "[3.2.4 Consistent Identification] (Level AA)\nDescription: Components that have the same functionality within a set of web pages are identified consistently.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to ensure consistent identification of functional\n         components that appear repeatedly within a set of web pages. A strategy that people\n         who use screen readers use when operating a website is to rely heavily on their familiarity\n         with functions that may appear on different web pages. If identical functions have\n         different labels (or, more generally, a different\naccessible name\n)\n         on different web pages, the site will be considerably more difficult\n         to use. It may also be confusing and increase the cognitive load for people with cognitive\n         limitations. Therefore, consistent labeling will help.\nThis consistency extends to the text alternatives. If icons or other non-text items\n         have the same functionality, then their text alternatives should be consistent as\n         well.\nIf there are two components on a web page that both have the same functionality as\n         a component on another page in a set of web pages, then all 3 must be consistent.\n         Hence the two on the same page will be consistent.\nWhile it is desirable and best practice always to be consistent within a single web\n         page, 3.2.4 only addresses consistency within a set of web pages where something is\n         repeated on more than one page in the set.",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.4_success_criterion",
    "type": "sc",
    "sc_id": "3.2.4",
    "section": "success_criterion",
    "text": "[3.2.4 Consistent Identification] (Level AA)\nDescription: Components that have the same functionality within a set of web pages are identified consistently.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nComponents that have the\nsame functionality\nwithin a\nset of web pages\nare identified consistently.",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.4_benefits",
    "type": "sc",
    "sc_id": "3.2.4",
    "section": "benefits",
    "text": "[3.2.4 Consistent Identification] (Level AA)\nDescription: Components that have the same functionality within a set of web pages are identified consistently.\n\nSection: benefits\n\nBenefits\nPeople who learn functionality on one page on a site can find the desired functions\n            on other pages if they are present.\nWhen non-text content is used in a consistent way to identify components with the\n            same functionality, people with difficulty reading text or detecting text alternatives\n            can interact with the web without depending on text alternatives.\nPeople who depend on text alternatives can have a more predictable experience. They\n            can also search for the component if it has a consistent label on different pages.",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.4_examples",
    "type": "sc",
    "sc_id": "3.2.4",
    "section": "examples",
    "text": "[3.2.4 Consistent Identification] (Level AA)\nDescription: Components that have the same functionality within a set of web pages are identified consistently.\n\nSection: examples\n\nExamples\nExample 1: Document Icon\nA document icon is used to indicate document download throughout a site. The text\n               alternative for the icon always begins with the word “Download,\" followed by a shortened\n               form of the document title. Using different text alternatives to identify document\n               names for different documents is a consistent use of text alternatives.\nExample 2: Check Mark\nA check mark icon functions as \"approved\", on one page but as \"included\" on another.\n               Since they serve different functions, they have different text alternatives.\nExample 3: Consistent references to other pages\nA website publishes articles on-line. Each article spans multiple web pages and\n               each page contains a link to the first page, the next page and the previous page of\n               the article. If the references to the next page read \"page 2\", \"page 3\", \"page 4\"\n               etcetera, the labels are not the same but they are consistent. Therefore, these references\n               are not failures of this success criterion.\nExample 4: Icons with similar functions\nAn e-commerce application uses a printer icon that allows the user to print receipts\n               and invoices. In one part of the application, the printer icon is labeled \"Print receipt\"\n               and is used to print receipts, while in another part it is labeled \"Print invoice\"\n               and is used to print invoices. The labeling is consistent (\"Print x\"), but the labels\n               are different to reflect the different functions of the icons. Therefore, this example\n               does not fail the success criterion.\nExample 5: Save icon\nA common \"save\" icon is used through out the site where page save function is provided\n               on multiple web pages.\nExample 6: Icon and adjacent link to same destination\nAn icon with alt text and a link are next to each other and go to the same location.\n               The best practice would be to group them into one link as per\nH2: Combining adjacent image and text links for the same resource\n. However if they are visually positioned one above the other but separated in the\n               source, this may not be possible. To meet the Success Criterion, the link text for\n               these two links need only be consistent, not identical. But best practice is to have\n               identical text so that when users encounter the second one, it is clear that it goes\n               to the same place as the first.\nExample 7: Example of a Failure\nA submit \"search\" button on one web page and a \"find\" button on another web page both\n               have a field to enter a term and list topics in the website related to the term submitted.\n               In this case, the buttons have the same functionality but are not labeled consistently.\nExample 8: Failure primarily impacting assistive technology users\nTwo buttons with the same functionality visually have the same text, but have been given\n                  different\naria-label=\"...\"\naccessible names. For users of assistive technologies,\n                  these two buttons will be announced differently and inconsistently.",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.4_brief",
    "type": "sc",
    "sc_id": "3.2.4",
    "section": "brief",
    "text": "[3.2.4 Consistent Identification] (Level AA)\nDescription: Components that have the same functionality within a set of web pages are identified consistently.\n\nSection: brief\n\nIn Brief\nGoal\nActions are more predictable across pages.\nWhat to do\nIdentify repeating functions consistently.\nWhy it's important\nConsistently identified actions are especially important to people with disabilities.",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.4_key_terms",
    "type": "sc",
    "sc_id": "3.2.4",
    "section": "key_terms",
    "text": "[3.2.4 Consistent Identification] (Level AA)\nDescription: Components that have the same functionality within a set of web pages are identified consistently.\n\nSection: key_terms\n\nKey Terms\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\nsame functionality\nsame result when used\nExample\nA submit \"search\" button on one web page and a \"find\" button on another web page may\n      both have a field to enter a term and list topics in the website related to the term\n      submitted. In this case, they would have the same functionality but would not be labeled\n      consistently.\nset of web pages\ncollection of\nweb pages\nthat share a common purpose and that are created by the same author, group or organization\nExample\nExamples include:\na publication which is split across multiple web pages, where each page contains one chapter or other significant section of the work. The publication is logically a single contiguous unit, and contains navigation features that enable access to the full set of pages.\nan e-commerce website shows products in a set of web pages that all share the same navigation and identification. However, when progressing to the checkout process, the template changes; the navigation and other elements are removed, so the pages in that process are functionally and visually different. The checkout pages are not part of the set of product pages.\na blog on a sub-domain (e.g. blog.example.com) which has a different navigation and is authored by a distinct set of people from the pages on the primary domain (example.com).\nNote\nDifferent language versions would be considered different sets of web pages.\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.\nweb page\na non-embedded resource obtained from a single URI using HTTP plus any other resources\n      that are used in the rendering or intended to be rendered together with it by a\nuser agent\nNote 1\nAlthough any \"other resources\" would be rendered together with the primary resource,\n      they would not necessarily be rendered simultaneously with each other.\nNote 2\nFor the purposes of conformance with these guidelines, a resource must be \"non-embedded\"\n      within the scope of conformance to be considered a web page.\nExample 1\nA web resource including all embedded images and media.\nExample 2\nA web mail program built using Asynchronous JavaScript and XML (AJAX). The program\n      lives entirely at http://example.com/mail, but includes an inbox, a contacts area\n      and a calendar. Links or buttons are provided that cause the inbox, contacts, or calendar\n      to display, but do not change the URI of the page as a whole.\nExample 3\nA customizable portal site, where users can choose content to display from a set of\n      different content modules.\nExample 4\nWhen you enter \"http://shopping.example.com/\" in your browser, you enter a movie-like\n      interactive shopping environment where you visually move around in a store dragging\n      products off of the shelves around you and into a visual shopping cart in front of\n      you. Clicking on a product causes it to be demonstrated with a specification sheet\n      floating alongside. This might be a single-page website or just one page within a\n      website.",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.4_sufficient",
    "type": "sc_sufficient",
    "sc_id": "3.2.4",
    "techniques": [
      "G197"
    ],
    "text": "[3.2.4 Consistent Identification] (Level AA)\nDescription: Components that have the same functionality within a set of web pages are identified consistently.\n\nSufficient techniques for SC 3.2.4 (no situation): G197",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.4_failures",
    "type": "sc_failures",
    "sc_id": "3.2.4",
    "techniques": [
      "F31"
    ],
    "text": "[3.2.4 Consistent Identification] (Level AA)\nDescription: Components that have the same functionality within a set of web pages are identified consistently.\n\nCommon failures for SC 3.2.4: F31",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.5_intent",
    "type": "sc",
    "sc_id": "3.2.5",
    "section": "intent",
    "text": "[3.2.5 Change on Request] (Level AAA)\nDescription: Changes of context are initiated only by user request or a mechanism is available to turn off such changes.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to encourage design of web content that gives\n         users full control of changes of context. \n         This success criterion aims to eliminate potential confusion that may be caused by\n         unexpected changes of context such as automatic launching of new windows, automatic\n         submission of forms after selecting an item from a list, etcetera. \n         Such unexpected changes of context may cause difficulties for people with motor impairments,\n         people with low vision, people who are blind, and people with certain cognitive limitations.\nSome types of change of context are not disruptive to some users, or actively benefit\n         some users. For example, single-switch users rely on context changes that are animated\n         by the system, and the preferences of low-vision users may vary depending on how much\n         of the content they can see at once and how much of the session structure they can\n         retain in working memory. Some types of content, such as slide shows, require the\n         ability to change context in order to provide the intended user experience. Content\n         that initiates changes of context automatically only when user preferences allow can\n         conform to this success criterion.\nNote\nIt is possible for more than one change of context to occur simultaneously. For example,\n            clicking on a link which automatically opens a new window is an example of two separate\n            changes of context related to the change in content and to the change in the viewport\n            (window). The change in the content in this case is initiated by user request when\n            they click on the link, but unless the user can be aware that the link will open in\n            a new window then that change of context cannot be regarded as user-initiated.",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.5_success_criterion",
    "type": "sc",
    "sc_id": "3.2.5",
    "section": "success_criterion",
    "text": "[3.2.5 Change on Request] (Level AAA)\nDescription: Changes of context are initiated only by user request or a mechanism is available to turn off such changes.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nChanges of context\nare initiated only by user request or a\nmechanism\nis available to turn off such changes.",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.5_benefits",
    "type": "sc",
    "sc_id": "3.2.5",
    "section": "benefits",
    "text": "[3.2.5 Change on Request] (Level AAA)\nDescription: Changes of context are initiated only by user request or a mechanism is available to turn off such changes.\n\nSection: benefits\n\nBenefits\nIndividuals who are unable to detect changes of context or who may not realize that the context has changed are less likely to become disoriented if they initiate the change themselves.\n               For example:\nindividuals who are blind or have low vision may have difficulty knowing when a visual\n                  context change has occurred, such as a new window popping up. In this case, warning\n                  users of context changes in advance minimizes confusion when the user discovers that\n                  the back button no longer behaves as expected.\nSome individuals with low vision, with reading and intellectual disabilities, and\n            who have difficulty interpreting visual cues may benefit from additional cues in order\n            to detect changes of context.\nPeople with certain\ncognitive limitations\ndo not get confused if automatic redirects are performed by the web server instead\n            of the browser.",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.5_examples",
    "type": "sc",
    "sc_id": "3.2.5",
    "section": "examples",
    "text": "[3.2.5 Change on Request] (Level AAA)\nDescription: Changes of context are initiated only by user request or a mechanism is available to turn off such changes.\n\nSection: examples\n\nExamples\nan \"update now\" button\nInstead of automatically updating the content, the author provides an \"Update now\"\n               button that requests a refresh of the content.\nAn automatic redirection\nUsers are automatically redirected from an old page to a new page in such a way that\n               they never realize the redirect has occurred.",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.5_brief",
    "type": "sc",
    "sc_id": "3.2.5",
    "section": "brief",
    "text": "[3.2.5 Change on Request] (Level AAA)\nDescription: Changes of context are initiated only by user request or a mechanism is available to turn off such changes.\n\nSection: brief\n\nIn Brief\nGoal\nUsers have full control of major content changes.\nWhat to do\nProvide ways for users to trigger or turn off changes of context.\nWhy it's important\nContent that behaves predictably is especially important to people with disabilities.",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.5_resources",
    "type": "sc",
    "sc_id": "3.2.5",
    "section": "resources",
    "text": "[3.2.5 Change on Request] (Level AAA)\nDescription: Changes of context are initiated only by user request or a mechanism is available to turn off such changes.\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nUse standard redirects: don't break the back button!\n(W3C \n            QA Tip).\nRFC 9110: HTTP Semantics 15.4. Redirection 3xx\n.",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.5_test_rules",
    "type": "sc",
    "sc_id": "3.2.5",
    "section": "test_rules",
    "text": "[3.2.5 Change on Request] (Level AAA)\nDescription: Changes of context are initiated only by user request or a mechanism is available to turn off such changes.\n\nSection: test_rules\n\nTest Rules\nThe following are Test Rules\n    for certain aspects of this Success Criterion.\n    It is not necessary to use these particular Test Rules to check for conformance with WCAG, but they are defined and approved test methods.\n    For information on using Test Rules, see\nUnderstanding Test Rules for WCAG Success Criteria\n.\nMeta element has no refresh delay\nMeta element has no refresh delay (no exception)",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.5_key_terms",
    "type": "sc",
    "sc_id": "3.2.5",
    "section": "key_terms",
    "text": "[3.2.5 Change on Request] (Level AAA)\nDescription: Changes of context are initiated only by user request or a mechanism is available to turn off such changes.\n\nSection: key_terms\n\nKey Terms\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\nchanges of context\nmajor changes that, if made without user awareness, can disorient users who are not able to view\n      the entire page simultaneously\nChanges in context include changes of:\nuser agent\n;\nviewport\n;\nfocus;\ncontent\nthat changes the meaning of the\nweb page\nNote\nA change of content is not always a change of context. Changes in content, such as\n      an expanding outline, dynamic menu, or a tab control do not necessarily change the\n      context, unless they also change one of the above (e.g., focus).\nExample\nOpening a new window, moving focus to a different component, going to a new page (including\n      anything that would look to a user as if they had moved to a new page) or significantly\n      re-arranging the content of a page are examples of changes of context.\nconformance\nsatisfying all the requirements of a given standard, guideline or specification\ncontent\ninformation and sensory experience to be communicated to the user by means of a\nuser agent\n, including code or markup that defines the content's\nstructure\n,\npresentation\n, and interactions\nmechanism\nprocess\nor technique for achieving a result\nNote 1\nThe mechanism may be explicitly provided in the content, or may be\nrelied upon\nto be provided by either the platform or by\nuser agents\n, including\nassistive technologies\n.\nNote 2\nThe mechanism needs to meet all success criteria for the conformance level claimed.\npresentation\nrendering of the\ncontent\nin a form to be perceived by users\nprocess\nseries of user actions where each action is required in order to complete an activity\nExample 1\nSuccessful use of a series of web pages on a shopping site requires users to view\n      alternative products, prices and offers, select products, submit an order, provide\n      shipping information and provide payment information.\nExample 2\nAn account registration page requires successful completion of a\nTuring test\nbefore\n      the registration form can be accessed.\nrelied upon\nthe content would not\nconform\nif that\ntechnology\nis turned off or is not supported\nstructure\nThe way the parts of a\nweb page\nare organized in relation to each other; and\nThe way a collection of\nweb pages\nis organized\ntechnology\nmechanism\nfor encoding instructions to be rendered, played or executed by\nuser agents\nNote 1\nAs used in these guidelines \"web technology\" and the word \"technology\" (when used\n      alone) both refer to web content technologies.\nNote 2\nWeb content technologies may include markup languages, data formats, or programming\n      languages that authors may use alone or in combination to create end-user experiences\n      that range from static web pages to synchronized media presentations to dynamic Web\n      applications.\nExample\nSome common examples of web content technologies include HTML, CSS, SVG, PNG, PDF,\n      Flash, and JavaScript.\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.\nviewport\nobject in which the\nuser agent\npresents content\nNote 1\nThe user agent presents content through one or more viewports. Viewports include windows, frames,\n      loudspeakers, and virtual magnifying glasses. A viewport may contain another viewport\n      (e.g., nested frames). Interface components created by the user agent such as prompts,\n      menus, and alerts are not viewports.\nNote 2\nThis definition is based on\nUser Agent Accessibility Guidelines 1.0 Glossary\n[\nUAAG10\n].\nweb page\na non-embedded resource obtained from a single URI using HTTP plus any other resources\n      that are used in the rendering or intended to be rendered together with it by a\nuser agent\nNote 1\nAlthough any \"other resources\" would be rendered together with the primary resource,\n      they would not necessarily be rendered simultaneously with each other.\nNote 2\nFor the purposes of conformance with these guidelines, a resource must be \"non-embedded\"\n      within the scope of conformance to be considered a web page.\nExample 1\nA web resource including all embedded images and media.\nExample 2\nA web mail program built using Asynchronous JavaScript and XML (AJAX). The program\n      lives entirely at http://example.com/mail, but includes an inbox, a contacts area\n      and a calendar. Links or buttons are provided that cause the inbox, contacts, or calendar\n      to display, but do not change the URI of the page as a whole.\nExample 3\nA customizable portal site, where users can choose content to display from a set of\n      different content modules.\nExample 4\nWhen you enter \"http://shopping.example.com/\" in your browser, you enter a movie-like\n      interactive shopping environment where you visually move around in a store dragging\n      products off of the shelves around you and into a visual shopping cart in front of\n      you. Clicking on a product causes it to be demonstrated with a specification sheet\n      floating alongside. This might be a single-page website or just one page within a\n      website.",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.5_situation_A",
    "type": "sc_situation",
    "sc_id": "3.2.5",
    "situation_id": "A",
    "techniques": [
      "G76"
    ],
    "text": "[3.2.5 Change on Request] (Level AAA)\nDescription: Changes of context are initiated only by user request or a mechanism is available to turn off such changes.\n\nSituation A: If the web page allows automatic updates:\n\nRelated techniques: G76",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.5_situation_B",
    "type": "sc_situation",
    "sc_id": "3.2.5",
    "situation_id": "B",
    "techniques": [
      "SVR1",
      "G110",
      "H76"
    ],
    "text": "[3.2.5 Change on Request] (Level AAA)\nDescription: Changes of context are initiated only by user request or a mechanism is available to turn off such changes.\n\nSituation B: If automatic redirects are possible:\n\nRelated techniques: SVR1, G110, H76",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.5_situation_C",
    "type": "sc_situation",
    "sc_id": "3.2.5",
    "situation_id": "C",
    "techniques": [
      "H83",
      "H83",
      "SCR24"
    ],
    "text": "[3.2.5 Change on Request] (Level AAA)\nDescription: Changes of context are initiated only by user request or a mechanism is available to turn off such changes.\n\nSituation C: If the web page uses pop-up windows:\n\nRelated techniques: H83, H83, SCR24",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.5_situation_D",
    "type": "sc_situation",
    "sc_id": "3.2.5",
    "situation_id": "D",
    "techniques": [
      "SCR19"
    ],
    "text": "[3.2.5 Change on Request] (Level AAA)\nDescription: Changes of context are initiated only by user request or a mechanism is available to turn off such changes.\n\nSituation D: If using an onchange event on a select element:\n\nRelated techniques: SCR19",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.5_advisory",
    "type": "sc_advisory",
    "sc_id": "3.2.5",
    "techniques": [
      "G200"
    ],
    "text": "[3.2.5 Change on Request] (Level AAA)\nDescription: Changes of context are initiated only by user request or a mechanism is available to turn off such changes.\n\nAdvisory techniques for SC 3.2.5: G200",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.5_failures",
    "type": "sc_failures",
    "sc_id": "3.2.5",
    "techniques": [
      "F60",
      "F61",
      "F9",
      "F22",
      "F52",
      "F40",
      "F41"
    ],
    "text": "[3.2.5 Change on Request] (Level AAA)\nDescription: Changes of context are initiated only by user request or a mechanism is available to turn off such changes.\n\nCommon failures for SC 3.2.5: F60, F61, F9, F22, F52, F40, F41",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.6_intent",
    "type": "sc",
    "sc_id": "3.2.6",
    "section": "intent",
    "text": "[3.2.6 Consistent Help] (Level A)\nDescription: New\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to ensure users can find help for completing tasks on a website, when it is available. When the placement of the help mechanism is kept consistent across a set of pages, users looking for help will find it easier to identify. This is distinct from interface-level help, such as contextual help, features like spell checkers, and instructional text in a form.\nLocating the help mechanism in a consistent location across pages makes it easier for users to find it.  For example, when a mechanism or link is located in the header of one web page, it will be easier to find if it is in the header of other pages. The help mechanism, such as a contact phone number, may be provided directly on the page, or it may also be a direct link to a contact page. Regardless of which approach is used, the mechanism must be located in the same relative order on each page within the set of pages.\nWhen testing this Success Criterion, it is the help item which is relative to the rest of the content. When testing a page, other content that is present across the set of web pages and is before the help item should be before the help item on this page. Items which are after the help item on other pages should be after the help item on this page.\nIf the help item is visually in a different location, but in the same serial order, that is not helpful from a user's point of view, but it would not fail this criterion.\nWhen having problems completing a task on a website (or part of a web site, what we call a\nset of web pages\n), people with some types of disabilities may not be able to work through the issue without further help.  Issues could include difficulty:\n         completing a form, or finding a document or page which provides information required to complete a task.\nWithout help, some users may abandon the task. They may also fail to correctly complete a task, or they may require assistance from people who do not necessarily keep private information secure.\nWhile it is recommended to consistently implement a help mechanism across a set of web pages, this criterion specifically pertains to pages that do include such a mechanism. Therefore, the absence of a help mechanism on certain pages within a set does not constitute a violation.\nLimitations and Exceptions\nIt is not the intent of this success criterion to require authors to provide help or access to help. The Criterion only requires that\nwhen\none of the listed forms of help is available across multiple pages that it be in a consistent location. It does not require authors to provide help information on PDFs or other static documents that may be available for viewing/download from the web pages. PDFs and other static documents are not considered part of the \"\nset of web pages\n\" from which they are downloaded.\nIt is also not the intent of this success criterion to require a human be available at all times. Ideally, if the human contact is not available during certain hours or certain days then information would be provided so the user can tell when it will be available.\nThis success criterion only requires help mechanisms to be consistent\nwithin\na particular\nset of web pages\n. Some complex web sites consist of multiple different sets of web pages with different purposes. For example, a web-based spreadsheet application might have one set of pages for editing spreadsheets and a separate set of pages for marketing the application. This success criterion would allow the different sets of web pages to use different help mechanism locations. However, it is best if help mechanisms are located as consistently as possible even among different related sets of web pages.\nThis success criterion contains an exception when \"a change is initiated by the user.\" This exception is intended to cover cases where a user performs an action with the intent of changing the display or layout of a page, such as changing the zoom level, orientation, or viewport size. Help mechanism locations may change in response to such a user-initiated change; as the criterion's second note clarifies, \"this criterion is concerned with relative order across pages displayed in the same page variation (e.g., same zoom level and orientation).\"\nThis exception allows the location in a smaller viewport to be different than in a larger viewport. However, it is best if the mechanism or link is consistent across a set of web pages. A consistent location, both visually and programmatically, is the most usable.\nThis exception is\nnot\nintended to treat every action that a user might initiate as a \"change\"; to qualify for the exception, the user must be initiating an action that would reasonably be expected to change the relative order of components within a page. For example, merely navigating between pages within a set of web pages is not a \"change initiated by the user\" for the purposes of this exception. Similarly, logging into or out of a page would not typically qualify, unless logging in would present the user with a distinct\nset of web pages\n.\nHelp Mechanisms\nTypical help mechanisms include:\nHuman contact details such as a phone number, email address, hours of operation.\nHuman contact mechanism such as a messaging system, chat client, contact form, social media channel.\nSelf-help option such as an up-to-date Frequently Asked Questions, How Do I page, Support page.\nA fully automated contact mechanism such as a chatbot.\nThe order of the types of help listed in the success criterion does not imply priority.\nSupport for people with cognitive and learning disabilities\nThis section is not required by the Consistent Help success criterion, but provides advice related to\nMaking Content Usable for People with Cognitive and Learning Disabilities\n.\nThe human contact details enable users to connect with the  organization or the part of the organization that can assist with the content. For example, an online jobs / recruitment portal may provide a contact method for the team that supports the recruitment portal and not a catch-all for the entire company. Each layer of contact added prolongs the time before the user will receive help.\nThe human contact mechanism enables a person to express what they are looking for using their own words. For some with cognitive disabilities, this may be the best way for them to find an answer to their problem.\nFor pages for which no human support is available it helps if a self-help option says that no human support is available. Self-help options can go beyond allowing the user to search within the site. Contextual help is still recommended (see\nSuccess Criterion 3.3.5\nfor more information), but a self-help option provides a single location that makes it easier for people with cognitive disabilities to understand what help is available without having to hunt for it. While some people may easily be able to identify that no support would be available for a particular type of web site, this may not be apparent to some users with disabilities.\nChatbots can work for many people, and particularly for people with cognitive disabilities if they:\nrecognize misspelled words,\nprovide human contact details if the chatbot is unable to provide a satisfactory response after 3 attempts, and\ncan be dismissed with a single interaction, and recalled using a link or button.\nThis criterion does not require that a site provide a help mechanism. However, when help is available:\nPeople who may have difficulty locating help are more likely to find it and complete their task.\nUsers that experience cognitive fatigue or cognitive shut down will be able to reserve their energy for the task, instead of using it to find support.\nEnabling users (especially those with cognitive disabilities) to find solutions while expressing their question using their own words (for example by interacting with a chatbot) increases their chances of success for completing a task.\nSelf help methods beyond the site, such as using internet search to find the contact information for an organization, can be too difficult. Further, the user's disability may make it more difficult to find the help available (such as a \"contact us\" link, phone number, or support page) if the information is not consistently present within a few interactions (e.g., displayed in the header, or via a menu). In addition, for some users with disabilities, struggling to complete a task on a site may cause additional cognitive challenges when searching for help within the site.\nWhen a user is quickly able to find help, they are able to complete the task even if they encounter challenges.",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.6_success_criterion",
    "type": "sc",
    "sc_id": "3.2.6",
    "section": "success_criterion",
    "text": "[3.2.6 Consistent Help] (Level A)\nDescription: New\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nIf a\nweb page\ncontains any of the following help\nmechanisms\n, and those mechanisms are repeated on multiple web pages within a\nset of web pages\n, they occur in the same order relative to other page content, unless a change is initiated by the user:\nHuman contact details;\nHuman contact mechanism;\nSelf-help option;\nA fully automated contact mechanism.\nNote 1\nHelp mechanisms may be provided directly on the page, or may be provided via a direct link to a different page containing the information.\nNote 2\nFor this success criterion, \"the same order relative to other page content\" can be thought of as how the content is ordered when the page is serialized. The visual position of a help mechanism is likely to be consistent across pages for the same page variation (e.g., CSS break-point). The user can initiate a change, such as changing the page's zoom or orientation, which may trigger a different page variation. This criterion is concerned with relative order across pages displayed in the same page variation (e.g., same zoom level and orientation).",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.6_benefits",
    "type": "sc",
    "sc_id": "3.2.6",
    "section": "benefits",
    "text": "[3.2.6 Consistent Help] (Level A)\nDescription: New\n\nSection: benefits\n\nBenefits\nPeople who may have difficulty locating help are more likely to find it when it is consistently located.",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.6_examples",
    "type": "sc",
    "sc_id": "3.2.6",
    "section": "examples",
    "text": "[3.2.6 Consistent Help] (Level A)\nDescription: New\n\nSection: examples\n\nExamples\nOn-line job application: Some of the application questions may be hard for new job seekers to understand even after reading the contextual help. For example, the form may request their identification number, but they may have several and not know which one to enter. Consistently located contact information will enable them to use phone or email so they can get an answer to their question.\nMedical appointment scheduling form: When the service a patient is trying to book is not easily findable within the interface, they may need human help. A consistently located messaging option (chat client) enables them to quickly interact with a staff person that can help, without requiring them to manage a second interface.\nFinding a specific policy or procedure: An employee who needs to complete a work task may have difficulty locating the specific policy or procedure document on their employer's web site. A consistently located \"How Do I\" page may include the information that enables them to independently complete this task.",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.6_brief",
    "type": "sc",
    "sc_id": "3.2.6",
    "section": "brief",
    "text": "[3.2.6 Consistent Help] (Level A)\nDescription: New\n\nSection: brief\n\nIn Brief\nGoal\nMake it easier to find help and support.\nWhat to do\nPut help in the same place when it is on multiple pages.\nWhy it's important\nPeople who need help can find it more easily if it's in the same place.",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.6_resources",
    "type": "sc",
    "sc_id": "3.2.6",
    "section": "resources",
    "text": "[3.2.6 Consistent Help] (Level A)\nDescription: New\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nCognitive Accessibility Gap Analysis Topic 6: Familiar Interface\nMaking Content Usable for People with Cogntive and Learning Disabilities 4.8.5 Make it Easy to Find Help and Give Feedback",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.6_key_terms",
    "type": "sc",
    "sc_id": "3.2.6",
    "section": "key_terms",
    "text": "[3.2.6 Consistent Help] (Level A)\nDescription: New\n\nSection: key_terms\n\nKey Terms\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\nconformance\nsatisfying all the requirements of a given standard, guideline or specification\nmechanism\nprocess\nor technique for achieving a result\nNote 1\nThe mechanism may be explicitly provided in the content, or may be\nrelied upon\nto be provided by either the platform or by\nuser agents\n, including\nassistive technologies\n.\nNote 2\nThe mechanism needs to meet all success criteria for the conformance level claimed.\nprocess\nseries of user actions where each action is required in order to complete an activity\nExample 1\nSuccessful use of a series of web pages on a shopping site requires users to view\n      alternative products, prices and offers, select products, submit an order, provide\n      shipping information and provide payment information.\nExample 2\nAn account registration page requires successful completion of a\nTuring test\nbefore\n      the registration form can be accessed.\nrelied upon\nthe content would not\nconform\nif that\ntechnology\nis turned off or is not supported\nset of web pages\ncollection of\nweb pages\nthat share a common purpose and that are created by the same author, group or organization\nExample\nExamples include:\na publication which is split across multiple web pages, where each page contains one chapter or other significant section of the work. The publication is logically a single contiguous unit, and contains navigation features that enable access to the full set of pages.\nan e-commerce website shows products in a set of web pages that all share the same navigation and identification. However, when progressing to the checkout process, the template changes; the navigation and other elements are removed, so the pages in that process are functionally and visually different. The checkout pages are not part of the set of product pages.\na blog on a sub-domain (e.g. blog.example.com) which has a different navigation and is authored by a distinct set of people from the pages on the primary domain (example.com).\nNote\nDifferent language versions would be considered different sets of web pages.\ntechnology\nmechanism\nfor encoding instructions to be rendered, played or executed by\nuser agents\nNote 1\nAs used in these guidelines \"web technology\" and the word \"technology\" (when used\n      alone) both refer to web content technologies.\nNote 2\nWeb content technologies may include markup languages, data formats, or programming\n      languages that authors may use alone or in combination to create end-user experiences\n      that range from static web pages to synchronized media presentations to dynamic Web\n      applications.\nExample\nSome common examples of web content technologies include HTML, CSS, SVG, PNG, PDF,\n      Flash, and JavaScript.\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.\nweb page\na non-embedded resource obtained from a single URI using HTTP plus any other resources\n      that are used in the rendering or intended to be rendered together with it by a\nuser agent\nNote 1\nAlthough any \"other resources\" would be rendered together with the primary resource,\n      they would not necessarily be rendered simultaneously with each other.\nNote 2\nFor the purposes of conformance with these guidelines, a resource must be \"non-embedded\"\n      within the scope of conformance to be considered a web page.\nExample 1\nA web resource including all embedded images and media.\nExample 2\nA web mail program built using Asynchronous JavaScript and XML (AJAX). The program\n      lives entirely at http://example.com/mail, but includes an inbox, a contacts area\n      and a calendar. Links or buttons are provided that cause the inbox, contacts, or calendar\n      to display, but do not change the URI of the page as a whole.\nExample 3\nA customizable portal site, where users can choose content to display from a set of\n      different content modules.\nExample 4\nWhen you enter \"http://shopping.example.com/\" in your browser, you enter a movie-like\n      interactive shopping environment where you visually move around in a store dragging\n      products off of the shelves around you and into a visual shopping cart in front of\n      you. Clicking on a product causes it to be demonstrated with a specification sheet\n      floating alongside. This might be a single-page website or just one page within a\n      website.",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.2.6_sufficient",
    "type": "sc_sufficient",
    "sc_id": "3.2.6",
    "techniques": [
      "G220"
    ],
    "text": "[3.2.6 Consistent Help] (Level A)\nDescription: New\n\nSufficient techniques for SC 3.2.6 (no situation): G220",
    "principle": "Understandable",
    "guideline": "3.2 Predictable"
  },
  {
    "id": "3.3.1_intent",
    "type": "sc",
    "sc_id": "3.3.1",
    "section": "intent",
    "text": "[3.3.1 Error Identification] (Level A)\nDescription: If an input error is automatically detected, the item that is in error is identified and the error\n      is described to the user in text.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to ensure that users are aware that an error\n         has occurred and can determine what is wrong. In the case of an unsuccessful form submission,\n         it is not sufficient to only re-display the form without providing any hint that the submission\n         failed.\n         The error must be indicated in\ntext\n.\n         Whether or not an error message provides users with sufficient information about the nature of\n         the error, and what they should do to correct it, is covered more specifically by\n3.3.3 Error Suggestion\n.\nAn \"input error\" is information provided by the user that is not accepted. This includes:\ninformation that is required by the web page but omitted by the user, or\ninformation that is provided by the user but that falls outside the required data format or allowed values.\nFor example:\nthe user fails to enter the proper abbreviation in a state, province, or region field;\nthe user enters a state abbreviation that is not a valid state;\nthe user enters a non existent zip or postal code;\nthe user enters a birth date 2 years in the future;\nthe user enters alphabetic characters or parentheses into their phone number field that only accepts numbers;\nthe user enters a bid that is below the previous bid or the minimum bid increment.\nNote\nIf a user enters a value that is too high or too low, and the coding on the page automatically\n            changes that value to fall within the allowed range, the user's error would still\n            need to be described to them as required by the success criterion. Such an error description\n            telling the person of the changed value would meet both this success criterion (Error\n            Identification) and\n3.3.3 Error Suggestion\n.\nThe identification and description of an error can be combined with programmatic information\n         that user agents or assistive technologies can use to identify an error and provide\n         error information to the user. For example, certain technologies can specify that\n         the user's input must not fall outside a specific range, or that a form field is required.\n         This type of programmatic information is not required for this success criterion, but may be covered\n         by other criteria such as\n4.1.2 Name, Role, Value\n.\nIt is perfectly acceptable to indicate the error in other ways such as through the use of an image,\n         color, or other visual indicator, in addition to the text description.\nNote\nThis criterion does not mandate any particular way in which errors should be displayed. Depending\n            on the situation, it may be more suitable for all errors to be listed at the start or before a form.\n            In other cases, it may be more appropriate to show errors inline, with error messages next to the specific\n            fields that are in error. Errors could also be listed in an alert, or dialog. This criterion does not\n            cover which of these methods should be used - the only requirement is for errors  to be presented to users in text or a text alternative.\nSee also\n3.3.3: Error Suggestion\n.",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.1_success_criterion",
    "type": "sc",
    "sc_id": "3.3.1",
    "section": "success_criterion",
    "text": "[3.3.1 Error Identification] (Level A)\nDescription: If an input error is automatically detected, the item that is in error is identified and the error\n      is described to the user in text.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nIf an\ninput error\nis automatically detected, the item that is in error is identified and the error\n      is described to the user in text.",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.1_benefits",
    "type": "sc",
    "sc_id": "3.3.1",
    "section": "benefits",
    "text": "[3.3.1 Error Identification] (Level A)\nDescription: If an input error is automatically detected, the item that is in error is identified and the error\n      is described to the user in text.\n\nSection: benefits\n\nBenefits\nProviding information about input errors in text allows users who are blind or color deficient (color blind) to perceive the fact that an error occurred.\nThis success criterion may help people with cognitive, language, and learning disabilities\n            who have difficulty understanding the specific reason why a form submission failed (in cases\n            where this is not already made obvious by the nature of the form).",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.1_examples",
    "type": "sc",
    "sc_id": "3.3.1",
    "section": "examples",
    "text": "[3.3.1 Error Identification] (Level A)\nDescription: If an input error is automatically detected, the item that is in error is identified and the error\n      is described to the user in text.\n\nSection: examples\n\nExamples\nIdentifying errors in a form submission\nAn airline website offers a special promotion on discounted flights. The user is\n               asked to complete a simple form that asks for personal information such as name, address,\n               phone number, seating preference and e-mail address. If any of the fields of the form\n               are either not completed or completed incorrectly, an alert is displayed notifying\n               the user which field or fields were missing or incorrect.\nNote\nThis success criterion does not mean that color or text styles cannot be used to indicate\n                  errors. It simply requires that errors also be identified using text.\nProviding multiple cues\nThe user fails to fill in two fields on the form.  In addition to describing the error\n               and providing a unique character to make it easy to search for the fields, the fields\n               are highlighted in yellow to make it easier to visually search for them as well.",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.1_brief",
    "type": "sc",
    "sc_id": "3.3.1",
    "section": "brief",
    "text": "[3.3.1 Error Identification] (Level A)\nDescription: If an input error is automatically detected, the item that is in error is identified and the error\n      is described to the user in text.\n\nSection: brief\n\nIn Brief\nGoal\nUsers know an error exists and what is wrong.\nWhat to do\nProvide descriptive notification of errors.\nWhy it's important\nFlagging errors helps people with reduced sight and cognitive disabilities resolve them.",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.1_test_rules",
    "type": "sc",
    "sc_id": "3.3.1",
    "section": "test_rules",
    "text": "[3.3.1 Error Identification] (Level A)\nDescription: If an input error is automatically detected, the item that is in error is identified and the error\n      is described to the user in text.\n\nSection: test_rules\n\nTest Rules\nThe following are Test Rules\n    for certain aspects of this Success Criterion.\n    It is not necessary to use these particular Test Rules to check for conformance with WCAG, but they are defined and approved test methods.\n    For information on using Test Rules, see\nUnderstanding Test Rules for WCAG Success Criteria\n.\nError message describes invalid form field value",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.1_key_terms",
    "type": "sc",
    "sc_id": "3.3.1",
    "section": "key_terms",
    "text": "[3.3.1 Error Identification] (Level A)\nDescription: If an input error is automatically detected, the item that is in error is identified and the error\n      is described to the user in text.\n\nSection: key_terms\n\nKey Terms\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\nhuman language\nlanguage that is spoken, written or signed (through visual or tactile means) to communicate\n      with humans\nNote\nSee also\nsign language\n.\ninput error\ninformation provided by the user that is not accepted\nNote\nThis includes:\nInformation that is required by the\nweb page\nbut omitted by the user\nInformation that is provided by the user but that falls outside the required data\n         format or values\nprogrammatically determined\ndetermined by software from author-supplied data provided in a way that different\nuser agents\n, including\nassistive technologies\n, can extract and present this information to users in different modalities\nExample 1\nDetermined in a markup language from elements and attributes that are accessed directly\n      by commonly available assistive technology.\nExample 2\nDetermined from technology-specific data structures in a non-markup language and exposed\n      to assistive technology via an accessibility API that is supported by commonly available\n      assistive technology.\nsign language\na language using combinations of movements of the hands and arms, facial expressions,\n      or body positions to convey meaning\ntext\nsequence of characters that can be\nprogrammatically determined\n, where the sequence is expressing something in\nhuman language\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.\nweb page\na non-embedded resource obtained from a single URI using HTTP plus any other resources\n      that are used in the rendering or intended to be rendered together with it by a\nuser agent\nNote 1\nAlthough any \"other resources\" would be rendered together with the primary resource,\n      they would not necessarily be rendered simultaneously with each other.\nNote 2\nFor the purposes of conformance with these guidelines, a resource must be \"non-embedded\"\n      within the scope of conformance to be considered a web page.\nExample 1\nA web resource including all embedded images and media.\nExample 2\nA web mail program built using Asynchronous JavaScript and XML (AJAX). The program\n      lives entirely at http://example.com/mail, but includes an inbox, a contacts area\n      and a calendar. Links or buttons are provided that cause the inbox, contacts, or calendar\n      to display, but do not change the URI of the page as a whole.\nExample 3\nA customizable portal site, where users can choose content to display from a set of\n      different content modules.\nExample 4\nWhen you enter \"http://shopping.example.com/\" in your browser, you enter a movie-like\n      interactive shopping environment where you visually move around in a store dragging\n      products off of the shelves around you and into a visual shopping cart in front of\n      you. Clicking on a product causes it to be demonstrated with a specification sheet\n      floating alongside. This might be a single-page website or just one page within a\n      website.",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.1_situation_A",
    "type": "sc_situation",
    "sc_id": "3.3.1",
    "situation_id": "A",
    "techniques": [
      "G83",
      "ARIA2",
      "ARIA21",
      "SCR18",
      "PDF5"
    ],
    "text": "[3.3.1 Error Identification] (Level A)\nDescription: If an input error is automatically detected, the item that is in error is identified and the error\n      is described to the user in text.\n\nSituation A: If a form contains fields for which information from the user is mandatory.\n\nRelated techniques: G83, ARIA2, ARIA21, SCR18, PDF5",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.1_situation_B",
    "type": "sc_situation",
    "sc_id": "3.3.1",
    "situation_id": "B",
    "techniques": [
      "ARIA18",
      "ARIA19",
      "ARIA21",
      "G84",
      "G85",
      "SCR18",
      "SCR32",
      "PDF22"
    ],
    "text": "[3.3.1 Error Identification] (Level A)\nDescription: If an input error is automatically detected, the item that is in error is identified and the error\n      is described to the user in text.\n\nSituation B: If information provided by the user is required to be in a specific data format or of certain values.\n\nRelated techniques: ARIA18, ARIA19, ARIA21, G84, G85, SCR18, SCR32, PDF22",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.1_advisory",
    "type": "sc_advisory",
    "sc_id": "3.3.1",
    "techniques": [
      "G139",
      "G199"
    ],
    "text": "[3.3.1 Error Identification] (Level A)\nDescription: If an input error is automatically detected, the item that is in error is identified and the error\n      is described to the user in text.\n\nAdvisory techniques for SC 3.3.1: G139, G199",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.2_intent",
    "type": "sc",
    "sc_id": "3.3.2",
    "section": "intent",
    "text": "[3.3.2 Labels or Instructions] (Level A)\nDescription: Labels or instructions are provided when content requires user input.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to have content authors present instructions\n         or labels that identify the controls in a form so that users know what input data\n         is expected. In the case of radio buttons, checkboxes, comboboxes, or similar controls\n         that provide users with options, each option must have an appropriate label so that\n         users know what they are actually selecting. \n         Instructions or labels may also specify data formats for data entry fields, especially\n         if they are out of the customary formats or if there are specific rules for correct\n         input. Content authors may also choose to make such instructions available to users\n         only when the individual control has focus especially when instructions are long and\n         verbose.\nThe intent of this success criterion is not to clutter the page with unnecessary information\n         but to provide important cues and instructions that will benefit people with disabilities.\n         Too much information or instruction can be just as harmful as too little.\n         The goal is to make certain that enough information is provided for the user to accomplish\n         the task without undue confusion or navigation.\nThis success criterion does not require that labels or instructions be correctly marked up, \n         identified, or associated with their respective controls — that aspect is covered separately by\n1.3.1: Info and Relationships\n. It is possible for content\n         to pass this success criterion (providing relevant labels and instructions) while failing\n         Success Criterion 1.3.1 (if the labels or instructions aren't correctly marked up, identified, or associated).\nFurther, this success criterion does not take into consideration whether or not alternative methods of\n         providing an accessible name or description for form controls and inputs has been used — that aspect is\n         covered separately by\n4.1.2: Name, Role and Value\n. It is possible\n         for controls and inputs to have an appropriate accessible name or description (e.g. using\naria-label=\"...\"\n)\n         and therefore pass Success Criterion 4.1.2, but to still fail this success criterion (if the labels or instructions\n         aren't presented to all users, not just those using assistive technologies).\nThis success criterion does not apply to links or other controls (such as an expand/collapse widget, or similar\n         interactive components) that are not associated with data entry.\nWhile this success criterion requires that controls and inputs have labels or instructions, whether or\n         not labels (if used) are accurate, sufficiently clear, or descriptive is covered separately by\n2.4.6: Headings and Labels\n.\nNote\nThe use of \"requires\" in this criterion's normative wording does not mean that the criterion only applies\n         to\nrequired\nform fields. It is used here as a synonym for \"accepts\", \"expects\", or \"allows\". The criterion\n         applies to all form fields, whether they're required or optional.",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.2_success_criterion",
    "type": "sc",
    "sc_id": "3.3.2",
    "section": "success_criterion",
    "text": "[3.3.2 Labels or Instructions] (Level A)\nDescription: Labels or instructions are provided when content requires user input.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nLabels\nor instructions are provided when content requires user input.",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.2_benefits",
    "type": "sc",
    "sc_id": "3.3.2",
    "section": "benefits",
    "text": "[3.3.2 Labels or Instructions] (Level A)\nDescription: Labels or instructions are provided when content requires user input.\n\nSection: benefits\n\nBenefits\nProviding labels and instructions (including examples of expected\n            data formats) helps all users — but particularly those with cognitive, language, and learning\n            disabilities — to enter information correctly.\nProviding labels and instructions (including identification of required\n            fields) can prevent users from making incomplete or incorrect form submissions, which prevents\n            users from having to navigate once more through a page/form in order to fix submission errors.",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.2_examples",
    "type": "sc",
    "sc_id": "3.3.2",
    "section": "examples",
    "text": "[3.3.2 Labels or Instructions] (Level A)\nDescription: Labels or instructions are provided when content requires user input.\n\nSection: examples\n\nExamples\nA field which asks the user to enter the two character abbreviation for a US state\n            has a link next to it which will pop up an alphabetized list of state names and the\n            correct abbreviation.\nA field for entering a date has text instructions to indicate the correct format\n            for the date.\nOn one website, a field with the text label of \"username\" is provided for someone to create a username to login to a website.\n          On another website, there are strict rules about what characters can be used to create a username. On this website additional instructions \n          would need to accompany the field to prevent users from encountering unnecessary errors.\nA website provides a global search field in the header of the site. Any term can be entered,\n          so there are no instructions needed, but the field needs a cue to communicate its purpose. Commonly, such search\n          field will be paired with a \"loupe\" or \"magnify glass\" search icon, serving as its visible label, if not also doubling\n          as the visual identifier for the button that submits the search query.\nTo enter their name, users are provided with two separate text fields. Rather than\n            having a single label \"Name\" (which would appear to leave the second text field unlabelled),\n            each field is given an explicit label — \"Given Name\" and \"Family Name\".\nA U.S. phone number separates the area code, exchange, and number into three fields.\n            Parentheses surround the area code field, and a dash separates the exchange and number\n            fields. While the punctuation provides visual clues to those familiar with the U.S.\n            telephone number format, the punctuation is not sufficient to label the fields. The\n            single \"Phone number\" label also cannot label all three fields. To address this, the\n            three fields are grouped in a fieldset with the legend \"Phone number\". Visual labels for\n            the fields (beyond the punctuation) cannot be provided\n            in the design, so invisible labels are provided with the \"title\" attribute to each\n            of the three fields. The value of this attribute for the three fields are, respectively,\n            \"Area Code\", \"Exchange\", and \"Number\".",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.2_brief",
    "type": "sc",
    "sc_id": "3.3.2",
    "section": "brief",
    "text": "[3.3.2 Labels or Instructions] (Level A)\nDescription: Labels or instructions are provided when content requires user input.\n\nSection: brief\n\nIn Brief\nGoal\nUsers know what information to enter.\nWhat to do\nProvide labels or instructions for inputs.\nWhy it's important\nEveryone, especially those with cognitive disabilities, will know how to respond.",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.2_key_terms",
    "type": "sc",
    "sc_id": "3.3.2",
    "section": "key_terms",
    "text": "[3.3.2 Labels or Instructions] (Level A)\nDescription: Labels or instructions are provided when content requires user input.\n\nSection: key_terms\n\nKey Terms\nASCII art\npicture created by a spatial arrangement of characters or glyphs (typically from the\n      95 printable characters defined by ASCII)\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\ncontent\ninformation and sensory experience to be communicated to the user by means of a\nuser agent\n, including code or markup that defines the content's\nstructure\n,\npresentation\n, and interactions\nhuman language\nlanguage that is spoken, written or signed (through visual or tactile means) to communicate\n      with humans\nNote\nSee also\nsign language\n.\nlabel\ntext\nor other component with a\ntext alternative\nthat is presented to a user to identify a component within web\ncontent\nNote 1\nA label is presented to all users whereas the\nname\nmay be hidden and only exposed by assistive technology. In many (but not all) cases\n      the name and the label are the same.\nNote 2\nThe term label is not limited to the label element in HTML.\nname\ntext by which software can identify a component within web content to the user\nNote 1\nThe name may be hidden and only exposed by assistive technology, whereas a\nlabel\nis presented to all users. In many (but not all) cases, the label and the name are\n      the same.\nNote 2\nThis is unrelated to the name attribute in HTML.\nnon-text content\nany content that is not a sequence of characters that can be\nprogrammatically determined\nor where the sequence is not expressing something in\nhuman language\nNote\nThis includes\nASCII art\n(which is a pattern of characters), emoticons, leetspeak (which uses character substitution),\n      and images representing text\npresentation\nrendering of the\ncontent\nin a form to be perceived by users\nprogrammatically determined\ndetermined by software from author-supplied data provided in a way that different\nuser agents\n, including\nassistive technologies\n, can extract and present this information to users in different modalities\nExample 1\nDetermined in a markup language from elements and attributes that are accessed directly\n      by commonly available assistive technology.\nExample 2\nDetermined from technology-specific data structures in a non-markup language and exposed\n      to assistive technology via an accessibility API that is supported by commonly available\n      assistive technology.\nsign language\na language using combinations of movements of the hands and arms, facial expressions,\n      or body positions to convey meaning\nstructure\nThe way the parts of a\nweb page\nare organized in relation to each other; and\nThe way a collection of\nweb pages\nis organized\ntext\nsequence of characters that can be\nprogrammatically determined\n, where the sequence is expressing something in\nhuman language\ntext alternative\nText\nthat is programmatically associated with\nnon-text content\nor referred to from text that is programmatically associated with non-text content.\n      Programmatically associated text is text whose location can be\nprogrammatically determined\nfrom the non-text content.\nExample\nAn image of a chart is described in text in the paragraph after the chart. The short\n      text alternative for the chart indicates that a description follows.\nNote\nRefer to\nUnderstanding Text Alternatives\nfor more information.\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.\nweb page\na non-embedded resource obtained from a single URI using HTTP plus any other resources\n      that are used in the rendering or intended to be rendered together with it by a\nuser agent\nNote 1\nAlthough any \"other resources\" would be rendered together with the primary resource,\n      they would not necessarily be rendered simultaneously with each other.\nNote 2\nFor the purposes of conformance with these guidelines, a resource must be \"non-embedded\"\n      within the scope of conformance to be considered a web page.\nExample 1\nA web resource including all embedded images and media.\nExample 2\nA web mail program built using Asynchronous JavaScript and XML (AJAX). The program\n      lives entirely at http://example.com/mail, but includes an inbox, a contacts area\n      and a calendar. Links or buttons are provided that cause the inbox, contacts, or calendar\n      to display, but do not change the URI of the page as a whole.\nExample 3\nA customizable portal site, where users can choose content to display from a set of\n      different content modules.\nExample 4\nWhen you enter \"http://shopping.example.com/\" in your browser, you enter a movie-like\n      interactive shopping environment where you visually move around in a store dragging\n      products off of the shelves around you and into a visual shopping cart in front of\n      you. Clicking on a product causes it to be demonstrated with a specification sheet\n      floating alongside. This might be a single-page website or just one page within a\n      website.",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.2_sufficient",
    "type": "sc_sufficient",
    "sc_id": "3.3.2",
    "techniques": [
      "G131",
      "ARIA1",
      "ARIA9",
      "ARIA17",
      "G89",
      "G184",
      "G162",
      "G83",
      "H90",
      "PDF5",
      "H44",
      "PDF10",
      "H71",
      "G167"
    ],
    "text": "[3.3.2 Labels or Instructions] (Level A)\nDescription: Labels or instructions are provided when content requires user input.\n\nSufficient techniques for SC 3.3.2 (no situation): G131, ARIA1, ARIA9, ARIA17, G89, G184, G162, G83, H90, PDF5, H44, PDF10, H71, G167",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.2_advisory",
    "type": "sc_advisory",
    "sc_id": "3.3.2",
    "techniques": [
      "G13"
    ],
    "text": "[3.3.2 Labels or Instructions] (Level A)\nDescription: Labels or instructions are provided when content requires user input.\n\nAdvisory techniques for SC 3.3.2: G13",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.2_failures",
    "type": "sc_failures",
    "sc_id": "3.3.2",
    "techniques": [
      "F82"
    ],
    "text": "[3.3.2 Labels or Instructions] (Level A)\nDescription: Labels or instructions are provided when content requires user input.\n\nCommon failures for SC 3.3.2: F82",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.3_intent",
    "type": "sc",
    "sc_id": "3.3.3",
    "section": "intent",
    "text": "[3.3.3 Error Suggestion] (Level AA)\nDescription: If an input error is automatically detected and suggestions for correction are known, then the suggestions\n      are provided to the user, unless it would jeopardize the security or purpose of the\n      content.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to ensure that users receive appropriate suggestions\n         for correction of an input error if it is possible. The definition of \"input error\"\n         says that it is \"information provided by the user that is not accepted\" by\n         the system. Some examples of information that is not accepted include information\n         that is required but omitted by the user and information that is provided by the user\n         but that falls outside the required data format or allowed values.\nSuccess Criterion 3.3.1 provides for notification of errors. However, persons with\n         cognitive limitations may find it difficult to understand how to correct the errors.\n         People with visual disabilities may not be able to figure out exactly how to correct\n         the error. In the case of an unsuccessful form submission, users may abandon the form\n         because they may be unsure of how to correct the error even though they are aware\n         that it has occurred.\nThe content author may provide the description of the error, or the user agent may\n         provide the description of the error based on technology-specific, programmatically\n         determined information.",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.3_success_criterion",
    "type": "sc",
    "sc_id": "3.3.3",
    "section": "success_criterion",
    "text": "[3.3.3 Error Suggestion] (Level AA)\nDescription: If an input error is automatically detected and suggestions for correction are known, then the suggestions\n      are provided to the user, unless it would jeopardize the security or purpose of the\n      content.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nIf an\ninput error\nis automatically detected and suggestions for correction are known, then the suggestions\n      are provided to the user, unless it would jeopardize the security or purpose of the\n      content.",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.3_benefits",
    "type": "sc",
    "sc_id": "3.3.3",
    "section": "benefits",
    "text": "[3.3.3 Error Suggestion] (Level AA)\nDescription: If an input error is automatically detected and suggestions for correction are known, then the suggestions\n      are provided to the user, unless it would jeopardize the security or purpose of the\n      content.\n\nSection: benefits\n\nBenefits\nProviding information about how to correct input errors allows users who have learning\n            disabilities to fill in a form successfully.\nUsers who are blind or have impaired vision understand more easily the nature of the\n            input error and how to correct it.\nPeople with motion impairment can reduce the number of times they need to change an\n            input value.",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.3_examples",
    "type": "sc",
    "sc_id": "3.3.3",
    "section": "examples",
    "text": "[3.3.3 Error Suggestion] (Level AA)\nDescription: If an input error is automatically detected and suggestions for correction are known, then the suggestions\n      are provided to the user, unless it would jeopardize the security or purpose of the\n      content.\n\nSection: examples\n\nExamples\nAdditional Help for Correcting An Input Error\nThe result of a form that was not successfully submitted describes an\n               input error in place in the page along with the correct input and offers additional\n               help for the form field that caused the input error.\nSuggestions from a Limited Set of Values\nAn input field requires that a month name be entered. If the user enters \"12,\" suggestions\n               for correction may include:\nA list of the acceptable values, e.g., \"Choose one of: January, February, March, April,\n                  May, June, July, August, September, October, November, December.\"\nThe conversion of the input data interpreted as a different month format, e.g., \"Do\n                  you mean 'December'?\"",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.3_brief",
    "type": "sc",
    "sc_id": "3.3.3",
    "section": "brief",
    "text": "[3.3.3 Error Suggestion] (Level AA)\nDescription: If an input error is automatically detected and suggestions for correction are known, then the suggestions\n      are provided to the user, unless it would jeopardize the security or purpose of the\n      content.\n\nSection: brief\n\nIn Brief\nGoal\nUsers get suggestions on how to resolve errors.\nWhat to do\nWhere errors are detected, suggest known ways to correct them.\nWhy it's important\nPeople can address errors faster and with reduced effort.",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.3_key_terms",
    "type": "sc",
    "sc_id": "3.3.3",
    "section": "key_terms",
    "text": "[3.3.3 Error Suggestion] (Level AA)\nDescription: If an input error is automatically detected and suggestions for correction are known, then the suggestions\n      are provided to the user, unless it would jeopardize the security or purpose of the\n      content.\n\nSection: key_terms\n\nKey Terms\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\ninput error\ninformation provided by the user that is not accepted\nNote\nThis includes:\nInformation that is required by the\nweb page\nbut omitted by the user\nInformation that is provided by the user but that falls outside the required data\n         format or values\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.\nweb page\na non-embedded resource obtained from a single URI using HTTP plus any other resources\n      that are used in the rendering or intended to be rendered together with it by a\nuser agent\nNote 1\nAlthough any \"other resources\" would be rendered together with the primary resource,\n      they would not necessarily be rendered simultaneously with each other.\nNote 2\nFor the purposes of conformance with these guidelines, a resource must be \"non-embedded\"\n      within the scope of conformance to be considered a web page.\nExample 1\nA web resource including all embedded images and media.\nExample 2\nA web mail program built using Asynchronous JavaScript and XML (AJAX). The program\n      lives entirely at http://example.com/mail, but includes an inbox, a contacts area\n      and a calendar. Links or buttons are provided that cause the inbox, contacts, or calendar\n      to display, but do not change the URI of the page as a whole.\nExample 3\nA customizable portal site, where users can choose content to display from a set of\n      different content modules.\nExample 4\nWhen you enter \"http://shopping.example.com/\" in your browser, you enter a movie-like\n      interactive shopping environment where you visually move around in a store dragging\n      products off of the shelves around you and into a visual shopping cart in front of\n      you. Clicking on a product causes it to be demonstrated with a specification sheet\n      floating alongside. This might be a single-page website or just one page within a\n      website.",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.3_situation_A",
    "type": "sc_situation",
    "sc_id": "3.3.3",
    "situation_id": "A",
    "techniques": [
      "ARIA18",
      "G85",
      "G177",
      "PDF22"
    ],
    "text": "[3.3.3 Error Suggestion] (Level AA)\nDescription: If an input error is automatically detected and suggestions for correction are known, then the suggestions\n      are provided to the user, unless it would jeopardize the security or purpose of the\n      content.\n\nSituation A: If information for a field is required to be in a specific data format:\n\nRelated techniques: ARIA18, G85, G177, PDF22",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.3_situation_B",
    "type": "sc_situation",
    "sc_id": "3.3.3",
    "situation_id": "B",
    "techniques": [
      "ARIA18",
      "G84",
      "G177",
      "PDF22"
    ],
    "text": "[3.3.3 Error Suggestion] (Level AA)\nDescription: If an input error is automatically detected and suggestions for correction are known, then the suggestions\n      are provided to the user, unless it would jeopardize the security or purpose of the\n      content.\n\nSituation B: Information provided by the user is required to be one of a limited set of values:\n\nRelated techniques: ARIA18, G84, G177, PDF22",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.3_advisory",
    "type": "sc_advisory",
    "sc_id": "3.3.3",
    "techniques": [
      "G139",
      "G199",
      "SCR18",
      "SCR32"
    ],
    "text": "[3.3.3 Error Suggestion] (Level AA)\nDescription: If an input error is automatically detected and suggestions for correction are known, then the suggestions\n      are provided to the user, unless it would jeopardize the security or purpose of the\n      content.\n\nAdvisory techniques for SC 3.3.3: G139, G199, SCR18, SCR32",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.4_intent",
    "type": "sc",
    "sc_id": "3.3.4",
    "section": "intent",
    "text": "[3.3.4 Error Prevention (Legal, Financial, Data)] (Level AA)\nDescription: For web pages that cause legal commitments or financial transactions for the user to occur, that modify or delete user-controllable data in data storage systems, or that submit user test responses, at least one of\n      the following is true:\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to help users with disabilities avoid serious\n         consequences as the result of a mistake when performing an action that cannot be reversed.\n         For example, purchasing non-refundable airline tickets or submitting an order to purchase\n         stock in a brokerage account are financial transactions with serious consequences.\n         If users have made a mistake on the date of air travel, they could end up with\n         a ticket for the wrong day that cannot be exchanged. If users made a mistake on\n         the number of stock shares to be purchased, they could end up purchasing more\n         stock than intended. Both of these types of mistakes involve transactions that take\n         place immediately and cannot be altered afterwards, and can be very costly. Likewise,\n         it may be an unrecoverable error if users unintentionally modify or delete data stored\n         in a database that they later need to access, such as their entire travel profile\n         in a travel services website. When referring to modification or deletion of 'user\n         controllable' data, the intent is to prevent mass loss of data such as deleting a\n         file or record. It is not the intent to require a confirmation for each save command\n         or the simple creation or editing of documents, records or other data.\nUsers with disabilities may be more likely to make mistakes. People with reading disabilities\n         may transpose numbers and letters, and those with motor disabilities may hit keys\n         by mistake. Providing the ability to reverse actions allows users to correct a mistake\n         that could result in serious consequences. Providing the ability to review and correct\n         information gives the user an opportunity to detect a mistake before taking an action\n         that has serious consequences.\nUser-controllable data is user-viewable data that the user can change and/or delete\n         through an intentional action. Examples of the user controlling such data would be\n         updating the phone number and address for the user's account, or deleting a record\n         of past invoices from a website. It does not refer such things as internet logs and\n         search engine monitoring data that the user can't view or interact with directly.",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.4_success_criterion",
    "type": "sc",
    "sc_id": "3.3.4",
    "section": "success_criterion",
    "text": "[3.3.4 Error Prevention (Legal, Financial, Data)] (Level AA)\nDescription: For web pages that cause legal commitments or financial transactions for the user to occur, that modify or delete user-controllable data in data storage systems, or that submit user test responses, at least one of\n      the following is true:\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nFor\nweb pages\nthat cause\nlegal commitments\nor financial transactions for the user to occur, that modify or delete\nuser-controllable\ndata in data storage systems, or that submit user test responses, at least one of\n      the following is true:\nReversible\nSubmissions are reversible.\nChecked\nData entered by the user is checked for\ninput errors\nand the user is provided an opportunity to correct them.\nConfirmed\nA\nmechanism\nis available for reviewing, confirming, and correcting information before finalizing the submission.",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.4_benefits",
    "type": "sc",
    "sc_id": "3.3.4",
    "section": "benefits",
    "text": "[3.3.4 Error Prevention (Legal, Financial, Data)] (Level AA)\nDescription: For web pages that cause legal commitments or financial transactions for the user to occur, that modify or delete user-controllable data in data storage systems, or that submit user test responses, at least one of\n      the following is true:\n\nSection: benefits\n\nBenefits\nProviding safeguards to avoid serious consequences resulting from mistakes helps users\n            with all disabilities who may be more likely to make mistakes.",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.4_examples",
    "type": "sc",
    "sc_id": "3.3.4",
    "section": "examples",
    "text": "[3.3.4 Error Prevention (Legal, Financial, Data)] (Level AA)\nDescription: For web pages that cause legal commitments or financial transactions for the user to occur, that modify or delete user-controllable data in data storage systems, or that submit user test responses, at least one of\n      the following is true:\n\nSection: examples\n\nExamples\nOrder confirmation\nA web retailer offers on-line shopping for customers. When an order is submitted,\n               the order information—including items ordered, quantity of each ordered item, shipping\n               address, and payment method—are displayed so that the user can inspect the order for\n               correctness. The user can either confirm the order or make changes.\nStock sale\nA financial services website lets users buy and sell stock online. When a user submits\n               an order to buy or sell stock, the system checks to see whether or not the market\n               is open. If it is after hours, the user is alerted that the transaction will be an\n               after-hours transaction, is told about the risks of trading outside of regular market\n               hours, and given the opportunity to cancel or confirm the order.",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.4_brief",
    "type": "sc",
    "sc_id": "3.3.4",
    "section": "brief",
    "text": "[3.3.4 Error Prevention (Legal, Financial, Data)] (Level AA)\nDescription: For web pages that cause legal commitments or financial transactions for the user to occur, that modify or delete user-controllable data in data storage systems, or that submit user test responses, at least one of\n      the following is true:\n\nSection: brief\n\nIn Brief\nGoal\nUsers can avoid submitting incorrect important information.\nWhat to do\nProvide ways for users to confirm, correct, or reverse important submissions.\nWhy it's important\nPeople with disabilities may be more likely to make mistakes, or not notice them.",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.4_key_terms",
    "type": "sc",
    "sc_id": "3.3.4",
    "section": "key_terms",
    "text": "[3.3.4 Error Prevention (Legal, Financial, Data)] (Level AA)\nDescription: For web pages that cause legal commitments or financial transactions for the user to occur, that modify or delete user-controllable data in data storage systems, or that submit user test responses, at least one of\n      the following is true:\n\nSection: key_terms\n\nKey Terms\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\nconformance\nsatisfying all the requirements of a given standard, guideline or specification\ninput error\ninformation provided by the user that is not accepted\nNote\nThis includes:\nInformation that is required by the\nweb page\nbut omitted by the user\nInformation that is provided by the user but that falls outside the required data\n         format or values\nlegal commitments\ntransactions where the person incurs a legally binding obligation or benefit\nExample\nA marriage license, a stock trade (financial and legal), a will, a loan, adoption,\n      signing up for the army, a contract of any type, etc.\nmechanism\nprocess\nor technique for achieving a result\nNote 1\nThe mechanism may be explicitly provided in the content, or may be\nrelied upon\nto be provided by either the platform or by\nuser agents\n, including\nassistive technologies\n.\nNote 2\nThe mechanism needs to meet all success criteria for the conformance level claimed.\nprocess\nseries of user actions where each action is required in order to complete an activity\nExample 1\nSuccessful use of a series of web pages on a shopping site requires users to view\n      alternative products, prices and offers, select products, submit an order, provide\n      shipping information and provide payment information.\nExample 2\nAn account registration page requires successful completion of a\nTuring test\nbefore\n      the registration form can be accessed.\nrelied upon\nthe content would not\nconform\nif that\ntechnology\nis turned off or is not supported\ntechnology\nmechanism\nfor encoding instructions to be rendered, played or executed by\nuser agents\nNote 1\nAs used in these guidelines \"web technology\" and the word \"technology\" (when used\n      alone) both refer to web content technologies.\nNote 2\nWeb content technologies may include markup languages, data formats, or programming\n      languages that authors may use alone or in combination to create end-user experiences\n      that range from static web pages to synchronized media presentations to dynamic Web\n      applications.\nExample\nSome common examples of web content technologies include HTML, CSS, SVG, PNG, PDF,\n      Flash, and JavaScript.\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.\nuser-controllable\ndata that is intended to be accessed by users\nNote\nThis does not refer to such things as Internet logs and search engine monitoring data.\nExample\nName and address fields for a user's account.\nweb page\na non-embedded resource obtained from a single URI using HTTP plus any other resources\n      that are used in the rendering or intended to be rendered together with it by a\nuser agent\nNote 1\nAlthough any \"other resources\" would be rendered together with the primary resource,\n      they would not necessarily be rendered simultaneously with each other.\nNote 2\nFor the purposes of conformance with these guidelines, a resource must be \"non-embedded\"\n      within the scope of conformance to be considered a web page.\nExample 1\nA web resource including all embedded images and media.\nExample 2\nA web mail program built using Asynchronous JavaScript and XML (AJAX). The program\n      lives entirely at http://example.com/mail, but includes an inbox, a contacts area\n      and a calendar. Links or buttons are provided that cause the inbox, contacts, or calendar\n      to display, but do not change the URI of the page as a whole.\nExample 3\nA customizable portal site, where users can choose content to display from a set of\n      different content modules.\nExample 4\nWhen you enter \"http://shopping.example.com/\" in your browser, you enter a movie-like\n      interactive shopping environment where you visually move around in a store dragging\n      products off of the shelves around you and into a visual shopping cart in front of\n      you. Clicking on a product causes it to be demonstrated with a specification sheet\n      floating alongside. This might be a single-page website or just one page within a\n      website.",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.4_situation_A",
    "type": "sc_situation",
    "sc_id": "3.3.4",
    "situation_id": "A",
    "techniques": [
      "G164",
      "G98",
      "G155"
    ],
    "text": "[3.3.4 Error Prevention (Legal, Financial, Data)] (Level AA)\nDescription: For web pages that cause legal commitments or financial transactions for the user to occur, that modify or delete user-controllable data in data storage systems, or that submit user test responses, at least one of\n      the following is true:\n\nSituation A: If an application causes a legal transaction to occur, such as making a purchase or submitting an income tax return:\n\nRelated techniques: G164, G98, G155",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.4_situation_B",
    "type": "sc_situation",
    "sc_id": "3.3.4",
    "situation_id": "B",
    "techniques": [
      "G99",
      "G168",
      "G155"
    ],
    "text": "[3.3.4 Error Prevention (Legal, Financial, Data)] (Level AA)\nDescription: For web pages that cause legal commitments or financial transactions for the user to occur, that modify or delete user-controllable data in data storage systems, or that submit user test responses, at least one of\n      the following is true:\n\nSituation B: If an action causes information to be deleted:\n\nRelated techniques: G99, G168, G155",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.4_situation_C",
    "type": "sc_situation",
    "sc_id": "3.3.4",
    "situation_id": "C",
    "techniques": [
      "G98",
      "G168"
    ],
    "text": "[3.3.4 Error Prevention (Legal, Financial, Data)] (Level AA)\nDescription: For web pages that cause legal commitments or financial transactions for the user to occur, that modify or delete user-controllable data in data storage systems, or that submit user test responses, at least one of\n      the following is true:\n\nSituation C: If the web page includes a testing application:\n\nRelated techniques: G98, G168",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.4_advisory",
    "type": "sc_advisory",
    "sc_id": "3.3.4",
    "techniques": [
      "SCR18",
      "G199"
    ],
    "text": "[3.3.4 Error Prevention (Legal, Financial, Data)] (Level AA)\nDescription: For web pages that cause legal commitments or financial transactions for the user to occur, that modify or delete user-controllable data in data storage systems, or that submit user test responses, at least one of\n      the following is true:\n\nAdvisory techniques for SC 3.3.4: SCR18, G199",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.5_intent",
    "type": "sc",
    "sc_id": "3.3.5",
    "section": "intent",
    "text": "[3.3.5 Help] (Level AAA)\nDescription: Context-sensitive help is available.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to help users avoid making mistakes. Some\n         users with disabilities may be more likely to make mistakes than users without disabilities.\n         Using context-sensitive help, users find out how to perform an operation without losing\n         track of what they are doing.\nContext-sensitive help only needs to be provided when the label is not\n         sufficient to describe all functionality. The existence of context-sensitive help\n         should be obvious to the user and they should be able to obtain it whenever they require\n         it.\nThe content author may provide the help text, or the user agent may provide the help\n         text based on technology-specific, programmatically determined information.",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.5_success_criterion",
    "type": "sc",
    "sc_id": "3.3.5",
    "section": "success_criterion",
    "text": "[3.3.5 Help] (Level AAA)\nDescription: Context-sensitive help is available.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nContext-sensitive help\nis available.",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.5_benefits",
    "type": "sc",
    "sc_id": "3.3.5",
    "section": "benefits",
    "text": "[3.3.5 Help] (Level AAA)\nDescription: Context-sensitive help is available.\n\nSection: benefits\n\nBenefits\nAssistance for text input helps individuals with writing disabilities and people with\n            reading and intellectual disabilities who often have difficulty writing text in forms\n            or other places that need text input.\nAdditionally, these kinds of assistance help people who are aging and have the same\n            difficulty in text input and/or mouse operation.",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.5_examples",
    "type": "sc",
    "sc_id": "3.3.5",
    "section": "examples",
    "text": "[3.3.5 Help] (Level AAA)\nDescription: Context-sensitive help is available.\n\nSection: examples\n\nExamples\non-line job application\nSome of the questions may be hard for new job seekers to understand. A help link\n               next to each question provides instructions and explanations for each question.",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.5_brief",
    "type": "sc",
    "sc_id": "3.3.5",
    "section": "brief",
    "text": "[3.3.5 Help] (Level AAA)\nDescription: Context-sensitive help is available.\n\nSection: brief\n\nIn Brief\nGoal\nUsers can avoid making mistakes.\nWhat to do\nProvide help to users on the function currently being performed.\nWhy it's important\nPeople with cognitive or other disabilities can complete their tasks more easily.",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.5_key_terms",
    "type": "sc",
    "sc_id": "3.3.5",
    "section": "key_terms",
    "text": "[3.3.5 Help] (Level AAA)\nDescription: Context-sensitive help is available.\n\nSection: key_terms\n\nKey Terms\ncontext-sensitive help\nhelp text that provides information related to the function currently being performed\nNote\nClear labels can act as context-sensitive help.",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.5_situation_A",
    "type": "sc_situation",
    "sc_id": "3.3.5",
    "situation_id": "A",
    "techniques": [
      "G71",
      "G193",
      "G194",
      "G184"
    ],
    "text": "[3.3.5 Help] (Level AAA)\nDescription: Context-sensitive help is available.\n\nSituation A: If a form requires text input:\n\nRelated techniques: G71, G193, G194, G184",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.5_situation_B",
    "type": "sc_situation",
    "sc_id": "3.3.5",
    "situation_id": "B",
    "techniques": [
      "G89",
      "G184"
    ],
    "text": "[3.3.5 Help] (Level AAA)\nDescription: Context-sensitive help is available.\n\nSituation B: If a form requires text input in an expected data format:\n\nRelated techniques: G89, G184",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.5_advisory",
    "type": "sc_advisory",
    "sc_id": "3.3.5",
    "techniques": [
      "H89"
    ],
    "text": "[3.3.5 Help] (Level AAA)\nDescription: Context-sensitive help is available.\n\nAdvisory techniques for SC 3.3.5: H89",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.6_intent",
    "type": "sc",
    "sc_id": "3.3.6",
    "section": "intent",
    "text": "[3.3.6 Error Prevention (All)] (Level AAA)\nDescription: For web pages that require the user to submit information, at least one of the following is true:\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to help users with disabilities avoid consequences\n         that may result from making a mistake when submitting form data. This criterion builds\n         on\nSuccess Criterion 3.3.4\nin that it applies to all forms that require users to submit information.\nUsers with disabilities may be more likely to make mistakes and may have more difficulty\n         detecting or recovering from mistakes. People with reading disabilities may transpose\n         numbers and letters, and those with motor disabilities may hit keys by mistake. Providing\n         the ability to reverse actions allows users to correct a mistake. Providing the ability\n         to review and correct information gives the user an opportunity to detect a mistake\n         before taking an action.",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.6_success_criterion",
    "type": "sc",
    "sc_id": "3.3.6",
    "section": "success_criterion",
    "text": "[3.3.6 Error Prevention (All)] (Level AAA)\nDescription: For web pages that require the user to submit information, at least one of the following is true:\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nFor\nweb pages\nthat require the user to submit information, at least one of the following is true:\nReversible\nSubmissions are reversible.\nChecked\nData entered by the user is checked for\ninput errors\nand the user is provided an opportunity to correct them.\nConfirmed\nA\nmechanism\nis available for reviewing, confirming, and correcting information before finalizing the submission.",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.6_benefits",
    "type": "sc",
    "sc_id": "3.3.6",
    "section": "benefits",
    "text": "[3.3.6 Error Prevention (All)] (Level AAA)\nDescription: For web pages that require the user to submit information, at least one of the following is true:\n\nSection: benefits\n\nBenefits\nProviding safeguards to avoid consequences resulting from mistakes helps users with\n            all disabilities who may be more likely to make mistakes.",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.6_brief",
    "type": "sc",
    "sc_id": "3.3.6",
    "section": "brief",
    "text": "[3.3.6 Error Prevention (All)] (Level AAA)\nDescription: For web pages that require the user to submit information, at least one of the following is true:\n\nSection: brief\n\nIn Brief\nGoal\nUsers can avoid submitting incorrect information.\nWhat to do\nProvide ways for users to confirm, correct, or reverse any submissions.\nWhy it's important\nPeople with disabilities may be more likely to make mistakes, or not notice them.",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.6_key_terms",
    "type": "sc",
    "sc_id": "3.3.6",
    "section": "key_terms",
    "text": "[3.3.6 Error Prevention (All)] (Level AAA)\nDescription: For web pages that require the user to submit information, at least one of the following is true:\n\nSection: key_terms\n\nKey Terms\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\nconformance\nsatisfying all the requirements of a given standard, guideline or specification\ninput error\ninformation provided by the user that is not accepted\nNote\nThis includes:\nInformation that is required by the\nweb page\nbut omitted by the user\nInformation that is provided by the user but that falls outside the required data\n         format or values\nmechanism\nprocess\nor technique for achieving a result\nNote 1\nThe mechanism may be explicitly provided in the content, or may be\nrelied upon\nto be provided by either the platform or by\nuser agents\n, including\nassistive technologies\n.\nNote 2\nThe mechanism needs to meet all success criteria for the conformance level claimed.\nprocess\nseries of user actions where each action is required in order to complete an activity\nExample 1\nSuccessful use of a series of web pages on a shopping site requires users to view\n      alternative products, prices and offers, select products, submit an order, provide\n      shipping information and provide payment information.\nExample 2\nAn account registration page requires successful completion of a\nTuring test\nbefore\n      the registration form can be accessed.\nrelied upon\nthe content would not\nconform\nif that\ntechnology\nis turned off or is not supported\ntechnology\nmechanism\nfor encoding instructions to be rendered, played or executed by\nuser agents\nNote 1\nAs used in these guidelines \"web technology\" and the word \"technology\" (when used\n      alone) both refer to web content technologies.\nNote 2\nWeb content technologies may include markup languages, data formats, or programming\n      languages that authors may use alone or in combination to create end-user experiences\n      that range from static web pages to synchronized media presentations to dynamic Web\n      applications.\nExample\nSome common examples of web content technologies include HTML, CSS, SVG, PNG, PDF,\n      Flash, and JavaScript.\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.\nweb page\na non-embedded resource obtained from a single URI using HTTP plus any other resources\n      that are used in the rendering or intended to be rendered together with it by a\nuser agent\nNote 1\nAlthough any \"other resources\" would be rendered together with the primary resource,\n      they would not necessarily be rendered simultaneously with each other.\nNote 2\nFor the purposes of conformance with these guidelines, a resource must be \"non-embedded\"\n      within the scope of conformance to be considered a web page.\nExample 1\nA web resource including all embedded images and media.\nExample 2\nA web mail program built using Asynchronous JavaScript and XML (AJAX). The program\n      lives entirely at http://example.com/mail, but includes an inbox, a contacts area\n      and a calendar. Links or buttons are provided that cause the inbox, contacts, or calendar\n      to display, but do not change the URI of the page as a whole.\nExample 3\nA customizable portal site, where users can choose content to display from a set of\n      different content modules.\nExample 4\nWhen you enter \"http://shopping.example.com/\" in your browser, you enter a movie-like\n      interactive shopping environment where you visually move around in a store dragging\n      products off of the shelves around you and into a visual shopping cart in front of\n      you. Clicking on a product causes it to be demonstrated with a specification sheet\n      floating alongside. This might be a single-page website or just one page within a\n      website.",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.6_sufficient",
    "type": "sc_sufficient",
    "sc_id": "3.3.6",
    "techniques": [
      "sufficient techniques for Success Criterion 3.3.4"
    ],
    "text": "[3.3.6 Error Prevention (All)] (Level AAA)\nDescription: For web pages that require the user to submit information, at least one of the following is true:\n\nSufficient techniques for SC 3.3.6 (no situation): sufficient techniques for Success Criterion 3.3.4",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.7_intent",
    "type": "sc",
    "sc_id": "3.3.7",
    "section": "intent",
    "text": "[3.3.7 Redundant Entry] (Level A)\nDescription: New\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to ensure that users can successfully complete multi-step processes. It reduces cognitive effort where information is asked for more than once during a process. It also reduces the need to recall information provided in a previous step.\nInformation that is required to be remembered for input can pose a significant barrier to users with cognitive or memory difficulties. All users experience a natural gradual mental fatigue as they proceed through steps in a process. This fatigue is accelerated by the stress of recalling information from short-term working memory. Users with learning, and cognitive disabilities are highly susceptible to mental fatigue.\nRequiring people to recall information previously entered can cause them to give up or re-enter the same information incorrectly. The autocomplete feature of browsers is not considered sufficient because it is the content (the website) that needs to provide the stored information for a redundant entry, or avoid asking for the same information again.\nThis success criterion does not add a requirement to store information between sessions. A\nprocess\nis defined on the basis of an activity and is not applicable when a user returns after closing a session or navigating away. However, a process can run across different domains, so if a check-out process includes a 3rd party payment provider, that would be in scope.\nThe term \"available to select\" is not prescriptive. The term allows authors to develop techniques where auto-population is not possible. It can include allowing the user to:\nselect and populate a field, including from a drop-down;\nselect text from the page and copy it into an input;\ntick a checkbox to populate inputs with the same values as previously entered (e.g., my billing address is the same as my shipping address).\nData which is \"available to select\" would need to be on the same page. Ideally, it would be visible by default and closely associated with the input where the data is required. However, it could be elsewhere on a page, including within a show/hide component.\nThis success criterion does not apply if data is provided by the user with a different method, such as uploading a resume in a document format.\nThis success criterion does not impact\nAccessible Authentication (Minimum)\n, for which allowing auto-filling of passwords is a sufficient technique. In that case the filling is performed by the user's browser. Redundant Entry is asking for the website content to make the previous entry available, but not between sessions or for essential purposes such as asking for a password.\nThis criterion does not include requirements or exceptions specific to privacy or personally identifiable information (PII), but when implementing techniques such as auto-population, authors should ensure data protection when storing information even temporarily during a process. It is possible to eliminate redundant entry in ways that do not introduce additional privacy risks, but it is also possible that a poor implementation (for meeting this criterion) could leak additional PII.\nExceptions\nThere are exceptions for:\nEssential uses of input re-entry for things like memory games which would be invalidated if the previous answers were supplied.\nSecurity measures such as preventing a password string from being shown or copied. When creating a password, it should be a unique and complex string and therefore cannot be validated by the author. If the system requires the user to manually create a password that is not displayed, having users re-validate their new string is allowed as an exception.\nWhen the previously entered information is no longer valid, it can be requested that the user enter that information again.",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.7_success_criterion",
    "type": "sc",
    "sc_id": "3.3.7",
    "section": "success_criterion",
    "text": "[3.3.7 Redundant Entry] (Level A)\nDescription: New\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nInformation previously entered by or provided to the user that is required to be entered again in the same\nprocess\nis either:\nauto-populated, or\navailable for the user to select.\nExcept when:\nre-entering the information is\nessential\n,\nthe information is required to ensure the security of the content, or\npreviously entered information is no longer valid.",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.7_benefits",
    "type": "sc",
    "sc_id": "3.3.7",
    "section": "benefits",
    "text": "[3.3.7 Redundant Entry] (Level A)\nDescription: New\n\nSection: benefits\n\nBenefits\nUsers with cognitive disabilities experience short-term, working memory difficulty. Not having to repeatedly remember particular information reduces stress and the likelihood of mistakes.\nUsers who experience difficulty forming new memories, recalling information, and other functions related to cognition can complete processes without having to unnecessarily rely on their memory.\nUsers with mobility impairments, for example using switch control or voice input, benefit from a reduced need for text entry.",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.7_examples",
    "type": "sc",
    "sc_id": "3.3.7",
    "section": "examples",
    "text": "[3.3.7 Redundant Entry] (Level A)\nDescription: New\n\nSection: examples\n\nExamples\nA form requests the user’s corporate identification number (ID) in the first step of a process to purchase a new computer. In the 3rd step the user is asked to confirm that the computer will belong to the user (rather than a colleague), and re-shows the ID. It allows the user to change the ID, but defaults to the previously entered one.\nA form on an e-commerce website allows the user to confirm that the billing address and delivery address are the same address.\nA search results page pre-fills the search input with the previously entered search term in the same process.",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.7_brief",
    "type": "sc",
    "sc_id": "3.3.7",
    "section": "brief",
    "text": "[3.3.7 Redundant Entry] (Level A)\nDescription: New\n\nSection: brief\n\nIn Brief\nGoal\nMake it easier for users to complete multi-step processes.\nWhat to do\nDon't ask for the same information twice in the same activity.\nWhy it's important\nSome people with cognitive disabilities have difficulty remembering what they entered before.",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.7_resources",
    "type": "sc",
    "sc_id": "3.3.7",
    "section": "resources",
    "text": "[3.3.7 Redundant Entry] (Level A)\nDescription: New\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nCognitive Accessibility Gap Analysis Topic 3: Entering Data, Error Prevention, & Recovery\nMaking Content Usable for People with Cogntive and Learning Disabilities 4.5.4 Design Forms to Prevent Mistakes",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.7_key_terms",
    "type": "sc",
    "sc_id": "3.3.7",
    "section": "key_terms",
    "text": "[3.3.7 Redundant Entry] (Level A)\nDescription: New\n\nSection: key_terms\n\nKey Terms\nessential\nif removed, would fundamentally change the information or functionality of the content,\nand\ninformation and functionality cannot be achieved in another way that would conform\nprocess\nseries of user actions where each action is required in order to complete an activity\nExample 1\nSuccessful use of a series of web pages on a shopping site requires users to view\n      alternative products, prices and offers, select products, submit an order, provide\n      shipping information and provide payment information.\nExample 2\nAn account registration page requires successful completion of a\nTuring test\nbefore\n      the registration form can be accessed.",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.7_sufficient",
    "type": "sc_sufficient",
    "sc_id": "3.3.7",
    "techniques": [
      "G221"
    ],
    "text": "[3.3.7 Redundant Entry] (Level A)\nDescription: New\n\nSufficient techniques for SC 3.3.7 (no situation): G221",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.8_intent",
    "type": "sc",
    "sc_id": "3.3.8",
    "section": "intent",
    "text": "[3.3.8 Accessible Authentication (Minimum)] (Level AA)\nDescription: New\n\nSection: intent\n\nIntent\nThe purpose of this success criterion is to ensure there is an accessible, easy-to-use, and secure method for users to authenticate when logging into an existing account. As the most prevalent form of authentication, websites commonly rely on usernames and passwords to log in. However, memorizing a username and password places a very high or impossible burden upon people with certain cognitive disabilities, as do additional steps often added to authentication processes. For instance, the need to transcribe a one-time verification code or requiring a puzzle to be solved.\nWhile websites can use the recognition of objects or of non-text content provided by the user to meet this Success Criterion, such techniques do not fully support the cognitive accessibility community and should be avoided if possible. Refer to\nAccessible Authentication (Enhanced)\nfor guidance to be more inclusive and accessible.\nThis success criterion is focused on authentication of existing users. It does\nnot\ncover creation of a username or initiation of an account.  For many websites, establishing an initial username and credentials may not differ greatly from logging in with that username. The techniques used to satisfy this criterion (particularly allowing pasting into inputs and not relying on transcription) can also reduce the cognitive burden in account creation. However, the focus of the success criterion is on reducing the ongoing need for users to recall previously supplied information each time they log in or otherwise authenticate to an account.\nCognitive Function Tests\nRemembering a site-specific password is a\ncognitive function test\n. Such tests are known to be problematic for many people with cognitive disabilities. Whether it is remembering random strings of characters, or a pattern gesture to perform on a touch screen, cognitive function tests will exclude some people. When a cognitive function test is used, at least one other authentication method must be available which is not a cognitive function test.\nSome\nCAPTCHA\nsystems have an audio alternative of the visible text. If the user needs to transcribe this audio, it cannot be used to meet the Alternative exception.\nIf there is more than one step in the authentication process, such as with multi-factor authentication, all steps need to comply with this success criterion to pass. There needs to be a path through authentication that does not rely on cognitive function tests.\nBeing able to recover or change the email and password is an important part of authentication. If the user is authenticating with alternative information in order to recover their account, there needs to be a method that is not a cognitive function test.\nMany organizations are required to use 2-factor authentication that combines independent sources to confirm a user's identity. These sources can consist of combining authentication through:\nknowledge (e.g., password, letters in a passphrase or memorized swipe path);\npossession (e.g., a verification code generated or received on a device, or scanning of a QR code on an external device);\nbiometrics (e.g., fingerprint scanning, facial recognition or keystroke dynamics).\nMost knowledge-based authentication methods rely on a cognitive function test, so mechanisms to assist users must be available. When authentication relies on performing an action on a separate device, it should be possible to complete the action without the need to transcribe information. It may not be possible to know what device-based authentication methods are available to a user; offering a choice of methods can allow them to choose the path that most suits them.\nAuthentication Approaches\nweb sites can employ username (or email) and password inputs as an authentication method if the author enables the user agent (browsers and third-party password managers) to fill in the fields automatically. Generally, if the login form meets\nSuccess Criterion 1.3.5 Input Purpose\n, and the form controls have an appropriate accessible name in accordance with\nSuccess Criterion 4.1.2 Name, Role, Value\n, the user agent should be able to reliably recognize the fields and automatically fill them in. However, if the user agent is actively blocked from filling in the fields (for instance, by a script), then the page would not pass this criterion because it prevents the mechanism from working.\nCopy and paste\nCopy and paste can be relied on to avoid transcription. Users can copy their login credentials from a local source (such as a standalone third-party password manager) and paste it into the username and password fields on a login form, or into a web-based command line interfaces asking for a password. Blocking people from pasting into authentication fields, or using a different format between the copied text and the input field (for example, \"Enter the 3rd, 4th, and 6th character of your password\"), would force the user to transcribe information and therefore fail this criterion, unless another method is available.\nTwo-factor authentication systems (verification codes)\nBeyond usernames and passwords, some sites may use two-factor authentication, asking the user to enter a verification code (also called a passcode or one-time password). A service that requires\nmanual\ntranscription of a verification code is not compliant. As with usernames and passwords, it must be possible for a user to at least paste the code (such as from a standalone third-party password manager, text message application, or software-based security key), or to allow user agents to fill in the fields automatically.\nThere are scenarios where a verification code must be received or generated on a secondary device. For example, authenticating in a web browser on a laptop requires a verification code that is sent as an SMS text message to a mobile phone. However, in most cases, it is possible for the code to then be sent directly to the primary device, where it can then be copied and pasted (for example, by copying the code on the secondary device and emailing it to the primary device, or through the use of a shared cross-device clipboard where copying content on the secondary device makes it available to paste on the primary device). Evaluating whether or not the code can be seamlessly transferred from the secondary device to the primary device is\noutside of the scope\nfor this success criterion. For the purpose of evaluating web content that relies on authentication using these types of secondary device systems, it is assumed that provisions are in place that make the code available in the user's clipboard. Evaluating this criterion therefore only requires verification that the web content does allow pasting the clipboard content in the related authentication challenge field.\nNote that two-factor systems that do not rely on codes — including hardware authentication devices (such as YubiKey), secondary applications (either on the same primary device, or on a secondary device) that expect the user to confirm that it is indeed them trying to log in, and authentication methods provided by the user's operating system (such as Windows Hello, or Touch ID/Face ID on macOS and iOS) — are\nnot\na\ncognitive function test\n.\nObject Recognition\nIf a\nCAPTCHA\nis used as part of an authentication process, there must be a method that does not include a cognitive function test, unless it meets the exception. If the test is based on something the website has set such as remembering or transcribing a word, or recognizing a picture the website provided, that would be a cognitive functional test. Recognizing objects, or a picture the user has provided is a cognitive function test; however, it is excepted at the AA level.\nAn object in this context means the general English definition (\"a material thing that can be seen and touched\") and can include vehicles and animals. If the test goes beyond recognition (e.g. multiply the number cats by the number of dogs), that does not meet the exception.\nSome forms of object recognition may require an understanding of a particular culture. For example, taxis can appear differently in different locales. This is an issue for many people, including people with disabilities, but it is not considered an accessibility-specific issue.\nSome CAPTCHAs and cognitive function tests used for authentication may only appear in certain situations, such as when ad blockers are present, or after repeated incorrect password entry. This criterion applies when these tests are used regardless of whether they are used every time or only triggered by specific scenarios.\nThere are a number of technologies that can be employed to prevent scripted abuse of the authentication process.\n1.1.1. Rate-limited Access\n1.1.2. Client Geo-Location\n1.1.3. Private Client Authentication\nNone of these systems are 100% effective. However, they may reduce the likelihood of a CAPTCHA being displayed.\nPersonal Content\nPersonal content is sometimes used as a second factor for authentication. For example, as part of account creation the user would upload a picture, and when logging in they would be asked to select that picture from several possible alternatives. Care must be taken to provide adequate security in this case, since non-legitimate users might be able to guess the correct personal content when presented with a choice.\nText-based personal content does not qualify for this exception as it relies on recall (rather than recognition), and transcription (rather than selecting an item). Whilst picture-based personal content will still be a barrier for some people, text based versions tend to be a much larger barrier.\nHiding characters\nAnother factor that can contribute to cognitive load is hiding characters when typing. Although this criterion requires that users do not have to type in (transcribe) a password, there are scenarios where that is necessary such as creating a password to be saved by a password manager. Providing a feature to optionally show a password can improve the chance of success for some people with cognitive disabilities or those who have difficulties with accurately typing.",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.8_success_criterion",
    "type": "sc",
    "sc_id": "3.3.8",
    "section": "success_criterion",
    "text": "[3.3.8 Accessible Authentication (Minimum)] (Level AA)\nDescription: New\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nA\ncognitive function test\n(such as remembering a password or solving a puzzle) is not required for any step in an authentication\nprocess\nunless that step provides at least one of the following:\nAlternative\nAnother authentication method that does not rely on a cognitive function test.\nMechanism\nA\nmechanism\nis available to assist the user in completing the cognitive function test.\nObject Recognition\nThe cognitive function test is to recognize objects.\nPersonal Content\nThe cognitive function test is to identify\nnon-text content\nthe user provided to the website.\nNote 1\n\"Object recognition\" and \"Personal content\" may be represented by images, video, or audio.\nNote 2\nExamples of mechanisms that satisfy this criterion include:\nsupport for password entry by password managers to reduce memory need, and\ncopy and paste to reduce the cognitive burden of re-typing.",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.8_benefits",
    "type": "sc",
    "sc_id": "3.3.8",
    "section": "benefits",
    "text": "[3.3.8 Accessible Authentication (Minimum)] (Level AA)\nDescription: New\n\nSection: benefits\n\nBenefits\nPeople with cognitive issues relating to memory, reading (for example, dyslexia), numbers (for example, dyscalculia), or perception-processing limitations will be able to authenticate irrespective of the level of their cognitive abilities.",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.8_examples",
    "type": "sc",
    "sc_id": "3.3.8",
    "section": "examples",
    "text": "[3.3.8 Accessible Authentication (Minimum)] (Level AA)\nDescription: New\n\nSection: examples\n\nExamples\nThe examples of this success criterion are the same as the\nAccessible Authentication (Enhanced)\nexamples.\nA website uses a properly marked up username (or email) and password fields as the login authentication (meeting\nSuccess Criterion 1.3.5 Input Purpose\nand\nSuccess Criterion 4.1.2: Name, Role, Value\n). The user's browser or integrated third-party password manager extension can identify the purpose of the inputs and automatically fill in the username and password.\nA website does not block paste functionality. The user is able to use a third-party password manager to store credentials, copy them, and paste them directly into a login form.\nA website uses WebAuthn so the user can authenticate with their device instead of username/password. The user's device could use any available modality. Common methods on laptops and phones are facial-scan, fingerprint, and PIN (Personal Identification Number). The website is not enforcing any particular use; it is assumed a user will set up a method that suits them.\nA website offers the ability to login with a third-party provider using the OAuth method.\nA website that requires two-factor authentication allows for multiple options for the 2nd factor, including a USB-based method where the user simply presses a button to enter a time-based token.\nA website that requires two-factor authentication displays a QR code which can be scanned by an app on a user's device to confirm identity.\nA website that requires two-factor authentication sends a notification to a user's device. The user must use their device's authentication mechanism (for example, user-defined PIN, fingerprint, facial recognition) to confirm identity.",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.8_brief",
    "type": "sc",
    "sc_id": "3.3.8",
    "section": "brief",
    "text": "[3.3.8 Accessible Authentication (Minimum)] (Level AA)\nDescription: New\n\nSection: brief\n\nIn Brief\nGoal\nMake logins possible with less mental effort.\nWhat to do\nDon't make people solve, recall, or transcribe something to log in.\nWhy it's important\nSome people with cognitive disabilities cannot solve puzzles, memorize a username and password, or retype one-time passcodes.",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.8_resources",
    "type": "sc",
    "sc_id": "3.3.8",
    "section": "resources",
    "text": "[3.3.8 Accessible Authentication (Minimum)] (Level AA)\nDescription: New\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nCognitive Accessibility Gap Analysis Topic 1: Authentication and Safety\nCognitive Accessibility Issue Papers 4. Web Security and Privacy Technologies\nand\nWeb Security and Privacy Technologies\nMaking Content Usable for People with Cognitive and Learning Disabilities 4.7.1 Provide a Login that Does Not Rely on Memory or Other Cognitive Skills\nWebAuthN specification\nWebAuthN Demo site\nWeb Authentication API on MDN\nOAuth on Wikipedia\n\"Let them paste passwords\", from the UK's National Cyber Security Centre\nNIST SP 800-63 Digital Identity Guidelines (Second Public Draft of Revision 4) / SP 800-63B Authentication & Authenticator Management",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.8_key_terms",
    "type": "sc",
    "sc_id": "3.3.8",
    "section": "key_terms",
    "text": "[3.3.8 Accessible Authentication (Minimum)] (Level AA)\nDescription: New\n\nSection: key_terms\n\nKey Terms\nASCII art\npicture created by a spatial arrangement of characters or glyphs (typically from the\n      95 printable characters defined by ASCII)\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\ncognitive function test\nA task that requires the user to remember, manipulate, or transcribe information. Examples include, but are not limited to:\nmemorization, such as remembering a username, password, set of characters, images, or patterns. The common identifiers name, e-mail, and phone number are not considered cognitive function tests as they are personal to the user and consistent across websites;\ntranscription, such as typing in characters;\nuse of correct spelling;\nperformance of calculations;\nsolving of puzzles.\nconformance\nsatisfying all the requirements of a given standard, guideline or specification\nhuman language\nlanguage that is spoken, written or signed (through visual or tactile means) to communicate\n      with humans\nNote\nSee also\nsign language\n.\nmechanism\nprocess\nor technique for achieving a result\nNote 1\nThe mechanism may be explicitly provided in the content, or may be\nrelied upon\nto be provided by either the platform or by\nuser agents\n, including\nassistive technologies\n.\nNote 2\nThe mechanism needs to meet all success criteria for the conformance level claimed.\nnon-text content\nany content that is not a sequence of characters that can be\nprogrammatically determined\nor where the sequence is not expressing something in\nhuman language\nNote\nThis includes\nASCII art\n(which is a pattern of characters), emoticons, leetspeak (which uses character substitution),\n      and images representing text\nprocess\nseries of user actions where each action is required in order to complete an activity\nExample 1\nSuccessful use of a series of web pages on a shopping site requires users to view\n      alternative products, prices and offers, select products, submit an order, provide\n      shipping information and provide payment information.\nExample 2\nAn account registration page requires successful completion of a\nTuring test\nbefore\n      the registration form can be accessed.\nprogrammatically determined\ndetermined by software from author-supplied data provided in a way that different\nuser agents\n, including\nassistive technologies\n, can extract and present this information to users in different modalities\nExample 1\nDetermined in a markup language from elements and attributes that are accessed directly\n      by commonly available assistive technology.\nExample 2\nDetermined from technology-specific data structures in a non-markup language and exposed\n      to assistive technology via an accessibility API that is supported by commonly available\n      assistive technology.\nrelied upon\nthe content would not\nconform\nif that\ntechnology\nis turned off or is not supported\nsign language\na language using combinations of movements of the hands and arms, facial expressions,\n      or body positions to convey meaning\ntechnology\nmechanism\nfor encoding instructions to be rendered, played or executed by\nuser agents\nNote 1\nAs used in these guidelines \"web technology\" and the word \"technology\" (when used\n      alone) both refer to web content technologies.\nNote 2\nWeb content technologies may include markup languages, data formats, or programming\n      languages that authors may use alone or in combination to create end-user experiences\n      that range from static web pages to synchronized media presentations to dynamic Web\n      applications.\nExample\nSome common examples of web content technologies include HTML, CSS, SVG, PNG, PDF,\n      Flash, and JavaScript.\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.8_sufficient",
    "type": "sc_sufficient",
    "sc_id": "3.3.8",
    "techniques": [
      "G218",
      "H100"
    ],
    "text": "[3.3.8 Accessible Authentication (Minimum)] (Level AA)\nDescription: New\n\nSufficient techniques for SC 3.3.8 (no situation): G218, H100",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.8_failures",
    "type": "sc_failures",
    "sc_id": "3.3.8",
    "techniques": [
      "F109"
    ],
    "text": "[3.3.8 Accessible Authentication (Minimum)] (Level AA)\nDescription: New\n\nCommon failures for SC 3.3.8: F109",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.9_intent",
    "type": "sc",
    "sc_id": "3.3.9",
    "section": "intent",
    "text": "[3.3.9 Accessible Authentication (Enhanced)] (Level AAA)\nDescription: New\n\nSection: intent\n\nIntent\nThe purpose of this success criterion is to ensure there is an accessible, easy-to-use, and secure method to log in, access content, and undertake tasks. This criterion is the same as\nAccessible Authentication (Minimum)\nbut without the exceptions for objects and user-provided content.\nAny required step of the authentication process:\ncannot display a selection of images, videos, or audio clips, where users must choose which image they provided;\ncannot display a selection of images, where users must choose the images which contain a specific object, such as a car.",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.9_success_criterion",
    "type": "sc",
    "sc_id": "3.3.9",
    "section": "success_criterion",
    "text": "[3.3.9 Accessible Authentication (Enhanced)] (Level AAA)\nDescription: New\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nA\ncognitive function test\n(such as remembering a password or solving a puzzle) is not required for any step in an authentication\nprocess\nunless that step provides at least one of the following:\nAlternative\nAnother authentication method that does not rely on a cognitive function test.\nMechanism\nA\nmechanism\nis available to assist the user in completing the cognitive function test.",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.9_benefits",
    "type": "sc",
    "sc_id": "3.3.9",
    "section": "benefits",
    "text": "[3.3.9 Accessible Authentication (Enhanced)] (Level AAA)\nDescription: New\n\nSection: benefits\n\nBenefits\nThe benefits of this success criterion are the same as\nAccessible Authentication (Minimum)\n.\nPeople with cognitive issues relating to memory, reading (for example, dyslexia), numbers (for example, dyscalculia), or perception-processing limitations will be able to authenticate irrespective of the level of their cognitive abilities.",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.9_examples",
    "type": "sc",
    "sc_id": "3.3.9",
    "section": "examples",
    "text": "[3.3.9 Accessible Authentication (Enhanced)] (Level AAA)\nDescription: New\n\nSection: examples\n\nExamples\nThe examples of this success criterion are very similar to the\nAccessible Authentication (Minimum)\nexamples.\nA website uses a properly marked up username (or email) and password fields as the login authentication (meeting\nSuccess Criterion 1.3.5 Input Purpose\nand\nSuccess Criterion 4.1.2: Name, Role, Value\n). The user's browser or integrated third-party password manager extension can identify the purpose of the inputs and automatically fill in the username and password.\nA website does not block paste functionality. The user is able to use a third-party password manager to store credentials, copy them, and paste them directly into a login form.\nA website uses WebAuthn so the user can authenticate with their device instead of username/password. The user's device could use any available modality. Common methods on laptops and phones are facial-scan, fingerprint, and PIN (Personal Identification Number). The website is not enforcing any particular use; it is assumed a user will set up a method that suits them.\nA website offers the ability to login with a third-party provider using the OAuth method.\nA website that requires two-factor authentication allows for multiple options for the 2nd factor, including a USB-based method where the user simply presses a button to enter a time-based token.\nA website that requires two-factor authentication displays a QR code which can be scanned by an app on a user's device to confirm identity.\nA website that requires two-factor authentication sends a notification to a user's device. The user must use their device's authentication mechanism (for example, user-defined PIN, fingerprint, facial recognition) to confirm identity.",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.9_brief",
    "type": "sc",
    "sc_id": "3.3.9",
    "section": "brief",
    "text": "[3.3.9 Accessible Authentication (Enhanced)] (Level AAA)\nDescription: New\n\nSection: brief\n\nIn Brief\nGoal\nMake logins possible with less mental effort.\nWhat to do\nDon't make people recognize objects or user-supplied images and media to login.\nWhy it's important\nSome people with cognitive disabilities can't do puzzles, including identifying objects and non-text information they previously supplied.",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.9_resources",
    "type": "sc",
    "sc_id": "3.3.9",
    "section": "resources",
    "text": "[3.3.9 Accessible Authentication (Enhanced)] (Level AAA)\nDescription: New\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nCognitive Accessibility Gap Analysis Topic 1: Authentication and Safety\nCognitive Accessibility Issue Papers 4. Web Security and Privacy Technologies\nand\nWeb Security and Privacy Technologies\nMaking Content Usable for People with Cogntive and Learning Disabilities 4.7.1 Provide a Login that Does Not Rely on Memory or Other Cognitive Skills\nSecurity and Privacy Technologies issue paper from the Cognitive Task Force\n.\nWebAuthN specification\n.\nWeb Authentication API on MDN\n.\nWebAuthN Demo site\n.\nOAuth on Wikipedia\n.\n\"Let them paste passwords\", from the UK's National Cyber Security Centre\nNIST SP 800-63 Digital Identity Guidelines (Second Public Draft of Revision 4) / SP 800-63B Authentication & Authenticator Management",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.9_key_terms",
    "type": "sc",
    "sc_id": "3.3.9",
    "section": "key_terms",
    "text": "[3.3.9 Accessible Authentication (Enhanced)] (Level AAA)\nDescription: New\n\nSection: key_terms\n\nKey Terms\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\ncognitive function test\nA task that requires the user to remember, manipulate, or transcribe information. Examples include, but are not limited to:\nmemorization, such as remembering a username, password, set of characters, images, or patterns. The common identifiers name, e-mail, and phone number are not considered cognitive function tests as they are personal to the user and consistent across websites;\ntranscription, such as typing in characters;\nuse of correct spelling;\nperformance of calculations;\nsolving of puzzles.\nconformance\nsatisfying all the requirements of a given standard, guideline or specification\nmechanism\nprocess\nor technique for achieving a result\nNote 1\nThe mechanism may be explicitly provided in the content, or may be\nrelied upon\nto be provided by either the platform or by\nuser agents\n, including\nassistive technologies\n.\nNote 2\nThe mechanism needs to meet all success criteria for the conformance level claimed.\nprocess\nseries of user actions where each action is required in order to complete an activity\nExample 1\nSuccessful use of a series of web pages on a shopping site requires users to view\n      alternative products, prices and offers, select products, submit an order, provide\n      shipping information and provide payment information.\nExample 2\nAn account registration page requires successful completion of a\nTuring test\nbefore\n      the registration form can be accessed.\nrelied upon\nthe content would not\nconform\nif that\ntechnology\nis turned off or is not supported\ntechnology\nmechanism\nfor encoding instructions to be rendered, played or executed by\nuser agents\nNote 1\nAs used in these guidelines \"web technology\" and the word \"technology\" (when used\n      alone) both refer to web content technologies.\nNote 2\nWeb content technologies may include markup languages, data formats, or programming\n      languages that authors may use alone or in combination to create end-user experiences\n      that range from static web pages to synchronized media presentations to dynamic Web\n      applications.\nExample\nSome common examples of web content technologies include HTML, CSS, SVG, PNG, PDF,\n      Flash, and JavaScript.\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.9_sufficient",
    "type": "sc_sufficient",
    "sc_id": "3.3.9",
    "techniques": [
      "G218",
      "H100"
    ],
    "text": "[3.3.9 Accessible Authentication (Enhanced)] (Level AAA)\nDescription: New\n\nSufficient techniques for SC 3.3.9 (no situation): G218, H100",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "3.3.9_failures",
    "type": "sc_failures",
    "sc_id": "3.3.9",
    "techniques": [
      "F109"
    ],
    "text": "[3.3.9 Accessible Authentication (Enhanced)] (Level AAA)\nDescription: New\n\nCommon failures for SC 3.3.9: F109",
    "principle": "Understandable",
    "guideline": "3.3 Input Assistance"
  },
  {
    "id": "4.1.1_intent",
    "type": "sc",
    "sc_id": "4.1.1",
    "section": "intent",
    "text": "[4.1.1 Parsing (Obsolete and removed)] (Level Unknown)\nDescription: \n\nSection: intent\n\nIntent\nNew in WCAG 2.2:\nThis criterion has been removed from WCAG 2.2.\nThe intent of this success criterion was to ensure that user-agents, including assistive technologies, can accurately interpret and parse content. Since WCAG 2.0 was published, the specifications (such as HTML) and browsers have improved their handling of parsing errors. It is also the case that assistive technology used to do their own parsing of markup, but now rely on the browser. For that reason this success criterion has been removed. Many issues that would have failed this criterion will fail\nInfo and Relationships\nor\nName, Role, Value\n. Other issues are excepted by the \"except where the specification allow these features\" part of the criterion.\nThe following content is left for historical purposes to show the original intent.\nSuccess Criterion\n4.1.1 Parsing\n(Level A): In content implemented using markup languages, elements have complete start and end\n               tags, elements are nested according to their specifications, elements do not contain\n               duplicate attributes, and any IDs are unique, except where the specifications allow\n               these features.\nNote\nStart and end tags that are missing a critical character in their formation, such\n               as a closing angle bracket or a mismatched attribute value quotation mark are not\n               complete.\nThe intent of this success criterion is to ensure that user agents, including assistive technologies, can accurately interpret and parse content.  If the content cannot be parsed into a data structure, then different user agents may present it differently or be completely unable to parse it. Some user agents use \"repair techniques\" to render poorly coded content.\nSince repair techniques vary among user agents, authors cannot assume that content\n         will be accurately parsed into a data structure or that it will be rendered correctly\n         by specialized user agents, including assistive technologies, unless the content is\n         created according to the rules defined in the formal grammar for that technology.\n         In markup languages, errors in element and attribute syntax and\n         failure to provide properly nested start/end tags lead to errors that\n         prevent user agents from parsing the content reliably.\n         Therefore, the success criterion requires that the content can be parsed using only\n         the rules of the formal grammar.\nNote\nThe concept of \"well formed\" is close to what is required here. However, exact parsing\n            requirements vary amongst markup languages, and most non XML-based languages do not\n            explicitly define requirements for well formedness. Therefore, it was necessary to\n            be more explicit in the success criterion in order to be generally applicable to markup\n            languages. Because the term \"well formed\" is only defined in XML, and (because end\n            tags are sometimes optional) valid HTML does not require well formed code, the term\n            is not used in this success criterion.\nWith the exception of one success criterion (\n1.4.4: Resize Text\n, which specifically mentions that the effect specified by the success criterion must\n            be achieved without relying on an assistive technology) authors can meet the Success\n            Criteria with content that assumes use of an assistive technology (or access features\n            in use agents) by the user, where such assistive technologies (or access features\n            in user agents) exist and are available to the user.",
    "principle": "Robust",
    "guideline": "4.1 Compatible"
  },
  {
    "id": "4.1.1_success_criterion",
    "type": "sc",
    "sc_id": "4.1.1",
    "section": "success_criterion",
    "text": "[4.1.1 Parsing (Obsolete and removed)] (Level Unknown)\nDescription: \n\nSection: success_criterion\n\nSuccess Criterion (SC)\nNote\nThis criterion was originally adopted to address problems that assistive technology had directly parsing\nHTML\n. Assistive technology no longer has any need to directly parse\nHTML\n. Consequently, these problems either no longer exist or are addressed by other criteria. This criterion no longer has utility and is removed.",
    "principle": "Robust",
    "guideline": "4.1 Compatible"
  },
  {
    "id": "4.1.1_benefits",
    "type": "sc",
    "sc_id": "4.1.1",
    "section": "benefits",
    "text": "[4.1.1 Parsing (Obsolete and removed)] (Level Unknown)\nDescription: \n\nSection: benefits\n\nBenefits\nEnsuring that web pages have complete start and end tags and are nested according\n            to specification\n            helps ensure that assistive technologies can parse the content accurately and without\n            crashing.",
    "principle": "Robust",
    "guideline": "4.1 Compatible"
  },
  {
    "id": "4.1.1_brief",
    "type": "sc",
    "sc_id": "4.1.1",
    "section": "brief",
    "text": "[4.1.1 Parsing (Obsolete and removed)] (Level Unknown)\nDescription: \n\nSection: brief\n\nIn Brief\nGoal\nAssistive technology can properly present page content.\nWhat to do\nCreate web pages according to specifications.\nWhy it's important\nPeople can browse web content more easily with their assistive technology.",
    "principle": "Robust",
    "guideline": "4.1 Compatible"
  },
  {
    "id": "4.1.1_test_rules",
    "type": "sc",
    "sc_id": "4.1.1",
    "section": "test_rules",
    "text": "[4.1.1 Parsing (Obsolete and removed)] (Level Unknown)\nDescription: \n\nSection: test_rules\n\nTest Rules\nThe following are Test Rules\n    for certain aspects of this Success Criterion.\n    It is not necessary to use these particular Test Rules to check for conformance with WCAG, but they are defined and approved test methods.\n    For information on using Test Rules, see\nUnderstanding Test Rules for WCAG Success Criteria\n.\nAttribute is not duplicated\nId attribute value is unique",
    "principle": "Robust",
    "guideline": "4.1 Compatible"
  },
  {
    "id": "4.1.2_intent",
    "type": "sc",
    "sc_id": "4.1.2",
    "section": "intent",
    "text": "[4.1.2 Name, Role, Value] (Level A)\nDescription: For all user interface components (including but not limited to: form elements, links and components generated by scripts),\n     the name and role can be programmatically determined; states, properties, and values that can be set by the user can be programmatically set; and notification of changes to these items is available to user agents, including assistive technologies.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to ensure that Assistive Technologies (AT)\n         can gather appropriate information about, activate (or set) and keep up to date on the status of\n         user interface controls in the content.\nWhen standard controls from accessible technologies are used, this process is straightforward.\n         If the user interface elements are used according to specification the conditions\n         of this provision will be met. (See examples of Success Criterion 4.1.2 below)\nIf custom controls are created, however, or interface elements are programmed (in\n         code or script) to have a different role and/or function than usual, then additional\n         measures need to be taken to ensure that the controls provide important and appropriate information\n         to assistive technologies and allow themselves to be controlled by assistive technologies.\nWhat roles and states are appropriate to convey to assistive technology will depend\n         on what the control represents. Specifics about such information are defined by other\n         specifications, such as\nWAI-ARIA\n, or the\n         relevant platform standards. Another factor to consider is whether there is sufficient\naccessibility support\nwith assistive technologies to convey the information as specified.\nA particularly important state of a user interface control is whether or not it has\n         focus. The focus state of a control can be programmatically determined, and notifications\n         about change of focus are sent to user agents and assistive technology. Other examples\n         of user interface control states are whether or not a checkbox or radio button has\n         been selected, or whether a collapsible tree view or accordion is expanded or collapsed.\nNote\nSuccess Criterion 4.1.2 requires a programmatically determinable name for all user\n            interface components. Names may be visible or invisible. Occasionally, the name needs\n            to be visible, in which case it is identified as a label. Refer to the definition of\n            name and label in the glossary for more information.",
    "principle": "Robust",
    "guideline": "4.1 Compatible"
  },
  {
    "id": "4.1.2_success_criterion",
    "type": "sc",
    "sc_id": "4.1.2",
    "section": "success_criterion",
    "text": "[4.1.2 Name, Role, Value] (Level A)\nDescription: For all user interface components (including but not limited to: form elements, links and components generated by scripts),\n     the name and role can be programmatically determined; states, properties, and values that can be set by the user can be programmatically set; and notification of changes to these items is available to user agents, including assistive technologies.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nFor all\nuser interface components\n(including but not limited to: form elements, links and components generated by scripts),\n     the\nname\nand\nrole\ncan be\nprogrammatically determined\n;\nstates\n, properties, and values that can be set by the user can be\nprogrammatically set\n; and notification of changes to these items is available to\nuser agents\n, including\nassistive technologies\n.\nNote\nThis success criterion is primarily for web authors who develop or script their own\n      user interface components. For example, standard\nHTML\ncontrols already meet this success\n      criterion when used according to specification.",
    "principle": "Robust",
    "guideline": "4.1 Compatible"
  },
  {
    "id": "4.1.2_benefits",
    "type": "sc",
    "sc_id": "4.1.2",
    "section": "benefits",
    "text": "[4.1.2 Name, Role, Value] (Level A)\nDescription: For all user interface components (including but not limited to: form elements, links and components generated by scripts),\n     the name and role can be programmatically determined; states, properties, and values that can be set by the user can be programmatically set; and notification of changes to these items is available to user agents, including assistive technologies.\n\nSection: benefits\n\nBenefits\nProviding role, state, and value information on all user interface components enables\n            compatibility with assistive technology, such as screen readers, screen magnifiers,\n            and speech recognition software, used by people with disabilities.",
    "principle": "Robust",
    "guideline": "4.1 Compatible"
  },
  {
    "id": "4.1.2_examples",
    "type": "sc",
    "sc_id": "4.1.2",
    "section": "examples",
    "text": "[4.1.2 Name, Role, Value] (Level A)\nDescription: For all user interface components (including but not limited to: form elements, links and components generated by scripts),\n     the name and role can be programmatically determined; states, properties, and values that can be set by the user can be programmatically set; and notification of changes to these items is available to user agents, including assistive technologies.\n\nSection: examples\n\nExamples\nAccessible APIs\nA Java applet uses the accessibility API defined by the language.",
    "principle": "Robust",
    "guideline": "4.1 Compatible"
  },
  {
    "id": "4.1.2_brief",
    "type": "sc",
    "sc_id": "4.1.2",
    "section": "brief",
    "text": "[4.1.2 Name, Role, Value] (Level A)\nDescription: For all user interface components (including but not limited to: form elements, links and components generated by scripts),\n     the name and role can be programmatically determined; states, properties, and values that can be set by the user can be programmatically set; and notification of changes to these items is available to user agents, including assistive technologies.\n\nSection: brief\n\nIn Brief\nGoal\nPeople using assistive technology understand all components.\nWhat to do\nGive components correct names, roles, states, and values.\nWhy it's important\nAssistive technology only works well when code is done properly.",
    "principle": "Robust",
    "guideline": "4.1 Compatible"
  },
  {
    "id": "4.1.2_resources",
    "type": "sc",
    "sc_id": "4.1.2",
    "section": "resources",
    "text": "[4.1.2 Name, Role, Value] (Level A)\nDescription: For all user interface components (including but not limited to: form elements, links and components generated by scripts),\n     the name and role can be programmatically determined; states, properties, and values that can be set by the user can be programmatically set; and notification of changes to these items is available to user agents, including assistive technologies.\n\nSection: resources\n\nRelated Resources\nResources are for information purposes only, no endorsement implied.\nDynamic Accessible Web Content Roadmap\nRole Taxonomy for Accessible Adaptable Applications\nWeb Accessibility Initiative - Accessible Rich Internet Applications (ARIA)",
    "principle": "Robust",
    "guideline": "4.1 Compatible"
  },
  {
    "id": "4.1.2_test_rules",
    "type": "sc",
    "sc_id": "4.1.2",
    "section": "test_rules",
    "text": "[4.1.2 Name, Role, Value] (Level A)\nDescription: For all user interface components (including but not limited to: form elements, links and components generated by scripts),\n     the name and role can be programmatically determined; states, properties, and values that can be set by the user can be programmatically set; and notification of changes to these items is available to user agents, including assistive technologies.\n\nSection: test_rules\n\nTest Rules\nThe following are Test Rules\n    for certain aspects of this Success Criterion.\n    It is not necessary to use these particular Test Rules to check for conformance with WCAG, but they are defined and approved test methods.\n    For information on using Test Rules, see\nUnderstanding Test Rules for WCAG Success Criteria\n.\nARIA attribute is defined in WAI-ARIA\nARIA state or property has valid value\nButton has non-empty accessible name\nElement with aria-hidden has no content in sequential focus navigation\nElement with presentational children has no focusable content\nForm field has non-empty accessible name\nImage button has non-empty accessible name\nLink has non-empty accessible name\nMenuitem has non-empty accessible name\nRole attribute has valid value\nARIA required ID references exist\nARIA state or property is permitted\nElement with role attribute has required states and properties\nIframe element has non-empty accessible name\nIframe elements with identical accessible names have equivalent purpose\nSummary element has non-empty accessible name",
    "principle": "Robust",
    "guideline": "4.1 Compatible"
  },
  {
    "id": "4.1.2_key_terms",
    "type": "sc",
    "sc_id": "4.1.2",
    "section": "key_terms",
    "text": "[4.1.2 Name, Role, Value] (Level A)\nDescription: For all user interface components (including but not limited to: form elements, links and components generated by scripts),\n     the name and role can be programmatically determined; states, properties, and values that can be set by the user can be programmatically set; and notification of changes to these items is available to user agents, including assistive technologies.\n\nSection: key_terms\n\nKey Terms\naccessibility supported\nsupported by users'\nassistive technologies\nas well as the accessibility features in browsers and other\nuser agents\nTo qualify as an accessibility-supported use of a web content technology (or feature\n      of a technology), both 1 and 2 must be satisfied for a web content technology (or\n      feature):\nThe way that the\nweb content technology\nis used must be supported by users' assistive technology (AT).\nThis means that the way that the technology is used has been tested for interoperability\n            with users' assistive technology in the\nhuman language(s)\nof the content,\nAND\nThe web content technology must have accessibility-supported user agents that are\n               available to users.\nThis means that at least one of the following four statements is true:\nThe technology is supported natively in widely-distributed user agents that are also\n                  accessibility supported (such as HTML and CSS);\nOR\nThe technology is supported in a widely-distributed plug-in that is also accessibility\n                  supported;\nOR\nThe content is available in a closed environment, such as a university or corporate\n                  network, where the user agent required by the technology and used by the organization\n                  is also accessibility supported;\nOR\nThe user agent(s) that support the technology are accessibility supported and are\n                  available for download or purchase in a way that:\ndoes not cost a person with a disability any more than a person without a disability\nand\nis as easy to find and obtain for a person with a disability as it is for a person\n                     without disabilities.\nNote 1\nThe Accessibility Guidelines Working Group and the W3C do not specify which or how much support by assistive\n      technologies there must be for a particular use of a web technology in order for it\n      to be classified as accessibility supported. (See\nLevel of Assistive Technology Support Needed for \"Accessibility Support\"\n.)\nNote 2\nWeb technologies can be used in ways that are not accessibility supported as long\n      as they are not\nrelied upon\nand the page as a whole meets the conformance requirements, including\nConformance Requirement 4\nand\nConformance Requirement 5\n.\nNote 3\nWhen a\nweb technology\nis used in a way that is \"accessibility supported,\" it does not imply that the entire\n      technology or all uses of the technology are supported. Most technologies, including\n      HTML, lack support for at least one feature or use. Pages conform to WCAG only if\n      the uses of the technology that are accessibility supported can be relied upon to\n      meet WCAG requirements.\nNote 4\nWhen citing web content technologies that have multiple versions, the version(s) supported\n      should be specified.\nNote 5\nOne way for authors to locate uses of a technology that are accessibility supported\n      would be to consult compilations of uses that are documented to be accessibility supported.\n      (See\nUnderstanding Accessibility-Supported Web Technology Uses\n.) Authors, companies, technology vendors, or others may document accessibility-supported\n      ways of using web content technologies. However, all ways of using technologies in\n      the documentation would need to meet the definition of accessibility-supported Web\n      content technologies above.\nASCII art\npicture created by a spatial arrangement of characters or glyphs (typically from the\n      95 printable characters defined by ASCII)\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\nconformance\nsatisfying all the requirements of a given standard, guideline or specification\ncontent\ninformation and sensory experience to be communicated to the user by means of a\nuser agent\n, including code or markup that defines the content's\nstructure\n,\npresentation\n, and interactions\nhuman language\nlanguage that is spoken, written or signed (through visual or tactile means) to communicate\n      with humans\nNote\nSee also\nsign language\n.\nlabel\ntext\nor other component with a\ntext alternative\nthat is presented to a user to identify a component within web\ncontent\nNote 1\nA label is presented to all users whereas the\nname\nmay be hidden and only exposed by assistive technology. In many (but not all) cases\n      the name and the label are the same.\nNote 2\nThe term label is not limited to the label element in HTML.\nmechanism\nprocess\nor technique for achieving a result\nNote 1\nThe mechanism may be explicitly provided in the content, or may be\nrelied upon\nto be provided by either the platform or by\nuser agents\n, including\nassistive technologies\n.\nNote 2\nThe mechanism needs to meet all success criteria for the conformance level claimed.\nname\ntext by which software can identify a component within web content to the user\nNote 1\nThe name may be hidden and only exposed by assistive technology, whereas a\nlabel\nis presented to all users. In many (but not all) cases, the label and the name are\n      the same.\nNote 2\nThis is unrelated to the name attribute in HTML.\nnon-text content\nany content that is not a sequence of characters that can be\nprogrammatically determined\nor where the sequence is not expressing something in\nhuman language\nNote\nThis includes\nASCII art\n(which is a pattern of characters), emoticons, leetspeak (which uses character substitution),\n      and images representing text\npresentation\nrendering of the\ncontent\nin a form to be perceived by users\nprocess\nseries of user actions where each action is required in order to complete an activity\nExample 1\nSuccessful use of a series of web pages on a shopping site requires users to view\n      alternative products, prices and offers, select products, submit an order, provide\n      shipping information and provide payment information.\nExample 2\nAn account registration page requires successful completion of a\nTuring test\nbefore\n      the registration form can be accessed.\nprogrammatically determined\ndetermined by software from author-supplied data provided in a way that different\nuser agents\n, including\nassistive technologies\n, can extract and present this information to users in different modalities\nExample 1\nDetermined in a markup language from elements and attributes that are accessed directly\n      by commonly available assistive technology.\nExample 2\nDetermined from technology-specific data structures in a non-markup language and exposed\n      to assistive technology via an accessibility API that is supported by commonly available\n      assistive technology.\nprogrammatically set\nset by software using methods that are supported by\nuser agents\n, including\nassistive technologies\nrelied upon\nthe content would not\nconform\nif that\ntechnology\nis turned off or is not supported\nrole\ntext or number by which software can identify the function of a component within Web\n      content\nExample\nA number that indicates whether an image functions as a hyperlink, command button,\n      or check box.\nsign language\na language using combinations of movements of the hands and arms, facial expressions,\n      or body positions to convey meaning\nstate\ndynamic property expressing characteristics of a\nuser interface component\nthat may change in response to user action or automated processes\nStates do not affect the nature of the component, but represent data associated with the component or user interaction possibilities. Examples include focus, hover, select, press, check, visited/unvisited, and expand/collapse.\nstructure\nThe way the parts of a\nweb page\nare organized in relation to each other; and\nThe way a collection of\nweb pages\nis organized\ntechnology\nmechanism\nfor encoding instructions to be rendered, played or executed by\nuser agents\nNote 1\nAs used in these guidelines \"web technology\" and the word \"technology\" (when used\n      alone) both refer to web content technologies.\nNote 2\nWeb content technologies may include markup languages, data formats, or programming\n      languages that authors may use alone or in combination to create end-user experiences\n      that range from static web pages to synchronized media presentations to dynamic Web\n      applications.\nExample\nSome common examples of web content technologies include HTML, CSS, SVG, PNG, PDF,\n      Flash, and JavaScript.\ntext\nsequence of characters that can be\nprogrammatically determined\n, where the sequence is expressing something in\nhuman language\ntext alternative\nText\nthat is programmatically associated with\nnon-text content\nor referred to from text that is programmatically associated with non-text content.\n      Programmatically associated text is text whose location can be\nprogrammatically determined\nfrom the non-text content.\nExample\nAn image of a chart is described in text in the paragraph after the chart. The short\n      text alternative for the chart indicates that a description follows.\nNote\nRefer to\nUnderstanding Text Alternatives\nfor more information.\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.\nuser interface component\na part of the content that is perceived by users as a single control for a distinct\n      function\nNote 1\nMultiple user interface components may be implemented as a single programmatic element.\n      \"Components\" here is not tied to programming techniques, but rather to what the user\n      perceives as separate controls.\nNote 2\nUser interface components include form elements and links as well as components generated\n      by scripts.\nNote 3\nWhat is meant by \"component\" or \"user interface component\" here is also sometimes\n      called \"user interface element\".\nExample\nAn applet has a \"control\" that can be used to move through content by line or page\n      or random access. Since each of these would need to have a name and be settable independently,\n      they would each be a \"user interface component.\"\nweb page\na non-embedded resource obtained from a single URI using HTTP plus any other resources\n      that are used in the rendering or intended to be rendered together with it by a\nuser agent\nNote 1\nAlthough any \"other resources\" would be rendered together with the primary resource,\n      they would not necessarily be rendered simultaneously with each other.\nNote 2\nFor the purposes of conformance with these guidelines, a resource must be \"non-embedded\"\n      within the scope of conformance to be considered a web page.\nExample 1\nA web resource including all embedded images and media.\nExample 2\nA web mail program built using Asynchronous JavaScript and XML (AJAX). The program\n      lives entirely at http://example.com/mail, but includes an inbox, a contacts area\n      and a calendar. Links or buttons are provided that cause the inbox, contacts, or calendar\n      to display, but do not change the URI of the page as a whole.\nExample 3\nA customizable portal site, where users can choose content to display from a set of\n      different content modules.\nExample 4\nWhen you enter \"http://shopping.example.com/\" in your browser, you enter a movie-like\n      interactive shopping environment where you visually move around in a store dragging\n      products off of the shelves around you and into a visual shopping cart in front of\n      you. Clicking on a product causes it to be demonstrated with a specification sheet\n      floating alongside. This might be a single-page website or just one page within a\n      website.",
    "principle": "Robust",
    "guideline": "4.1 Compatible"
  },
  {
    "id": "4.1.2_situation_A",
    "type": "sc_situation",
    "sc_id": "4.1.2",
    "situation_id": "A",
    "techniques": [
      "ARIA14",
      "ARIA16",
      "G108",
      "H91",
      "H44",
      "H64",
      "H65",
      "H88"
    ],
    "text": "[4.1.2 Name, Role, Value] (Level A)\nDescription: For all user interface components (including but not limited to: form elements, links and components generated by scripts),\n     the name and role can be programmatically determined; states, properties, and values that can be set by the user can be programmatically set; and notification of changes to these items is available to user agents, including assistive technologies.\n\nSituation A: If using a standard user interface component in a markup language (e.g., HTML):\n\nRelated techniques: ARIA14, ARIA16, G108, H91, H44, H64, H65, H88",
    "principle": "Robust",
    "guideline": "4.1 Compatible"
  },
  {
    "id": "4.1.2_situation_B",
    "type": "sc_situation",
    "sc_id": "4.1.2",
    "situation_id": "B",
    "techniques": [
      "ARIA16",
      "ARIA16"
    ],
    "text": "[4.1.2 Name, Role, Value] (Level A)\nDescription: For all user interface components (including but not limited to: form elements, links and components generated by scripts),\n     the name and role can be programmatically determined; states, properties, and values that can be set by the user can be programmatically set; and notification of changes to these items is available to user agents, including assistive technologies.\n\nSituation B: If using script or code to re-purpose a standard user interface component in a markup language:\n\nRelated techniques: ARIA16, ARIA16",
    "principle": "Robust",
    "guideline": "4.1 Compatible"
  },
  {
    "id": "4.1.2_situation_C",
    "type": "sc_situation",
    "sc_id": "4.1.2",
    "situation_id": "C",
    "techniques": [
      "G135",
      "PDF10",
      "PDF12"
    ],
    "text": "[4.1.2 Name, Role, Value] (Level A)\nDescription: For all user interface components (including but not limited to: form elements, links and components generated by scripts),\n     the name and role can be programmatically determined; states, properties, and values that can be set by the user can be programmatically set; and notification of changes to these items is available to user agents, including assistive technologies.\n\nSituation C: If using a standard user interface component in a programming technology:\n\nRelated techniques: G135, PDF10, PDF12",
    "principle": "Robust",
    "guideline": "4.1 Compatible"
  },
  {
    "id": "4.1.2_situation_D",
    "type": "sc_situation",
    "sc_id": "4.1.2",
    "situation_id": "D",
    "techniques": [
      "G10",
      "ARIA4",
      "ARIA5",
      "ARIA16"
    ],
    "text": "[4.1.2 Name, Role, Value] (Level A)\nDescription: For all user interface components (including but not limited to: form elements, links and components generated by scripts),\n     the name and role can be programmatically determined; states, properties, and values that can be set by the user can be programmatically set; and notification of changes to these items is available to user agents, including assistive technologies.\n\nSituation D: If creating your own user interface component in a programming language:\n\nRelated techniques: G10, ARIA4, ARIA5, ARIA16",
    "principle": "Robust",
    "guideline": "4.1 Compatible"
  },
  {
    "id": "4.1.2_failures",
    "type": "sc_failures",
    "sc_id": "4.1.2",
    "techniques": [
      "F59",
      "F15",
      "F20",
      "F42",
      "F68",
      "F79",
      "F86",
      "F89",
      "F111"
    ],
    "text": "[4.1.2 Name, Role, Value] (Level A)\nDescription: For all user interface components (including but not limited to: form elements, links and components generated by scripts),\n     the name and role can be programmatically determined; states, properties, and values that can be set by the user can be programmatically set; and notification of changes to these items is available to user agents, including assistive technologies.\n\nCommon failures for SC 4.1.2: F59, F15, F20, F42, F68, F79, F86, F89, F111",
    "principle": "Robust",
    "guideline": "4.1 Compatible"
  },
  {
    "id": "4.1.3_intent",
    "type": "sc",
    "sc_id": "4.1.3",
    "section": "intent",
    "text": "[4.1.3 Status Messages] (Level AA)\nDescription: In content implemented using markup languages, status messages can be programmatically determined through role or properties such that they can be presented to the user by assistive technologies without receiving focus.\n\nSection: intent\n\nIntent\nThe intent of this success criterion is to make users aware of important changes in content that are not given focus, and to do so in a way that doesn't unnecessarily interrupt their work.\nThe intended beneficiaries are blind and low vision users of assistive technologies with screen reader capabilities. An additional benefit is that assistive technologies for users with cognitive disabilities may achieve an alternative means of indicating (or even delaying or supressing) status messages, as preferred by the user.\nThe scope of this success criterion is specific to changes in content that involve status messages. A\nstatus message\nis a defined term in WCAG. There are two main criteria that determine whether something meets the definition of a status message:\nthe message\nprovides information to the user on the success or results of an action, on the waiting state of an application, on the progress of a process, or on the existence of errors;\nthe message is not delivered via a change in context.\nInformation can be added to pages which does not meet the definition of a status message. For example, the list of results obtained from a search are not considered a status update and thus are not covered by this success criterion. However, brief text messages displayed\nabout\nthe completion or status of the search, such as \"Searching...\", \"18 results returned\" or \"No results returned\" would be status updates if they do not take focus. Examples of status messages are given in the section titled\nStatus Message Examples\nbelow.\nThis success criterion specifically addresses scenarios where new content is added to the page without changing the user's context.\nChanges of context\n, by their nature, interrupt the user by taking focus. They are already surfaced by assistive technologies, and so have already met the goal to alert the user to new content. As such, messages that involve changes of context do not need to be considered and are not within the scope of this success criterion. Examples of scenarios that add new content by changing the context are given in the section titled\nExamples of Changes That Are Not Status Messages\nbelow.",
    "principle": "Robust",
    "guideline": "4.1 Compatible"
  },
  {
    "id": "4.1.3_success_criterion",
    "type": "sc",
    "sc_id": "4.1.3",
    "section": "success_criterion",
    "text": "[4.1.3 Status Messages] (Level AA)\nDescription: In content implemented using markup languages, status messages can be programmatically determined through role or properties such that they can be presented to the user by assistive technologies without receiving focus.\n\nSection: success_criterion\n\nSuccess Criterion (SC)\nIn content implemented using markup languages,\nstatus messages\ncan be\nprogrammatically determined\nthrough\nrole\nor properties such that they can be presented to the user by\nassistive technologies\nwithout receiving focus.",
    "principle": "Robust",
    "guideline": "4.1 Compatible"
  },
  {
    "id": "4.1.3_benefits",
    "type": "sc",
    "sc_id": "4.1.3",
    "section": "benefits",
    "text": "[4.1.3 Status Messages] (Level AA)\nDescription: In content implemented using markup languages, status messages can be programmatically determined through role or properties such that they can be presented to the user by assistive technologies without receiving focus.\n\nSection: benefits\n\nBenefits\nWhen appropriate roles or properties are assigned to status messages, the new content is spoken by screen readers in such a way as to assist blind and low vision users. Most sighted users can observe text peripherally added to the viewport. Such content provides additional information without affecting the user's current point of regard. The ability of an assistive technology to announce such new important text content allows more users to benefit from an awareness of the information in an equivalent manner.\nAssigning proper roles or properties to status messages provides possible future uses and personalization opportunities, such as the potential to be exploited by assistive technologies created for users with some cognitive disabilities. Where page authors elect to design additions to the screen which do\nnot\nchange the user's context (i.e., take focus), the information is arguably of less importance than something presented using a modal dialog, which must be acknowledged by the user. As such, depending on the user's preferences, an assistive technology may choose to delay, suppress, or transform such messages so a user is not unnecessarily interrupted; or conversely the assistive technology may highlight such messages where the user finds it optimal to do so.",
    "principle": "Robust",
    "guideline": "4.1 Compatible"
  },
  {
    "id": "4.1.3_examples",
    "type": "sc",
    "sc_id": "4.1.3",
    "section": "examples",
    "text": "[4.1.3 Status Messages] (Level AA)\nDescription: In content implemented using markup languages, status messages can be programmatically determined through role or properties such that they can be presented to the user by assistive technologies without receiving focus.\n\nSection: examples\n\nExamples\nStatus Message Examples\nAfter a user presses a Search button, the page content is updated to include the results of the search, which are displayed in a section below the Search button. The change to content also includes the message \"5 results returned\" near the top of this new content. This text is given an appropriate role for a status message. A screen reader announces, \"Five results returned\".\nAfter a user presses an Add to Shopping Cart button, a section of content near the Shopping Cart icon adds the text \"5 items\". A screen reader announces \"Five items\" or \"Shopping cart, five items\".\nAfter a user enters incorrect text in an input called Postal Code, a message appears above the input reading \"Invalid entry\".  The screen reader announces, \"Invalid entry\" or \"Postal code, invalid entry\".\nAfter a user activates a process, an icon symbolizing 'busy'  appears on the screen. The screen reader announces \"application busy\".\nAn application displays a progressbar to indicate the status of an upgrade. The element is assigned a suitable role. The screen reader provides intermittent announcements of the progress.\nAfter a user submits a form, text is added to the existing form which reads, \"Your form was successfully submitted.\" The screen reader announces the same message.\nAfter a user unsuccessfully fills in a form because some of the data is in the incorrect format, text is added to the existing form which reads \"5 errors on page\". The screen reader announces the same message.\nAfter a user puts a photo in an album in an online photo app, a\nsnackbar\ndisplays the message \"Saved in 'Wedding' album\", which is also read by a screen reader.\nExamples of Status Messages that Do Not Add New Text to the Screen\nThis success criterion was intentionally worded to apply primarily when visible text is added to (or becomes visible on) the page. The reason for this is that where new text is displayed, it is intended to be visible to all users. By providing a programmatic means of ensuring the text is also surfaced through assistive technologies, the success criterion provides the same information to users who cannot or may not see it. However, not all changes to content involve the addition of text to the screen. The following are all considerations relevant to this Success Criterion:\nNon-displayed text specific to AT users;\nModification of status text;\nRemoval of status text; and\nNon-textual status content, such as images.\nNon-displayed text specific to AT users\nThere may be cases where the addition of visible text does not by itself convey sufficient information to the user of assistive technology. For example, the proximity of new content to other pieces of information on the screen may provide a visual context that is lacking in the text alone.\nIn such cases, authors may wish to designate additional content for inclusion in the status message, including non-displayed text which can be provided to the assistive technologies, for added context. Important considerations regarding the appropriate use of such techniques are further discussed in the Sufficient Techniques.\nModification of status text\nIf a status message persists on the page, modifications to this text are usually equivalent to a new status message. An example would be a shopping cart which updates text from reading \"0 items\" to \"3 items\". Typical methods of writing such changes in the page content result in the entire modified text string being considered a new change, and thus read by assistive technologies. However, where only the number in this string was coded as an updated chunk of content, the resulting experience for screen reader users could be to only hear \"three\", which may not be sufficient information to provide context for the user. In such situations, marking the entire \"3 items\" string as the status text would normally be a better solution. See Sufficient Techniques for more discussion, including the use of\naria-atomic\n. In this case it would also be a courtesy to add offscreen text such as \"in shopping cart\" to the message.\nRemoval of status text\nIn situations where status text is entirely removed, its absence may itself convey information about the status. The most obvious example of this is where a message is displayed that the system is \"busy\" or \"waiting\". For a sighted user, when this text disappears, it is normally an indication that the state is now available. However non-sighted users would be unaware of this change, unless the end of the waiting state results in a change of context for the user. Where updating the visible message (e.g., to \"system available\") is not feasible, the use of a non-visible status message, such as \"system available\", ensures equivalent status information is provided. See Sufficient Techniques for more discussion.\nNon-textual status content\nChanges in content are not restricted to text changes. Where an icon or sound indicates a status message, this information will be surfaced by the screen reader through a combination of two things: 1) existing WCAG requirements governing text alternatives (under SC 1.1.1 Non-Text Content), and 2) the requirement of this current success criterion to supply an appropriate role.\nExamples of Changes That Are Not Status Messages\nThe following examples identify situations where no additional author action is necessary. All cases are excepted from this success criterion since they do not meet the definition of \"status messages.\"\nAn author displays an error message in a dialog.\nSince the dialog takes focus, it is defined as a change of context and does not meet the definition of a status message. As a result of taking focus, the new change of context is already announced by the screen reader, and thus does not need to be included in the scope of this success criterion.\nContent is exposed or hidden when a user interacts with a user interface component, for example expanding components such as a menu, select, accordion or tree, or selecting a different tab item in a tablist.\nNone of the resulting changes to content meet the definition of status messages. Further, all components that meet the definition of a user interface component already have requirements specified under\n4.1.2 Name, Role, Value\n, including the need to make notifications of changes to values and states available to user agents, including assistive technologies. As a result, changes in state, such as \"expanded\" or \"collapsed,\" would be announced by the screen reader, and thus the user would be alerted to the 'addition' or 'removal' of content. As such, such content does not need to be addressed by this success criterion.\nAfter a user completes a survey question which indicates they are unhappy, a series of new questions are added to the page about customer satisfaction.\nThe new inputs do not meet the definition of status message. They do not \"provide information to the user on the success or results of an action, on the waiting state of an application, on the progress of a process or on the existence of errors,\" and so are not required to meet this success criterion.\nNote\nCreating a status message about these questions being added, or notifying the user in advance that content changes may take place based on the user's response, are best practices but are not requirements in this scenario.\nOther uses of live regions or alerts\nLive regions and alerts can be usefully applied in many situations where a change of content takes place which does not constitute a status message, as defined in this success criterion. However, there is a risk of making an application too \"chatty\" for a screen reader user. User testing should be carried out to ensure the appropriate level of feedback is achieved. The Advisory Techniques provide examples of how alerts or live regions can enhance the user experience.\nNote\nThe purpose of this success criterion is not to force authors to generate new status messages. Its intent is to ensure that when status messages\nare\ndisplayed, they are programmatically identified in a way that allows assistive technologies to present them to the user.",
    "principle": "Robust",
    "guideline": "4.1 Compatible"
  },
  {
    "id": "4.1.3_brief",
    "type": "sc",
    "sc_id": "4.1.3",
    "section": "brief",
    "text": "[4.1.3 Status Messages] (Level AA)\nDescription: In content implemented using markup languages, status messages can be programmatically determined through role or properties such that they can be presented to the user by assistive technologies without receiving focus.\n\nSection: brief\n\nIn Brief\nGoal\nMake users aware of important changes in content.\nWhat to do\nLet assistive technology notify users about status changes that don't take focus.\nWhy it's important\nPeople who do not see messages need to be informed about them.",
    "principle": "Robust",
    "guideline": "4.1 Compatible"
  },
  {
    "id": "4.1.3_key_terms",
    "type": "sc",
    "sc_id": "4.1.3",
    "section": "key_terms",
    "text": "[4.1.3 Status Messages] (Level AA)\nDescription: In content implemented using markup languages, status messages can be programmatically determined through role or properties such that they can be presented to the user by assistive technologies without receiving focus.\n\nSection: key_terms\n\nKey Terms\nassistive technology\nhardware and/or software that acts as a\nuser agent\n, or along with a mainstream user agent, to provide functionality to meet the requirements\n      of users with disabilities that go beyond those offered by mainstream user agents\nNote 1\nFunctionality provided by assistive technology includes alternative presentations\n      (e.g., as synthesized speech or magnified content), alternative input methods (e.g.,\n      voice), additional navigation or orientation mechanisms, and content transformations\n      (e.g., to make tables more accessible).\nNote 2\nAssistive technologies often communicate data and messages with mainstream user agents\n      by using and monitoring APIs.\nNote 3\nThe distinction between mainstream user agents and assistive technologies is not absolute.\n      Many mainstream user agents provide some features to assist individuals with disabilities.\n      The basic difference is that mainstream user agents target broad and diverse audiences\n      that usually include people with and without disabilities. Assistive technologies\n      target narrowly defined populations of users with specific disabilities. The assistance\n      provided by an assistive technology is more specific and appropriate to the needs\n      of its target users. The mainstream user agent may provide important functionality\n      to assistive technologies like retrieving web content from program objects or parsing\n      markup into identifiable bundles.\nExample\nAssistive technologies that are important in the context of this document include\n      the following:\nscreen magnifiers, and other visual reading assistants, which are used by people with\n         visual, perceptual and physical print disabilities to change text font, size, spacing,\n         color, synchronization with speech, etc. in order to improve the visual readability\n         of rendered text and images;\nscreen readers, which are used by people who are blind to read textual information\n         through synthesized speech or braille;\ntext-to-speech software, which is used by some people with cognitive, language, and\n         learning disabilities to convert text into synthetic speech;\nspeech recognition software, which may be used by people who have some physical disabilities;\nalternative keyboards, which are used by people with certain physical disabilities\n         to simulate the keyboard (including alternate keyboards that use head pointers, single\n         switches, sip/puff and other special input devices.);\nalternative pointing devices, which are used by people with certain physical disabilities\n         to simulate mouse pointing and button activations.\nchanges of context\nmajor changes that, if made without user awareness, can disorient users who are not able to view\n      the entire page simultaneously\nChanges in context include changes of:\nuser agent\n;\nviewport\n;\nfocus;\ncontent\nthat changes the meaning of the\nweb page\nNote\nA change of content is not always a change of context. Changes in content, such as\n      an expanding outline, dynamic menu, or a tab control do not necessarily change the\n      context, unless they also change one of the above (e.g., focus).\nExample\nOpening a new window, moving focus to a different component, going to a new page (including\n      anything that would look to a user as if they had moved to a new page) or significantly\n      re-arranging the content of a page are examples of changes of context.\ncontent\ninformation and sensory experience to be communicated to the user by means of a\nuser agent\n, including code or markup that defines the content's\nstructure\n,\npresentation\n, and interactions\npresentation\nrendering of the\ncontent\nin a form to be perceived by users\nprocess\nseries of user actions where each action is required in order to complete an activity\nExample 1\nSuccessful use of a series of web pages on a shopping site requires users to view\n      alternative products, prices and offers, select products, submit an order, provide\n      shipping information and provide payment information.\nExample 2\nAn account registration page requires successful completion of a\nTuring test\nbefore\n      the registration form can be accessed.\nprogrammatically determined\ndetermined by software from author-supplied data provided in a way that different\nuser agents\n, including\nassistive technologies\n, can extract and present this information to users in different modalities\nExample 1\nDetermined in a markup language from elements and attributes that are accessed directly\n      by commonly available assistive technology.\nExample 2\nDetermined from technology-specific data structures in a non-markup language and exposed\n      to assistive technology via an accessibility API that is supported by commonly available\n      assistive technology.\nrole\ntext or number by which software can identify the function of a component within Web\n      content\nExample\nA number that indicates whether an image functions as a hyperlink, command button,\n      or check box.\nstatus message\nchange in content that is not a\nchange of context\n, and that provides information to the user on the success or results of an action, on the waiting state of an application, on the progress of a\nprocess\n, or on the existence of errors\nstructure\nThe way the parts of a\nweb page\nare organized in relation to each other; and\nThe way a collection of\nweb pages\nis organized\nuser agent\nany software that retrieves and presents web content for users\nExample\nWeb browsers, media players, plug-ins, and other programs — including\nassistive technologies\n— that help in retrieving, rendering, and interacting with web content.\nviewport\nobject in which the\nuser agent\npresents content\nNote 1\nThe user agent presents content through one or more viewports. Viewports include windows, frames,\n      loudspeakers, and virtual magnifying glasses. A viewport may contain another viewport\n      (e.g., nested frames). Interface components created by the user agent such as prompts,\n      menus, and alerts are not viewports.\nNote 2\nThis definition is based on\nUser Agent Accessibility Guidelines 1.0 Glossary\n[\nUAAG10\n].\nweb page\na non-embedded resource obtained from a single URI using HTTP plus any other resources\n      that are used in the rendering or intended to be rendered together with it by a\nuser agent\nNote 1\nAlthough any \"other resources\" would be rendered together with the primary resource,\n      they would not necessarily be rendered simultaneously with each other.\nNote 2\nFor the purposes of conformance with these guidelines, a resource must be \"non-embedded\"\n      within the scope of conformance to be considered a web page.\nExample 1\nA web resource including all embedded images and media.\nExample 2\nA web mail program built using Asynchronous JavaScript and XML (AJAX). The program\n      lives entirely at http://example.com/mail, but includes an inbox, a contacts area\n      and a calendar. Links or buttons are provided that cause the inbox, contacts, or calendar\n      to display, but do not change the URI of the page as a whole.\nExample 3\nA customizable portal site, where users can choose content to display from a set of\n      different content modules.\nExample 4\nWhen you enter \"http://shopping.example.com/\" in your browser, you enter a movie-like\n      interactive shopping environment where you visually move around in a store dragging\n      products off of the shelves around you and into a visual shopping cart in front of\n      you. Clicking on a product causes it to be demonstrated with a specification sheet\n      floating alongside. This might be a single-page website or just one page within a\n      website.",
    "principle": "Robust",
    "guideline": "4.1 Compatible"
  },
  {
    "id": "4.1.3_situation_A",
    "type": "sc_situation",
    "sc_id": "4.1.3",
    "situation_id": "A",
    "techniques": [
      "ARIA22",
      "G199"
    ],
    "text": "[4.1.3 Status Messages] (Level AA)\nDescription: In content implemented using markup languages, status messages can be programmatically determined through role or properties such that they can be presented to the user by assistive technologies without receiving focus.\n\nSituation A: If a status message advises on the success or results of an action, or the state of an application:\n\nRelated techniques: ARIA22, G199",
    "principle": "Robust",
    "guideline": "4.1 Compatible"
  },
  {
    "id": "4.1.3_situation_B",
    "type": "sc_situation",
    "sc_id": "4.1.3",
    "situation_id": "B",
    "techniques": [
      "ARIA19",
      "G83",
      "G84",
      "G85",
      "G177",
      "G194"
    ],
    "text": "[4.1.3 Status Messages] (Level AA)\nDescription: In content implemented using markup languages, status messages can be programmatically determined through role or properties such that they can be presented to the user by assistive technologies without receiving focus.\n\nSituation B: If a status message conveys a suggestion, or a warning on the existence of an error:\n\nRelated techniques: ARIA19, G83, G84, G85, G177, G194",
    "principle": "Robust",
    "guideline": "4.1 Compatible"
  },
  {
    "id": "4.1.3_situation_C",
    "type": "sc_situation",
    "sc_id": "4.1.3",
    "situation_id": "C",
    "techniques": [
      "ARIA23",
      "ARIA22",
      "ARIA22"
    ],
    "text": "[4.1.3 Status Messages] (Level AA)\nDescription: In content implemented using markup languages, status messages can be programmatically determined through role or properties such that they can be presented to the user by assistive technologies without receiving focus.\n\nSituation C: If a status message conveys information on the progress of a process:\n\nRelated techniques: ARIA23, ARIA22, ARIA22",
    "principle": "Robust",
    "guideline": "4.1 Compatible"
  },
  {
    "id": "4.1.3_advisory",
    "type": "sc_advisory",
    "sc_id": "4.1.3",
    "techniques": [
      "1.4.13 Content on Hover or Focus",
      "1.4.13 Content on Hover or Focus",
      "ARIA18",
      "ARIA18",
      "ARIA18",
      "SCR14"
    ],
    "text": "[4.1.3 Status Messages] (Level AA)\nDescription: In content implemented using markup languages, status messages can be programmatically determined through role or properties such that they can be presented to the user by assistive technologies without receiving focus.\n\nAdvisory techniques for SC 4.1.3: 1.4.13 Content on Hover or Focus, 1.4.13 Content on Hover or Focus, ARIA18, ARIA18, ARIA18, SCR14",
    "principle": "Robust",
    "guideline": "4.1 Compatible"
  },
  {
    "id": "4.1.3_failures",
    "type": "sc_failures",
    "sc_id": "4.1.3",
    "techniques": [
      "F103"
    ],
    "text": "[4.1.3 Status Messages] (Level AA)\nDescription: In content implemented using markup languages, status messages can be programmatically determined through role or properties such that they can be presented to the user by assistive technologies without receiving focus.\n\nCommon failures for SC 4.1.3: F103",
    "principle": "Robust",
    "guideline": "4.1 Compatible"
  },
  {
    "id": "G94",
    "type": "technique",
    "code": "G94",
    "text": "[G94] Providing short text alternative for non-text content that serves the same purpose and presents the same information as the non-text content\n\nDescription:\nThe objective of this technique is to create a text alternative that serves the same purpose and presents the same information as the original non-text content.  As a result, it is possible to remove the non-text content and replace it with the text alternative and no functionality or information would be lost.   This text alternative should not necessarily describe the non-text content.  It should serve the same purpose and convey the same information.  This may sometimes result in a text alternative that looks like a description of the non-text content.  But this would only be true if that was the best way to serve the same purpose.\n\nIf possible, the short text alternative should completely convey the purpose and information.  If it is not possible to do this in a short phrase or sentence, then the short text alternative should provide a brief overview of the information.  A long text alternative would be used in addition to convey the full information.\n\nThe text alternative should be able to substitute for the non-text content. If the non-text content were removed from the page and substituted with the text, the page would still provide the same function and information. The text alternative would be brief but as informative as possible.\n\nIn deciding what text to include in the alternative, it is often a good idea to consider the following questions:\n\n- Why is this non-text content here?\n- What information is it presenting?\n- What purpose does it fulfill?\n- If I could not use the non-text content, what words would I use to convey the same function and/or information?\n\nWhen non-text content contains words that are important to understanding the content, the alt text should include those words. If the text in the image is more than can fit in a short text alternative then it should be described in the short text alternative and a long text alternative should be provided as well with the complete text.\n\nExamples:\n- **Example 1:** A search button uses an image of a magnifying glass.  The text alternative is \"search\" and not \"magnifying glass\".\n- **Example 2:** A picture shows how a knot is tied including arrows showing how the ropes go to make the knot.  The text alternative describes how to tie the knot, not what the picture looks like.\n- **Example 3:** A picture shows what a toy looks like from the front.  The text alternative describes a front view of the toy.\n- **Example 4:** An animation shows how to change a tire. A short text alternative describes what the animation is about. A long text alternative describes how to change a tire.\n- **Example 5:** A logo of the TechTron company appears next to each product in a list that is made by that and has a short text alternative that reads, \"TechTron.\"\n- **Example 6:** A chart showing sales for October has an short text alternative of  \"October sales chart\". It also has a long description that provides all of the information on the chart.\n- **Example 7:** A heading contains a picture of the words, \"The History of War\" in stylized text. The alt text for the picture is \"The History of War\".\n- **Example 8:** An image of a series of books on a shelf contains interactive areas that provide the navigation means to a web page about the particular book. The text alternative \"The books available to buy in this section. Select a book for more details about that book.\" describes the picture and the interactive nature.  ---",
    "referenced_by": [
      "1.1.1"
    ]
  },
  {
    "id": "ARIA6",
    "type": "technique",
    "code": "ARIA6",
    "text": "[ARIA6] Using aria-label to provide labels for objects\n\nDescription:\nThe purpose of this technique is to provide a label for objects that can be read by assistive technology. The **aria-label** attribute provides the text label for an object, such as a button. When a screen reader encounters the object, the **aria-label** text is read so that the user will know what it is.\n\nAuthors should be aware that **aria-label** may be disregarded by assistive technologies in situations where **aria-labelledby** is used for the same object. For more information on the naming hierarchy please consult the [accessible name and description computation](https://www.w3.org/TR/accname/#mapping_additional_nd_te) section of the Accessible Name And Description Computation recommendation. Authors should be aware that use of **aria-label** will override any native naming such as **alt** on images or **label** associated with a form field using the **for** attribute.\n\nExamples:\n- **Example 1: Distinguishing navigation landmarks**  The following example shows howaria-labelcould be used to distinguish two navigation landmarks in an HTML document, where there are more than two of the same type of landmark on the same page, and there is no existing text on the page that can be referenced as the label.  ```html <div role=\"navigation\" aria-label=\"Primary\"> <ul> <li>...a list of links here ...</li> </ul> </div> <div role=\"navigation\" aria-label=\"Secondary\"> <ul> <li>...a list of links here ...</li> </ul> </div> ```\n- **Example 2: Identifying region landmarks**  The following example shows how a generic \"region\" landmark might be added to a weather portlet. There is no existing text on the page that can be referenced as the label, so it is labelled witharia-label.  ```html <div role=\"region\" aria-label=\"weather portlet\"> ... </div> ```\n- **Example 3: Providing a label for Math**  Below is an example of a MathML function, using the math role, appropriate label, and MathML rendering:  ```html <div role=\"math\" aria-label=\"6 divided by 4 equals 1.5\"> <math xmlns=\"https://www.w3.org/1998/Math/MathML\"> <mfrac> <mn>6</mn> <mn>4</mn> </mfrac> <mo>=</mo> <mn>1.5</mn> </math> </div> ```    ---",
    "referenced_by": [
      "1.1.1"
    ]
  },
  {
    "id": "ARIA10",
    "type": "technique",
    "code": "ARIA10",
    "text": "[ARIA10] Using aria-labelledby to provide a text alternative for non-text content\n\nDescription:\nThe purpose of this technique is to provide a short description for an element that can be read by assistive technologies by using the **aria-labelledby** attribute. The **aria-labelledby** attribute associates an element with text that is visible elsewhere on the page by using an **id** reference value that matches the **id** attribute of the labeling element. Assistive technology such as screen readers use the text of the element identified by the value of the **aria-labelledby** attribute as the text alternative for the element with the attribute.\n\nExamples:\n- **Example 1: Providing a short description for a complex graphic**  This example shows how to use thearia-labelledbyattribute to provide a short text description for a read-only complex graphic of an star rating pattern; the graphic is composed of several image elements. The text alternative for the graphic is the label, visible on the page beneath the star pattern.  Working example:Providing a short description for a complex graphic.  ```html <div role=\"img\" aria-labelledby=\"star-id\"> <img src=\"fullstar.png\" alt=\"\"> <img src=\"fullstar.png\" alt=\"\"> <img src=\"fullstar.png\" alt=\"\"> <img src=\"fullstar.png\" alt=\"\"> <img src=\"emptystar.png\" alt=\"\"> </div> <div id=\"star-id\">4 of 5</div> ```    ---",
    "referenced_by": [
      "1.1.1"
    ]
  },
  {
    "id": "G196",
    "type": "technique",
    "code": "G196",
    "text": "[G196] Using a text alternative on one item within a group of images that describes all items in the group\n\nDescription:\nThe objective of this technique is to avoid unnecessary duplication that occurs when a grouping of adjacent non-text content is used to present information or functionality.\n\nIn some cases, pages will present a group of images to convey information. When presented together or in a specific combination these groupings can convey different types of information. For example, two images of a star where one is presented in black and white and the other is colored can be used in combination to represent a user rating. For example, three filled stars followed by two unfilled stars might represent a rating of three out of five stars.\n\nTo use this technique, an author provides a text alternative that serves the equivalent purpose for the entire group and associates it with one item in the group. The other items in the group are then marked in a way that can be ignored by assistive technologies. In this way, the user is able to more efficiently identify the purpose of the group and can avoid duplication or confusion that may result had a text alternative been provided for each item in the group.\n\nExamples:\n- **Example 1: A rating system inHTML**  In the following example, a rating is shown as three filled stars and two empty stars. While a text alternative could have been provided for each of the five images, the author has instead provided the rating in the form \"3 out of 5 stars\" for the first image and has marked the others using null alt text.  ```html <p>Rating: <img src=\"star-filled\" alt=\"3 out of 5 stars\"> <img src=\"star-filled\" alt=\"\"> <img src=\"star-filled\" alt=\"\"> <img src=\"star-empty\" alt=\"\"> <img src=\"star-empty\" alt=\"\"> </p> ```\n- **Example 2: Buttons created with groups of images in HTML**  In this example, each button has a set of images to indicate the level of conformance to WCAG being claimed. This approach makes it possible for assistive technologies to avoid announcing things like, \"Image A, Image A, Image A\" etc.  ```html <p>Conformance Level:</p> <button name=\"A\" type=\"button\"> <img src=\"a.png\" alt=\"A\"> </button> <button name=\"AA\" type=\"button\"> <img src=\"a.png\" alt=\"AA\"> <img src=\"a.png\" alt=\"\"> </button> <button name=\"AAA\" type=\"button\"> <img src=\"a.png\" alt=\"AAA\"> <img src=\"a.png\" alt=\"\"> <img src=\"a.png\" alt=\"\"> </button> ```    ---",
    "referenced_by": [
      "1.1.1"
    ]
  },
  {
    "id": "H2",
    "type": "technique",
    "code": "H2",
    "text": "[H2] Combining adjacent image and text links for the same resource\n\nDescription:\nThis objective of this technique is to provide both text and iconic representations of links without making the web page more confusing or difficult for keyboard users or assistive technology users. Since different users finding text and icons more usable, providing both can improve the accessibility of the link.\n\nMany links have both a text and iconic representation adjacent to each other, but rendered in separate **a** elements. Visually they appear to be a single link, but many users encounter them as adjacent identical links. For a keyboard user, it is tedious to navigate through redundant links. For users of assistive technologies, it can be confusing to encounter successive identical links. When the text alternative for the icon is a duplicate of the link text, it is repetitive as screen readers read the description twice.\n\nIf the author omitted alternative text from the link image, it would fail [Success Criterion 1.1.1](https://www.w3.org/WAI/WCAG22/Understanding/non-text-content.html) because the text alternative would not serve the same purpose as the graphical link.\n\nThis technique provides such links by putting the text and image together in one **a** element and providing null alternative text on the image to eliminate duplication of text. In this way, both representations of the link are provided, but keyboard users only encounter one link and assistive technology that provides users with link lists for a web page do not include duplicate links.\n\nSometimes the text and the icon link are rendered in separate, adjacent table cells to facilitate page layout. Although WCAG 2 does not prohibit the use of layout tables, CSS-based layouts are recommended in order to retain the defined semantic meaning of the HTML table elements and to conform to the coding practice of separating presentation from content. If CSS is used, this technique can be applied to combine the links.\n\nExamples:\n- **Example 2**  A link contains an icon and text, and the site help refers to the icon. Theimghas a text alternative which is the name used for the icon in the site help, which describes clicking the home page icon.  ```html <a href=\"home.html\"> <img src=\"house.gif\" alt=\"home page icon\">Go to the home page </a> ```    ---\n- **Example 1**  The icon and text are contained in the sameaelement.  ```html <a href=\"products.html\"> <img src=\"icon.gif\" alt=\"\">Products page </a> ```",
    "referenced_by": [
      "1.1.1",
      "2.4.4",
      "2.4.9"
    ]
  },
  {
    "id": "H37",
    "type": "technique",
    "code": "H37",
    "text": "[H37] Using alt attributes on img elements\n\nDescription:\nWhen using the **img** element, specify a short text alternative with the\n**alt** attribute. Note. The value of this attribute is referred to as \"alt\ntext\".\n\nWhen an image contains words that are important to understanding the content, the alt\ntext should include those words. This will allow the alt text to play the same function\non the page as the image. Note that it does not necessarily describe the visual\ncharacteristics of the image itself but must convey the same meaning as the image.\n\nExamples:\n- **Example 1**  An image on a Website provides a link to a free newsletter. The image contains the text \"Free newsletter. Get free recipes, news, and more. Learn more.\" The alt text matches the text in the image.  ```html <img src=\"newsletter.gif\" alt=\"Free newsletter. Get free recipes, news, and more. Learn more.\"> ```\n- **Example 2**  An image on a website depicts the floor plan of a building. The image is an image map with each room an interactive map area. The alt text is \"The building's floor plan. Select a room for more information about the purpose or content of the room.\" The instruction to \"select a room\" indicates that the image is interactive.    ---",
    "referenced_by": [
      "1.1.1"
    ]
  },
  {
    "id": "H53",
    "type": "technique",
    "code": "H53",
    "text": "[H53] Using the body of the object element\n\nDescription:\nThe objective of this technique is to provide a text alternative for content rendered\nusing the object element. The body of the **object** element can be used to provide a complete text alternative for the object, or may contain additional non-text content with text alternatives.\n\nFallback content for the **object** element is only available to the user when the media loaded by the element is not rendered by the user agent, because the user agent does not support the media technology or the user has instructed the user agent not to render that technology. In these situations, the fallback content will be presented to the user. If the media is rendered without the fallback content, the media needs to be directly accessible. Authors can only rely on this technique to satisfy the success criterion if they are not relying on the direct accessibility of the media's technology in their conformance claim, and reasonably expect users will be able to access the fallback.\n\nExamples:\n- **Example 1: An object includes a long description that describes it**  ```html <object classid=\"https://www.example.com/analogclock.py\"> <p>Here is some text that describes the object and its operation.</p> </object> ```\n- **Example 2: An object includes non-text content with a text alternative**  ```html <object classid=\"https://www.example.com/animatedlogo.py\"> <img src=\"staticlogo.gif\" alt=\"Company Name\"> </object> ```\n- **Example 3: The image object has content that provides a brief description of the function of the image**  ```html <object data=\"companylogo.gif\" type=\"image/gif\"> <p>Company Name</p> </object> ```\n- **Example 4**  This example takes advantage of the fact theobjectelements may be nested to provide for alternative representations of information.  ```html <object classid=\"java:Press.class\" width=\"500\" height=\"500\"> <object data=\"pressure.mpeg\" type=\"video/mpeg\"> <object data=\"pressure.gif\" type=\"image/gif\"> As temperature increases, the molecules in the balloon... </object> </object> </object> ```    ---",
    "referenced_by": [
      "1.1.1",
      "1.2.3",
      "1.2.8"
    ]
  },
  {
    "id": "H86",
    "type": "technique",
    "code": "H86",
    "text": "[H86] Providing text alternatives for ASCII art, emoticons, and leetspeak\n\nDescription:\nEmojis are very popular and are frequently used online to help provide more context and expression to text-based communication. Emojis come with their own pre-defined names that might not always match what the author is intending to communicate. For example, the emoji of a black right-facing triangle (►) is described by default as black right-pointing pointer, which would be confusing if a designer had changed its rotation or color, or if it was being used to give the accessible name to a \"play\" button in a multimedia player.\n\nEmoticons pre-date emojis, are still used but are much less popular than they once were. Emoticons use ASCII characters to create facial expressions and other ways to communicate an emotion. Because emoticons are made from many text characters, they can be confusing for screen reader users. When possible it is better simply to use a word like \"smile\" or a suitable emoji instead of an emoticon. If emoticons are used they should have a text alternative.\n\nASCII art was common on the internet before graphics became widely used. ASCII characters were arranged to form pictures, pictures of text, or graphs. Although ASCII content is not used frequently on the web anymore, it must be remembered that, when it is used, it can be very confusing to people who are accessing the internet using screen readers. If ASCII art is used, it should also have a text explanation of what the picture is. It is also suggested that, if the ASCII picture isn't marked up as an image using ARIA, that there is a link to skip over the art (although this is not required).\n\nLeet used to be a fairly-common part of Internet culture and slang, but is now hardly used. Leetspeak uses various combinations of characters, including numerals and special characters, to replace standard characters. Leet is often incomprehensible to people using screen readers, and therefore requires a text alternative in order to conform to [Success Criterion 1.1.1 (Non-Text Content)](https://www.w3.org/WAI/WCAG22/Understanding/non-text-content.html).\n\nExamples:\n- **Example 1: Marking up emojis in a sentence**  This shows a technique to mark up emojis with accessible names that differ from their default. Because you can't use analtattribute on aspanelement and theARIArecommendation disallows accessible names on generic elements, to give the emojis accessible names they are defined as images with the ARIArole=\"img\"property which then allows the creation of an accessible name using thearia-labelproperty.  ```html <p>I smiled at my friend and gestured <span aria-label=\"you\" role=\"img\">👉🏾</span> <span aria-label=\"rock\" role=\"img\">🤘🏾</span>! </p> ```\n- **Example 2: Four options for providing alternatives for an emoticon representing \"smile\"**  The following shows four options for providing alternatives for an emoticon representing \"smile\", which is consists of a colon followed by a closing parenthesis.  ```html :) (smile) <abbr title=\"smile\">:)</abbr> <span aria-label=\"smile\" role=\"img\">:)</span> <img alt=\"smile\" src=\"smile.gif\"> ```\n- **Example 3: Using thearia-labelandrole=\"img\"properties**  Adding therole=\"img\"property to the ASCII content's containing element defines it as an image, and thearia-labelproperty gives it the required text alternative.Skip to the next ASCII example.  ```html <div aria-label=\"WCAG\" role=\"img\"> oooooo   oooooo     oooo   .oooooo.         .o.         .oooooo. `888.    `888.     .8'   d8P'  `Y8b       .888.       d8P'  `Y8b `888.   .8888.   .8'   888              .8\"888.     888 `888  .8'`888. .8'    888             .8' `888.    888 `888.8'  `888.8'     888            .88ooo8888.   888     ooooo `888'    `888'      `88b    ooo   .8'     `888.  `88.    .88' `8'      `8'        `Y8bood8P'  o88o     o8888o  `Y8bood8P' </div> ```\n- **Example 4: ASCII art with an explanation of the picture preceding it**  This example includes a link to skip over the ASCII art.Skip to the Leetspeak example.  ```html <figure> <figcaption> <p>Figure 1: ASCII art picture of a butterfly. <a href=\"#skipbutterfly\">Skip ASCII butterfly image</a> </p> </figcaption>  LLLLLLLLLLL __LLLLLLLLLLLLLL LLLLLLLLLLLLLLLLL _LLLLLLLLLLLLLLLLLL LLLLLLLLLLLLLLLLLLLL _LLLLLLLLLLLLLLLLLLLLL LLLLLLLLLLLLLLLLLLLLLL L     _LLLLLLLLLLLLLLLLLLLLLLL LL     LLLLLL~~~LLLLLLLLLLLLLL _L    _LLLLL      LLLLLLLLLLLLL L~    LLL~        LLLLLLLLLLLLL LL   _LLL        _LL   LLLLLLLL LL    LL~         ~~     ~LLLLLL L   _LLL_LLLL___         _LLLLLL LL  LLLLLLLLLLLLLL      LLLLLLLL L  LLLLLLLLLLLLLLL        LLLLLL LL LLLLLLLLLLLLLLLL        LLLLL~ LLLLLLLL_______       L _LLLLLLLLLLLLLLLL     LLLLLLLL ~~~~~~~LLLLLLLLLLLLLLLLLLLLLLLLL~       LLLLLL ______________LLL  LLLLLLLLLLLLLL ______LLLLLLLLL_ LLLLLLLLLLLLLLLLLLLL  LLLLLLLL~~LLLLLLL~~~~~~   ~LLLLLL ___LLLLLLLLLL __LLLLLLLLLLLLL LLLLLLLLLLLLL____       _LLLLLL_ LLLLLLLLLLL~~   LLLLLLLLLLLLLLL   LLLLLLLLLLLLLLLLLL     ~~~LLLLL __LLLLLLLLLLL     _LLLLLLLLLLLLLLLLL_  LLLLLLLLLLLLLLLLLL_       LLLLL LLLLLLLLLLL~       LLLLLLLLLLLLLLLLLLL   ~L ~~LLLLLLLLLLLLL      LLLLLL _LLLLLLLLLLLL       LLLLLLLLLLLLLLLLLLLLL_  LL      LLLLLLLLL   LLLLLLLLL LLLLLLLLLLLLL        LLLLLLLLLLLLL~LLLLLL~L   LL       ~~~~~       ~LLLLLL LLLLLLLLLLLLLLL__L    LLLLLLLLLLLL_LLLLLLL LL_  LL_            _     LLLLLL LLLLLLLLLLLLLLLLL~     ~LLLLLLLL~~LLLLLLLL   ~L  ~LLLL          ~L   LLLLLL~ LLLLLLLLLLLLLLLL               _LLLLLLLLLL    LL  LLLLLLL___     LLLLLLLLLL LLLLLLLLLLLLLLLL              LL~LLLLLLLL~     LL  LLLLLLLLLLLL   LLLLLLL~ LLLLLLLLLLLLLLLL_  __L       _L  LLLLLLLL      LLL_ LLLLLLLLLLLLLLLLLLLLL LLLLLLLLLLLLLLLLLLLL        L~  LLLLLLLL      LLLLLLL~LLLLLLLLLLLLLLLL~ LLLLLLLLLLLLLLLLLLLL___L_ LL   LLLLLLL       LLLL     LLLLLLLLLLLLLL ~~LLLLLLLLLLLLLLLLLLLLLLLL     LLLLL~      LLLLL        ~~~~~~~~~ LLLLLLLLLLLLLLLLLL_ _   LLL       _LLLLL ~~~~~~LLLLLLLLLL~             LLLLLL LLLLL              _LLLLLL LLLLL    L     L   LLLLLLL LLLLL__LL    _L__LLLLLLLL LLLLLLLLLL  LLLLLLLLLLLL LLLLLLLLLLLLLLLLLLLLLL ~LLLLLLLLLLLLLLLLL~~ LLLLLLLLLLLLL ~~~~~~~~~ </figure> <p id=\"skipbutterfly\">New content after the ASCII image.</p> ```\n- **Example 5: Marking up Leetspeak**  The following is Leetspeak for \"Austin Rocks\".  ```html <abbr title=\"Austin Rocks\">Au5t1N r0xx0rz</abbr> ```    ---",
    "referenced_by": [
      "1.1.1"
    ]
  },
  {
    "id": "PDF1",
    "type": "technique",
    "code": "PDF1",
    "text": "[PDF1] Applying text alternatives to images with the Alt entry in PDF documents\n\nDescription:\nThe objective of this technique is to provide text alternatives for\nimages via an **/Alt** entry in the property list for a Tag. This is normally\naccomplished using a tool for authoring PDF.\n\nPDF documents may be enhanced by providing alternative descriptions\nfor images, formulas, and other items that do not translate naturally\ninto text. In fact, such text alternatives are required for accessibility:\nalternate descriptions are human-readable text that can be vocalized\nby text-to-speech technology for the benefit of users with vision disabilities.\n\nWhen an image contains words that are important to understanding the\ncontent, the text alternative should include those words. This will\nallow the alternative to accurately represent the image. Note that\nit does not necessarily describe the visual characteristics of the\nimage itself but must convey the same meaning as the image.\n\nExamples:\n- **Example 1: Adding alt text to an image in Adobe Acrobat DC Pro**  This example is shown with Adobe Acrobat Pro. There are other software tools that perform similar functions.  This example is shown in operation in theworking example of Adding an/Altentry to an image.\n- **Example 2: Adding alt text to an image in Microsoft Word**\n- **Example 3: Adding alt text to an image in OpenOffice with the Writer add-on**  This example is shown with Open Office Writer. There are other software tools that perform similar functions.\n- **Example 4: Adding a text alternative to an image in a PDF document using an/Altentry**  The/Altproperty used on an image of mountains with a moon and trees typically would be used like this (typically accomplished by an authoring tool):  The image might also be represented by a tag with a different name. A different name might be used because the tag name is written in a language other than English or because a specific tool uses a different name for some other reason. In this situation, it is also necessary that theRoleMapcontained within theStructTreeRootfor the PDF document contain an entry which explicitly maps the name of the tag used for the image with the standard structure type used in PDF documents (in this case, Figure). If the RoleMap contains only an entry mapping Shape tags to Figure tags, therolemapinformation would appear as follows:  In this case, the usage of the/Altentry as follows would also be correct:  Note that the/Altentry in property lists can be combined with other entries.  ```html /Figure <</Alt (Sketch of Mountains with moon rising over trees)>> ```  ```html /RoleMap << /Shape /Figure >> ```  ```html /Shape <</Alt (Crater Lake in the summer, with the blue sky, clouds and crater walls perfectly reflected in the lake) >> ```    ---",
    "referenced_by": [
      "1.1.1"
    ]
  },
  {
    "id": "G95",
    "type": "technique",
    "code": "G95",
    "text": "[G95] Providing short text alternatives that provide a brief description of the non-text content\n\nDescription:\nThis technique is used when the text needed to serve the same purpose and\npresent the same information as the original non-text content is too lengthy\nor when this goal cannot be achieved with text alone. In that case this\ntechnique is used to provide a short text alternative that briefly describes\nthe non-text content. (A long text alternative is then provided using\nanother technique such that the combination serves the same purpose and\npresents the same information as the original non-text content.)\n\nIn deciding what text to include in the alternative, it is often a good idea\nto consider the following questions:\n\n- Why is this non-text content here?\n- What information is it presenting?\n- What purpose does it fulfill?\n- If I could not use the non-text content, what words would I use to\nconvey the same function and/or information?\n\nExamples:\n- **Example 1:** A chart showing sales for October has an short text alternative of \"October sales chart\". It also has a long description that provides all of the information on the chart.  ---",
    "referenced_by": [
      "1.1.1"
    ]
  },
  {
    "id": "ARIA15",
    "type": "technique",
    "code": "ARIA15",
    "text": "[ARIA15] Using aria-describedby to provide descriptions of images\n\nDescription:\nThe objective of this technique is to provide descriptions of images when a short text alternative does not adequately convey the function or information provided in the object.\n\nA feature of WAI-ARIA is the ability to associate descriptive text with a section, drawing, form element, picture, and so on using the **aria-describedby** property. Descriptive text provided using **aria-describedby** is separate from the short name provided using the **alt** attribute in HTML. An advantage of providing long descriptions using content from the same page as the image is that the alternative is available to all, including sighted people who do not have assistive technology.\n\nLike **aria-labelledby**, **aria-describedby** can accept multiple **id**s to point to other regions of the page using a space separated list. It is also limited to **id**s for defining these sets.\n\nExamples:\n- **Example 1: Describing an image**  The following example shows howaria-describedbycan be applied to an image to provide a long description, where that text description is on the same page as the image.  ```html <img src=\"ladymacbeth.jpg\" alt=\"Lady MacBeth\" aria-describedby=\"p1\"> <p id=\"p1\">This painting dates back to 1889 and is oil on canvas. It was created by John Singer Sargent, and represents ...</p> ```    ---",
    "referenced_by": [
      "1.1.1"
    ]
  },
  {
    "id": "G73",
    "type": "technique",
    "code": "G73",
    "text": "[G73] Providing a long description in another location with a link to it that is immediately adjacent to the non-text content\n\nDescription:\nThe objective of this technique is to provide a way to link to remote long\ndescriptions in technologies that do not have a long description feature\nbuilt directly into them (e.g., longdesc) or where the feature is known to\nnot be supported.\n\nWith this technique, the long description is provided in another location\nthan the non-text content. This could be at another location within the same\nURI or at another URI. A link to that long description is provided that is\nimmediately adjacent to the non-text content. The link can be immediately\nbefore or after the non-text content. If the description is located along\nwith other text then put \"End of description\" at the end so that they know\nwhen to stop reading and return to the main content. If a \"Back\" button will\nnot take the person back to the point from which they jumped, then a link\nback to the non-text content location is provided.\n\nThis technique was commonly used in HTML before 'longdesc' was added to the\nspecification. In HTML it was called a D-Link because it was usually\nimplemented by putting a D next to images and using the D as a link to the\nlong description. This technique is not technology specific and can be used\nin any technology that supports links.\n\nExamples:\n- **Example 1: Bar chart**  There is a bar chart on a web page showing the sales for the top three salespeople.  The short text alternative says \"October sales chart for top three salespeople.\"  Immediately after the non-text content is a small image denoting a long description. The alternate text for the image is \"Long description of chart\". The image links to the bottom of the page where there is a section titled \"Description of charts on this page\". The link points to this specific description: \"Sales for October show Mary leading with 400 units. Mike follows closely with 389. Chris rounds out our top 3 with sales of 350. [end of description]\"\n- **Example 2: Bar chart - in non-HTML technology where user agent \"back\" is not supported for security reasons.**  There is a bar chart on a web page showing the sales for the top three salespeople.  The short text alternative says \"October sales chart for top three salespeople.\"  Immediately after the non-text content is a small image denoting the long description. The alternate text for the image is \"Long description of chart\". The image links to another page titled \"Description of charts in October Sales Report\". The description link points to this specific description: \"Sales for October show Mary leading with 400 units. Mike follows closely with 389. Chris rounds out our top 3 with sales of 350. End of description. <link>Back to Sales Chart</link>\"\n- **Example 3: Caption used as link**  There is a chart. The figure caption immediately below the chart serves as a link to the long description. The Title attribute of the link makes it clear that this is a link to a long description.\n- **Example 4: Transcript of an audio-only file**  There is a recording of a speech by Martin Luther King. Links to the audio file and the transcript appear side by side.    ---",
    "referenced_by": [
      "1.1.1"
    ]
  },
  {
    "id": "G74",
    "type": "technique",
    "code": "G74",
    "text": "[G74] Providing a long description in text near the non-text content, with a reference to the location of the long description in the short description\n\nDescription:\nThe objective of this technique is to provide a long description without\nrequiring the user to jump off to another location for the description. It\nalso allows all users to see the description which may be useful to anyone\nwho might miss some features in the non-text content.\n\nWith this technique, the long description is provided as part of the\nstandard presentation (i.e., everyone receives it). The description is\nlocated near the non-text content but does not have to be the very next\nitem. For example, there may be a caption under a chart with the long\ndescription provided in the following paragraph.\n\nThe location of this long description is then provided within the short text\nalternative so the user knows where to look for it if they cannot view the\nnon-text content.\n\nExamples:\n- **Example 1: Bar chart**  There is a bar chart on a web page showing the sales for the top three salespeople.  The short text alternative says: \"October sales chart for top three salespeople. Details in text following the chart:\"  The following is in the paragraph immediately below the chart. \"Sales for October show Mary leading with 400 units. Mike follows closely with 389. Chris rounds out our top 3 with sales of 350.\"    ---",
    "referenced_by": [
      "1.1.1"
    ]
  },
  {
    "id": "G92",
    "type": "technique",
    "code": "G92",
    "text": "[G92] Providing long description for non-text content that serves the same purpose and presents the same information\n\nDescription:\nThe objective of this technique is to provide a long text alternative that\nserves the same purpose and presents the same information as the original\nnon-text content when a short text alternative is not sufficient.\n\nCombined with the short text alternative, the long description should be\nable to substitute for the non-text content. The short alternative\nidentifies the non-text content; the long alternative provides the\ninformation. If the non-text content were removed from the page and\nsubstituted with the short and long descriptions, the page would still\nprovide the same function and information.\n\nIn deciding what should be in the text alternatives, the following questions\nare helpful.\n\n- Why is this non-text content here?\n- What information is it presenting?\n- What purpose does it fulfill?\n- If I could not use the non-text content, what words would I use to\nconvey the same function and/or information?\n\nExamples:\n- **Example 1**  A chart showing sales for October has a short text alternative of \"October sales chart\". The long description would read \"Bar Chart showing sales for October. There are 6 salespersons. Maria is highest with 349 units. Frances is next with 301. Then comes Juan with 256, Sue with 250, Li with 200 and Max with 195. The primary use of the chart is to show leaders, so the description is in sales order.\"\n- **Example 2**  A line graph that shows average winter temperatures from the past 10 years includes a short text alternative of \"Average winter temperatures 1996-2006.\" The long description includes the data table that was used to generate the line graph.    ---",
    "referenced_by": [
      "1.1.1"
    ]
  },
  {
    "id": "G82",
    "type": "technique",
    "code": "G82",
    "text": "[G82] Providing a text alternative that identifies the purpose of the non-text content\n\nDescription:\nThe purpose of this technique is to provide useful information via the text\nalternative even if the full function of the non-text content cannot be\nprovided.\n\nSometimes, a text alternative cannot serve the same purpose as the original\nnon-text content (for example an applet meant to develop two dimensional\nrapid targeting skills and eye hand coordination.) In these cases this\ntechnique is used. With this technique a description of the purpose of the\nnon-text content is provided.\n\nExamples:\n- **Example 1**    ---",
    "referenced_by": [
      "1.1.1"
    ]
  },
  {
    "id": "ARIA9",
    "type": "technique",
    "code": "ARIA9",
    "text": "[ARIA9] Using aria-labelledby to concatenate a label from several text nodes\n\nDescription:\nThe **aria-labelledby** property can be used to provide a name for all visual objects. Applied to inputs, the **aria-labelledby** property can be used to provide a name to native inputs as well as non-native elements, such as custom text inputs constructed with div contenteditable=\"true\".\n\nOne particular use of **aria-labelledby** is for text inputs in situations where a meaningful name should consist of more than one text string.\n\nAuthors assign unique **id**s to the label strings to be concatenated as the name for the **input** element. The value of the **aria-labelledby** attribute is then a space-separated list of all **id**s in the order in which the label strings referenced should be read by screen readers. Supporting user agents will concatenate the label strings referenced and read them as one continuous name for the input.\n\nThe concatenation of strings can be useful for different reasons. In example 1, an input is nested within the context of a full sentence. The desired screen reader output is \"Extend time-out to [ 20 ] minutes - edit with autocomplete, selected 20\". Since the **id** of the text input is included in the string of **id**s referenced by aria-labelledby, the value of the input is included in the concatenated name at the right position.\n\nAnother application of **aria-labelledby** is when there is no space to provide a visible label next to the input, or when using native labels would create unnecessary redundancy. Here, the use **aria-labelledby** makes it possible to associate visible elements on the page as name for such inputs. This is demonstrated in example 2 where table column and row headings are concatenated into names for the text input elements inside the table.\n\nExamples:\n- **Example 3: A conference workshop booking table**  A conference workshop booking table with two parallel tracks allows users to select the workshop they want to attend. When tabbing through the checkbox inputs in the table, the track (1 or 2), the title, and the speaker of the workshop followed by the adjacent checkbox label \"Attend\" are provided as concatenated name for the checkboxes viaaria-labelledby.  Working example:Conference workshop booking timetable.  ```html <h1>Dinosaur Conference workshops timetable Thursday, 14 & Friday, 15 March 2013</h1> <table> <caption>Dinosaur Conference workshop booking table</caption> <tr> <th rowspan=\"2\" scope=\"col\">Track</th> <th colspan=\"2\" scope=\"colgroup\">Thursday</th> <th colspan=\"2\" scope=\"colgroup\">Friday</th> </tr> <tr> <th scope=\"col\" id=\"am1\">9 to 12 AM</th> <th scope=\"col\" id=\"pm1\">2 to 5 PM</th> <th scope=\"col\" id=\"am2\">9 to 12 AM</th> <th scope=\"col\" id=\"pm2\">2 to 5 PM</th> </tr> <tr> <th id=\"track1\" scope=\"row\">Track 1</th> <td> <h2 id=\"title-TM1\">The Paleozoic era </h2> <p>2 places left</p> <input type=\"checkbox\" id=\"TM1\" aria-labelledby=\"title-TM1 track1 am1 TM1-att\"> <label id=\"TM1-att\" for=\"TM1\">Attend</label> </td> <td> <h2 id=\"title-TA1\">The Mesozoic era overview</h2> <p>2 places left</p> <input type=\"checkbox\" id=\"TA1\" aria-labelledby=\"title-TA1 track1 am2 TA1-att\"> <label id=\"TA1-att\" for=\"TA1\">Attend</label> </td> <td> <h2 id=\"title-FM1\">The Triassic period, rise of the dinosaurs</h2> <p>1 place left</p> <input type=\"checkbox\" id=\"FM1\" aria-labelledby=\"title-FM1 track1 pm1 FM1-att\"> <label id=\"FM1-att\" for=\"FM1\">Attend</label> </td> <td> <h2 id=\"title-FA1\">The Jurassic period</h2> <p>11 places left</p> <input type=\"checkbox\" id=\"FA1\" aria-labelledby=\"title-FA1 track1 pm2 FA1-att\"> <label id=\"FA1-att\" for=\"FA1\">Attend</label> </td> </tr> <tr> <th id=\"track2\" scope=\"row\">Track 2</th> <td> <h2 id=\"title-TM2\">The Cretaceous period</h2> <p>18 places left</p> <input type=\"checkbox\" id=\"TM2\" aria-labelledby=\"title-TM2 track2 am1 TM2-att\"> <label id=\"TM2-att\" for=\"TM2\">Attend</label> </td> <td> <h2 id=\"title-TA2\">The end of the dinosaurs</h2> <p>2 places left</p> <input type=\"checkbox\" id=\"TA2\" aria-labelledby=\"title-TA2 track2 am2 TA2-att\"> <label id=\"TA2-att\" for=\"TA2\">Attend</label> </td> <td> <h2 id=\"title-FM2\">First discoveries of dinosaurs</h2> <p>2 places left</p> <input type=\"checkbox\" id=\"FM2\" aria-labelledby=\"title-FM2 track2 pm1 FM2-att\"> <label id=\"FM2-att\" for=\"FM2\">Attend</label> </td> <td> <h2 id=\"title-FA2\">Emerging scholarship</h2> <p>19 places left</p> <input type=\"checkbox\" id=\"FA2\" aria-labelledby=\"title-FA2 track2 pm2 FA2-att\"> <label id=\"FA2-att\" for=\"FA2\">Attend</label> </td> </tr> </table> ```    ---\n- **Example 1: A time-out input field with concatenated name**  A text input allows users to extend the default time before a time-out occurs.  The string \"Extend time-out to\" is contained in a nativelabelelement and is associated with the input with the input by id=\"timeout-duration\" . This label is associated with this input using the for/id association only on user agents that don't support ARIA. On user agents that support ARIA, the for/id association is ignored and the name for the input is provided only byaria-labelledby, per theAccessible Name and Description Computationin the HTML Accessibility API Mappings 1.0.  Thearia-labelledbyattribute on the text input references three elements: (1) thespancontaining the native label, (2) the text input containing the default text '20' (recall that this input is not labelled with the for/id associated label text), and (3) the string 'minutes' contained in aspan. These elements should be concatenated to provide the full name for the text input  Working example,Time-out input field with concatenated label, adapted from Easy ARIA tip #2: aria-labelledby and aria-describedby, an example put together by Marco Zehe.  ```html <div> <span id=\"timeout-label\"> <label for=\"timeout-duration\">Extend time-out to</label> </span> <input type=\"text\" size=\"3\" id=\"timeout-duration\" value=\"20\" aria-labelledby=\"timeout-label timeout-duration timeout-unit\"> <span id=\"timeout-unit\"> minutes</span> </div> ```\n- **Example 2: A simple data table with text inputs**  A simple data table containing text inputs. The input labels are concatenated througharia-labelledbyreferencing the respective column and row headers.  Working example,Using aria-labelledby for simple table with text inputs, based on an example by Jim Thatcher.  ```html <table> <tr> <td></td> <th id=\"tpayer\">Taxpayer</th> <th id=\"sp\">Spouse</th> </tr> <tr> <th id=\"gross\">W2 Gross</th> <td><input type=\"text\" size=\"20\" aria-labelledby=\"tpayer gross\"></td> <td><input type=\"text\" size=\"20\" aria-labelledby=\"sp gross\"></td> </tr> <tr> <th id=\"divi\">Dividends</th> <td><input type=\"text\" size=\"20\" aria-labelledby=\"tpayer divi\"></td> <td><input type=\"text\" size=\"20\" aria-labelledby=\"sp divi\"></td> </tr> </table> ```",
    "referenced_by": [
      "1.1.1",
      "3.3.2"
    ]
  },
  {
    "id": "H24",
    "type": "technique",
    "code": "H24",
    "text": "[H24] Providing text alternatives for the area elements of image maps\n\nDescription:\nThe objective of this technique is to provide text alternatives that serve the same\npurpose as the selectable regions of an image map. An image map is an image divided into\nselectable regions defined by **area** elements. Each area is a link to another\nweb page or another part of the current web page. The **alt** attribute of each\n**area** element serves the same purpose as the selectable area of the\nimage.\n\nExamples:\n- **Example 1**  This example uses thealtattribute of theareaelement to provide text that describes the purpose of the image map areas.  ```html <img src=\"welcome.gif\" usemap=\"#map1\" alt=\"Areas in the library. Select an area for more information on that area.\"> <map id=\"map1\" name=\"map1\"> <area shape=\"rect\" coords=\"0,0,30,30\" href=\"reference.html\" alt=\"Reference\"> <area shape=\"rect\" coords=\"34,34,100,100\" href=\"media.html\" alt=\"Audio visual lab\"> </map> ```    ---",
    "referenced_by": [
      "1.1.1",
      "2.4.4",
      "2.4.9"
    ]
  },
  {
    "id": "H30",
    "type": "technique",
    "code": "H30",
    "text": "[H30] Providing link text that describes the purpose of a link for anchor elements\n\nDescription:\nThe objective of this technique is to describe the purpose of a link by providing descriptive text as the content of the **a** element. The description lets a user distinguish this link from other links in the web page and helps the user determine whether to follow the link. The URI of the destination is generally not sufficiently descriptive.\n\nWhen an image is the only content of a link, the text alternative for the image describes the unique function of the link.\n\nWhen the content of a link contains both text and one or more images, if the text is sufficient to describe the purpose of the link, the images may have an empty text alternative. (See [Using null alt text and no title attribute on img elements for images that assistive technology should ignore](H67).) When the images convey information beyond the purpose of the link, they must also have appropriate alt text.\n\nExamples:\n- **Example 2**  Using thealtattribute for theimgelement to describe the purpose of a graphical link.  ```html <a href=\"routes.html\"> <img src=\"topo.gif\" alt=\"Current routes at Boulders Climbing Gym\"> </a> ```\n- **Example 1**  Describing the purpose of a link in HTML in the text content of theaelement.  ```html <a href=\"routes.html\"> Current routes at Boulders Climbing Gym </a> ```\n- **Example 4**  A site allows users to provide feedback on products by clicking on the \"Feedback\" link in a product detail page. Other users are able to provide a response to any feedback. When a response to the user's feedback is available, the feedback link displays an icon, with \"response received\" as its text alternative, after the \"Feedback\" text. The site's help document describes this icon as a speech bubble containing quotation marks and includes the icon, with its text alternative, as an example. The same text alternative is used in the product detail pages (when a response is available) to help ensure that users following the documentation can identify the image correctly as documented.  ```html <a href=\"prod_123_feedback.html\"> Feedback <img src=\"response.gif\" width=\"15\" height=\"15\" alt=\"response received\"> </a> ```\n- **Example 5**  A link contains text and an icon, and the icon provides additional information about the target.  ```html <a href=\"WMFP.pdf\"> Woodend Music Festival Program <img src=\"pdficon.gif\" alt=\"PDF format\"> </a> ```\n- **Example 3**  Using an emptyaltattribute when the anchor (a) element contains text that describes the purpose of the link in addition to theimgelement. Note that the link text will appear on the page next to the image.  ```html <a href=\"routes.html\"> <img src=\"topo.gif\" alt=\"\"> Current routes at Boulders Climbing Gym </a> ```\n- **Example 6**  The \"MyCorp\" company's annual report is made available on the corporate website as aPDF, and the annual corporate budget is made available as an Excel file on the website.  ```html <ul> <li> <a href=\"2009mycorp_report.pdf\">MyCorp 2009 Annual Report (PDF)</a> </li> <li> <a href=\"2009mycorp_budget.xls\">MyCorp 2009 Annual Budget (Excel)</a> </li> </ul> ```    ---",
    "referenced_by": [
      "1.1.1",
      "2.4.4",
      "2.4.9"
    ]
  },
  {
    "id": "H36",
    "type": "technique",
    "code": "H36",
    "text": "[H36] Using alt attributes on images used as submit buttons\n\nDescription:\nFor input elements of type **image**, the **alt** attribute of the **input** element is used to provide a functional label. This label indicates the button's function, but does not attempt to describe the image. The label is especially important if there are multiple submit buttons on the page that each lead to different results.\n\nExamples:\n- **Example 1: Aninputelement with analtattribute**  ```html <form action=\"/find\" method=\"post\" role=\"search\"> <label for=\"look-up\">Find books<label> <input id=\"look-up\" type=\"text\"> <input alt=\"Search\" src=\"button.gif\" type=\"image\"> </form> ```    ---",
    "referenced_by": [
      "1.1.1"
    ]
  },
  {
    "id": "H44",
    "type": "technique",
    "code": "H44",
    "text": "[H44] Using label elements to associate text labels with form controls\n\nDescription:\nThe objective of this technique is to use the **label** element to explicitly associate a form control with a label. A **label** is attached to a specific form control through the use of the **for** attribute. The value of the **for** attribute must be the same as the value of the **id** attribute of the form control.\n\nThe **id** attribute may have the same value as the **name** attribute, but both must be provided, and the **id** must be unique in the web page.\n\nThis technique is sufficient for Success Criteria [1.1.1 (Non-Text Content)](https://www.w3.org/WAI/WCAG22/Understanding/non-text-content.html), [1.3.1 (Info and Relationships)](https://www.w3.org/WAI/WCAG22/Understanding/info-and-relationships.html) and [4.1.2 (Name, Role, Value)](https://www.w3.org/WAI/WCAG22/Understanding/name-role-value.html) whether or not the **label** element is visible. That is, it may be hidden using CSS. However, for Success Criterion [3.3.2 (Labels or Instructions)](https://www.w3.org/WAI/WCAG22/Understanding/labels-or-instructions.html), the **label** element must be visible since it provides assistance to all users who need help understanding the purpose of the field.\n\nAn additional benefit of this technique is a larger clickable area for the control, since clicking on the label or the control will activate the control. This can be helpful for users with impaired motor control.\n\nNote that the **label** is positioned after **input** elements of **type=\"checkbox\"** and **type=\"radio\"**.\n\nExamples:\n- **Example 1: A text input field**  The text field in this example has the explicit label of \"First name:\". Thelabelelement'sforattribute matches theidattribute of theinputelement.  ```html <label for=\"firstname\">First name:</label> <input id=\"firstname\" name=\"firstname\" type=\"text\"> ```\n- **Example 2: A checkbox**  ```html <input checked id=\"markuplang\" name=\"computerskills\" type=\"checkbox\"> <label for=\"markuplang\">HTML</label> ```\n- **Example 3: A group of radio buttons**  A small, related group of radio buttons with a clear description and labels for each individual element.  ```html <h1>Doughnut Selection</h1> <form action=\"/buy-doughnuts\" method=\"post\"> <fieldset> <legend>Pick the doughnut you would like</legend> <input id=\"dn-choc\" name=\"flavor\" type=\"radio\" value=\"chocolate\"> <label for=\"dn-choc\">Chocolate</label> <input id=\"dn-cream\" name=\"flavor\" type=\"radio\" value=\"cream\"> <label for=\"dn-cream\">Cream Filled</label> <input id=\"dn-raspberry\" name=\"flavor\" type=\"radio\" value=\"raspberry\"> <label for=\"dn-raspberry\">Raspberry Filled</label> </fieldset> <input type=\"submit\" value=\"Purchase Your Doughnut\"> </form> ```    ---",
    "referenced_by": [
      "1.1.1",
      "1.3.1",
      "3.3.2",
      "4.1.2"
    ]
  },
  {
    "id": "H65",
    "type": "technique",
    "code": "H65",
    "text": "[H65] Using the title attribute to identify form controls when the label element cannot be used\n\nDescription:\nThe objective of this technique is to use the **title** attribute to provide an accessible name for form controls when the visual design does not include text on the screen that can be associated with the control as a label. User agents, including assistive technology, can speak the **title** attribute.\n\nExamples:\n- **Example 4: A data table of form controls**  A data table of form controls needs to associate each control with the column and row headers for that cell. Without a title (or off-screen label) it is difficult for non-visual users to pause and interrogate for corresponding row or column header values using their assistive technology while tabbing through the form.  For example, a survey form has four column headers in first row: Question, Agree, Undecided, Disagree. Each following row contains a question and a radio button in each cell corresponding to answer choice in the three columns. The title attribute for every radio button contains the information necessary to identify the control.    ---\n- **Example 2: Input fields for a phone number**  A web page contains controls for entering a phone number in the United States, with three fields for area code, exchange, and last four digits.  ```html <fieldset> <legend>Phone number</legend> <input id=\"area-code\" name=\"area-code\" title=\"Area Code\" type=\"text\" size=\"3\" value=\"\"> <input id=\"exchange\" name=\"exchange\" title=\"First three digits of phone number\" type=\"text\" size=\"3\" value=\"\"> <input id=\"last-digits\" name=\"last-digits\" title=\"Last four digits of phone number\" type=\"text\" size=\"4\" value=\"\"> </fieldset> ```\n- **Example 1: A pulldown menu that limits the scope of a search**  A search form uses a pulldown menu to limit the scope of the search. The pulldown menu is immediately adjacent to the text field used to enter the search term. The relationship between the search field and the pulldown menu is clear to users who can see the visual design, which does not have room for a separate visible label. Thetitleattribute is used to identify theselectmenu. Thetitleattribute can be spoken by screen readers or displayed as a tool tip for people using screen magnifiers. There must be visual information on the page which allows sighted users to understand the purpose of the form controls and user agents.  ```html <label for=\"search-term\">Search for:</label> <input id=\"search-term\" name=\"search-term\" type=\"text\" value=\"\"> <select title=\"Search in\" id=\"scope\"> ... </select> ```\n- **Example 3: A Search Function**  A web page contains a text field where the user can enter search terms and a button labeled \"Search\" for performing the search. Thetitleattribute is used to identify the form control and the button is positioned right after the text field so that it is clear to the user that the text field is where the search term should be entered.  ```html <input type=\"text\" title=\"Type search term here\"> <input type=\"submit\" value=\"Search\"> ```",
    "referenced_by": [
      "1.1.1",
      "1.3.1",
      "4.1.2"
    ]
  },
  {
    "id": "G68",
    "type": "technique",
    "code": "G68",
    "text": "[G68] Providing a short text alternative that describes the purpose of live audio-only and live video-only content\n\nDescription:\nThis technique provides a short text alternative for Live audio-only and live video-only content. This text may be used in combination with a full text alternative for time-based media (for audio or video), or in combination with audio description (for video).\nThose alternatives, however, are not part of this technique. The purpose of\nthis technique is to ensure that the user can determine what the non-text\ncontent is, even if they cannot access it. NOTE: Even if full alternatives\nare also available, it is important that users be able to identify the\nnon-text content when they encounter it so that they are not confused, and\nso that they can associate it with the full alternative when they encounter\nit.\n\nExamples:\n- **Example 1**    ---",
    "referenced_by": [
      "1.1.1"
    ]
  },
  {
    "id": "G100",
    "type": "technique",
    "code": "G100",
    "text": "[G100] Providing a short text alternative which is the accepted name or a descriptive name of the non-text content\n\nDescription:\nThe objective of this technique is to allow users to identify the non-text\ncontent even if the non-text content is intended to provide a specific\nsensory experience. For example, a deaf person may want to know what an\naudio instrumental file is - even if they cannot hear it. Similarly, a blind\nperson may want to know what the subject of a visual image is - even if they\ncannot see it.\n\nExamples:\n- **Example 1**    ---",
    "referenced_by": [
      "1.1.1"
    ]
  },
  {
    "id": "G143",
    "type": "technique",
    "code": "G143",
    "text": "[G143] Providing a text alternative that describes the purpose of the CAPTCHA\n\nDescription:\nThe purpose of this technique is to provide information via the text alternative that identifies the non-text content as a\nCAPTCHA. Such tests often involve asking the user to type in text that is presented in an obscured image or audio file. From the text alternative, the user can tell that the CAPTCHA requires completing a task and what type of task it is.\n\nWhen an alternate version of a CAPTCHA is available, the text alternative should include instructions about how to find the alternate version.\n\nExamples:\n- **Example 1:** A CAPTCHA test asks the user to type in text that is displayed in an obscured image. The text alternative is \"Type the word in the image\".\n- **Example 2:** A CAPTCHA test asks the user to type in text that is played in an audio file. The text alternative is \"Type the letters spoken in the audio\".  ---",
    "referenced_by": [
      "1.1.1"
    ]
  },
  {
    "id": "G144",
    "type": "technique",
    "code": "G144",
    "text": "[G144] Ensuring that the Web Page contains another CAPTCHA serving the same purpose using a different modality\n\nDescription:\nThe purpose of this technique is to reduce occasions in which a user with a disability cannot complete a CAPTCHA task. Because there are alternate CAPTCHA tasks that use different modalities, a user is more likely to be able to complete one of the tasks successfully.\n\nExamples:\n- **Example 1:** A web page that includes a CAPTCHA test that must be completed successfully before the user can advance to the next step in a process. The page includes both a visual task, such as typing words displayed in a image, and an audio task, such as typing letters spoken in an audio file. A user with hearing disabilities who cannot pass the audio CAPTCHA may be able to pass the visual CAPTCHA.\n- **Example 2:** A blog comment form includes a visual CAPTCHA that must be completed before a user can submit comments. In addition to the visual CAPTCHA, it includes a CAPTCHA with a form field that asks, \"What is two plus seven?\" with a text entry field that allows users to enter the correct answer.  ---",
    "referenced_by": []
  },
  {
    "id": "C9",
    "type": "technique",
    "code": "C9",
    "text": "[C9] Using CSS to include decorative images\n\nDescription:\nThe objective of this technique is to provide a mechanism to add purely decorative images and images used for visual formatting to Web content without requiring additional markup within the content. This makes it possible for assistive technologies to ignore the non-text content. Some user agents can ignore or turn off CSS at the user's request, so that background images included with CSS simply \"disappear\" and do not interfere with display settings such as enlarged fonts or high contrast settings.\n\nBackground images can be included with the following CSS properties:\n\n- background;\n- background-image;\n- content, combined with the::beforeand::afterpseudo-elements;\n- list-style-image.\n\nExamples:\n- **Example 1: Background image for anHTMLpage**  The stylesheet for a web page specifies a background image for the whole page.  ```html <style> body { background: #ffe url('/images/home-bg.jpg') repeat; } </style> ```\n- **Example 2: Background image with CSS for image rollovers**  The stylesheet for a web page uses the CSS background property to create a decorative rollover effects when a user hovers their mouse pointer over a link.  ```html a:hover { background: #ffe url('/images/hover.gif') repeat; color: #000; text-decoration: none; } ```    ---",
    "referenced_by": [
      "1.1.1"
    ]
  },
  {
    "id": "H67",
    "type": "technique",
    "code": "H67",
    "text": "[H67] Using null alt text and no title attribute on img elements for images that AT should ignore\n\nDescription:\nThe purpose of this technique is to show how images can be marked so that they can be ignored by assistive technology.\n\nIf no **title** attribute is used, and the **alt** text is set to null (i.e., **alt=\"\"**) it indicates to assistive technology that the image can be safely ignored.\n\nExamples:\n- **Example 1: Inserting a decorative image on a web page**  ```html <img alt=\"\" src=\"squiggle.gif\" height=\"20\" width=\"20\"> ```    ---",
    "referenced_by": [
      "1.1.1"
    ]
  },
  {
    "id": "PDF4",
    "type": "technique",
    "code": "PDF4",
    "text": "[PDF4] Hiding decorative images with the Artifact tag in PDF documents\n\nDescription:\nThe purpose of this technique is to show how purely decorative images in PDF documents can be marked so that they can be ignored by Assistive Technology by using the **/Artifact** tag. This is typically accomplished by using a tool for authoring PDF.\n\nIn PDF, artifacts are generally graphics objects or other markings that are not part of the authored content. Examples of artifacts include page header or footer information, lines or other graphics separating sections of the page, or decorative images.\n\nExamples:\n- **Example 1: Marking an image as an artifact using Acrobat Pro's TouchUp Reading Order Tool**  This example is shown with Adobe Acrobat Pro. There are other software tools that perform similar functions.  The TouchUp Reading Order Tool can be used to mark an image as \"Background / Artifact\", which removes it from the document tag structure.  This example is shown in operation in theworking example of creating a decorative image (Word file)andworking example of marking a background image as an artifact (PDF file).\n- **Example 2: Marking an image as an artifact in a PDF document using an /Artifact tag or property list**  The PDF specification allows images to be marked as \"artifacts\". An artifact is explicitly distinguished from real content by enclosing it in a marked-content sequence with the/Artifacttag.  ```html BMC  ...  EMC ```  ```html BDC  ...  EMC ```    ---",
    "referenced_by": [
      "1.1.1"
    ]
  },
  {
    "id": "C18",
    "type": "technique",
    "code": "C18",
    "text": "[C18] Using CSS margin and padding rules instead of spacer images for layout design\n\nDescription:\nWeb designers sometimes use spacer images (usually 1x1 pixel, transparent GIFs) for better control over layout, for example in tables or to indent a paragraph. However, Cascading Style Sheets (CSS) allow sufficient control over layout to replace spacer images. The CSS properties for margins and padding can be used on their own or in combination to control the layout. The margin properties ('**margin-top**', '**margin-right**', '**margin-bottom**', '**margin-left**', and the shorthand '**margin**') can be used on any element that is displayed as a block; they add space at the outside of an element. The padding properties ('**padding-top**', '**padding-right**', '**padding-bottom**', '**padding-left**', and the shorthand '**padding**') can be used on any element; they add space inside the element.\n\nExamples:\n- **Example 1**  The following example consists of two parts: the CSS code, which specifies a margin on all sides of the table, and padding for the table cells; and theHTMLcode for the table, which does not contain spacer images and is not nested inside another table.  ```html table { margin: .5em; border-collapse: collapse; } td, th { padding: .4em; border: 1px solid #000; } ```  ```html <table> <caption>Books in the category 'Web development'</caption> <thead> <tr> <th>Title</th> <th>Author</th> <th>Date</th> </tr> </thead> <tbody> <tr> <td>How to Think Straight About Web Standards</td> <td>Andrew Stanovich</td> <td>1 April 2007</td> </tr> </tbody> </table> ```    ---",
    "referenced_by": [
      "1.1.1"
    ]
  },
  {
    "id": "F3",
    "type": "technique",
    "code": "F3",
    "text": "[F3] Failure of Success Criterion 1.1.1 due to using CSS to include images that convey important information\n\nDescription:\nThe CSS background-image property provides a way to include images in the\ndocument with CSS without any reference in the HTML code. The CSS\nbackground-image property was designed for decorative purposes and it is not\npossible to associate text alternatives with images that are included via\nCSS. Text alternatives are necessary for people who cannot see images that\nconvey important information. Therefore, it is a failure to use this\nproperty to add images to convey important information. This failure would apply equally in a case where the background image was declared in the HTML style attribute, as well as in a case where the background image declaration was created dynamically in a client script (see example 3 below).\n\nExamples:\n- **Example 1**  In the following example, part of the content is contained in an image that is presented by CSS alone. In this example, the image TopRate.png is a 180 by 200 pixel image that contains the text, \"19.3% APR Typical Variable.\"  It is used in this excerpt:  ```html p#bestinterest { padding-left: 200px; background: transparent url(/images/TopRate.png) no-repeat top left; } ```  ```html <p id=\"bestinterest\">Where else would you find a better interest rate?</p> ```\n- **Example 2**  A book distributor uses background images to provide icons against a list of book titles to indicate whether they are new, limited, in-stock, or out of stock.  The CSS contains:  It is used in this excerpt:  ```html ul#booklist li { padding-left: 20px; }  ul#booklist li.new { background: transparent url(new.png) no-repeat top left; }  ul#booklist li.limited { background: transparent url(limited.png) no-repeat top left; }  ul#booklist li.instock { background: transparent url(instock.png) no-repeat top left; }  ul#booklist li.outstock { background: transparent url(outstock.png) no-repeat top left; } ```  ```html <ul id=\"booklist\"> <li class=\"new\">Some book</li> <li class=\"instock\">Some other book</li> <li class=\"limited\">A book we desperately want to get rid of</li> ... <li class=\"outstock\">A book you actually want </li> </ul> ```\n- **Example 3**  Using the code from example 1, the same background image is declared in the HTML style attribute:  In the following code, the background image declaration is created in a client script:  ```html <p id=\"bestinterest\" style=\"background: transparent url(/images/TopRate.png) no-repeat top left;\"> Where else would you find a better interest rate?<p> ```  ```html <script> var newP = document.createElement('p'); var newPText = document.createTextNode('Where else would you find a better interest rate?'); newP.appendChild(newPText); newP.style.background = 'transparent url(/images/TopRate.png) no-repeat top left'; document.body.appendChild(newP); </script> ```    ---",
    "referenced_by": [
      "1.1.1"
    ]
  },
  {
    "id": "F13",
    "type": "technique",
    "code": "F13",
    "text": "[F13] Failure of Success Criterion 1.1.1 and 1.4.1 due to having a text alternative that does not include information that is conveyed by color differences in the image\n\nDescription:\nThe objective of this technique is to describe the failure that occurs when\nan image uses color differences to convey information, but the text alternative for the\nimage does not convey that information. This can cause problems for people\nwho are blind or colorblind because they will not be able to perceive the\ninformation conveyed by the color differences.\n\nExamples:\n- **Example 1:** A bar chart of sales data is provided as an image. The chart includes yearly sales figures for four employees in the Sales Department. The text alternative for the image says, \"The following bar chart displays the yearly sales figures for the Sales Department. Mary sold 3.1 Million; Fred, 2.6 Million; Bob, 2.2 Million; and Andrew, 3.4 Million. The red bars indicate sales that were below the yearly quota\". This text alternative fails to provide the information which is conveyed by the color red in the image. The alternative should indicate which people did not meet the sales quota rather than relying on color.  ---",
    "referenced_by": [
      "1.1.1",
      "1.4.1"
    ]
  },
  {
    "id": "F20",
    "type": "technique",
    "code": "F20",
    "text": "[F20] Failure of Success Criterion 1.1.1 and 4.1.2 due to not updating text alternatives when changes to non-text content occur\n\nDescription:\nThe objective of this failure condition is to address situations where the\nnon-text content is updated, but the text alternative is not updated at the\nsame time. If the text in the text alternative cannot still be used in\nplace of the non-text content without losing information or function, then\nit fails because it is no longer a text alternative for the non-text\ncontent.\n\nExamples:\n- **Example 1:** Failure Example 1:A Sales chart is updated to October results, but the text alternative still describes September results.\n- **Example 2:** Failure Example 2:Pictures on a home page change daily, but text alternatives are not updated at the same time.\n- **Example 3:** Failure Example 3:The source attribute of images on a page is updated periodically using script, but the text alternatives are not updated at the same time.  ---",
    "referenced_by": [
      "1.1.1",
      "4.1.2"
    ]
  },
  {
    "id": "F30",
    "type": "technique",
    "code": "F30",
    "text": "[F30] Failure of Success Criterion 1.1.1 and 1.2.1 due to using text alternatives that are not alternatives (e.g., filenames or placeholder text)\n\nDescription:\nThis describes a failure condition for all techniques involving text\nalternatives. If the text in the \"text alternative\" cannot be used in place\nof the non-text content without losing information or function then it fails\nbecause it is not, in fact, an alternative to the non-text content.\n\nExamples:\n- **Example 1**  Examples of text that are not text alternatives include:    ---",
    "referenced_by": [
      "1.1.1",
      "1.2.1"
    ]
  },
  {
    "id": "F38",
    "type": "technique",
    "code": "F38",
    "text": "[F38] Failure of Success Criterion 1.1.1 due to not marking up decorative images in HTML in a way that allows assistive technology to ignore them\n\nDescription:\nThis describes a failure condition for text alternatives for images that\nshould be ignored by AT. If there is no alt attribute at all assistive\ntechnologies are not able to ignore the non-text content. The alt attribute\nmust be provided and have a null value (i.e., alt=\"\" ) to avoid a failure of this Success Criterion.\n\nThis describes a failure condition for text alternatives for images that should be ignored by assistive technology (AT). If an image has the attribute role=\"presentation\", it will be ignored by AT. However, if it does not have role=\"presentation\", and if there is no **alt** attribute at all assistive technologies are not able to ignore the image. For decorative images which need to be ignored by AT, either role=\"presentation\" must be used or the alt attribute must be provided and have a null value (i.e., alt=\"\") to avoid a failure of this Success Criterion.\n\nExamples:\n- **Example 1:** Decorative images that have noaltattribute and noroleattribute  ---",
    "referenced_by": [
      "1.1.1"
    ]
  },
  {
    "id": "F39",
    "type": "technique",
    "code": "F39",
    "text": "[F39] Failure of Success Criterion 1.1.1 due to providing a text alternative that is not null (e.g., alt=\"spacer\" or alt=\"image\") for images that should be ignored by assistive technology\n\nDescription:\nThis technique describes a failure condition for images that should\nbe ignored by assistive technologies. A text alternative for an image\nshould convey the meaning of the image. When an image is used for decoration,\nspacing or other purpose that is not part of the meaningful content\nin the page then the image has no meaning and should be ignored by\nassistive technologies.\n\nProviding a null text alternative (i.e., alt=\"\" )\nwill allow assistive technology to ignore the image and avoid a failure\nof this Success Criterion.\n\nExamples:\n- **Example 1: Decorative images that have noaltattribute**  An image is used to create a blank space between content, where the spacing itself is not meaningful to the content. The image has an alt text value of \"spacer\". This image fails the Success Criterion because the text alternative does not serve an equivalent purpose. The image is meant to be ignored but its alternative text \"spacer\" is announced by screen readers and displayed in some alternate color schemes.  ```html <div> Tree type: <img src=\"spacer.gif\" width=\"100\" height=\"1\" alt=\"spacer\"> Cedrus deodara </div> ```    ---",
    "referenced_by": [
      "1.1.1"
    ]
  },
  {
    "id": "F65",
    "type": "technique",
    "code": "F65",
    "text": "[F65] Failure of Success Criterion 1.1.1 due to omitting the alt attribute or text alternative on img elements, area elements, and input elements of type \"image\"\n\nDescription:\nThis describes a failure condition for text alternatives on images. If there is no source of text to provide an alternative for the image then assistive technologies are not able to identify the image or to convey its purpose to the user. The **alt** attribute continues to be the preferred way to provide alternative text for images. Appropriate WAI-ARIA attributes may be used to provide alternative text, as long as they are accessibility supported.  For more information about accessibility support, see [Documenting Accessibility Support](https://www.w3.org/WAI/WCAG22/Understanding/documenting-accessibility-support). The [Accessible Name and Description Computation](https://www.w3.org/TR/accname/) described the method of deriving text alternative from the HTML and WAI-ARIA attributes of an element.\n\nSome Assistive Technologies attempt to compensate for the missing text alternatives by reading the file name of the image. But it is insufficient to rely simply on the file name for many reasons. For example, file names may not be descriptive (e.g., **images/nav01.gif**), and technology specifications do not require descriptive file names. And some Assistive Technologies do not read the file name if there is no text alternative provided via HTML attributes.\n\nExamples:\n- **Example 1: Missing text alternative**  In the code example below, the person using a screen reader would not know the purpose of the image.  ```html <img src=\"../images/animal.jpg\"> ```    ---",
    "referenced_by": [
      "1.1.1"
    ]
  },
  {
    "id": "F67",
    "type": "technique",
    "code": "F67",
    "text": "[F67] Failure of Success Criterion 1.1.1 and 1.2.1 due to providing long descriptions for non-text content that does not serve the same purpose or does not present the same information\n\nDescription:\nThe objective of this technique is to describe the failure that occurs when the long description for non-text content does not serve the same purpose or does not present the same information as the non-text content.  This can cause problems for people who cannot interpret the non-text content because they rely on the long description to provide the necessary information conveyed by the non-text content.  Without a long description that provides complete information, a person may not be able to comprehend or interact with the web page.\n\nExamples:\n- **Example 1:** An image showing the locations of venues for events at the Olympic Games displayed on a street map. The image also contains an icon for each type of sporting event held at each venue.  The long description states, \"Map showing the location of each Olympic venue.  Skating, hockey and curling are held at the Winter Park Ice Arena, Downhill skiing and jumping are held at Snow Mountain, Gymnastics is held at the JumpUp Arena, Cross Country Skiing is held at the Kilometer Forest\".  While this description provides useful information, it does not convey the same information as the image because it provides no specific location information such as the address or the distance of each location from some fixed point.  Note that long descriptions do not always need to be in prose form; sometimes the information may best be presented in a table or other alternate format.  ---",
    "referenced_by": [
      "1.1.1",
      "1.2.1"
    ]
  },
  {
    "id": "F71",
    "type": "technique",
    "code": "F71",
    "text": "[F71] Failure of Success Criterion 1.1.1 due to using text look-alikes to represent text without providing a text alternative\n\nDescription:\nThe objective of this failure condition is to avoid substituting characters whose glyphs look similar to the intended character, for that intended character. The Unicode character set defines thousands of characters, covering dozens of writing systems. While the glyphs for some of these characters may look like the glyphs for other characters in visual presentation, they are not processed the same by text-to-speech tools.\n\nFor example, the characters **U+0063** and **U+03F2** both look like the letter \"c\", yet the first is from the Western alphabet and the second from the Greek alphabet and not used in Western languages. The characters **U+0033** and **U+04E0** both look like the number \"3\", yet the second is actually a letter from the Cyrillic alphabet.\n\nExamples:\n- **Example 1: Characters**  The following word looks, in browsers with appropriate font support, like the English word \"cook\", yet is composed of the stringU+03f2 U+043E U+03BF U+006B, only one of which is a letter from the Western alphabet. This word will not be processed meaningfully, and a text alternative is not provided.  ```html ϲоοk ```\n- **Example 2: Character entities**  The following example, like its predecessor, will look like the English word \"cook\" when rendered in browsers with appropriate font support. In this case, the characters are implemented with character entities, but the word will still not be processed meaningfully, and a text alternative is not provided.  Working Example: \"ϲоοk\"  ```html &#x03F2;&#x043E;&#x03BF;&#x006B; ```    ---",
    "referenced_by": [
      "1.1.1"
    ]
  },
  {
    "id": "F72",
    "type": "technique",
    "code": "F72",
    "text": "[F72] Failure of Success Criterion 1.1.1 due to using ASCII art without providing a text alternative\n\nDescription:\nThe objective of this failure condition is to avoid the use of [ASCII art](https://www.w3.org/TR/WCAG22/#dfn-ascii-art) when a text alternative is not provided. Although ASCII art is implemented as a character string, its meaning comes from the pattern of glyphs formed by a visual presentation of that string, not from the text itself. Therefore ASCII art is non-text content and requires a text alternative. Text alternatives, or links to them, should be placed near the ASCII art in order to be associated with it.\n\nExamples:\n- **Example 1:  ASCII Art chart without a text alternative**  The following ASCII art chart lacks a text alternative and therefore does not meet Success Criterion 1.1.1. Note this failure example does in fact cause this page to fail, but you mayskip over the example.  ```html %   __ __ __ __ __ __ __ __ __ __ __ __ __ __ 100 |             *                             | 90 |                *  *                       | 80 |          *           *                    | 70 |             @           *                 | 60 |          @                 *              | 50 |       *        @              *           | 40 |                   @              *        | 30 |    *  @              @  @           *     | 20 |                                           | 10 |    @                       @  @  @  @     | 0  5 10 15 20 25 30 35 40 45 50 55 60 65 70 Flash frequency (Hz) ```    ---",
    "referenced_by": [
      "1.1.1"
    ]
  },
  {
    "id": "G158",
    "type": "technique",
    "code": "G158",
    "text": "[G158] Providing an alternative for time-based media for audio-only content\n\nDescription:\nThe purpose of this technique is to provide an accessible alternative way of presenting the information in an audio-only presentation.\n\nIn an audio-only presentation, information is presented in a variety of ways including dialogue and sounds (both natural and artificial). In order to present the same information in accessible form, this technique involves creating a document that tells the same story and presents the same information in the same [human language](https://www.w3.org/TR/WCAG22/#dfn-human-language-s) as the prerecorded audio-only content. In this technique, the document serves as long description for the content and includes all of the important dialogue and as well as descriptions of background sounds etc. that are part of the story.\n\nIf an actual script was used to create the audio-only content in the first place, this can be a good place to start. In production and editing however, the content often varies somewhat from the script. For this technique, the original script would be corrected to match the dialogue and what actually happens in the final edited form of the audio presentation.\n\nExamples:\n- **Example 1:** A podcast includes a description of new features in a recent software release. It involves two speakers informally discussing the new and updated features and describing how they are used. One of the speakers works from a list of questions that was used to outline the discussion prior to recording. After the recording is complete, the outline is then edited and supplemented to match the dialogue etc. The resulting transcript is then made available on the speakers website along with the audio-only file. The text alternative that identifies the audio only content reads, \"Episode 42: Zap Version 12 (text transcript follows)\" and the link to the transcript is provided immediately following the audio-only content.  ---",
    "referenced_by": [
      "1.2.1"
    ]
  },
  {
    "id": "G159",
    "type": "technique",
    "code": "G159",
    "text": "[G159] Providing an alternative for time-based media for video-only content\n\nDescription:\nThe purpose of this technique is to provide an accessible alternative way of presenting the information in a video-only presentation.\n\nIn a video-only presentation, information is presented in a variety of ways including animation, text or graphics, the setting and background, the actions and expressions of people, animals, etc. In order to present the same information in accessible form, this technique involves creating a document that tells the same story and presents the same information as the prerecorded video-only content. In this technique, the document serves as a long description for the content and includes all of the important information as well as descriptions of scenery, actions, expressions, etc. that are part of the presentation, in the same [human language](https://www.w3.org/TR/WCAG22/#dfn-human-language-s) as the video or page.\n\nIf a screenplay for the video-only content was used to create the content in the first place, this can be a good place to start. In production and editing however, the final version often varies somewhat from the screenplay. To use the screenplay, it would need to be corrected to match the final edited form of the video-only presentation.\n\nExamples:\n- **Example 1:** An animation shows how to assemble a woodworking project. There is no audio, but the animation includes a series of numbers to represent each step in the process as well as arrows and picture-in-picture highlights illustrating how the assembly is completed. It also includes short outtake animations illustrating what will happen if assembly is done incorrectly. A text alternative that identifies the video-only content reads, \"Breadbox assembly video (text description follows),\" and the text description of the video includes a full text description of each step in the video.  ---",
    "referenced_by": [
      "1.2.1",
      "1.2.8"
    ]
  },
  {
    "id": "G166",
    "type": "technique",
    "code": "G166",
    "text": "[G166] Providing audio that describes the important video content and describing it as such\n\nDescription:\nVideo-only content is inaccessible to people who are blind and to some who have low vision. Therefore, it is important for them to have an audio alternative. One way of doing this is to provide an audio track describing the information in the video in the [human language](https://www.w3.org/TR/WCAG22/#dfn-human-language-s) of the page. The audio should be a common audio format used on the internet, such as MP3.\n\nExamples:\n- **Example 1**  A web page has a link to a video-only presentation of a spaceship landing on Mars. The link to the video is a picture of a spaceship. Near the video is a link to an audio file of a person describing the video. This would look something like the following code example in HTML.  ```html <a href=\"../video/marslanding.mp4\"> <img src=\"../images/spaceship.jpg\" alt=\"Mars landing, video-only\" width=\"193\" height=\"255\"/> </a> <p><a href=\"mars-landing-audio.mp3\">Audio description of \"Mars Landing\"</a></p> ```    ---",
    "referenced_by": [
      "1.2.1"
    ]
  },
  {
    "id": "H96",
    "type": "technique",
    "code": "H96",
    "text": "[H96] Using the track element to provide audio descriptions\n\nDescription:\nThe objective of this technique is to use the HTML **track** element to specify a descriptions timed text track for a **video** element. Audio description timed text tracks contain textual descriptions of the video component of the media resource, intended for audio synthesis when the visual component is obscured, unavailable, or not usable. The user agent makes the cues available to the user in a non-visual fashion, for instance, by synthesizing them into speech.\n\nThe **src** attribute of the **track** element is an URL providing the text track data.\n\nThe audio description cues must fit into the gaps available in the audio component of the media resource. If there is not enough time to synthesize the description text in the track cue's time interval, user agents may truncate the speech. This limits the amount of supplementary information that can be added.\n\nUser agents may also support extended audio descriptions by halting the video until the description has been completely synthesized, then restarting the video.\n\nExamples:\n- **Example 2: Audio description in multiple languages**  Avideoelement for a video with both an English and French language source element, and with an English and a French audio description track using the WebVTT file format.  ```html <video poster=\"myvideo.png\" controls> <source src=\"myvideo.mp4\" srclang=\"en\" type=\"video/mp4\"> <source src=\"myvideo.webm\" srclang=\"fr\" type=\"video/webm\"> <track kind=\"descriptions\" label=\"English\" src=\"myvideo-en.vtt\" srclang=\"en\"> <track kind=\"descriptions\" label=\"Français\" src=\"myvideo-fr.vtt\" srclang=\"fr\"> </video> ```    ---\n- **Example 1: Audio description in one language**  Avideoelement for a video in the English language. The audio descriptions are provided in the WebVTT format.  ```html <video poster=\"myvideo.png\" controls> <source src=\"myvideo.mp4\" srclang=\"en\" type=\"video/mp4\"> <track kind=\"descriptions\" label=\"English\" src=\"myvideo-en.vtt\" srclang=\"en\"> </video> ```",
    "referenced_by": [
      "1.2.1",
      "1.2.3",
      "1.2.5",
      "1.2.7"
    ]
  },
  {
    "id": "G93",
    "type": "technique",
    "code": "G93",
    "text": "[G93] Providing open (always visible) captions\n\nDescription:\nThe objective of this technique is to provide a way for people who are deaf or otherwise have trouble hearing the dialogue in audio visual material to be able to view the material in the same [human language](https://www.w3.org/TR/WCAG22/#dfn-human-language-s).  With this technique all of the dialogue and important sounds are embedded as text in the video track.  As a result they are always visible and no special support for captioning is required by the user agent.\n\nNOTE: Captions should not be confused with subtitles. Subtitles provide text of only the dialogue, in a different [human language](https://www.w3.org/TR/WCAG22/#dfn-human-language-s), and do not include important sounds.\n\nExamples:\n- **Example 2:** A news organization provides open captions on all of its material.  ---\n- **Example 1:** In order to ensure that everyone can view their online movies, even if users do not know how to turn on captions in their media player, a library association puts the captions directly into the video.",
    "referenced_by": [
      "1.2.2"
    ]
  },
  {
    "id": "G87",
    "type": "technique",
    "code": "G87",
    "text": "[G87] Providing closed captions\n\nDescription:\nThe objective of this technique is to provide a way for people who have\nhearing impairments or otherwise have trouble hearing the dialogue in\nsynchronized media material to be able to view the material and see the dialogue and\nsounds - without requiring people who are not deaf to watch the captions.\nWith this technique all of the dialogue and important sounds are embedded as\ntext in the same [human language](https://www.w3.org/TR/WCAG22/#dfn-human-language-s) as the video, in a fashion that causes the text not to be visible unless the user\nrequests it. As a result they are visible only when needed. This requires\nspecial support for captioning in the user agent.\n\nNOTE: Captions should not be confused with subtitles. Subtitles provide text\nof only the dialogue, in a different [human language](https://www.w3.org/TR/WCAG22/#dfn-human-language-s), and do not include important sounds.\n\nExamples:\n- **Example 2**  The online movies at a media outlet all include captions and are provided in a format that allows embedding of closed captions.\n- **Example 4**  A video of a local news event has captions provided that can be played over the video or in a separate window depending on the player used.    ---\n- **Example 1**  In order to ensure that users who are deaf can use their interactive educational materials, the college provides captions and instructions for turning on captions for all of their audio interactive educational programs.\n- **Example 3**  Special caption files including synchronization information are provided for an existing movie. Players are available that can play the captions in a separate window on screen, synchronized with the movie window.",
    "referenced_by": [
      "1.2.2"
    ]
  },
  {
    "id": "SM11",
    "type": "technique",
    "code": "SM11",
    "text": "[SM11] Providing captions through synchronized text streams in SMIL 1.0\n\nDescription:\nThe objective of this technique is to provide a way for people who are deaf or otherwise have trouble hearing the dialogue in audio visual material to be able to view the material. With this technique all of the dialogue and important sounds are available in a text stream that is displayed in a caption area.\n\nWith SMIL 1.0, separate regions can be defined for the video and the captions. The captions and video playback are synchronized, with the caption text displayed in one region of the screen, while the corresponding video is displayed in another region.\n\nExamples:\n- **Example 2: SMIL 1.0 caption sample with internal text streams**  This example shows atextelement that includes synchronized text streams within the SMIL file.  ```html <?xml version=\"1.0\" encoding=\"UTF-8\"?> <smil xmlns=\"https://www.w3.org/TR/REC-smil\"> <head> <layout> <root-layout background-color=\"black\" height=\"310\" width=\"330\"/> <region id=\"video\" background-color=\"black\" top=\"5\" left=\"5\" height=\"240\" width=\"320\"/> <region id=\"captions\" background-color=\"black\" top=\"250\" height=\"60\" left=\"5\" width=\"320\"/> </layout> </head> <body> <par> <video src=\"salesdemo.mpg\" region=\"video\" title=\"Sales Demo\" alt=\"Sales Demo\"/> <text src=\"data:,This%20is%20inline%20text.\" region=\"captions\" begin=\"0s\" dur=\"3\" alt=\"Sales Demo Captions\"> <param name=\"charset\" value=\"iso-8859-1\"/> <param name=\"fontFace\" value=\"System\"/> <param name=\"fontColor\" value=\"yellow\"/> <param name=\"backgroundColor\" value=\"blue\"/> </text> </par> </body> </smil> ```    ---\n- **Example 1: SMIL 1.0 caption sample for QuickTime player**  ```html <?xml version=\"1.0\" encoding=\"UTF-8\"?> <smil xmlns:qt=\"http://www.apple.com/quicktime/resources/smilextensions\" xmlns=\"https://www.w3.org/TR/REC-smil\" qt:time-slider=\"true\"> <head> <layout> <root-layout width=\"320\" height=\"300\" background-color=\"black\"/> <region top=\"0\" width=\"320\" height=\"240\" left=\"0\" background-color=\"black\" id=\"videoregion\"/> <region top=\"240\" width=\"320\" height=\"60\" left=\"0\" background-color=\"black\" id=\"textregion\"/> </layout> </head> <body> <par> <video dur=\"0:01:20.00\" region=\"videoregion\" src=\"salesdemo.mov\" alt=\"Sales Demo\"/> <textstream dur=\"0:01:20.00\" region=\"textregion\" src=\"salesdemo_cc.txt\" alt=\"Sales Demo Captions\"/> </par> </body> </smil> ```",
    "referenced_by": [
      "1.2.2",
      "1.2.4"
    ]
  },
  {
    "id": "SM12",
    "type": "technique",
    "code": "SM12",
    "text": "[SM12] Providing captions through synchronized text streams in SMIL 2.0\n\nDescription:\nThe objective of this technique is to provide a way for people who are deaf or otherwise have trouble hearing the dialogue in audio visual material to be able to view the material. With this technique all of the dialogue and important sounds are available in a text stream that is displayed in a caption area.\n\nWith SMIL 2.0, separate regions can be defined for the video and the captions. The captions and video playback are synchronized, with the caption text displayed in one region of the screen, and the corresponding video displayed in another region.\n\nExamples:\n- **Example 1: SMIL 2.0 caption sample with internal text streams for RealMedia player**  This example shows atextelement that includes synchronized text streams within the SMIL file.  ```html <?xml version=\"1.0\" encoding=\"UTF-8\"?> <smil xmlns=\"https://www.w3.org/2001/SMIL20/Language\"> <head> <layout> <root-layout backgroundColor=\"black\" height=\"310\" width=\"330\"/> <region id=\"video\" backgroundColor=\"black\" top=\"5\" left=\"5\" height=\"240\" width=\"320\"/> <region id=\"captions\" backgroundColor=\"black\" top=\"250\" height=\"60\" left=\"5\" width=\"320\"/> </layout> </head> <body> <par> <video src=\"salesdemo.mpg\" region=\"video\" title=\"Sales Demo\" alt=\"Sales Demo\"/> <text src=\"data:,This%20is%20inline%20text.\" region=\"captions\" begin=\"0s\" dur=\"3\"> <param name=\"charset\" value=\"iso-8859-1\"/> <param name=\"fontFace\" value=\"System\"/> <param name=\"fontColor\" value=\"yellow\"/> <param name=\"backgroundColor\" value=\"blue\"/> </text> <text src=\"data:,This%20is%20a%20second%20text.\" region=\"captions\" begin=\"3s\" dur=\"3\"> <param name=\"charset\" value=\"iso-8859-1\"/> <param name=\"fontFace\" value=\"System\"/> <param name=\"fontColor\" value=\"yellow\"/> <param name=\"backgroundColor\" value=\"blue\"/> </text> </par> </body> </smil> ```    ---",
    "referenced_by": [
      "1.2.2",
      "1.2.4"
    ]
  },
  {
    "id": "H95",
    "type": "technique",
    "code": "H95",
    "text": "[H95] Using the track element to provide captions\n\nDescription:\nThe objective of this technique is to use the HTML **track** element to specify a captions timed text track for a video element. Caption timed text tracks contain transcription or translation of the dialogue, sound effects, relevant musical cues, and other relevant audio information, suitable for when sound is unavailable or not clearly audible.\n\nThe **src** attribute of the **track** element is a URL that is the address of the text track data.\n\nThe **kind** attribute of the **track** element indicates the kind of information in the timed text. captions text tracks provide a text version of dialogue and other sounds important to understanding the video. Subtitles contain only the dialogue. If other audio information is important to understanding the video, a subtitle track will not be sufficient to meet the success criterion.\n\nExamples:\n- **Example 1: Captions in one language**  Avideoelement for a video in the English language with an English caption track. The captions are provided in the WebVTT format.  ```html <video poster=\"myvideo.png\" controls> <source src=\"myvideo.mp4\" srclang=\"en\" type=\"video/mp4\"> <track kind=\"captions\" label=\"English\" src=\"myvideo_en.vtt\" srclang=\"en\"> </video> ```\n- **Example 2: Captions in multiple languages**  Avideoelement for a video in the English language with an English caption track. The captions are provided in the WebVTT format.  ```html <video poster=\"myvideo.png\" controls> <source src=\"myvideo.mp4\" srclang=\"en\" type=\"video/mp4\"> <source src=\"myvideo.webm\" srclang=\"fr\" type=\"video/webm\"> <track kind=\"captions\" label=\"English\" src=\"myvideo-en.vtt\" srclang=\"en\"> <track kind=\"captions\" label=\"Français\" src=\"myvideo-fr.ttml\" srclang=\"fr\"> </video> ```    ---",
    "referenced_by": [
      "1.2.2"
    ]
  },
  {
    "id": "F8",
    "type": "technique",
    "code": "F8",
    "text": "[F8] Failure of Success Criterion 1.2.2 due to captions omitting some dialogue or important sound effects\n\nDescription:\nThis describes a failure condition for all techniques involving captions. If\nthe \"caption\" does not include all of the dialogue (either verbatim or in\nessence) as well as all important sounds then the 'Captions' are not real\ncaptions.\n\nExamples:\n- **Example 1**  Examples of text streams that are not captions include:    ---",
    "referenced_by": [
      "1.2.2"
    ]
  },
  {
    "id": "F75",
    "type": "technique",
    "code": "F75",
    "text": "[F75] Failure of Success Criterion 1.2.2 by providing synchronized media without captions when the synchronized media presents more information than is presented on the page\n\nDescription:\nThe objective of this failure is to avoid situations in which synchronized media alternatives provide more information than the text for which they are alternatives, but do not provide their own text alternatives to provide access to the extra information. Synchronized media alternatives provide enhanced access to users for whom synchronized media is a more effective format than text. Since they are alternatives to text, they do not need themselves to have redundant text alternatives in the form of captions, audio descriptions or full text alternatives. However, if they provide more information than the text for which they are an alternative, then they are not just alternatives but are synchronized media content in their own right. In this case they are subject to the full requirements of [Success Criterion 1.2.2](https://www.w3.org/WAI/WCAG22/Understanding/captions-prerecorded) to provide captions and to [Success Criterion 1.2.3](https://www.w3.org/WAI/WCAG22/Understanding/audio-description-or-media-alternative-prerecorded), and [Success Criterion 1.2.5](https://www.w3.org/WAI/WCAG22/Understanding/audio-description-prerecorded).\n\n---",
    "referenced_by": [
      "1.2.2"
    ]
  },
  {
    "id": "F74",
    "type": "technique",
    "code": "F74",
    "text": "[F74] Failure of Success Criterion 1.2.2 and 1.2.8 due to not labeling a synchronized media alternative to text as an alternative\n\nDescription:\nThe objective of this failure is to avoid situations in which synchronized media alternatives are not labeled with the text for which they are alternatives. Synchronized media alternatives provide enhanced access to users for whom synchronized media is a more effective format than text. Since they are alternatives to text, they do not need themselves to have redundant text alternatives. However, they need to be clearly labeled with the text for which they substitute, so users can find them and so users who normally expect text alternatives to synchronized media know not to look for them.\n\nExamples:\n- **Example 1: Synchronized media alternatives provided elsewhere on page**  A page with instructions to complete a tax form provides a prose description of the fields to complete, data to provide, etc. Additionally, a synchronized media alternative provides spoken instructions, with video of a person completing the section being discussed in the audio. Although both versions are provided on the page, the synchronized media version is provided elsewhere on the page and is not clearly labeled with the part of the text for which it is a substitute. This makes it difficult for users encountering the text to find it, and users encountering the video do not know where its text alternative is.    ---",
    "referenced_by": [
      "1.2.2",
      "1.2.8"
    ]
  },
  {
    "id": "G69",
    "type": "technique",
    "code": "G69",
    "text": "[G69] Providing an alternative for time based media\n\nDescription:\nThe purpose of this technique is to provide an accessible alternative way of presenting the information in a synchronized media presentation.\n\nIn a synchronized media presentation, information is presented in a variety of ways including:\n\n- dialogue,\n- sounds (natural and artificial),\n- the setting and background,\n- the actions and expressions of people, animals, etc.,\n- text or graphics,\n- and more.\n\nIn order to present the same information in accessible form, this technique involves creating a document that tells the same story and presents the same information as the synchronized media in the same [human language](https://www.w3.org/TR/WCAG22/#dfn-human-language-s).  Such a document is sometimes called a screenplay. It includes all the important dialogue and actions as well as descriptions of backgrounds etc. that are part of the story.\n\nIf an actual screenplay was used to create the synchronized media in the first place, this can be a good place to start.  In production and editing however, the synchronized media usually changes from the screenplay.  For this technique, the original screenplay would be corrected to match the dialogue and what actually happens in the final edited form of the synchronized media.\n\nIn addition, some special types of synchronized media include interaction that has to occur at particular places in the playing of the synchronized media.   Sometimes it may result in an action taking place (e.g., something is purchased, sent, done, etc.). Sometimes it may change the course of the synchronized media (e.g., the synchronized media has multiple paths that are determined by user input).  In those cases links or some other mechanism would be used in the alternative for time-based media to allow people using the alternative to be able to have the same options and abilities as those using the synchronized media.\n\nExamples:\n- **Example 1:** A training film shows employees how to use a new piece of equipment.  It involves a person talking throughout while they demonstrate the operation.  The screenplay used to create the training film is used as a starting point. It is then edited and corrected to match the dialogue etc.  The film and the resulting alternative for time-based media are then made available on the company website. Employees can then use either or both to learn how to use the machine.\n- **Example 2:** An interactive shopping environment is created that allows users to steer themselves around in a virtual store and shop.  An alternative for time-based media allows the users to access the same shopping in text with links to choose aisles and to purchase things instead of dragging them into a virtual shopping basket.  ---",
    "referenced_by": [
      "1.2.3",
      "1.2.8"
    ]
  },
  {
    "id": "G58",
    "type": "technique",
    "code": "G58",
    "text": "[G58] Placing a link to the alternative for time-based media immediately next to the non-text content\n\nDescription:\nWith this technique, a link to the collated document of captions and audio description is provided. The collated document could be at another location on the same web page or at another URI. A link to the collated document is immediately adjacent to the non-text content. The link can be immediately before or after the synchronized media content. If the collated document is on the same web page as other content then put \"End of document\" at the end so that they know when to stop reading and return to their previous place. If a Back button will not take the person back to the point from which they jumped, then a link back to the non-text content location is provided.\n\nExamples:\n- **Example 2: The link back to the .MOV Document in an HTML Document**  Code on the page olympic-wrestling-transcript.html  ```html <p>Sports announcer 1: This is a great battle tonight between England's \"Will Johnson\" and \"Theodore Derringo\" from Argentina.</p> <p>Scenery: There is a mat set out in the middle of the stadium with 500 people in the stands...</p> <p>...more dialogue...<p> <p>...more scenery...</p> <p>...etc...</p> <p>Sports announcer 2: And that is all for tonight, thank you for joining us tonight where Will Johnson is the new Gold Medalist. <a href=\"../movies/olympic-sports.html#olympic-wrestling\">Return to movie page</a></p> ```    ---\n- **Example 1: A .MOV Document in an HTML Document**  Code on a page called \"olympic-sports.html\"  ```html <p id=\"olympic-wrestling\"> <a href=\"/movies/olympic-wrestling.mov\">Olympic wrestling movie</a>, <a href=\"/transcripts/olympic-wrestling-transcript.html\">Olympic wrestling collated transcript</a> </p> ```",
    "referenced_by": [
      "1.2.3",
      "1.2.8"
    ]
  },
  {
    "id": "G78",
    "type": "technique",
    "code": "G78",
    "text": "[G78] Providing a second, user-selectable, audio track that includes audio descriptions\n\nDescription:\nThe objective of this technique is to provide an audio (spoken) version of information that is provided visually so that it is possible for people who cannot see to be able to understand audio-visual material.\n\nSince most user agents today cannot merge multiple sound tracks, this technique adds the additional audio information to synchronized media by providing an option which allows users to replace the soundtrack with a new copy of the original soundtrack that has the additional audio description added in the same [human language](https://www.w3.org/TR/WCAG22/#dfn-human-language-s). This added information focuses on actions, characters, scene changes and on-screen text (not captions) that are important to understanding the content.\n\nSince it is not helpful to have this new information obscure key audio information in the original sound track (or be obscured by loud sound effects), the new information is added during pauses in dialogue and sound effects. This limits the amount of supplementary information that can be added to the program.\n\nThe soundtrack with the audio description (of visual information) can either be an alternate sound track that the user can choose, or it can be the standard sound track that everyone hears.\n\nExamples:\n- **Example 4:** A movie file has two audio tracks, one of which includes audio description. Users can choose either one when listening to the movie by selecting the appropriate track in their media player.  ---\n- **Example 2:** A video shows a woodpecker carving a nest in a tree. A button within the content allows users to turn the audio description track on or off.\n- **Example 3:** A lecture has audio description added whenever the instructor says things like \"andthisis the one that is most important.\" The audio descriptions lets listeners who can not see the video know what \"this\" is.\n- **Example 1:** A travelogue of the northeast has additional audio description added during the gaps in the dialogue to let listeners who are blind know what the person is talking about at any point in time.",
    "referenced_by": [
      "1.2.3",
      "1.2.5"
    ]
  },
  {
    "id": "G173",
    "type": "technique",
    "code": "G173",
    "text": "[G173] Providing a version of a movie with audio descriptions\n\nDescription:\nThe objective of this technique is to provide a second version of video content that provides audio desciptions in the same [human language](https://www.w3.org/TR/WCAG22/#dfn-human-language-s) as the video, so that it is possible for people who cannot see to be able to understand audio-visual material.\n\nSince most user agents today cannot merge multiple sound tracks, this technique adds the additional audio information to synchronized media by providing a second version of the movie where the original soundtrack and additional audio description have been combined in a single track. This additional information focuses on actions, characters, scene changes and on-screen text (not captions) that are important to understanding the content.\n\nSince it is not helpful to have this new information obscure key audio information in the original sound track (or be obscured by loud sound effects), the new information is added during pauses in dialogue and sound effects. This limits the amount of supplementary information that can be added to program.\n\nProviding a second version of the movie that includes audio descriptions as the primary sound track will make this content accessible for blind people who need to hear not only the dialogue, but also the context and other aspects of the video that are not communicated by the characters' dialogue alone.\n\nExamples:\n- **Example 2:** A video of juggler performing in front of group of children includes a version with audio description. The narrator of the audio description describes the number and type of items the juggler is juggling as well as the reactions the children have during the performance.  ---\n- **Example 1:** Two versions of a video of an opera are available. The first version includes only the music. The second version includes both the music and voice describing the actions of the performers on stage.",
    "referenced_by": [
      "1.2.3",
      "1.2.5"
    ]
  },
  {
    "id": "SM6",
    "type": "technique",
    "code": "SM6",
    "text": "[SM6] Providing audio description in SMIL 1.0\n\nDescription:\nThe objective of this technique is to provide a way for people who are blind\nor otherwise have trouble seeing the video in audio-visual material to be\nable to access the material. With this technique a description of the video\nis provided via audio description that will fit into the gaps in the dialogue\nin the audio-visual material.\n\nExamples:\n- **Example 1: SMIL 1.0 audio description sample for QuickTime player**  ```html <?xml version=\"1.0\" encoding=\"UTF-8\"?> <smil xmlns:qt=\"http://www.apple.com/quicktime/resources/smilextensions\" xmlns=\"https://www.w3.org/TR/REC-smil\" qt:time-slider=\"true\"> <head> <layout> <root-layout background-color=\"black\" height=\"266\" width=\"320\"/> <region id=\"videoregion\" background-color=\"black\" top=\"26\" left=\"0\" height=\"144\" width=\"320\"/> </layout> </head> <body> <par> <video dur=\"0:01:20.00\" region=\"videoregion\" src=\"salesdemo.mov\" alt=\"Sales Demo\"/> <audio dur=\"0:01:20.00\" src=\"salesdemo_ad.mp3\" alt=\"Sales Demo Audio Description\"/> </par> </body> </smil> ```    ---",
    "referenced_by": [
      "1.2.3",
      "1.2.5"
    ]
  },
  {
    "id": "SM7",
    "type": "technique",
    "code": "SM7",
    "text": "[SM7] Providing audio description in SMIL 2.0\n\nDescription:\nThe objective of this technique is to provide a way for people who are blind or otherwise have trouble seeing the video in audio-visual material to be able to access the material. With this technique a description of the video is provided via audio description that will fit into the gaps in the dialogue in the audio-visual material.\n\nExamples:\n- **Example 1: SMIL 2.0 audio description sample for RealMedia player**  The example shows aparsegment containing anaudioand avideotag. The audio stream is not started immediately.  ```html <smil xmlns=\"https://www.w3.org/2001/SMIL20/Language\"> <head> <layout> <root-layout backgroundColor=\"black\" height=\"266\" width=\"320\"/> <region id=\"video\" backgroundColor=\"black\" top=\"26\" left=\"0\" height=\"144\" width=\"320\"/> </layout> </head> <body> <par> <video src=\"salesdemo.mpg\" region=\"video\" title=\"Sales Demo\" alt=\"Sales Demo\"/> <audio src=\"salesdemo_ad.mp3\" begin=\"33.71s\" title=\"audio description\" alt=\"Sales Demo Audio Description\"/> </par> </body> </smil> ```    ---",
    "referenced_by": [
      "1.2.3",
      "1.2.5"
    ]
  },
  {
    "id": "G8",
    "type": "technique",
    "code": "G8",
    "text": "[G8] Providing a movie with extended audio descriptions\n\nDescription:\nThe objective of this technique is to provide a second version of video content that provides extended audio descriptions in the same [human language](https://www.w3.org/TR/WCAG22/#dfn-human-language-s) as the video. One of the difficult things about creating traditional audio descriptions is that the narrator sometimes has to provide a lot of information during very short pauses in dialogue. Extended audio description temporarily pauses the audio and video to allow critical information to be delivered when pauses in dialogue are insufficient for adequate description.\n\nProviding a second version of the movie with extended audio descriptions will make this content accessible for blind people who need to hear not only the dialogue but also the context and other aspects of the video that are not communicated by the characters' dialogue alone, and for which there is insufficient time during the natural dialogue.\n\nBecause it disrupts viewing for those who do not need the additional description, techniques that allow you to turn the feature on and off are often provided. Alternately, versions with and without the additional description can be provided.\n\nExamples:\n- **Example 1**  An alternate version of an online video of a family escaping from a burning building: there is a continuous dialogue between the husband and wife about where the children are. Meanwhile, in the background, a wall caves in. This is important information in the story because it will block their exit from that part of the building. The video track halts (same frame is repeated) while a narrator gives the details about the wall falling and the video continues.\n- **Example 2**  A training film has narrative that runs almost continuously throughout. An alternate version is available for people who have difficulty viewing the video portion. The alternate version freezes the video and provides audio description of key information.    ---",
    "referenced_by": [
      "1.2.3",
      "1.2.5",
      "1.2.7"
    ]
  },
  {
    "id": "SM1",
    "type": "technique",
    "code": "SM1",
    "text": "[SM1] Adding extended audio description in SMIL 1.0\n\nDescription:\nThe purpose of this technique is to allow there to be more audio description than will fit into the gaps in the dialogue of the audio-visual material.\n\nWith SMIL 1.0 there is no easy way to do this but it can be done by breaking the audio and video files up into a series of files that are played sequentially. Additional audio description is then played while the audio-visual program is frozen. The last frame of the video file is frozen so that it remains on screen while the audio file plays out.\n\nThe effect is that the video appears to play through from end to end but freezes in places while a longer audio description is provided. It then continues automatically when the audio description is complete.\n\nTo turn the extended audio description on and off one could use script to switch back and forth between two SMIL scripts, one with and one without the extended audio description lines. Or script could be used to add or remove the extended audio description lines from the SMIL file so that the film clips would just play sequentially.\n\nIf scripting is not available then two versions of the video could be provided, one with and one without extended audio descriptions.\n\nExamples:\n- **Example 1: SMIL 1.0 Video with audio descriptions that pause the main media in 4 locations to allow extended audio description**  The markup above is broken into fiveparsegments. In each, there is avideoand anaudiotag (the lastparhas no <audio> tag intentionally). The convention with extended audio descriptions is that the main media pauses during the description. The way to make this happen in SMIL 1.0 is to set aclip-beginandclip-endwhich dictate the start and end of the video clip, and to set a duration for the clip that is longer than what is defined by theclip-beginandclip-end. Thefill=\"freeze\"holds the last frame of the video during the extended description. Theaudiotag has abeginattribute with a value that is equal to theclip-endvalue of the precedingvideotag.  To determine the values forclip-begin,clip-end, anddur, find the start and end time of the portion of the video being described, and find out the total length of the extended audio description. Theclip-beginandclip-enddefine their own values, but thedurvalue is the sum of the length of the extended description and the clip defined by theclip-beginandclip-end. In the firstpar, the video clip starts at 0 seconds, ends at 5.4 seconds, and the description length is 3.3 seconds, so thedurvalue is 5.4s + 3.3s = 8.7s.  ```html <?xml version=\"1.0\" encoding=\"UTF-8\"?> <smil xmlns:qt=\"http://www.apple.com/quicktime/resources/smilextensions\" xmlns=\"https://www.w3.org/TR/REC-smil\" qt:time-slider=\"true\"> <head> <layout> <root-layout background-color=\"black\" height=\"266\" width=\"320\"/> <region id=\"videoregion\" background-color=\"black\" top=\"26\" left=\"0\" height=\"144\" width=\"320\"/> </layout> </head> <body> <par> <seq> <par> <video src=\"video.rm\" region=\"videoregion\" clip-begin=\"0s\" clip-end=\"5.4\" dur=\"8.7\" fill=\"freeze\" alt=\"videoalt\"/> <audio src=\"no1.wav\" begin=\"5.4\" alt=\"audio alt\"/> </par> <par> <video src=\"video.rm\" region=\"videoregion\" clip-begin=\"5.4\" clip-end=\"24.1\" dur=\"20.3\" fill=\"freeze\" alt=\"videoalt\"/> <audio src=\"no2.wav\" begin=\"18.7\" alt=\"audio alt\"/> </par> <par> <video src=\"video.rm\" region=\"videoregion\" clip-begin=\"24.1\" clip-end=\"29.6\" dur=\"7.7\" fill=\"freeze\" alt=\"videoalt\"/> <audio src=\"no3.wav\" begin=\"5.5\" alt=\"audio alt\"/> </par> <par> <video src=\"video.rm\" region=\"videoregion\" clip-begin=\"29.6\" clip-end=\"34.5\" dur=\"5.7\" fill=\"freeze\" alt=\"videoalt\"/> <audio src=\"no4.wav\" begin=\"4.9\" alt=\"audio alt\"/> </par> <par> <video src=\"video.rm\" region=\"videoregion\" clip-begin=\"77.4\" alt=\"video alt\"/> </par> </seq> </par> </body> </smil> ```    ---",
    "referenced_by": [
      "1.2.3",
      "1.2.5",
      "1.2.7"
    ]
  },
  {
    "id": "SM2",
    "type": "technique",
    "code": "SM2",
    "text": "[SM2] Adding extended audio description in SMIL 2.0\n\nDescription:\nThe purpose of this technique is to allow there to be more audio description than will fit into the gaps in the dialogue of the audio-visual material.\n\nWith SMIL 2.0 it is possible to specify that particular audio files be played at particular times, and that the program be frozen (paused) while the audio file is being played.\n\nThe effect is that the video appears to play through from end to end but freezes in places while a longer audio description is provided. It then continues automatically when the audio description is complete.\n\nTo turn the extended audio description on and off one could use script to switch back and forth between two SMIL scripts, one with and one without the extended audio description lines. Or script could be used to add or remove the extended audio description lines from the SMIL file so that the film clips would just play uninterrupted.\n\nIf scripting is not available then two versions of the SMIL file could be provided, one with and one without extended audio description.\n\nExamples:\n- **Example 1: Video with extended audio description**  ```html <smil xmlns=\"https://www.w3.org/2001/SMIL20/Language\"> <head> <layout> <root-layout backgroundColor=\"black\" height=\"266\" width=\"320\"/> <region id=\"video\" backgroundColor=\"black\" top=\"26\" left=\"0\" height=\"144\" width=\"320\"/> </layout> </head> <body> <excl> <priorityClass peers=\"pause\"> <video src=\"movie.rm\" region=\"video\" title=\"video\" alt=\"video\" /> <audio src=\"desc1.rm\" begin=\"12.85s\" alt=\"Description 1\" /> <audio src=\"desc2.rm\" begin=\"33.71s\" alt=\"Description 2\" /> <audio src=\"desc3.rm\" begin=\"42.65s\" alt=\"Description 3\" /> <audio src=\"desc4.rm\" begin=\"59.80s\" alt=\"Description 4\" /> </priorityClass> </excl> </body> </smil> ```    ---",
    "referenced_by": [
      "1.2.3",
      "1.2.5",
      "1.2.7"
    ]
  },
  {
    "id": "G203",
    "type": "technique",
    "code": "G203",
    "text": "[G203] Using a static text alternative to describe a talking head video\n\nDescription:\nThe purpose of this technique is to provide an alternative to audio description for synchronized media that has no important time based information contained in the video portion of the media. This particularly applies to \"talking head\" videos where a person is talking in front of an unchanging background, such as a press conference, company president talk, or government announcement, etc. In this case there are no \"important visual details\" which would warrant audio description.\n\nAudio description is not necessary when there is one person speaking against an unchanging background because there is no time-based visual information in the video that is \"important\" to the understanding of the content. The environment is static and therefore can be described in a non-multimedia static format such as alternative text that is programmatically associated with the video.\n\nAll that is necessary in this case is a static text alternative which would contain a general description of the context of the environment, any opening/closing credits, any text that appears in the bottom of the video with the name of the speaker, and other basic information, if these are seen on the screen and cannot be heard in the audio.\n\nThis technique does NOT apply to a situation where there are multiple speakers and where the identity of each new speaker is not evident in the audio track but is identified on screen with visual text as they speak. In this case, audio description should be used, and this  technique would not apply.\n\nExamples:\n- **Example 1: A video of a CEO speaking to shareholders**  A CEO is speaking to shareholders from their office. The video has a title page at the beginning of the video giving the date. When the speaker begins, there is a strip of text at the bottom of the video saying \"Jane Doe, President of XYZ Cooperation\". At the end of the video are title credits that say \"produced by the Honest TV Productions Ltd.\"  As an alternative, there is a paragraph below the video which is associated with the video file using aria-describedby which says: \"July 22, 2011, Jane Doe, President of XYZ cooperation, speaking from her office. Video produced by the Honest TV Productions Ltd.\"    ---",
    "referenced_by": [
      "1.2.3",
      "1.2.5"
    ]
  },
  {
    "id": "G9",
    "type": "technique",
    "code": "G9",
    "text": "[G9] Creating captions for live synchronized media\n\nDescription:\nThe objective of this technique is to allow users who cannot hear to be able\nto access real-time synchronized media broadcasts in the same [human language](https://www.w3.org/TR/WCAG22/#dfn-human-language-s) as the orginal. It is more difficult to create\naccurate real-time captions because there is little time to correct mistakes\nor to listen a second time or consult someone to be sure the words are\naccurately reproduced. It is also harder to simplify or paraphrase\ninformation if it is flowing too quickly.\n\nReal-time typing text entry techniques exist using stenographic and rapid\ntyping technologies. Re-voicing speech-to-text (where a person listens to\nspeech and then carefully re-voices it into a computer trained to their\nspeech) is used today for telephone relay services and may be used in the\nfuture for captioning. Eventually speech-to-text with correction will be\npossible.\n\nExamples:\n- **Example 1**  A television studio uses a real-time captioning service to create captions for its evening news online.\n- **Example 2**  A user watches an online seminar on their mobile device, including captioning provided through the use of Communication Access Real-time Translation (CART). The captions provided also benefit in-person participants who need captioning and can view the information on their own device.    ---",
    "referenced_by": [
      "1.2.4"
    ]
  },
  {
    "id": "G54",
    "type": "technique",
    "code": "G54",
    "text": "[G54] Including a sign language interpreter in the video stream\n\nDescription:\nThe objective of this technique is to allow users who cannot hear or read text rapidly to be able to access synchronized media material.\n\nFor those who communicate primarily in sign language it is sometimes less preferable and sometimes not possible for them to read and understand text at the rate it is presented in captions.   For these latter individuals it is important to provide sign language presentation of the audio information.\n\nOne universally compatible way of doing this is to simply embed a video of the sign language interpreter in the video stream.   This has the disadvantage of providing a lower resolution image that cannot be easily enlarged without enlarging the entire image.\n\nExamples:\n- **Example 1:** Example 1: A television station provides a sign language interpreter in the corner of or beside its on-line news video.  ---",
    "referenced_by": [
      "1.2.6"
    ]
  },
  {
    "id": "G81",
    "type": "technique",
    "code": "G81",
    "text": "[G81] Providing a synchronized video of the sign language interpreter that can be displayed in a different viewport or overlaid on the image by the player\n\nDescription:\nThe objective of this technique is to allow users who cannot hear or read\ntext rapidly to be able to access synchronized media material without affecting the\npresentation of the material for all viewers.\n\nFor those who communicate primarily in sign language it is sometimes less\npreferable and sometimes not possible for them to read and understand text\nat the rate it is presented in captions. For these latter individuals it is\nimportant to provide sign language presentation of the audio information.\n\nThis technique accomplishes this by providing the sign language\ninterpretation as a separate video stream that is synchronized with the\noriginal video stream. Depending on the player, this secondary video stream\ncan be overlaid on top of the original video or displayed in a separate\nwindow. It may also be possible to enlarge the sign language interpreter\nseparately from the original video to make it easier to read the hand, body\nand facial movements of the signer.\n\nNOTE: Since sign language is not usually a signed version of the printed\nlanguage, the author has to decide which sign language to include. Usually\nthe sign language of the primary audience would be used. If intended for\nmultiple audiences, multiple languages may be used. See advisory technique\nfor multiple sign languages.\n\nExamples:\n- **Example 1**  Example 1: A university provides a synchronized sign language interpreter video stream that can be displayed, at the viewer's option, along with any of their education programs.    ---",
    "referenced_by": [
      "1.2.6"
    ]
  },
  {
    "id": "SM13",
    "type": "technique",
    "code": "SM13",
    "text": "[SM13] Providing sign language interpretation through synchronized video streams in SMIL 1.0\n\nDescription:\nThe objective of this technique is to provide a way for people who are deaf\nor otherwise have trouble hearing the dialogue in audio visual material to be\nable to view the material. With this technique all of the dialogue and\nimportant sounds are available in a sign-language interpretation video that\nis displayed in a caption area.\n\nWith SMIL 1.0, separate regions can be defined for the two videos. The two\nvideo playbacks are synchronized, with the content video displayed in one\nregion of the screen, while the corresponding sign-language interpretation\nvideo is displayed in another region.\n\nExamples:\n- **Example 1: SMIL 1.0 sign-language interpretation sample for QuickTime player**  ```html <?xml version=\"1.0\" encoding=\"UTF-8\"?> <smil xmlns:qt=\"http://www.apple.com/quicktime/resources/smilextensions\" xmlns=\"https://www.w3.org/TR/REC-smil\" qt:time-slider=\"true\"> <head> <layout> <root-layout width=\"320\" height=\"300\" background-color=\"black\"/> <region top=\"0\" width=\"320\" height=\"240\" left=\"0\" background-color=\"black\" id=\"videoregion\"/> <region top=\"240\" width=\"320\" height=\"60\" left=\"0\" background-color=\"black\" id=\"signingregion\"/> </layout> </head> <body> <par> <video dur=\"0:01:20.00\" region=\"videoregion\" src=\"salesdemo.mov\" alt=\"Sales Demo\"/> <video dur=\"0:01:20.00\" region=\"signingregion\" system-captions=\"on\" src=\"salesdemo_si.mov\" alt=\"Sales Demo Sign Language Interpretation\"/> </par> </body> </smil> ```    ---",
    "referenced_by": [
      "1.2.6"
    ]
  },
  {
    "id": "SM14",
    "type": "technique",
    "code": "SM14",
    "text": "[SM14] Providing sign language interpretation through synchronized video streams in SMIL 2.0\n\nDescription:\nThe objective of this technique is to provide a way for people who are deaf\nor otherwise have trouble hearing the dialogue in audio visual material to be\nable to view the material. With this technique all of the dialogue and\nimportant sounds are available in a sign-language interpretation video that\nis displayed in a caption area.\n\nWith SMIL 2.0, separate regions can be defined for the two videos. The two\nvideo playbacks are synchronized, with the content video displayed in one\nregion of the screen, while the corresponding sign-language interpretation\nvideo is displayed in another region.\n\nExamples:\n- **Example 1: SMIL 2.0 sign-language video sample for RealMedia player**  The example shows aparsegment containing twovideotags. ThesystemCaptionsattribute indicates that the sign language video should be displayed when the user's player setting for captions indicates the preference for captions to be displayed. Thelayoutsection defines the regions used for the main video and the sign language interpretation video.  ```html <smil xmlns=\"https://www.w3.org/2001/SMIL20/Language\"> <head> <layout> <root-layout backgroundColor=\"black\" height=\"310\" width=\"330\"/> <region id=\"video\" backgroundColor=\"black\" top=\"5\" left=\"5\" height=\"240\" width=\"320\"/> <region id=\"signing\" backgroundColor=\"black\" top=\"250\" height=\"60\" left=\"5\" width=\"320\"/> </layout> </head> <body> <par> <video src=\"salesdemo.mpg\" region=\"video\" title=\"Sales Demo\" alt=\"Sales Demo\"/> <video src=\"salesdemo_signing.mpg\" region=\"signing\" systemCaptions=\"on\" title=\"sign language interpretation\" alt=\"Sales Demo Sign Language Interpretation\"/> </par> </body> </smil> ```    ---",
    "referenced_by": [
      "1.2.6"
    ]
  },
  {
    "id": "G151",
    "type": "technique",
    "code": "G151",
    "text": "[G151] Providing a link to a text transcript of a prepared statement or script if the script is followed\n\nDescription:\nThe objective of this technique is to provide a transcript or script if the live audio content is following a set script. Because it is prepared in advance, the script can be more accurate and complete than live transcription. However, the script will not be synchronized with the audio as it plays. Live audio should not deviate from the script for this technique.\n\nWith this technique, a link to the transcript or script is provided and should conform to WCAG 2.0 and could either be included at another location on the same web page or at another URI.\n\nExamples:\n- **Example 1:** A live radio play of a fringe theatre group is being broadcast to the Web. As the actors stick largely to a set script, and the budget for the program is small, the producers provide a link (with the playwright's permission) to the script of the play in HTML.\n- **Example 2:** A member of the government broadcasts an important policy speech on the Web. A transcript of the speech is made available on the website when the speech starts.  ---",
    "referenced_by": [
      "1.2.9"
    ]
  },
  {
    "id": "G150",
    "type": "technique",
    "code": "G150",
    "text": "[G150] Providing text based alternatives for live audio-only content\n\nDescription:\nThe objective of this technique is to allow users who cannot hear to be able to access real-time audio broadcasts. It is more difficult to create accurate real-time alternatives because there is little time to correct mistakes, to listen a second time or to consult someone to be sure the words are accurately reproduced. It is also harder to simplify or paraphrase information if it is flowing too quickly.\n\nReal-time typing text entry techniques exist using stenographic and rapid typing technologies. Re-voicing speech-to-text (where a person listens to speech and then carefully re-voices it into a computer trained to their speech) is used today for telephone relay services and may be used in the future for captioning. Eventually speech-to-text with correction will be possible.\n\nExamples:\n- **Example 1:** A radio station uses Web based captioning services to provide alternatives for live sporting events; the output from the service is incorporated in a viewport of the web page which also includes a streaming audio control.  ---",
    "referenced_by": [
      "1.2.9"
    ]
  },
  {
    "id": "G157",
    "type": "technique",
    "code": "G157",
    "text": "[G157] Incorporating a live audio captioning service into a Web page\n\nDescription:\nThe objective of this technique is to use a real-time caption service to provide a text version of live audio content. Such services use a trained human operator who listens in to what is being said and uses a special keyboard to enter the text with only a small delay. They are able to capture a live event with a high degree of fidelity, and also to insert notes on any non spoken audio which is essential to understanding the event. The viewport containing the caption text is available on the same web page as the live audio content.\n\nExamples:\n- **Example 1:** An internet radio station provides a viewport on its web page for its news services. Live news reports, especially emergency reports, are transcribed by a real-time caption service and displayed in the viewport.\n- **Example 2:** A conferencing or screen-sharing service includes a window with running real-time transcription of the verbal presentation. This is achieved by arranging ahead of time with a remote relay audio-teleconference captioning service. The online web conferencing or screen-sharing service needs to be designed with this possible usage in mind because using a separate window for the live text would be a significant usability barrier.\n- **Example 3:** A recurring audio conference uses an online hand-raising utility to assist with queuing. In order to facilitate use of this product in conjunction with an on-line relay conference captioning service, the queuing utility is designed to be fully operational in a narrow viewport. For additional enhancement, a website is created to bring up both viewports within a single web page.  ---",
    "referenced_by": [
      "1.2.9"
    ]
  },
  {
    "id": "ARIA11",
    "type": "technique",
    "code": "ARIA11",
    "text": "[ARIA11] Using ARIA landmarks to identify regions of a page\n\nDescription:\nThe purpose of this technique is to provide programmatic access to sections of a web page.  Landmark roles (or \"landmarks\") programmatically identify sections of a page. Landmarks help assistive technology (AT) users orient themselves to a page and help them navigate easily to various sections of a page.\n\nThey also provide an easy way for users of assistive technology to skip over blocks of content that are repeated on multiple pages and notify them of programmatic structure of a page. For instance, if there is a common navigation menu found on every page, landmark roles (or \"landmarks\") can be used to skip over it and navigate from section to section. This will save assistive technology users and keyboard users the trouble and time of tabbing through a large amount of content to find what they are really after, much like a traditional \"skip links\" mechanism. (Refer to User Agent Notes above for specifics of AT support). A blind user who may be familiar with a news site's menu, and is only interested in getting to the top story could easily navigate to the \"main\" landmark, and bypass dozens of menu links. In another circumstance, a user who is blind may want to quickly find a navigation menu, and can do so by jumping to the navigation landmark.\n\nLandmarks also can help sighted keyboard-only users navigate to sections of a page using a [browser plugin](https://www.tpgi.com/improving-access-to-landmark-navigation/).\n\nLandmarks are inserted into the page using the role attribute on an element that marks the section. The value of the attribute is the name of the landmark. These role values are listed below. For HTML mappings of landmark roles, refer to the Rules of ARIA attribute usage by HTML element table in the [ARIA In HTML recommendation](https://www.w3.org/TR/html-aria/).\n\n- banner: A region that contains the prime heading or internal title of a page.\n- navigation: A region that contains navigation links links to other pages or different parts of the same page.\n- main: A region that contains a page's main content.\n- region: A region that contains a perceivable section of the page containing content that is sufficiently important for users to be able to navigate to the section. Aregionlandmark isn't exposed as a landmark region unless it has an accessible name.\n- form: A region of the document that represents a collection of form-associated elements, some of which can represent editable values that can be submitted to a server for processing.\n- search: A region of the page containing search functionality.\n- complementary: Any section of the document that supports the main content, yet is separate and meaningful on its own.\n- contentinfo: A region that contains information about the parent document such as copyrights and links to privacy statements.\n\nThere are cases when a particular landmark role could be used more than once on a page, such as on primary and secondary blocks of navigation. In these cases, identical roles should be labeled using a valid technique for labelling regions.\n\nLandmarks should supplement native semantic markup such as HTML headings, lists and other structural markup. Landmarks are interpretable by WAI-ARIA-aware assistive technologies and are not exposed by browsers directly to users.\n\nIt is a best practice to include all content on the page in landmarks, so that screen reader users who rely on them to navigate from section to section do not lose track of content.\n\nExamples:\n- **Example 4: Search form**  The following example shows a search form with a \"search\" landmark. Thesearchrole typically goes on theformelement or adivsurrounding the form:  ```html <form role=\"search\"> <label for=\"product-search\" id=\"search-label\">Search</label> <input id=\"product-search\" placeholder=\"title, author, or ISBN\" type=\"text\"> <button type=\"submit\">Find Books</button> </form> ```    ---\n- **Example 3: Multiple landmarks of the same type and aria-label**  The following example shows a best practice of how landmarks might be added to an HTML document in situations where there are two or more of the same type of landmark on the same page, and there is no existing text on the page that can be referenced as the label:  ```html <div aria-label=\"Site\" role=\"navigation\"> <ul> <li><a href=\"...\">nav link 1</a></li> <li><a href=\"...\">nav link 2</a></li> <li><a href=\"...\">nav link 3</a></li> </ul> </div> <div aria-label=\"Tags\" role=\"navigation\"> <ul> <li><a href=\"...\">tag link 1</a></li> <li><a href=\"...\">tag link 2</a></li> <li><a href=\"...\">tag link 3</a></li> </ul> </div> ```\n- **Example 1: Simple landmarks**  The following example shows how landmarks might be added to an HTML document:  ```html <div role=\"banner\">site logo and name, etc. here</div> <div role=\"search\">search functionality here</div> <div role=\"navigation\">a list of navigation links here</div> <div role=\"form\">a sign-up form here</div> <div role=\"main\">the page's main content here</div> <div role=\"region\">a sponsor's promotion here</div> <div role=\"complementary\">sidebar content here</div> <div role=\"contentinfo\"> site contact details, copyright information, etc. here </div> ```\n- **Example 2: Multiple landmarks of the same type and aria-labelledby**  The following example shows a best practice of how landmarks might be added to an HTML document in situations where there are two or more of the same type of landmark on the same page. For instance, if a navigation role is used multiple times on a page, each instance may have a unique label specified usingaria-labelledby:  ```html <div aria-labelledby=\"site-nav-heading\" role=\"navigation\"> <h2 id=\"site-nav-heading\">Site</h2> <ul> <li><a href=\"...\">nav link 1</a></li> <li><a href=\"...\">nav link 2</a></li> <li><a href=\"...\">nav link 3</a></li> </ul> </div> <div aria-labelledby=\"related-nav-heading\" role=\"navigation\"> <h2 id=\"related-nav-heading\">Related Topics</h2> <ul> <li><a href=\"...\">topic link 1</a></li> <li><a href=\"...\">topic link 2</a></li> <li><a href=\"...\">topic link 3</a></li> </ul> </div> ```",
    "referenced_by": [
      "1.3.1",
      "1.3.6",
      "2.4.1"
    ]
  },
  {
    "id": "ARIA12",
    "type": "technique",
    "code": "ARIA12",
    "text": "[ARIA12] Using role=heading to identify headings\n\nDescription:\nThe purpose of this technique is to provide a way for Assistive Technologies (AT) to identify\na piece of content as a heading. Applying **role=\"heading\"** to an element causes an AT (like a screen reader) to treat it as though it were a heading. The **role=\"heading\"** property must be paired with the **aria-level** property to define the heading level.\n\nWhen possible, [use native heading markup](https://www.w3.org/TR/using-aria/#rule1). For example, it is preferable to use an **h1** element, rather than using **<div role=\"heading\" aria-level=\"1\">**. Native HTML elements have implicit styling and features that won't necessarily be replicated with ARIA equivalents. For instance, heading elements will have specific styling adjustments made when viewing a page in a browser's Reader Mode. Whereas a **<div role=\"heading\" aria-level=\"1\">** will not be styled as a heading, because the underlying element is a **div**. ARIA only modifies the way an element is exposed to assistive technology, it does nothing to change the implicit style or functionality of the element it is applied to.\n\nExamples:\n- **Example 1: Simple headings**  This example demonstrates how to implement headings usingrole=\"heading\"andaria-level.  ```html <div role=\"heading\" aria-level=\"2\">Global News Items</div> ... a list of global news with editorial comment....  <div role=\"heading\" aria-level=\"3\">Politics</div> ... a list of global political news stories ... ```\n- **Example 2: Additional heading levels**  This example demonstrates how to implement a level 7 heading usingrole=\"heading\"and thearia-levelattribute. Since HTML only supports headings up to level 6, there is no native element to provide these semantics.  ```html <h5>Fruit Trees</h5> <h6>Apples</h6> <p>Apples grow on trees in areas known as orchards...</p> ... <div role=\"heading\" aria-level=\"7\">Jonagold</div> <p>Jonagold is a cross between the Golden Delicious and Jonathan varieties...</p> ```    ---",
    "referenced_by": [
      "1.3.1"
    ]
  },
  {
    "id": "ARIA13",
    "type": "technique",
    "code": "ARIA13",
    "text": "[ARIA13] Using aria-labelledby to name regions and landmarks\n\nDescription:\nThe purpose of this technique is to provide names for regions of a page that can be read by assistive technology.  The **aria-labelledby** attribute provides a way to associate a section of the page marked up as a region or landmarks with text that is on the page that labels it.\n\nLandmark roles (or \"landmarks\") programmatically identify sections of a page. Landmarks help assistive technology (AT) users orient themselves to a page and help them navigate easily to various sections of a page.\n\nLike **aria-describedby**, **aria-labelledby** can accept multiple **id**s to point to other regions of the page using a space separated list. It is also limited to **id**s for defining these sets.\n\nExamples:\n- **Example 1: Identify a landmark with on-page text**  Below is an example ofaria-labelledbyused on a complementary Landmark. The region of the document to which the heading pertains could be marked with thearia-labelledbyproperty containing the value of theidfor the header.  ```html <div role=\"complementary\" aria-labelledby=\"hdr1\"> <h1 id=\"hdr1\">Top News Stories</h1> ... </div> ```\n- **Example 2: Identification for Application landmarks**  The following code snippet for application landmarks with static prose. If you have a regional landmark of type application and static descriptive text is available, then on the application landmark, include an aria-describedby reference to associate the application and the static text as shown here:  ```html <div role=\"application\" aria-labelledby=\"p123\" aria-describedby=\"info\"> <h1 id=\"p123\">Calendar<h1> <p id=\"info\">This calendar shows the game schedule for the Boston Red Sox.</p> <div role=\"grid\"> ... </div> </div> ```    ---",
    "referenced_by": [
      "1.3.1"
    ]
  },
  {
    "id": "ARIA16",
    "type": "technique",
    "code": "ARIA16",
    "text": "[ARIA16] Using aria-labelledby to provide a name for user interface controls\n\nDescription:\nThe purpose of this technique is to provide names for user interface controls that can be read by assistive technology.  WAI-ARIA provides a way to associate text with a section, drawing, form element, picture, and so on, using the **aria-labelledby** property. This techniques uses the **aria-labelledby** attribute to associate a user interface control, such as a form field, with text on the page that labels it.\n\nLike **aria-describedby**, **aria-labelledby** can accept multiple ids to point to other elements of the page using a space separated list. This capability makes **aria-labelledby** especially useful in situations where sighted users use information from the surrounding context to identify a control. [Using aria-labelledby to concatenate a label from several text nodes](ARIA9) contains more examples of situations where names are created from several other text elements on the page.\n\nWhile the function of aria-labelledby appears similar to the native HTML label element, there are some differences:\n\n- aria-labelledbycan reference more than one text element;labelcan only reference one.\n- aria-labelledbycan be used for a variety of elements while thelabelelement can only be used on form elements.\n- Clicking on alabelfocuses the associated form field. This does not occur witharia-labelledby. If this behaviour is required then uselabelor implement this functionality using scripting.\n\nExamples:\n- **Example 1: Labelling a simple text field**  The following is an example ofaria-labelledbyused on a simple text field to provide a label in a situation where there is no text available for a dedicated label but there is other text on the page that can be used to accurately label the control.  ```html <input name=\"searchtxt\" type=\"text\" aria-labelledby=\"searchbtn\"> <input name=\"searchbtn\" id=\"searchbtn\" type=\"submit\" value=\"Search\"> ```\n- **Example 2: Labelling a slider**  Below is an example ofaria-labelledbyused to provide a label for a slider control. In this case the label text is selected from within a longer adjacent text string. Please note that this example is simplified to show only the labeling relationship; authors implementing custom controls also need to ensure that controls meet other success criteria.  ```html <p>Please select the <span id=\"mysldr-lbl\">number of days for your trip</span></p> <div id=\"mysldr\" role=\"slider\" aria-labelledby=\"mysldr-lbl\"></div> ```\n- **Example 3: A label from multiple sources**  The following example ofaria-labelledbywith multiple references uses thelabelelement. For additional detail on concatenating multiple sources of information into a label witharia-labelledby, please view the techniqueUsing ARIA labelledby to concatenate a label from several text nodes.  Note: The use of thelabelelement is included for a number of reasons. If the user clicks on the text of thelabelelement, the corresponding form field will receive focus, which makes the clicking target larger for people with dexterity problems. Also thelabelelement will always be exposed via the accessibility API. Aspancould have been used. However, aspanwould lose the advantage of the larger clickable region.  ```html <label id=\"l1\" for=\"f3\">Notify me</label> <select name=\"amt\" id=\"f3\" aria-labelledby=\"l1 f3 l2\"> <option value=\"1\">1</option> <option value=\"2\">2</option> </select> <span id=\"l2\">days in advance</span> ```    ---",
    "referenced_by": [
      "1.3.1",
      "4.1.2"
    ]
  },
  {
    "id": "ARIA17",
    "type": "technique",
    "code": "ARIA17",
    "text": "[ARIA17] Using grouping roles to identify related form controls\n\nDescription:\nThe objective of this technique is to mark up a set of related controls within a form  as a group. Any label associated with the group also serves as a common label or qualifier for individual controls in the group. Assistive technologies can indicate the start and end of the group and the group's label as one navigates into and out of the group. This is a viable alternative for grouping form controls programmatically when the user interface's design makes it difficult to employ the **fieldset** / **legend** technique ([H71](../html/H71)).\n\nFor a group of radio buttons, one should use **role=\"radiogroup\"** instead of **role=\"group\"**.\n\nThe group can be labeled using **aria-labelledby**.\n\nThis technique is not meant for wrapping  all controls on a form within a single container with **role=\"group\"**.\n\nExamples:\n- **Example 1: Social Security Number**  Social security number fields which are nine digits long and broken up into three segments can be grouped usingrole=\"group\".  Working example:Multiple part field groups.  ```html <div role=\"group\" aria-labelledby=\"ssn1\"> <span id=\"ssn1\">Social Security Number</span> <span style=\"color: #D90D0D;\"> (required)</span> <input size=\"3\" type=\"text\" aria-required=\"true\" title=\"First 3 digits\">- <input size=\"2\" type=\"text\" aria-required=\"true\" title=\"Next 2 digits\">- <input size=\"4\" type=\"text\" aria-required=\"true\" title=\"Last 4 digits\"> </div> ```\n- **Example 2: Identifying radio groups**  This example demonstrates userole=radiogroup. Note also that the radio buttons are custom controls withrole=radio. One may optionally employ CSS to place a border around groups of such fields to visually reinforce the group relationship. The CSS properties are available below the form.  Related CSS Style Definition to place a border around the group of fields:  Working example:using grouping roles to identify related form controls.  ```html <h3>Set Alerts for your Account</h3> <div role=\"radiogroup\" aria-labelledby=\"alert1\"> <p id=\"alert1\">Send an alert when balance exceeds $3,000</p> <div> <span role=\"radio\" aria-checked=\"false\" aria-labelledby=\"a1r1\" name=\"a1radio\"></span> <span id=\"a1r1\">Yes</span> </div> <div> <span role=\"radio\" aria-checked=\"false\" aria-labelledby=\"a1r2\" name=\"a1radio\"></span> <span id=\"a1r2\">No</span> </div> </div> <div role=\"radiogroup\" aria-checked=\"false\" aria-labelledby=\"alert2\"> <p id=\"alert2\">Send an alert when a charge exceeds $250</p> <div> <span role=\"radio\" aria-checked=\"false\" aria-labelledby=\"a2r1\" name=\"a2radio\"></span> <span id=\"a2r1\">Yes</span> </div> <div> <span role=\"radio\" aria-checked=\"false\" aria-labelledby=\"a2r2\" name=\"a2radio\"></span> <span id=\"a2r2\">No</span> </div> </div> <input type=\"submit\" value=\"Continue\" name=\"continue_btn\"> ```  ```html div[role=radiogroup] { border: black thin solid; } ```    ---",
    "referenced_by": [
      "1.3.1",
      "3.3.2"
    ]
  },
  {
    "id": "ARIA20",
    "type": "technique",
    "code": "ARIA20",
    "text": "[ARIA20] Using the region role to identify a region of the page\n\nDescription:\nThis technique demonstrates how to assign a generic **region** role to a section of a page so that user agents and assistive technologies may be able to programmatically identify it. The **region** role demarcates a segment of the page that contains content of significance so that it is more readily discoverable and navigable. The generic region should be used when the section cannot be marked up using a standard document landmark role (see [ARIA11](ARIA11)).\n\nIt is important to name regions, because they are generic grouping elements and users will need some way to tell which region they are in. Regions can be named using **aria-labelledby**, **aria-label**, or another technique. Doing so helps to better expose content and information relationships on the page. The role of **region** should be used prudently, because if overused they can make the page overly verbose for screen reader users.\n\nExamples:\n- **Example 1: Region on a news website**  A section on the home page of a news website that contains a poll that changes every week is marked up withrole=\"region\". Theh3above the form is referenced as the region's name usingaria-labelledby.  ```html <div role=\"region\" aria-labelledby=\"pollhead\"> <h3 id=\"pollhead\">This week's Poll</h3> <form> <fieldset> <legend>Do you believe the tax code needs to be overhauled?</legend> <input type=\"radio\" id=\"r1\" name=\"poll\"> <label for=\"r1\">No, it's fine the way it is</label> <input type=\"radio\" id=\"r2\" name=\"poll\"> <label for=\"r2\">Yes, the wealthy need to pay more</label> <input type=\"radio\" id=\"r3\" name=\"poll\"> <label for=\"r3\">Yes, we need to close corporate loopholes</label> <input type=\"radio\" id=\"r4\" name=\"poll\"> <label for=\"r4\">Changes should be made across the board</label> </fieldset> </form> <a href=\"results.php\">See Poll Results</a> </div> ```\n- **Example 2: Identifying a region on a banking site**  A user can expand links on a bank website after logging in to see details of term deposit accounts. The details are within aspanmarked up withregionrole. The heading for the region hasrole=headingand is included in thearia-labelledbythat names the region.  ```html <ol> <li> <button aria-controls=\"block1\" aria-expanded=\"false\" id=\"l1\" title=\"show details\" type=\"button\">John Henry's Account <img alt=\"\" src=\"images/panel_expand.gif\"> </button> <div id=\"block1\" class=\"nowHidden\" tabindex=\"-1\" aria-labelledby=\"l1 cd1\" role=\"region\"> <span id=\"cd1\" role=\"heading\" aria-level=\"3\">Certificate Of Deposit</span> <table> <tr> <th scope=\"row\">Account:</th> <td>25163522</td> </tr> <tr> <th scope=\"row\">Start date:</th> <td>February 1, 2014</td> </tr> <tr> <th scope=\"row\">Maturity date:</th> <td>February 1, 2016</td> </tr> <tr> <th scope=\"row\">Deposit Amount:</th> <td>$ 3,000.00</td> </tr> <tr> <th scope=\"row\">Maturity Amount:</th> <td>$ 3,072.43</td> </tr> </table> </div> </li> </ol> ```\n- **Example 3: Identifying a portlet with a generic region**  This example shows how a genericregionlandmark might be added to a weather portlet. There is no existing text on the page that can be referenced as the label, so it is labelled witharia-label.  ```html <div role=\"region\" aria-label=\"weather portlet\"> ... </div> ```    ---",
    "referenced_by": [
      "1.3.1"
    ]
  },
  {
    "id": "G115",
    "type": "technique",
    "code": "G115",
    "text": "[G115] Using semantic elements to mark up structure\n\nDescription:\nThe objective of this technique is to mark up the structure of the Web content using the appropriate semantic elements. In other words, the elements are used according to their meaning, not because of the way they appear visually.\n\nUsing the appropriate semantic elements will make sure the structure is available to the user agent. This involves explicitly indicating the role that different units have in understanding the meaning of the content. The nature of a piece of content as a paragraph, header, emphasized text, table, etc. can all be indicated in this way. In some cases, the relationships between units of content should also be indicated, such as between headings and subheadings, or amongst the cells of a table. The user agent can then make the structure perceivable to the user, for example using a different visual presentation for different types of structures or by using a different voice or pitch in an auditory presentation.\n\nIn HTML, for example, phrase-level elements such as **em**, **abbr**, and **cite** add semantic information within sentences, marking text for emphasis and identifying abbreviations and citations, respectively. MathML, a markup language designed to maintain important distinctions between structure and presentation in mathematics, includes special \"presentation\" markup for the complex notations used to represent mathematical ideas as well as \"content\" (semantic) markup for the mathematical ideas themselves.\n\nExamples:\n- **Example 1: Linking to another page**  A paragraph contains a hyperlink to another page. The hyperlink is marked up using theaelement.  ```html <p>Do you want to try our new tool yourself? A free demonstration version is available in our <a href=\"download.html\">download section</a> </p> ```\n- **Example 2: Usingciteandblockquoteto reference a book and a quotation from it**  A page about the history of marriage uses a quotation from Jane Austen's novel, Pride and Prejudice, as an example. The reference to the book is marked up using theciteelement and the quotation itself is marked up using theblockquoteelement.  ```html <p>Marriage was considered a logical step for a bachelor, as can be seen in the first chapter of the novel <cite>Pride and Prejudice</cite>:</p> <blockquote> <p>It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife.</p> <p>However little known the feelings or views of such a man may be on his first entering a neighbourhood, this truth is so well fixed in the minds of the surrounding families, that he is considered the rightful property of some one or other of their daughters.</p> </blockquote> ```\n- **Example 3: Using thestrongelement to emphasize important text**  A car manual explains how to start the engine. The instructions include a warning to make sure the gear is in neutral. The author feels the warning is so important that it should be emphasized so the warning is marked up using thestrongelement.  ```html <h1>How to start the engine</h1> <p>Before starting the engine, <strong>make sure the gear is in neutral</strong> Next, turn the key in the ignition. The engine should start.</p> ```\n- **Example 4: Using theemandstrongelements to emphasize text**  ```html <p>What the user <em>really</em> meant to say was, <q>This is not ok, it is <strong>excellent</strong>!</q> </p> ```\n- **Example 5: Using highlighting and background color to visually and semantically identify important information**  ```html <style> .vocab { background-color:cyan; font-style:normal; } </style> ... <p>New vocabulary words are emphasized and highlighted with a cyan background.</p> <p>The <em class=\"vocab\">scathing</em> review of the play seemed a bit too harsh.</p> ```    ---",
    "referenced_by": [
      "1.3.1"
    ]
  },
  {
    "id": "H49",
    "type": "technique",
    "code": "H49",
    "text": "[H49] Using semantic markup to mark emphasized or special text\n\nDescription:\nThe objective of this technique is to demonstrate how semantic markup can be used to\nmark emphasized or special text so that it can be programmatically determined. Using\nsemantic markup to mark emphasized or special text also provides structure to the\ndocument. User agents can then make the structure perceivable to the user, for example\nusing a different visual presentation for different types of structures or by using a\ndifferent voice or pitch in an auditory presentation.\n\nMost user agents will visually distinguish text that has been identified using semantic\nmarkup. Some assistive technologies provide a mechanism for determining the\ncharacteristics of content that has been created using proper semantic markup.\n\nExamples:\n- **Example 1: Using theemandstrongelements to emphasize text**  Theemandstrongelements are designed to indicate structural emphasis that may be rendered in a variety of ways (font style changes, speech inflection changes, etc.).  ```html ... What she <em>really</em> meant to say was, &quot;This is not OK, it is <strong>excellent</strong>&quot;! ... ```\n- **Example 2: Using theblockquoteelement to mark up long quotations from another source**  This example also demonstrates the use of theciteelement to specify a reference.  ```html <p>The following is an excerpt from the <cite>The Story Of My Life</cite> by Helen Keller:</p> <blockquote> <p>Even in the days before my teacher came, I used to feel along the square stiff boxwood hedges, and, guided by the sense of smell, would find the first violets and lilies. There, too, after a fit of temper, I went to find comfort and to hide my hot face in the cool leaves and grass.</p> </blockquote> ```\n- **Example 3: Using theqelement to mark up a shorter quotation from another source**  Quotation marks aren't manually added to the quote because they are added by the user agent.  ```html <p>Helen Keller said, <q>Self-pity is our worst enemy and if we yield to it, we can never do anything good in the world</q>.</p> ```\n- **Example 4: Using thesupandsubelements to mark up superscripts and subscripts**  Thesupandsubelements must be used only to mark up typographical conventions with specific meanings, not for typographical presentation for presentation's sake.  ```html <p>Henry won 1<sup>st</sup> place in the 9<sup>th</sup> grade science competition.</p> <p>The chemical notation for water is H<sub>2</sub>O.</p> ```\n- **Example 5: Using thecodeelement to mark up code**  This example shows use of thecodeelement to provide visual emphasis for a CSS rule:  ```html <code> .trial { background-image: url(30daytrial.jpg); background-position: left top; background-repeat: no-repeat; padding-top: 68px; } </code> ```    ---",
    "referenced_by": []
  },
  {
    "id": "G117",
    "type": "technique",
    "code": "G117",
    "text": "[G117] Using text to convey information that is conveyed by variations in presentation of text\n\nDescription:\nThe objective of this technique is to ensure that information conveyed through variations in the formatting of text is conveyed in text as well. When the visual appearance of text is varied to convey information, state the information explicitly in the text. Variations in the visual appearance can be made by changes in font face, font size, underline, strike through and various other text attributes. When these types of variations convey information, that information needs to be available elsewhere in the content via text. Including additional sections in the document or an inline description where the variation in presentation of text occurs can be used to convey the information.\n\nExamples:\n- **Example 1: Indicating new content with boldface and a text indicator**  The following example shows a list of accessibility standards. WCAG 2.2 is new, so is indicated in bold face. To avoid conveying information solely by presentation, the word \"(new)\" is included after it as well.  ```html <h2>Web Accessibility Guidelines</h2> <ul> <li><strong>WCAG 2.2 (New)</strong></li> <li>WCAG 2.1</li> <li>WCAG 2.0</li> <li>Section 508</li> <li>JIS X 8341-3</li> ... </ul> ```\n- **Example 2: Font variations and explicit statements.**  An online document has gone through multiple drafts. Insertions are underlined and deletions are struck through. At the end of the draft a \"change history\" lists all changes made to each draft.\n- **Example 3: Providing an alternate way to know which words in the text have been identified by using a different font.**  An on-line test requires students to write a short summary of a longer document. The summary must contain certain words from the original document. When a sentence in the original document contains a word or phrase that must be used in the summary, the word or phrase is shown in a different font than the rest of the sentence. A separate section also lists all the words and phrases that must be used in the summary.    ---",
    "referenced_by": [
      "1.3.1"
    ]
  },
  {
    "id": "G140",
    "type": "technique",
    "code": "G140",
    "text": "[G140] Separating information and structure from presentation to enable different presentations\n\nDescription:\nThe objective of this technique is to facilitate the interaction of assistive technology with content by logically separating the content's structural encoding from the presentational encoding. Structural encoding is the indication of elements such as headings, paragraphs, lists, tables, etc., and is done by using technology features reserved for the purpose. By contrast, presentational encoding is the indication of formatting effects, such as typeface, color, size, position, borders, etc., and is also supported by technology features.\n\nWhile presentational features visually imply structure — users can determine headings, paragraphs, lists, etc. from the formatting conventions used — these features do not encode the structure unambiguously enough for assistive technology to interact with the page effectively. Providing separate structure, functionality, and presentation layers allows the semantics implied by the formatting to become programmatically determined via the structure layer.\n\nFollowing this technique allows user agents to:\n\n- Perform meaningful structure transformations based on the existing structure of the content, such as reordering sections or generating a list of sections or a list of links.\n- Support interaction with content based on structural characteristics that cannot be determined by assistive technology on the basis of presentational information alone. For instance, it may be desirable to provide special interactions with lists by indicating the number of list items or skipping to the end, but this is only possible if the list structure is encoded in addition to the list presentation.\n- Modify the presentation of content by substituting alternate presentation rules attached to structural features.\n\nExamples:\n- **Example 1: HTML with CSS**  An HTML document uses the structural features of HTML, such as paragraphs, lists, headings, etc., and avoids presentational features such as font changes, layout hints, etc. CSS is used to format the document based on its structural properties. Well-crafted \"class\" attributes in the HTML extend the semantics of the structural markup if needed to allow more flexible formatting with CSS. Assistive technologies can substitute or extend the CSS to modify presentation, or ignore the CSS and interact directly with the structural encoding.\n- **Example 2: Tagged PDF**  A PDF document consists mostly of the content embedded with formatting information. Information about the structure is provided in a separate section of the document using XML-like tags; this is called \"tagged PDF\". The information in these tags can be used by assistive technologies to perform meaningful structure transformations (e.g., generating a list of sections) or to support interaction with content based on structural characteristics (e.g., jumping to the start of forms).    ---",
    "referenced_by": [
      "1.3.1",
      "1.4.5",
      "1.4.9"
    ]
  },
  {
    "id": "ARIA24",
    "type": "technique",
    "code": "ARIA24",
    "text": "[ARIA24] Semantically identifying a font icon with role=\"img\"\n\nDescription:\nThe objective of this technique is to show how to semantically identify an element that uses a font file for icons. When a user overrides font-family these icons typically disappear unless there is a means to identify them. The point is to provide a technique to differentiate icon fonts from general font (text) usage.\n\nSome low vision users need user stylesheets, scripts, or extensions to override the fonts on a page to perceive text content. However, they need to be able to perceive icon fonts that are meaningful, such as a star signifying a favorite, or an email icon in a link.\n\nThe key is for the author to semantically markup icon fonts with **role=\"img\"**. Then the user's font replacement selector can hook into that semantic and exclude **role=\"img\"**. This results in those icon fonts being shown.\n\nThe first step is used for adding a font face with icons via the CSS file.\n\nThe second step adds classes, the role=\"img\" attribute for semantics and an accessible name.\n\nThe third step uses the \":not selector\" in combination with the \"[attribute] selector\" to only replace font faces for regular text.\n\nExamples:\n- **Example 1: Star Icon Font used as an indicator (not interactive)**  In this example a star icon is used to indicate a favorite. It is not interactive and does not disappear if the user overrides the font family via CSS.  ```html /* default class for fonts-face with icons */ .icon { font-family: 'IconFontRoleImg' !important; }  /* specific class for icon */ .icon-star-bg:before { content: \"\\e982\"; } ```  ```html <p> <span class=\"icon icon-star-bg\"></span> </p> ```  ```html <p> <span class=\"icon icon-star-bg\" role=\"img\" aria-label=\"Favorite\"></span> </p> ```  ```html *:not([role=\"img\"]) { font-family: Verdana, sans-serif !important; } ```\n- **Example 2: Two colored / stacked star Icon Font used as an indicator**  In this example a two colored star icon is created by stacking two fonts with different colors on top of each other. This way it's possible to mimic only half the star is filled. It is not interactive and does not disappear if the user overrides the font family via CSS.  ```html /* default class for fonts-face with icons */ .icon { font-family: 'IconFontRoleImg' !important; }  /* specific classes for icons */ .icon-star-bg:before    {content: \"\\e982\"; } .icon-star-half:before  {content: \"\\e983\"; } ```  ```html <span class=\"icon-stacked\"> <span class=\"icon icon-star-bg grey\"></span> <span class=\"icon icon-star-half yellow\"></span> </span> ```  ```html <span class=\"icon-stacked\" role=\"img\" aria-label=\"Favorite star half filled\"> <span class=\"icon icon-star-bg grey\" role=\"img\" aria-hidden=\"true\"></span> <span class=\"icon icon-star-half yellow\" role=\"img\" aria-hidden=\"true\"></span> </span> ```  ```html *:not([role=\"img\"]) { font-family: Verdana, sans-serif !important; } ```\n- **Example 3: Email Icon Font in a link WITHOUT visible text**  In this example an email icon is in a link with no visible text. It does not disappear if a user overrides font family. The icon font is identified by assistive technology as a \"link image\" and the name \"Email\" (keyboard or mouse).  ```html /* default class for fonts-face with icons */ .icon { font-family: 'IconFontRoleImg' !important; }  /* specific class for icon */ .icon-email:before { content: \"\\e93e\"; } ```  ```html <a href=\"email.html\"> <span class=\"icon icon-email\"></span> </a> ```  ```html <a href=\"email.html\"> <span class=\"icon icon-email\" role=\"img\" aria-label=\"Email\"></span> </a> ```  ```html *:not([role=\"img\"]) { font-family: Verdana, sans-serif !important; } ```\n- **Example 4: Multiple Icon Fonts as part of another sematic element WITH visible text**  This example already has a visible text label in the link to be used as an accessible name, the mail and chevron font icons must stay visible when the font family is changed. This can be done by ensuring the icons are contained in their own element and the attributearia-hidden=\"true\"is used so the font icons will be ignored by assistive technologies.  ```html /* default class for fonts-face with icons */ .icon { font-family: 'IconFontRoleImg' !important; }  /* specific class for icon */ - See style declarations in HTML examples - ```  ```html <style> .icon-double-link:before   { content: \"\\e93e\"; } .icon-double-link:after    { content: \"\\e993\"; } </style>  <a href=\"email.html\" class=\"icon-double-link\">Email</a> ```  ```html <style> .icon-email:before   { content: \"\\e93e\"; } .icon-chevron:before { content: \"\\e993\"; } .icon-double-link .icon-chevron  { float: right; margin-left: 1.5rem; } </style>  <a href=\"email.html\" class=\"icon-double-link\"> <span class=\"icon icon-email\" role=\"img\" aria-hidden=\"true\"></span> <span class=\"icon icon-chevron\" role=\"img\" aria-hidden=\"true\"></span> Email </a> ```  ```html *:not([role=\"img\"]) { font-family: Verdana, sans-serif !important; } ```    ---",
    "referenced_by": [
      "1.3.1"
    ]
  },
  {
    "id": "G138",
    "type": "technique",
    "code": "G138",
    "text": "[G138] Using semantic markup whenever color cues are used\n\nDescription:\nThe objective of this technique is to combine color and semantic markup to convey information. Most users can quickly scan the content to locate information conveyed by using color. For users who cannot see color, semantic markup can provide a different type of cue. User agents can then make this type of structure perceivable to the user, for example using a different visual presentation for different types of structures or by using a different voice or pitch in an auditory presentation.\n\nMost user agents will visually distinguish text that has been identified using semantic markup. Some assistive technologies provide a mechanism for determining the characteristics of content that has been created using proper semantic markup.\n\nExamples:\n- **Example 1: Color and strong emphasis for required form fields**  An HTML form contains several required fields. The labels for the required fields are displayed in red. In addition, the text of each label is marked up with the STRONG element for stronger emphasis. The instructions for completing the form indicate that \"all required fields are displayed in red and are emphasized\", followed by an example.    ---",
    "referenced_by": [
      "1.3.1"
    ]
  },
  {
    "id": "H51",
    "type": "technique",
    "code": "H51",
    "text": "[H51] Using table markup to present tabular information\n\nDescription:\nThe objective of this technique is to present tabular information in a way that\npreserves relationships within the information even when users cannot see the table or\nthe presentation format is changed. Information is considered tabular when logical\nrelationships among text, numbers, images, or other data exist in two dimensions\n(vertical and horizontal). These relationships are represented in columns and rows, and\nthe columns and rows must be recognizable in order for the logical relationships to be\nperceived.\n\nUsing the **table** element with the child elements **tr**,\n**th**, and **td** makes these relationships perceivable. Techniques\nsuch as inserting tabs to create columns or using the **pre** element are purely visual, and visually implied logical relationships are lost if the user cannot see the table or the visual presentation is changed.\n\nSimple tables generally have only one level of headers for columns and/or one level of headers on the rows.\n\nUsually, for simple tables, row 1 column 1 is either blank or describes the contents of the entire column 1. Row 1 columns are not blank (i.e., they contain \"column headings\"), describe the contents of the entire column, and allow the reader to distinguish the difference in meaning between that column and other columns.\n\nColumn 1 rows are usually not blank, they often contain \"row headings\" which describe the contents of the entire row, and allow the reader to distinguish the difference in meaning between that row and the other rows. Otherwise, the Column 1 would contain simple data.\n\nExamples:\n- **Example 1: A schedule marked up as a simple data table with column and row headers**  This example uses markup for a simple data table. The first row shows the days of the week. Time intervals are shown in the first column. These cells are marked with thethelement. This identifies the days of the week as column headers and the time intervals as row headers.  Screen readers speak header information that changes as the user navigates the table. Thus, when screen reader users move to left or right along a row, they will hear the day of the week (the column header) followed by the appointment (if any). They will hear the time interval as they move up or down within the same column.  ```html <table> <tr> <th>Time</th> <th>Monday</th> <th>Tuesday</th> <th>Wednesday</th> <th>Thursday</th> <th>Friday</th> </tr> <tr> <th scope=\"row\">8:00-9:00</th> <td>Meet with Sam</td> <td></td> <td></td> <td></td> <td></td> </tr> <tr> <th scope=\"row\">9:00-10:00</th> <td></td> <td></td> <td>Doctor Williams</td> <td>Sam again</td> <td>Leave for San Antonio</td> </tr> </table> ```    ---",
    "referenced_by": [
      "1.3.1"
    ]
  },
  {
    "id": "PDF6",
    "type": "technique",
    "code": "PDF6",
    "text": "[PDF6] Using table elements for table markup in PDF Documents\n\nDescription:\nThe purpose of this technique is to show how tables in PDF documents can be marked up so that they are recognized by assistive technology. This is typically accomplished by using a tool for authoring PDF.\n\nTabular information must be presented in a way that preserves relationships within the information even when users cannot see the table or the presentation format is changed. Information is considered tabular when logical relationships among text, numbers, images, or other data exist in two dimensions (vertical and horizontal). These relationships are represented in columns and rows, and the columns and rows must be recognizable in order for the logical relationships to be perceived.\n\nTagged tables can be created using the Add Tags to Document feature in Adobe Acrobat, using the Object Library in Adobe LiveCycle, or converting tables to PDF from a third-party application, such as Microsoft Word. However, the resulting tables may not be tagged correctly and you should ensure that table tagging issues are resolved.\n\nWithin PDF documents, a table uses the following structure types for table elements:\n\n- A table element (Table).\n- One or more table row elements (TR) which define each row of table cells as immediate children of theTableelement.\n- One or more table header elements (TH) or table data elements (TD) as the immediate children of each table row element.\n- Cells that span two or more rows or columns should use theRowSpanorColSpanattribute.\n- For tables that contain blank cells, you may need to add emptyTDcells so that each row or column has the same number of cells.\n\nExamples:\n- **Example 1: Creating tables in Microsoft Word that have correctly tagged headings when converted to PDF**  This example is shown with Word. There are other software tools that perform similar functions.  This example is shown in operation in theworking example of tagged table headings in Word.\n- **Example 2: Creating tables in OpenOffice.org Writer 2.2 that have correctly tagged headings when converted to PDF**  This example is shown with OpenOffice.org Writer. There are other software tools that perform similar functions.  This example is shown in operation in theworking example of tagged table headings in OpenOffice Writer.\n- **Example 3: Modifying table tags using the Tags tab in Adobe Acrobat Pro**  This example is shown with Adobe Acrobat Pro. There are other software tools that perform similar functions.  To check that a converted document with tables has correct table tagging:  Note that in this case, the table headers were incorrectly formatted, and are marked as data cells (TD). To change these toTHtags:  This example is shown in operation in theworking example of tagged table headings in Acrobat.\n- **Example 4: Marking up a table using table structure elements**  The following code fragment illustrates code that is typical for a simple table (header row and data row):  ```html 95 0 obj                %Structure element for a table << /A 39 0 R /K[96 0 R 101 0 R 106 0 R 111 0 R] /P 93 0 R /S/Table              %standard structure type is table >> endobj 96 0 obj                %Structure element for a table row << /K[97 0 R 98 0 R 99 0 R 100 0 R] /P 95 0 R /S/TR                 %standard structure type is table row >> endobj 97 0 obj                %Structure element for a table header << /A[23 0 R 120 0 R] /K 1 /P 96 0 R /S/TH                 %standard structure type is table head /Pg 8 0 R >> endobj 104 0 obj                %Structure element for table data (cell contents) << /A 29 0 R /K 7 /P 101 0 R /S/TD                  %standard structure type is table data /Pg 8 0 R >> endobj ```    ---",
    "referenced_by": [
      "1.3.1"
    ]
  },
  {
    "id": "PDF20",
    "type": "technique",
    "code": "PDF20",
    "text": "[PDF20] Using Adobe Acrobat Pro's Table Editor to repair mistagged tables\n\nDescription:\nThe purpose of this technique is to show how table cells in PDF documents\ncan be marked up so that the logical relationships among rows and columns\nare preserved and recognized by assistive technology. This is typically\naccomplished by using a tool for authoring PDF.\n\nHowever, tables converted to PDF may have incorrectly merged or split\ntable cells, even if they were marked up correctly in the authoring\ntool. Authors can ensure that table cells are structured properly by\nusing the Table Editor in Adobe Acrobat Pro's Reading Order\ntool.\n\nExamples:\n- **Example 1: Repairing table cells using the table editor in the Reading Order tool in Adobe Acrobat Pro**  This example is shown with Adobe Acrobat Pro. There are other software tools that perform similar functions.  This example uses a table that was marked up correctly when it was created in Microsoft Word. Some table headers span two rows in the header row; one table header spans two columns.  To check the table in the PDF document:  The following image shows the example table in the Reading Order tool.  The following images shows the example table in the Table Editor. The cells are outlined in red, and the tab for each cell is displayed. Upon conversion, the Results headers were correctly split, but most of the table headers were incorrectly tagged as table data cells.  To repair the header cells:  Similarly, to repair the incorrectly split header cells to the left of Results header:  The following image shows the repaired example table.  This example is shown in operation in theworking example of repairing table structure (Word file)andworking example of repairing table structure (PDF file).\n- **Example 2: Marking up a table using table structure elements**  The following code fragment illustrates code that is typical for a simple table (header row and data row) such as shown in Examples 1-3:  ```html 95 0 obj                %Structure element for a table << /A 39 0 R /K[96 0 R 101 0 R 106 0 R 111 0 R] /P 93 0 R /S/Table              %standard structure type is table >> endobj 96 0 obj                %Structure element for a table row << /K[97 0 R 98 0 R 99 0 R 100 0 R] /P 95 0 R /S/TR                 %standard structure type is table row >> endobj 97 0 obj                %Structure element for a table header <</A[23 0 R 120 0 R] /K 1 /P 96 0 R /S/TH                 %standard structure type is table head /Pg 8 0 R >> endobj 104 0 obj                %Structure element for table data (cell contents) << /A 29 0 R /K 7 /P 101 0 R /S/TD                  %standard structure type is table data /Pg 8 0 R >> endobj ```    ---",
    "referenced_by": [
      "1.3.1"
    ]
  },
  {
    "id": "H39",
    "type": "technique",
    "code": "H39",
    "text": "[H39] Using caption elements to associate data table captions with data tables\n\nDescription:\nThe objective of this technique is to programmatically associate captions for data\ntables where captions are provided in the presentation. The **caption** for a **table** is a table identifier and acts like a title or heading for the table.\n\nThe **caption** element is the appropriate markup for such text and it ensures that the table identifier remains associated with the table, including visually (by default). In addition, using the **caption** element allows screen reading software to navigate directly to the caption for a table if one is present.\n\nExamples:\n- **Example 1: An appointment calendar with acaption**  ```html <table> <caption>Schedule for the week of March 6</caption> ... </table> ```    ---",
    "referenced_by": [
      "1.3.1"
    ]
  },
  {
    "id": "H63",
    "type": "technique",
    "code": "H63",
    "text": "[H63] Using the scope attribute to associate header cells and data cells in data tables\n\nDescription:\nThe objective of this technique is to associate header cells with data cells in complex tables using the **scope** attribute. The **scope** attribute may be used to clarify the scope of any cell used as a header. The **scope** identifies whether the cell is a header for a row, column, or group of rows or columns. The values **row**, **col**, **rowgroup**, and **colgroup** identify these possible scopes, respectively.\n\nFor simple data tables where the header is not in the first row or column, like the one in Example 1, this technique can be used.\n\nExamples:\n- **Example 1: A simple schedule**  In the following example, the first column contains serial numbers for rows in the table, and the second column contains the key value for the row. The cells in the second column may then usescope=\"row\". The cells in the first row too are marked up withtdand usescope=\"col\".  ```html <table> <caption>Contact Information</caption> <tr> <td></td> <th scope=\"col\">Name</th> <th scope=\"col\">Phone Number</th> <th scope=\"col\">City</th> </tr> <tr> <td>1.</td> <th scope=\"row\">Charlotte Smith</th> <td>412-212-5421</td> <td>Pittsburgh</td> </tr> <tr> <td>2.</td> <th scope=\"row\">Joetta Frere</th> <td>410-306-5400</td> <td>Baltimore</td> </tr> <tr> <td>3.</td> <th scope=\"row\">David Walls</th> <td>281-511-6600</td> <td>New York</td> </tr> </table> ```    ---",
    "referenced_by": [
      "1.3.1"
    ]
  },
  {
    "id": "H43",
    "type": "technique",
    "code": "H43",
    "text": "[H43] Using id and headers attributes to associate data cells with header cells in data tables\n\nDescription:\nThe objective of this technique is to associate each data cell (in a data table) with the appropriate headers. This technique adds a **headers** attribute to each data cell (**td** element). It also adds an **id** attribute to any cell used as a header for other cells. The **headers** attribute of a cell contains a list of the **id** attributes of the associated header cells. If there is more than one **id**, they are separated by spaces.\n\nThis technique is used when data cells are associated with more than one row and/or one column header. This allows screen readers to speak the headers associated with each data cell when the relationships are too complex to be identified using the **th** element alone or the **th** element with the **scope** attribute. Using this technique also makes these complex relationships perceivable when the presentation format changes.\n\nThis technique is not recommended for layout tables since its use implies a relationship between cells that is not meaningful when tables are used for layout.\n\nExamples:\n- **Example 1: A table with multiple rows of headers**  ```html <table> <tr> <th rowspan=\"2\" id=\"h\">Homework</th> <th colspan=\"3\" id=\"e\">Exams</th> <th colspan=\"3\" id=\"p\">Projects</th> </tr> <tr> <th id=\"e1\" headers=\"e\">1</th> <th id=\"e2\" headers=\"e\">2</th> <th id=\"ef\" headers=\"e\">Final</th> <th id=\"p1\" headers=\"p\">1</th> <th id=\"p2\" headers=\"p\">2</th> <th id=\"pf\" headers=\"p\">Final</th> </tr> <tr> <td headers=\"h\">15%</td> <td headers=\"e e1\">15%</td> <td headers=\"e e2\">15%</td> <td headers=\"e ef\">20%</td> <td headers=\"p p1\">10%</td> <td headers=\"p p2\">10%</td> <td headers=\"p pf\">15%</td> </tr> </table> ```    ---",
    "referenced_by": [
      "1.3.1"
    ]
  },
  {
    "id": "PDF10",
    "type": "technique",
    "code": "PDF10",
    "text": "[PDF10] Providing labels for interactive form controls in PDF documents\n\nDescription:\nThe objective of this technique is to ensure that users of assistive\ntechnology are able to perceive form control labels and understand\nhow form controls are used.\n\nForm controls allow users to interact with a PDF document by filling\nin information or indicating choices which can then be submitted for\nprocessing. Assistive technology users must be able to recognize and\nunderstand the form fields, make selections, and provide input to complete\nthe forms, and submit the form, just as sighted users can. Understandable\nlabels that convey the purpose of each form control are essential to\nform accessibility.\n\nForm inputs generally have labels and instructions to help users understand\nwhat information is required and how to fill in the form. Unless these\nlabels are programmatically associated with the relevant fields, assistive\ntechnology might not be able to associate them correctly, and thus\nusers might not understand how to complete the form.\n\nUsing Adobe Acrobat Pro with documents with interactive forms, you\ncan make sure that the forms are accessible and usable by making sure\nthat programmatically associated labels that convey the purpose of\nthe fields are provided.\n\nThe heuristics used by assistive technology will sometimes use the\ntext label if a programmatically associated label cannot be found.\nThe TU entry (which is the tooltip) of the\nfield dictionary is the programmatically\nassociated label. Therefore, add a tooltip to each field to provide\na label that assistive technology can interpret.\n\nExamples:\n- **Example 1: Providing labels using the Forms tool in Adobe Acrobat Pro**  This example is shown with Adobe Acrobat Pro. There are other software tools that perform similar functions.  As noted in the Description, text labels added in an authoring tool and then converted to PDF might be visually associated with the fields but are not programmatically associated, and you should provide a tooltip.  This example is shown in operation in theworking example of providing labels using the forms tool (PDF).\n- **Example 2: Adding a tooltip to interactive form controls**  The following code fragment illustrates the use of the TU entry to provide a tooltip (or programmatically associated text label) for a form field. This is typically accomplished by an authoring tool.  ```html << /AP -dict- /DA /Helv  0 Tf 0 g /DR -dict- /F 0x4 /FT Tx              % FT key set to Tx for Text Field /P -dict- /Rect -array- /StructParent 0x1 /Subtype Widget /T Date you are available   % Partial field name Date /TU Date you are available: use MM/DD/YYYY format % TU tool tip serves as description /Type Annot /V Pat Jones >> ... <Start Stream> BT /P <</MCID 0 >>BDC /CS0 cs 0  scn /TT0 1 Tf -0.001 Tc 0.003 Tw 11.04 0 0 11.04 72 709.56 Tm [(P)-6(le)-3(as)10(e)-3( )11(P)-6(rin)2(t)-3( Y)8(o)-7(u)2(r N)4(a)11(m)-6(e)]TJ 0 Tc 0 Tw 9.533 0 Td ( )Tj -0.004 Tc 0.004 Tw 0.217 0 Td [(\\()-5(R)-4(e)5(q)-1(u)-1(i)-3(r)-3(e)-6(d)-1(\\))]TJ EMC /P <</MCID 1 >>BDC 0 Tc 0 Tw 4.283 0 Td [( )-2( )]TJ EMC /ArtifactSpan <</MCID 2 >>BDC 0.002 Tc -0.002 Tw 0.456 0 Td [(__)11(___)11(___)11(___)11(___)11(_)11(____)11(___)11(___)11(__)]TJ 0 Tc 0 Tw 13.391 0 Td ( )Tj EMC ET <End Stream> ```    ---",
    "referenced_by": [
      "1.3.1",
      "3.3.2",
      "4.1.2"
    ]
  },
  {
    "id": "PDF12",
    "type": "technique",
    "code": "PDF12",
    "text": "[PDF12] Providing name, role, value information for form fields in PDF documents\n\nDescription:\nThe objective of this technique is to ensure that assistive technologies\ncan gather information about and interact with form controls in PDF\ncontent.\n\nThe types of PDF form controls are: text input field, check box, radio\nbutton, combo box, list box, and button.\n\nProviding name, role, state, and value information for all form components\nenables compatibility with assistive technology, such as screen readers,\nscreen magnifiers, and speech recognition software used by people with\ndisabilities.\n\nThe following table describes how the role, name, value, and state\nare defined for PDF form controls created using Adobe Acrobat Pro.\nAdobe LiveCycle Designer provides the same controls as well as several\nadditional ones: see Example 2 below.\n\nExamples:\n- **Example 1: Specifying name, role, value and/or state for a form field using Adobe Acrobat Pro**  This example is shown with Adobe Acrobat Pro. There are other software tools that perform similar functions.  This example uses a check box for illustration; the procedure is the same for other form controls.  The image below shows the Check Box Properties dialog, open in the General tab. (The Name field in the dialog is not needed for accessibility.)  This example is shown in operation in theworking example of specifying name, role, value using Acrobat Pro.\n- **Example 2: Adding a checkbox in a PDF document using the/Btnfield type**  The following code fragment illustrates code that is typical for a simple check box field such as shown in Examples 1 and 2. This is typically accomplished by an authoring tool.  ```html 1 0 obj << /FT /Btn     % Role /TU Retiree  % Name /V /Yes      % Value /AS /Yes /AP << /N << /Yes 2 0 R /Off 3 0 R>> >> endobj ```    ---",
    "referenced_by": [
      "1.3.1",
      "4.1.2"
    ]
  },
  {
    "id": "H71",
    "type": "technique",
    "code": "H71",
    "text": "[H71] Providing a description for groups of form controls using fieldset and legend elements\n\nDescription:\nThe objective of this technique is to provide a semantic grouping for related form controls. This allows users to understand the relationship of the controls and interact with the form more quickly and effectively.\n\nForm controls can be grouped by enclosing them within the **fieldset** element. All controls within a given **fieldset** are then related. The first element inside the **fieldset** must be a **legend** element, which provides a label or description for the group. Authors should avoid nesting **fieldset**s unnecessarily, as this can lead to confusion.\n\nGrouping controls is most important for related radio buttons and checkboxes. A set of radio buttons or checkboxes is related when they all submit values for a single named field. They work in the same way as selection lists, allowing the user to choose from a set of options, except selection lists are single controls while radio buttons and checkboxes are multiple controls. The individual label associated with each radio or checkbox control may not fully convey the group's descriptive context. In this situation, it is essential that they be grouped together semantically to facilitate being treated as a single control, as well as to provide an additional group level description. Often, user agents will present the value of the **legend** before the label of each control to provide this description, as well as to remind users that they are part of the same group.\n\nIt can also be useful to group other sets of controls less tightly related than radio buttons and checkboxes. For instance, several fields that collect a user's address might be grouped together with a **legend** of \"Address\", thus providing a group level description for these controls. As a rule of thumb, it can be said that where a group of controls within a larger form requires an additional heading to provide a description specific to that particular group, the use of fieldset and legend elements is appropriate.\n\nHowever, when a group of related radio buttons or checkboxes (even having values for a single named field) includes clear instructions and distinct selections (i.e., where the individual label associated with each particular control provides a sufficient description), the use of the **fieldset** and **legend** elements is not required. [H44](../html/H44) is sufficient in this case.\n\nAuthors sometimes avoid using the **fieldset** element because of the default display in the browser, which draws a border around the grouped controls. This visual grouping is also useful and authors should seriously consider retaining it (or some form of visual grouping). The visual effect can be modified in CSS by overriding the **border** property of the **fieldset** and the **position** property of the **legend**.\n\nExamples:\n- **Example 2: A set of checkboxes**  The User Profile page for a website allows users to indicate their interests by selecting multiple checkboxes. Each checkbox (input type=\"checkbox\") has alabel. The checkboxes are contained within afieldset, and thelegendelement contains the prompt for the entire group of checkboxes.  ```html <fieldset> <legend>I am interested in the following (check all that apply):</legend> <div> <input id=\"photo\" name=\"interests\" type=\"checkbox\" value=\"ph\"> <label for=\"photo\">Photography</label> </div> <div> <input checked=\"checked\" id=\"watercol\" name=\"interests\" type=\"checkbox\" value=\"wa\"> <label for=\"watercol\">Watercolor</label> </div> <div> <input checked=\"checked\" id=\"acrylic\" name=\"interests\" type=\"checkbox\" value=\"ac\"> <label for=\"acrylic\">Acrylic</label> </div> </fieldset> ```\n- **Example 1: A multiple choice test**  This example shows a test item with one question and five possible answers. Each answer is represented by a radio button (input type=\"radio\"). The radio buttons are contained within afieldset. The test question is tagged with thelegendelement. Each field has the samenameattribute, indicating these radio buttons are related, and should be grouped as shown. Also note that while thenameattributes have the same value, theidattributes' values must be unique.  ```html <fieldset> <legend>The play <cite>Hamlet</cite> was written by:</legend> <div> <input checked=\"checked\" id=\"shakesp\" name=\"hamlet\" type=\"radio\" value=\"a\"> <label for=\"shakesp\">William Shakespeare</label> </div> <div> <input id=\"austen\" name=\"hamlet\" type=\"radio\" value=\"b\"> <label for=\"austen\">Jane Austen</label> </div> <div> <input id=\"gbshaw\" name=\"hamlet\" type=\"radio\" value=\"c\"> <label for=\"gbshaw\">George Bernard Shaw</label> </div> <div> <input id=\"woolf\" name=\"hamlet\" type=\"radio\" value=\"d\"> <label for=\"woolf\">Virginia Woolf</label> </div> <div> <input id=\"dickens\" name=\"hamlet\" type=\"radio\" value=\"e\"> <label for=\"dickens\">Charles Dickens</label> </div> </fieldset> ```\n- **Example 3: Logically related controls**  In this example, form fields for residential and postal addresses are distinguished by the value of thelegendin eachfieldsetgrouping.  ```html <form action=\"/adduser\" method=\"post\"> <fieldset> <legend>Your Residential Address</legend> <div> <label for=\"raddress\">Address:</label> <input autocomplete=\"street-address\" id=\"raddress\" name=\"raddress\" type=\"text\"> </div> <div> <label for=\"rzip\">Postal/Zip Code:</label> <input autocomplete=\"postal-code\" id=\"rzip\" name=\"rzip\" type=\"text\"> </div> </fieldset> <fieldset> <legend>Your Postal Address</legend> <div> <label for=\"paddress\">Address:</label> <input autocomplete=\"street-address\" id=\"paddress\" name=\"paddress\" type=\"text\"> </div> <div> <label for=\"pzip\">Postal/Zip Code:</label> <input autocomplete=\"postal-code\" id=\"pzip\" name=\"pzip\" type=\"text\"> </div> </fieldset> </form> ```    ---",
    "referenced_by": [
      "1.3.1",
      "3.3.2"
    ]
  },
  {
    "id": "H85",
    "type": "technique",
    "code": "H85",
    "text": "[H85] Using OPTGROUP to group OPTION elements inside a SELECT\n\nDescription:\nThe objective of this technique is to group items in a selection list. A selection list is a set of allowed values for a form control such as a multi-select list or a combo box. Often, selection lists have groups of related options. Those groups should be semantically identified, rather than being delimited with \"dummy\" list entries, for example: an **option** element containing only a series of dashes to create a horizontal line. Semantically identifying groups of options helps to visually break up long lists so that users can more easily locate what they are interested in.\n\nIn HTML, the **select** element is used to create both multi-select lists and combo boxes. The various allowed options are each indicated with **option** elements. To group options together, use the **optgroup** element, with the related **option** elements inside that element. Label the group with the **label** attribute so users will know what to expect inside the group.\n\nThe **optgroup** element should be directly inside the **select** element, and the **option**  elements directly inside the **optgroup**. It is possible for a **select** element to contain both single **option** elements and **optgroup** groups, though authors should consider if this is in fact the desired intent when using this. It is not possible to nest the **optgroup** element, so only one level of grouping can be done within a **select**.\n\nIf grouping information is essential to understanding the list, authors may define **option** labels that can be understood even when the screen reader does not present the grouping information provided by **optgroup**.\n\nExamples:\n- **Example 1**  The following combo box collects data about favorite foods. Grouping by type allows users to select their preference more quickly.  ```html <form action=\"/favorite-food/\" method=\"post\"> <label for=\"food\">What is your favorite food?</label> <select id=\"food\" name=\"food\"> <optgroup label=\"Fruits\"> <option value=\"1\">Apples</option> <option value=\"2\">Bananas</option> <option value=\"3\">Peaches</option> </optgroup> <optgroup label=\"Vegetables\"> <option value=\"4\">Broccoli</option> <option value=\"5\">Carrots</option> <option value=\"6\">Cucumbers</option> </optgroup> <optgroup label=\"Baked Goods\"> <option value=\"7\">Apple Pie</option> <option value=\"8\">Bagels</option> <option value=\"9\">Chocolate Cake</option> </optgroup> </select> </form> ```\n- **Example 2**  The following example shows how a multi-select box can make use of theoptgroupelement.  ```html <form action=\"/animals/\" method=\"post\"> <label for=\"animals\">Pick your favorite animals:</label> <select id=\"animals\" multiple name=\"animals\" size=\"10\"> <optgroup label=\"Dinosaurs\"> <option value=\"brontosaurus\">Brontosaurus</option> <option value=\"pterodactyl\">Pterodactyl</option> <option value=\"trex\">Tyrannosaurus Rex</option> <option value=\"velociraptor\">Velociraptor</option> </optgroup> <optgroup label=\"Ungulates\"> <option value=\"camel\">Camel</option> <option value=\"giraffe\">Giraffe</option> <option value=\"hippo\">Hippo</option> <option value=\"horse\">Horse</option> <option value=\"zebra\">Zebra</option> </optgroup> <optgroup label=\"Household Pets\"> <option value=\"cat\">Cat</option> <option value=\"dog\">Dog</option> <option value=\"fish\">Fish</option> <option value=\"rabbit\">Rabbit</option> </optgroup> </select> </form> ```    ---",
    "referenced_by": [
      "1.3.1"
    ]
  },
  {
    "id": "H48",
    "type": "technique",
    "code": "H48",
    "text": "[H48] Using ol, ul and dl for lists or groups of links\n\nDescription:\nThe objective of this technique is to create lists of related items using list elements appropriate for their purposes. The **ol** element is used when the list is ordered and the **ul** element is used when the list is unordered. Description lists (**dl**) are used to group name-value pairs of information, for example: terms and definitions or questions and answers. Although the use of this markup can make lists more readable, not all lists need markup. For instance, sentences that contain comma-separated lists may not need list markup.\n\nWhen markup is used that visually formats items as a list but does not indicate the list relationship, users may have difficulty in navigating the information. An example of such visual formatting is including asterisks in the content at the beginning of each list item and using **br** elements to separate the list items.\n\nSome assistive technologies allow users to navigate from list to list or item to item. Style sheets can be used to change the presentation of the lists while preserving their integrity.\n\nThe list structure, commonly unordered lists, is also useful to group hyperlinks. When this is done, it helps screen reader users to navigate from the first item in a list to the end of the list or jump to the next list. This helps them to bypass groups of links if they choose to.\n\nExamples:\n- **Example 1: A list showing steps in a sequence**  This example uses an ordered list to show the sequence of steps in a process.  ```html <ol> <li>Mix flour, eggs, milk, and seasoning in a bowl.</li> <li>Whisk until the batter is smooth.</li> <li>Rest the batter for at least 30 minutes before cooking.</li> </ol> ```\n- **Example 2: A grocery list**  This example shows an unordered list of items to buy at the store.  ```html <ul> <li>Milk</li> <li>Eggs</li> <li>Butter</li> </ul> ```\n- **Example 3: A word and its definition**  This example uses a description list to group a definition with the term that is being defined.  ```html <dl> <dt>blink</dt> <dd>turn on and off between 0.5 and 3 times per second</dd> </dl> ```\n- **Example 4: Contact information using a description list**  This example uses a description list to mark up pairs of related items. The pairs themselves are a logically related list.  This is shown in theworking example of contact information using a description list.  ```html <dl> <div> <dt>Name:</dt> <dd>Taisha Silveri</dd> </div> <div> <dt>Tel:</dt> <dd>503-123-4567</dd> </div> <div> <dt>Email:</dt> <dd>taisha-silveri@example.com</dd> </div> </dl> ```\n- **Example 5: Using lists to group links**  In this example the links are grouped using theulandlielements.  ```html <h2 id=\"product-categories\">Product Categories</h2> <nav aria-labelledby=\"product-categories\"> <ul> <li><a href=\"kitchen.html\">Kitchen</a></li> <li><a href=\"bedbath.html\">Bed &amp; Bath</a></li> <li><a href=\"dining.html\">Fine Dining</a></li> <li><a href=\"lighting.html\">Lighting</a></li> <li><a href=\"storage.html\">Storage</a><li> </ul> </nav> ```    ---",
    "referenced_by": [
      "1.3.1"
    ]
  },
  {
    "id": "H42",
    "type": "technique",
    "code": "H42",
    "text": "[H42] Using h1-h6 to identify headings\n\nDescription:\nThe objective of this technique is to use HTML heading markup to provide semantic code for headings in the content. Heading markup will allow assistive technologies to present the heading status of text to a user. A screen reader can recognize the code and announce the text as a heading with its level, beep or provide some other auditory indicator. Screen readers are also able to navigate heading markup which can be an effective way for screen reader users to more quickly find the content of interest. Assistive technologies that alter the authored visual display will also be able to provide an appropriate alternate visual display for headings that can be identified by heading markup.\n\nExamples:\n- **Example 1: Hierarchical Heading Organization**  In the following example, headings are used in a hierarchical layout withh3as a subsection ofh2, which is a subsection ofh1.  ```html <h1>Plant Foods that Humans Eat</h1> <p>There are an abundant number of plants that humans eat ...</p> <h2>Fruit</h2> <p>A fruit is a structure of a plant that contains its seeds ...</p> <h3>Apple</h3> <p>The apple is the pomaceous fruit of the apple tree ...</p> <h3>Orange</h3> <p>The orange is a hybrid of ancient cultivated origin ...</p> <h3>Banana</h3> <p>Banana is the common name for herbaceous plants ...</p> <h2>Vegetables</h2> <p>A vegetable is an edible plant or part of a plant other than a sweet fruit ...</p> <h3>Broccoli</h3> <p>Broccoli is a plant of the mustard/cabbage family ...</p> <h3>Brussels sprouts</h3> <p>The Brussels sprout of the Brassicaceae family, is a Cultivar group of wild cabbage ...</p> <h3>Green beans</h3> <p>Green beans have been bred for the fleshiness, flavor, or sweetness of their pods ...</p> ```\n- **Example 2: Headings in a three-column layout**  In this example, the main content of the page is in the middle column of a three-column page. The title of the main content matches the title of the page, and is marked ash1, even though it is not the first thing on the page. The content in the first and third columns is less important, and marked withh2.  ```html <!doctype html> <html lang=\"en\"> <head> <title>Stock Market Up Today</title> </head> <body> <!-- left nav --> <nav class=\"left-nav\"> <h2>Site Navigation</h2> <!-- content here --> </nav>  <!-- main contents --> <main class=\"main\"> <h1>Stock Market up today</h1> <!-- content here --> </main>  <!-- right panel --> <aside class=\"side-bar\"> <h2>Related links</h2> <!-- content here --> </aside> </body> </html> ```    ---",
    "referenced_by": [
      "1.3.1"
    ]
  },
  {
    "id": "PDF9",
    "type": "technique",
    "code": "PDF9",
    "text": "[PDF9] Providing headings by marking content with heading tags in PDF documents\n\nDescription:\nThe purpose of this technique is to show how headings in PDF documents can be marked so that they are recognized by assistive technologies. Headings are marked up using the heading elements (**H**, **H1**, **H2**, ... **H6**) in the structure tree. This is typically accomplished by using a tool for authoring PDF.\n\nHeading markup can be used:\n\n- to indicate start of main content;\n- to mark up section headings within the main content area;\n- to demarcate different navigational sections, such as top or main navigation, left or secondary navigation, and footer navigation;\n- to mark up images (containing text) which have the appearance of headings visually.\n\nBecause headings indicate the start of important sections of content, it is possible for assistive technology users to access the list of headings and to jump directly to the appropriate heading and begin reading the content. This ability to \"skim\" the content through the headings and go directly to content of interest significantly speeds interaction for users who would otherwise access the content slowly.\n\nExamples:\n- **Example 2: Creating documents in Microsoft Word that have correctly tagged headings when converted to PDF**  This example is shown with Microsoft Word. There are other software tools that perform similar functions.  Use Styles to create heading formats: Heading 1, Heading 2, Heading 3, etc. Make styles progress in a logical manner; e.g., a Heading 2 should come after a Heading 1.    ---\n- **Example 1: Adding or modifying tagged headings in PDF documents with Adobe Acrobat Pro**  This example is shown with Adobe Acrobat Pro. There are other software tools that perform similar functions.  To correct theH3:",
    "referenced_by": [
      "1.3.1",
      "2.4.1"
    ]
  },
  {
    "id": "SCR21",
    "type": "technique",
    "code": "SCR21",
    "text": "[SCR21] Using functions of the Document Object Model (DOM) to add content to a page\n\nDescription:\nThe objective of this technique is to demonstrate how to use functions of the Document\nObject Model (DOM) to add content to a page. If the DOM functions are used to add\nthe content, user agents can access the DOM to retrieve the content. The **createElement()** function can be used to create elements within the DOM. The **createTextNode()** is used to create text associated with elements. The **appendChild()**, **removeChild()**, **insertBefore()**, and **replaceChild()** functions are used to add and remove elements and nodes. Other DOM functions are\nused to assign attributes to the created elements.\n\nExamples:\n- **Example 1**  This example demonstrates use of client-side scripting to validate a form. If errors are found appropriate error messages are displayed. The example uses the DOM functions to add error notification consisting of a title, a short paragraph explaining that an error has occurred, and a list of errors in an ordered list. The content of the title is written as a link so that it can be used to draw the user's attention to the error using the focus method. Each item in the list is also written as a link that places the focus onto the form field in error when the link is followed.  For simplicity, the example just validates two text fields, but can easily be extended to become a generic form handler. Client-side validation should not be the sole means of validation, and should be backed up with server-side validation. The benefit of client-side validation is that you can provide immediate feedback to the user to save them waiting for the errors to come back from the server, and it helps reduce unnecessary traffic to the server.  Here is the script that adds the event handlers to the form. If scripting is enabled, thevalidateNumbers()function will be called to perform client-side validation before the form is submitted to the server. If scripting is not enabled, the form will be immediately submitted to the server, so validation should also be implemented on the server.  Here is the validation function.  Note the use of thecreateElement(),createTextNode(), andappendChild()DOM functions to create the error message elements.  Below are the helper functions to create the error message and to set focus to the associated form field.  Here is the HTML for the example form.  This example is limited to client-side scripting, and should be backed up with server-side validation. The example is limited to the creation of error messages when client-side scripting is available.  Here is a link to a working example:Form Validation  ```html window.onload = initialise; function initialise() { // Add an event handler for the number form var objForm = document.getElementById('numberform'); objForm.onsubmit= function(){return validateNumbers(this);}; } ```  ```html function validateNumbers(objForm) { // Test whether fields are valid var bFirst = isNumber(document.getElementById('num1').value); var bSecond = isNumber(document.getElementById('num2').value); // If not valid, display errors if (!bFirst || !bSecond) { var objExisting = document.getElementById('validationerrors'); var objNew = document.createElement('div'); var objTitle = document.createElement('h2'); var objParagraph = document.createElement('p'); var objList = document.createElement('ol'); var objAnchor = document.createElement('a'); var strID = 'firsterror'; var strError; // The heading element will contain a link so that screen readers // can use it to place focus - the destination for the link is // the first error contained in a list objAnchor.appendChild(document.createTextNode('Errors in Submission')); objAnchor.setAttribute('href', '#firsterror'); objTitle.appendChild(objAnchor); objParagraph.appendChild(document.createTextNode('Please review the following')); objNew.setAttribute('id', 'validationerrors'); objNew.appendChild(objTitle); objNew.appendChild(objParagraph);  // Add each error found to the list of errors if (!bFirst) { strError = 'Please provide a numeric value for the first number'; objList.appendChild(addError(strError, '#num1', objForm, strID)); strID = ''; } if (!bSecond) { strError = 'Please provide a numeric value for the second number'; objList.appendChild(addError(strError, '#num2', objForm, strID)); strID = ''; }  // Add the list to the error information objNew.appendChild(objList);  // If there were existing errors, replace them with the new lot, // otherwise add the new errors to the start of the form if (objExisting) { objExisting.parentNode.replaceChild(objNew, objExisting); } else { var objPosition = objForm.firstChild; objForm.insertBefore(objNew, objPosition); }  // Place focus on the anchor in the heading to alert // screen readers that the submission is in error objAnchor.focus();  // Do not submit the form objForm.submitAllowed = false; return false; } return true; }  // Function to validate a number function isNumber(strValue) { return (!isNaN(strValue) && strValue.replace(/^\\s+|\\s+$/, '') !== ''); } ```  ```html // Function to create a list item containing a link describing the error // that points to the appropriate form field function addError(strError, strFragment, objForm, strID) { var objAnchor = document.createElement('a'); var objListItem = document.createElement('li'); objAnchor.appendChild(document.createTextNode(strError)); objAnchor.setAttribute('href', strFragment); objAnchor.onclick = function(event){return focusFormField(this, event, objForm);}; objAnchor.onkeypress = function(event){return focusFormField(this, event, objForm);};  // If strID has a value, this is the first error in the list if (strID.length > 0){ objAnchor.setAttribute('id', strID); } objListItem.appendChild(objAnchor); return objListItem; }  // Function to place focus to the form field in error function focusFormField(objAnchor, objEvent, objForm) {  // Allow keyboard navigation over links if (objEvent && objEvent.type == 'keypress') { if (objEvent.keyCode != 13 && objEvent.keyCode != 32){ return true; } }  // set focus to the form control var strFormField = objAnchor.href.match(/[^#]\\w*$/); objForm[strFormField].focus(); return false; } ```  ```html <!doctype html> <html lang=\"en\"> <head> <meta charset=\"utf-8\"> <title>ECMAScript Form Validation</title> <script src=\"validate.js\"></script> </head> <body> <h1>Form Validation</h1> <form id=\"numberform\"> <fieldset> <legend>Numeric Fields</legend> <div> <label for=\"num1\">Enter first number</label> <input type=\"text\" size=\"20\" name=\"num1\" id=\"num1\"> </div> <div> <label for=\"num2\">Enter second number</label> <input type=\"text\" size=\"20\" name=\"num2\" id=\"num2\"> </div> </fieldset> <div> <input type=\"submit\" name=\"submit\" value=\"Submit Form\"> </div> </form> </body> </html> ```    ---",
    "referenced_by": []
  },
  {
    "id": "PDF11",
    "type": "technique",
    "code": "PDF11",
    "text": "[PDF11] Providing links and link text using the Link annotation and the /Link structure element in PDF documents\n\nDescription:\nThe purpose of this technique is to show how link text in PDF documents\ncan be marked up to be recognizable by keyboard and assistive technology\nusers. That is, the link information is programmatically available\nto user agents so that links are recognizable when presented in a different\nformat. This is typically accomplished by using a tool for authoring\nPDF.\n\nLinks in PDF documents are represented by a Link tag and objects in\nits sub-tree, consisting of a link object reference (or Link annotation)\nand one or more text objects. The text object or objects inside the\nLink tag are used by assistive technologies to provide a name for the\nlink.\n\nThe simplest way to provide links that comply with the WCAG success\ncriteria is to create them when authoring the document, before conversion\nto PDF.\n\nHowever, in some cases, it may not be possible to create the links\nusing the original authoring tool. In these cases, Adobe Acrobat Pro\ncan be used to create the link. But, because the tooltip created using\nthe Link dialog in Adobe Acrobat Pro is not accessible to screen readers,\nbe sure that the link text or the link context makes the purpose clear.\n\nIn all cases, link purpose should be made clear as described in the\ngeneral techniques:\n\n- G53:\nIdentifying the purpose of a link using link text combined with\nthe text of the enclosing sentence\n- G91:\nProviding link text that describes the purpose of a link\n\nExamples:\n- **Example 3: Creating a hyperlink using the Create Link dialog in Adobe Acrobat Pro**  This example is shown with Adobe Acrobat Pro. There are other software tools that perform similar functions.  This example is shown in operation in theworking example of creating a hyperlink in a PDF.\n- **Example 2: Creating a hyperlink in OpenOffice Writer before conversion to PDF**  This example is shown with OpenOffice Writer. There are other software tools that perform similar functions.\n- **Example 4: Marking up link text using a/Linkstructure element**  Link annotations in PDF documents are associated with a geometric region of a page rather than a particular object in a content stream. For this reason, link annotations alone are not useful for users with visual impairments, or to applications that must determine which content can be activated to invoke a hypertext link.  Tagged PDF/Linkelements use PDF's logical structure to establish the association between content items and link annotations, providing functionality comparable toHTMLhypertext links.  In HTML, the following example produces text containing a hypertext link:  In PDF the page must be painted first and then a link annotation placed over the area where the object action will occur.  The following code fragment shows PDF equivalent to the HTML above; it uses link text displayed in blue and underlined. A second code fragment follows, indicating the associated logical structure hierarchy. This is typically accomplished by an authoring tool.  The following code fragment is an excerpt from the logical structure that establishes the association between the content items and the link annotation:  ```html <p>Here is some text <a href=\"https://www.w3.org/WAI/\">with a link</a> inside.</p> ```  ```html /P <</MCID 0>>                                                %Marked Content Sequence 0 (paragraph) BDC                                                          %Begin marked content sequence BT                                                          %Begin text object /F1 11.04 Tf                                               %set text font and size 1 0 0 1 72.024 709.54 Tm                                   %set text matrix 0 g                                                        %set non stroking color to black 0 G                                                        %set stroke color to black [(H)3(ere )-4(is s)10(o)5(m)-4(e)9( t)-3(e)9(xt)-3( )] TJ   %Show text preceding the link\" Here is some text\" ET                                                          %end text object EMC                                                          %end marked content sequence  /Span <</MCID 1>>                                             %Marked Content Sequence 1 (underlined link text) BDC                                                          %Begin marked content sequence BT                                                          %Begin text object 1 0 0 1 152.42 709.54 Tm                                   %set text matrix 0 0 1 rg                                                   %set non-stroking color to blue 0 0 1 RG                                                   %set stroke color to blue [(with a )-2(li)3(n)14(k)] TJ                              %Show link text \" with a link\" ET                                                          %end text object 0 0 1 rg                                                   %set stroke color to blue 152.42 707.62 45.984 0.72 re                               %rectangle operator - target area for the link f*                                                         %fill the path using the even-odd rule EMC                                                          %end marked content sequence  /P <</MCID 2>>                                                %Marked Content Sequence 2 (paragraph) BDC                                                          %Begin marked content sequence BT                                                          %begin text object 1 0 0 1 198.41 709.54 Tm                                   %set text matrix 0 g                                                        %set non stroking color to black 0 G                                                        %set stroke color to black [( )] TJ                                                   %empty text string showing white space ET                                                          %end text object BT                                                          %begin text object 1 0 0 1 200.93 709.54 Tm                                   %set text matrix [(in)5(sid)5(e.)] TJ                                       %show text following the link \"inside.\" ET                                                          %end text BT                                                          %begin text object 1 0 0 1 229.97 709.54 Tm                                   %set text matrix [( )] TJ                                                   %empty text string showing white space ET                                                          %end text object EMC                                                          %end marked content sequence ```  ```html 11 0 obj                                              %Object ID 11, generation   0, obj keyword <</K[1                                               %immediate child of the structure tree root << /Obj 26 0 R                                        %reference to Object 26 /Type/OBJR                                         %this object describes an indirect object reference >>] /P 12 0 R /Pg 17 0 R /S/Link >> endobj  26 0 obj                                              %object ID 26 which is referenced by the OBJR in Object 11 <</A 31 0 R /BS <</S/S /Type/Border /W 0 >> /Border[0 0 0]                                      %a colorless border /H/I /Rect[150.128 694.558 200.551 720.0]                %the boundaries defining target area where link annotation is active /StructParent 1 /Type/Annot                                         %Structure element is an annotation /Subtype/Link >>                                                   %It is a link annotation endobj 31 0 obj                                              %Object 31, gen 0, obj <</S/URI                                             %Object type is URI action /URI(https://www.w3.org/WAI)                        %The Uniform resource identifier to resolve >> endobj ```    ---\n- **Example 1: Creating a hyperlink in Microsoft Word before conversion to PDF**  This example is shown with Microsoft Word. There are other software tools that perform similar functions.  To create a hyperlink in Microsoft Word:",
    "referenced_by": [
      "1.3.1",
      "2.1.1",
      "2.4.4",
      "2.4.9"
    ]
  },
  {
    "id": "PDF17",
    "type": "technique",
    "code": "PDF17",
    "text": "[PDF17] Specifying consistent page numbering for PDF documents\n\nDescription:\nThe objective of this technique is to help users locate themselves in a document by ensuring that the page numbering displayed in the PDF viewer page controls has the same page numbering as the document. For example, Adobe Acrobat Pro and Reader display page numbers in the Page Navigation toolbar. The page number format is specified by the **/PageLabels** entry in the Document Catalog.\n\nMany documents use specific page number formats within a document. Commonly, front matter is numbered with lowercase Roman numerals. The main content, starting on the page numbered 1, may actually be the fifth or sixth page in the document. Similarly, appendices may begin with page number 1 plus a prefix of the appendix letter (e.g., \"A-1\").\n\nAuthors should make sure that the page numbering of their converted documents is reflected in any page number displays in their user agent. Consistency in presenting the document's page numbers will help make navigating the document more predictable and understandable.\n\nAs an example, if **/PageLabels** has not been provided to describe the page number formatting, the page numbering scheme will not be reflected in the Page Navigation toolbar in Adobe Acrobat Pro or Reader. This toolbar displays the page number in a text box, which users can change to move to another page. In addition, users can select the arrows to move one page up or down in the document. The toolbar also displays the relative page number location. In the image below, the default display indicates the user is on page 12 of 116 pages.\n\nA more direct way of going to a page is to use the shortcut for the View > Page Navigation → Go To Page menu item. On Windows, this shortcut is \"Ctrl+Shift+N\"; on Mac OS, it is \"Cmd+Shift + N\". This brings up a dialog box to go to a specific page number.\n\nExamples:\n- **Example 2: Adding Page Numbers in OpenOffice Writer**  To add page numbering in OpenOffice with Writer, the user needs to add a footer from the Insert dropdown.  After inserting the footer, click in the footer then select Insert ← Fields ← Page Number.\n- **Example 1: Editing PDF page number formatting specifications using Adobe Acrobat Pro**  This example is shown with Adobe Acrobat Pro. There are other software tools that perform similar functions.  The example document converted from Microsoft Word has 4 pages, numbered i, ii, iii, iv, and 1. This is specified In Word using the Format Page Numbers in the Page Number option in Word's Insert ribbon.  In this document, a new section has been created with page numbering beginning with Arabic numeral 1 on the fourth page of the document. The document was then converted to PDF from Word.  In Adobe Acrobat Pro:  To correct the page numbers:  The following image shows the Page Numbering dialog and selections.  Follow the same process to change the fifth page number to Arabic numeral 1.  The following image shows the correct page numbers for the 5 pages.  This example is shown in operation in theworking example of specifying page numbers in a document converted from Word (Word file)andworking example of specifying page numbers in a document converted from Word (PDF file).\n- **Example 3: Specifying page numbers using the/PageLabelsentry**  The following code fragment illustrates code that is typical for specifying multiple page numbering schemes in a document.  The example below is for a document with pages labeled: i, ii, iii, iv, 1, 2, 3, A-8, A-9, ...  This numbering scheme requires 3 page-label dictionaries (for lowercase Roman, Arabic, and prefixed numbers)  Page labels are specified as follows:  ```html 1 0 obj << /Type /Catalog /PageLabels << /Nums [ 0 << /S /r >>  % lowercase Roman numerals 4 << /S /D >>  % Arabic numerals 7 << /S /D     % Arabic numerals with ... /P (A-)                % the prefix \"A-\"... /St 8                  % starting at page 8 >> ] >> ... >> endobj ```    ---",
    "referenced_by": [
      "1.3.1",
      "2.4.8",
      "3.2.3"
    ]
  },
  {
    "id": "PDF21",
    "type": "technique",
    "code": "PDF21",
    "text": "[PDF21] Using List tags for lists in PDF documents\n\nDescription:\nThe intent of this technique is to create lists of related items using list elements appropriate for their purposes. PDF files containing lists are normally created or repaired using a tool for authoring PDF.\n\nWhen markup is used that visually formats items as a list but does not indicate the list relationship, users may have difficulty navigating the information. An example of such visual formatting is simply using line-breaks to separate list items.\n\nSome assistive technologies allow users to navigate from list to list or item to item. If the lists are not correctly formatted with list tags, these users will have difficulty understanding the list content.\n\nThe easiest way to create lists in PDF content is to format them properly using list markup in the authoring tool, for example, Microsoft Word or OpenOffice Writer. However, if you do not have access to the source file and authoring tool, you can use Acrobat Pro's Reading Order tool and the Tags panel.\n\nThe structure types for lists in PDF documents are:\n\n- L- the List tag, which contains one or moreLItags.\n- LI- the List Item tag. List item tags can containLblandLBodytags.\n- Lbl- the list item label. Contains distinguishing information such as a item number or bullet character.\n- LBody- the list item body. Contains list item content, or in the case of a nested list, it may contain additional List tag trees.\n\nExamples:\n- **Example 1: Adding lists to Microsoft Word documents**  This example is shown with Microsoft Word. There are other software tools that perform similar functions.  On the Home ribbon, use the lists tools to create or repair lists in Word documents. This is the easiest way to ensure that lists are formatted correctly when they are converted to PDF.\n- **Example 2: Adding lists to OpenOffice Writer documents**  This example is shown with OpenOffice Writer. There are other software tools that perform similar functions.  Use the Bullets and Numbering tool to create or repair lists in OpenOffice Writer documents. This is the easiest way to ensure that lists are formatted correctly when they are converted to PDF.\n- **Example 3: Ensuring that lists are correctly formatted using Adobe Acrobat Pro**  This example is shown with Adobe Acrobat Pro. There are other software tools that perform similar functions.  In the following image, the third list is formatted as text. The list items are separated only by line-breaks. Assistive technology may not be able to render the list intelligibly for users.  To repair the list, use the Tags panel to create list tags in the content.  The following image shows the resulting first list item correctly formatted.  This example, with two list items not nested inside the list element, is shown in theworking example of ensuring lists are properly formatted.    ---",
    "referenced_by": [
      "1.3.1"
    ]
  },
  {
    "id": "H97",
    "type": "technique",
    "code": "H97",
    "text": "[H97] Grouping related links using the nav element\n\nDescription:\nThe objective of this technique is to group navigation links using the HTML **nav** element. The **nav** element is one of several sectioning elements in HTML. Use of this markup can make groups of links easier to locate and skip past by users of assistive technology such as screen readers. Using semantic structures allow custom style sheets to be used to change the presentation of groups of links while preserving their relationship. When the **nav** element is employed more than once on a page, distinguish the navigation groups by using an **aria-labelledby** or **aria-label** attribute.\n\nNot all groups of links need to use the **nav** element for markup. For instance, links may be grouped in other structure such as lists or may use ARIA markup if they do not represent a discrete section of the page.\n\nExamples:\n- **Example 1: Navigation links enclosed in a nav element**  This example uses anavelement to group navigation links in an accessibility curriculum.  ```html <nav> <ul> <li><a href=\"/web-accessibility.html\">Web Accessibility</a></li> <li><a href=\"/doc-accessibility.html\">Document Accessibility</a></li> <li><a href=\"/mobile-accessibility.html\">Mobile Accessibility</a></li> </ul> </nav> ```\n- **Example 2: Multiplenavelements andaria-labelledby**  The following example shows a best practice of how landmarks might be added to an HTML document in situations where there are two or more of the same type of landmark on the same page. For instance, if anavelement is used multiple times on a page, each instance may have a unique label specified usingaria-labelledby:  ```html <nav aria-labelledby=\"site-nav-heading\"> <h2 id=\"site-nav-heading\">Site</h2> <ul> <li><a href=\"...\">nav link 1</a></li> <li><a href=\"...\">nav link 2</a></li> <li><a href=\"...\">nav link 3</a></li> </ul> </nav> <nav aria-labelledby=\"related-nav-heading\"> <h2 id=\"related-nav-heading\">Related Topics</h2> <ul> <li><a href=\"...\">topic link 1</a></li> <li><a href=\"...\">topic link 2</a></li> <li><a href=\"...\">topic link 3</a></li> </ul> </nav> ```\n- **Example 3: Multiplenavelements andaria-label**  The following example shows a best practice of how landmarks might be added to an HTML document in situations where there are two or more of the same type of landmark on the same page, and there is no existing text on the page that can be referenced as the label:  ```html <nav aria-label=\"Site\"> <ul> <li>< href=\"...\">nav link 1</a></li> <li>< href=\"...\">nav link 2</a></li> <li>< href=\"...\">nav link 3</a></li> </ul> </nav> <nav aria-label=\"Tags\"> <ul> <li><a href=\"...\">tag link 1</a></li> <li><a href=\"...\">tag link 2</a></li> <li><a href=\"...\">tag link 3</a></li> </ul> </nav> ```    ---",
    "referenced_by": [
      "1.3.1",
      "2.4.1"
    ]
  },
  {
    "id": "T1",
    "type": "technique",
    "code": "T1",
    "text": "[T1] Using standard text formatting conventions for paragraphs\n\nDescription:\nThe objective of this technique is to recognize a paragraph in a plain text document. A paragraph is a coherent block of text, such as a group of related sentences that develop a single topic or a coherent part of a larger topic.\n\nThe beginning of a paragraph is indicated by\n\n- the beginning of the content, that is, the paragraph is the first content in the document, or\n- exactly one blank line preceding the paragraph text\n\nThe end of a paragraph is indicated by\n\n- the end of the content, that is, the paragraph is the last content in the document, or\n- one or more blank lines following the paragraph text\n\nA blank line contains zero or more non-printing characters, such as space or tab, followed by a new line.\n\nExamples:\n- **Example 1**  Two paragraphs. Each starts and ends with a blank line.  ```html This is the first sentence in this paragraph. Paragraphs may be long or short.  In this paragraph the first line is indented. Indented and non-indented sentences are allowed. White space within the paragraph lines is ignored in defining paragraphs. Only completely blank lines are significant. ```    ---",
    "referenced_by": [
      "1.3.1"
    ]
  },
  {
    "id": "T2",
    "type": "technique",
    "code": "T2",
    "text": "[T2] Using standard text formatting conventions for lists\n\nDescription:\nThe objective of this technique is to use text formatting conventions to create simple lists of related items. Hierarchical lists or nested lists cannot be represented using this technique and should be represented using a different technology.\n\nA list is a sequence of list items. A list item is a paragraph that begins with a label. For unordered lists, asterisks, dashes, and bullet characters may be used as the label, but the same label characters must be used for all the items in a list. For ordered lists, the label may be alphabetic or numeric, and may be terminated by a period or a right parenthesis. The labels must be in ascending order, that is,\n\n- numbers must be in numeric order,\n- alphabetic labels must be in alphabetical order or in numeric order when interpreted as Roman numerals.\n\nExamples:\n- **Example 1: Unordered list**  ```html - unordered list item  - unordered list item  - unordered list item ```\n- **Example 2: Numeric ordered list**  ```html 1. Ordered list item  2. Ordered list item  3. Ordered list item ```\n- **Example 3: Roman numeral ordered list**  ```html i.   Ordered list item  ii.  Ordered list item  iii. Ordered list item  iv.  Ordered list item ```\n- **Example 4: Alphabetic ordered list**  ```html A) Ordered list item  B) Ordered list item  C) Ordered list item ```    ---",
    "referenced_by": [
      "1.3.1"
    ]
  },
  {
    "id": "T3",
    "type": "technique",
    "code": "T3",
    "text": "[T3] Using standard text formatting conventions for headings\n\nDescription:\nThe objective of this technique is to use text formatting conventions to convey the structure of the content. Headings are used to locate and label sections of a text document, showing the organization of the document.\n\nThe beginning of a heading is indicated by\n\n- two blank lines preceding the heading\n\nThe end of a heading is indicated by\n\n- a blank line following the heading\n\nA blank line contains any number of non-printing characters, such as space or tab, followed by a new line.\n\nThe programmatic identification of the Heading is the two blank lines preceding it and one blank line succeeding it. Text documents are necessarily void of underlying structure and so structure must be indicated in the programmatic layout for screen readers. This programmatic layout will enable screen readers to voice blank lines twice before the text that will be considered as a heading. A screen magnifier user would decipher headings by visually identifying the space before it (or their technology may have Screen reader capabilities that can identify the spaces).\n\nExamples:\n- **Example 1**  A paragraph is followed by two blank lines, then a heading, then one blank line, then another paragraph:  ```html ...this is the end of paragraph 1.   The Text of the Heading  This is the beginning of paragraph 2. ```    ---",
    "referenced_by": [
      "1.3.1"
    ]
  },
  {
    "id": "C22",
    "type": "technique",
    "code": "C22",
    "text": "[C22] Using CSS to control visual presentation of text\n\nDescription:\nThe objective of this technique is to demonstrate how CSS can be used to control the visual presentation of text. This will allow users to modify, via the user agent, the visual characteristics of the text to meet their requirement. The text characteristics include aspects such as size, color, font family and relative placement.\n\nCSS benefits accessibility primarily by separating document structure from presentation. Style sheets were designed to allow precise control - outside of markup - of character spacing, text alignment, object position on the page, audio and speech output, font characteristics, etc. By separating style from markup, authors can simplify and clean up the markup in their content, making it more accessible at the same time.\n\nText within images has several accessibility problems, including the inability to:\n\n- be scaled according to settings in the browser\n- be displayed in colors specified by settings in the browser or rules in user-defined style sheets\n- honor operating system settings, such as high contrast\n\nIt is better to use real text for the text portion of these elements, and a combination of semantic markup and style sheets to create the appropriate visual presentation. For this to work effectively, choose fonts that are likely to be available on the user's system and define fallback fonts for users who may not have the first font that is specified. Newer machines and user agents often smooth or anti-alias all text, so it is likely that your headings and buttons will look nice on these systems without resorting to images of text.\n\nThe following CSS properties are useful to style text and avoid the need for text in images:\n\n- Thefont-familyproperty is used to display the code aspect in a monospace font family.\n- Thetext-alignproperty is used to display the text to the right of the viewport.\n- Thefont-sizeproperty is used to display the text in a larger size.\n- Thefont-styleproperty is used to display text in italics.\n- Thefont-weightproperty is used to set how thick or thin characters in text should be displayed.\n- Thecolorproperty is used to display the color of text or text containers.\n- Theline-heightproperty is used to display the line height for a block of text.\n- Thetext-transformproperty is used to control the case of letters in text.\n- Theletter-spacingproperty is used to control the spacing of letters in text.\n- Thebackground-imageproperty can be used to display text on a non-text background.\n- The::first-linepseudo-element can be used to modify the presentation of the first line in a block of text.\n- The::first-letterpseudo-element can be used to modify the presentation of the first letter in a block of text.\n- The::beforeand::afterpseudo-elements can be used to insert decorative non-text content before or after blocks of text.\n\nExamples:\n- **Example 10: Using CSSbackground-imageto layer text and images**  The CSSfont-styleproperty is used to display the textual component of a banner andbackground-imageproperty is used to display a picture behind the text.  ```html <div id=\"banner\"><span id=\"bannerstyle1\">Welcome</span> <span id=\"bannerstyle2\">to your local city council</span> </div> ```  ```html #banner { color:white; background-image:url(banner-bg.gif); background-repeat:no-repeat; background-color:#003399; width:29em; }  #bannerstyle1 { text-transform:uppercase; font-weight:bold; font-size:2.5em; }  #bannerstyle2 { font-style:italic; font-weight:bold; letter-spacing:-0.1em; font-size:1.5em; } ```\n- **Example 5: Using CSS font-style to italicize text**  ```html <p>The article is available in the <a href=\"https://www.example.com\" class=\"featuredsite\">Endocrinology Blog</a>. </p> ```  ```html .featuredsite{ font-style:italic; } ```\n- **Example 4: Using CSS color to control the color of text**  ```html <p>09 <em class=\"highlight\">March</em> 2008</p> ```  ```html .highlight{ color: red; } ```\n- **Example 1: Using CSS font-family to control the font family for text**  ```html <p>The JavaScript method to convert a string to uppercase is <code>toUpperCase()</code>.</p> ```  ```html code { font-family:\"Courier New\", Courier, monospace } ```\n- **Example 8: Using CSSline-heightto control spacing between lines of text**  The CSSline-heightproperty is used to display the line height for the paragraph at twice the height of the font.  The CSSline-heightproperty is used to display the line height for the text at less than the height of the font. The second line of text is positioned after the first line of text and visually appears as though the text is part of the first line but dropped a little.  ```html <p>Concern for man and his fate must always form the chief interest of all technical endeavors. Never forget this in the  midst of your diagrams and equations.</p> ```  ```html p { line-height:2; } ```  ```html <h1 class=\"overlap\"><span class=\"upper\">News</span> <span class=\"byline\">today</span> </h1> ```  ```html .overlap { line-height:0.2;} .upper { text-transform:uppercase; } .byline { color:red; font-style:italic; font-weight:bold; padding-left:3em; } ```\n- **Example 3: Using CSS font-size to control the size of text**  ```html <p>09 <strong class=\"largersize\">March</strong> 2008</p> ```  ```html strong.largersize { font-size: 1.5em; } ```\n- **Example 9: Using CSSletter-spacingto space text**  The CSSletter-spacingproperty is used to display the letters farther apart in the heading.  The CSSletter-spacingproperty is used to display the letters closer together in the second line of text.  ```html <h1 class=\"overlap\"><span class=\"upper\">News</span><br> <span class=\"byline\">today</span> </h1> ```  ```html .overlap { line-height:0.2em; } .upper { text-transform:uppercase; } .byline { color:red; font-style:italic; font-weight:bold; padding-left:3em; letter-spacing:-0.1em; } ```  ```html <h1 class=\"upper2\">News</h1> ```  ```html .upper2 { text-transform:uppercase; letter-spacing:1em; } ```\n- **Example 6: Using CSS font-weight to control the font weight of the text**  ```html <p>This deal is available <span class=\"highlight\">now!</span></p> ```  ```html .highlight { font-weight:bold; color:#990000; } ```\n- **Example 12: Using CSS::first-letterto control the presentation of the first letter of text**  The CSS::first-letterpseudo-element is used to display the first letter in a larger font size, red and vertically aligned in the middle.  ```html <p class=\"startletter\">Once upon a time...</p> ```  ```html .startletter::first-letter { font-size:2em; color:#990000; vertical-align:middle; } ```    ---\n- **Example 11: Using CSS::first-lineto control the presentation of the first line of text**  The CSS::first-linepseudo-element is used to display the first line of text in a larger, red font.  ```html <p class=\"startline\">Once upon a time...<br /> ...in a land far, far away...</p> ```  ```html .startline::first-line { font-size:2em; color:#990000; } ```\n- **Example 7: Using CSS text-transform to control the case of text**  ```html <p>09 <span class=\"caps\">March</span> 2008</p> ```  ```html .caps { text-transform:uppercase; } ```\n- **Example 2: Using CSS text-align to control the placement (alignment) of text**  ```html <p class=\"right\">This text should be to the right of the viewport.</p> ```  ```html .right { text-align: right; } ```",
    "referenced_by": [
      "1.3.1",
      "1.4.4",
      "1.4.5",
      "1.4.9"
    ]
  },
  {
    "id": "G162",
    "type": "technique",
    "code": "G162",
    "text": "[G162] Positioning labels to maximize predictability of relationships\n\nDescription:\nWhen labels for form fields are positioned where the user expects them visually, it is easier to understand complex forms and to locate specific fields. Labels for most fields are positioned immediately before the field, that is, for left-to-right languages, either to the left of the field or above it, and for right-to-left languages, to the right of the field or above it. Labels for radio buttons and checkboxes are positioned after the field.\n\nThese positions are defined because that is the usual (and therefore most predictable) position for the label for fields, radiobuttons and checkboxes.\n\nLabels are positioned before input fields since the fields sometimes vary in length. Positioning them before allows the labels to line up. It also makes labels easier to locate with a screen magnifier since they are immediately before the field and also can be found in a vertical column (when the start of the fields line up vertically). Finally, if the field has data in it, it is easier to understand or check the data if one reads the label first and then the content rather than the other way around.\n\nCheckboxes and radio buttons have a uniform width while their labels often do not. Having the radio button or checkbox first therefore allows both the buttons and the labels to line up vertically.\n\nExamples:\n- **Example 3: Labels to the right of radio buttons**    ---\n- **Example 1: Labels above text fields**\n- **Example 2: Labels to the left of text fields**",
    "referenced_by": [
      "1.3.1",
      "2.5.3",
      "3.3.2"
    ]
  },
  {
    "id": "ARIA1",
    "type": "technique",
    "code": "ARIA1",
    "text": "[ARIA1] Using the aria-describedby property to provide a descriptive label for user interface controls\n\nDescription:\nThe purpose of this technique is to demonstrate how to use the WAI-ARIA [aria-describedby](https://www.w3.org/TR/wai-aria-1.2/#aria-describedby) property to provide programmatically determined, descriptive information about a user interface element. The **aria-describedby** property may be used to attach descriptive information to one or more elements through the use of an **id** reference list. The **id** reference list contains one or more unique element **id**s.\n\nRefer to [ARIA in HTML](https://www.w3.org/TR/html-aria/) for information on how to provide WAI-ARIA States and Properties with HTML. WAI-ARIA States and Properties are compatible with other languages as well; refer to documentation in those languages.\n\nExamples:\n- **Example 1: Usingaria-describedbyto associate instructions with form fields**  Sample form field usingaria-describedbyto associate instructions with form fields while there is a form label.  ```html <form> <label for=\"fname\">First name</label> <input aria-describedby=\"int2\" autocomplete=\"given-name\" id=\"fname\" type=\"text\"> <p id=\"int2\">Your first name is sometimes called your \"given name\".</p> </form> ```\n- **Example 2: Usingaria-describedbyproperty to provide more detailed information about the button**  ```html <div> <span id=\"fontDesc\">Select the font faces and sizes to be used on this page</span> <button aria-describedby=\"fontDesc\" id=\"fontB\" type=\"button\">Fonts</button> </div> <div> <span id=\"colorDesc\">Select the colors to be used on this page</span> <button aria-describedby=\"colorDesc\" id=\"colorB\" type=\"button\">Colors</button> </div> <div> <span id=\"customDesc\">Customize the layout and styles used on this page</span> <button aria-describedby=\"customDesc\" id=\"customB\" type=\"button\">Customize</button> </div> ```    ---",
    "referenced_by": [
      "1.3.1",
      "3.3.2"
    ]
  },
  {
    "id": "ARIA2",
    "type": "technique",
    "code": "ARIA2",
    "text": "[ARIA2] Identifying a required field with the aria-required property\n\nDescription:\nThe objective of this technique is to provide programmatic indication that a form field (which shown through presentation to be required) is mandatory for successful submission of a form.\n\nThe fact that the element is required is often visually presented (via a text or non-text symbol, or text indicating input is required or color / styling) but this is not programmatically determinable as part of the field's name.\n\nThe WAI-ARIA **aria-required** property indicates that user input is required before submission. The **aria-required** property can have values of **true** or **false**. For example, if a user must fill in an address field, then **aria-required** is set to **true**.\n\nExamples:\n- **Example 2: Therequiredproperty is indicated by the word \"required\" placed next to thelabelelement**  ```html <form> <div> <label for=\"fname\">First name:</label> <span>(required)</span> <input aria-required=\"true\" autocomplete=\"given-name\" id=\"fname\" type=\"text\"> </div> <div> <label for=\"mname\">Middle name:</label> <span>(required)</span> <input autocomplete=\"additional-name\" id=\"mname\" type=\"text\"> </div> <div> <label for=\"lname\">Last name:</label> <span>(required)</span> <input aria-required=\"true\" autocomplete=\"family-name\" id=\"lname\" type=\"text\"> </div> <div> <label for=\"email\">Email address:</label> <span>(required)</span> <input aria-required=\"true\" autocomplete=\"email\" id=\"email\" type=\"text\"> </div> <div> <label for=\"zip_post\">Zip / Postal code:</label> <span>(required)</span> <input aria-required=\"true\" autocomplete=\"postal-code\" id=\"zip_post\" type=\"text\"> </div> <div> <input type=\"submit\" value=\"Next Step\"> </div> </form> ```\n- **Example 3: Required fields are indicated by a red border around the fields and a star icon rendered via CSS using::after**  This example uses custom radio buttons withrole=radio. The CSS properties are available below the form.  Related CSS style definition for this example:  ```html <form> <label data-required=\"true\" for=\"acctnum\">Account Number</label> <input aria-required=\"true\" id=\"acctnum\" type=\"text\">  <p data-required=\"true\" id=\"radio_label\"> Please send an alert when balance exceeds $3,000. </p>  <ul aria-required=\"true\" aria-labelledby=\"radio_label\" role=\"radiogroup\"> <li aria-checked=\"false\" id=\"rb1\" role=\"radio\" tabindex=\"0\">Yes</li> <li aria-checked=\"false\" id=\"rb2\" role=\"radio\" tabindex=\"-1\">No</li> </ul> </form> ```  ```html [aria-required=true] { border: red thin solid; } [data-required=true]::after { content: url('/iconStar.gif'); } ```    ---\n- **Example 1: Therequiredproperty is indicated by an asterisk placed in thelabelelement**  ```html <form> <p>Note: * denotes a required field</p> <div> <label for=\"usrname\">Login name *:</label> <input aria-required=\"true\" autocomplete=\"username\" id=\"usrname\" type=\"text\"> </div> <div> <label for=\"pwd\">Password *:</label> <input aria-required=\"true\" autocomplete=\"current-password\" id=\"pwd\" type=\"password\"> </div> <div> <input type=\"submit\" value=\"Login\"> </div> </form> ```",
    "referenced_by": [
      "1.3.1",
      "3.3.1"
    ]
  },
  {
    "id": "G141",
    "type": "technique",
    "code": "G141",
    "text": "[G141] Organizing a page using headings\n\nDescription:\nThe objective of this technique is to ensure that sections have headings that identify them. Success Criterion 1.3.1 requires that the headings be marked such that they can be programmatically identified.\n\nIn HTML, this could be done using the HTML heading elements (**h1**, **h2**, **h3**, **h4**, **h5**, and **h6**). These allow user agents to automatically identify section headings. Other technologies use other techniques for identifying headers. To facilitate navigation and understanding of overall document structure, authors should use headings that are properly nested (e.g., **h1** followed by **h2**, **h2** followed by **h2** or **h3**, **h3** followed by **h3** or **h4**, etc.).\n\nExamples:\n- **Example 1: Headings used to organize an HTML page**  A page on cooking techniques uses a h1 element for the overall title, and h2 elements for major sections on cooking with oil vs cooking with butter, and h3 elements for sub-sections on oil-cooking techniques.  ```html <!doctype html> <html lang=\"en\"> <head> <title>Cooking techniques</title> </head> <body> <h1>Cooking techniques</h1> ... some text here ... <h2>Cooking with oil</h2> ... text of the section ... <h3>Sautéeing</h3> ... <h3>Deep frying</h3> <h2>Cooking with butter</h2> ... text of the section ... </body> </html> ```    ---",
    "referenced_by": [
      "1.3.1"
    ]
  },
  {
    "id": "F2",
    "type": "technique",
    "code": "F2",
    "text": "[F2] Failure of Success Criterion 1.3.1 due to using changes in text presentation to convey information without using the appropriate markup or text\n\nDescription:\nThis document describes a failure that occurs when a change in the appearance of text conveys meaning without using appropriate semantic markup. This failure also applies to images of text that are not enclosed in the appropriate semantic markup.\n\nExamples:\n- **Example 1: Using CSS to style thepelement to look like a heading**  The author intended to make a heading but didn't want the look of the default HTML heading. So they used CSS to style the P element to look like a heading and they called it a heading. But they failed to use the proper HTML heading element. Therefore, the Assistive Technology could not distinguish it as a heading.  ```html <style> .heading1{ font-family: Times, serif; font-size:200%; font-weight:bold; } </style>  <p class=\"heading1\">Introduction</p> <p>This introduction provides detailed information about how to use this ...</p> ```\n- **Example 2: Images of text used as headings where the images are not marked up with heading tags**  Chapter1.gif is an image of the words, \"Chapter One\" in a Garamond font sized at 20 pixels. This is a failure because at a minimum the img element should be enclosed within a header element. A better solution would be to eliminate the image and to enclose the text within a header element which has been styled using CSS.  ```html <img src=\"Chapter1.gif\" alt=\"Chapter One\"> <p>Once upon a time in the land of the Web...</p> ```    ---",
    "referenced_by": [
      "1.3.1"
    ]
  },
  {
    "id": "F33",
    "type": "technique",
    "code": "F33",
    "text": "[F33] Failure of Success Criterion 1.3.1 and 1.3.2 due to using white space characters to create multiple columns in plain text content\n\nDescription:\nThe objective of this technique is to describe how using white space\ncharacters, such as space, tab, line break, or carriage return, to format columns of\ndata in text content is a failure to use structure properly. Assistive\ntechnologies will interpret content in the reading order of the current\nlanguage. Using white space characters to create multiple columns does not\nprovide the information in a natural reading order. Thus, the assistive\ntechnology user will not be presented with the information in an\nunderstandable manner.\n\nPlain text is not suitable for displaying multiple columns of text. Modify\nthe content to present the data in a different layout. Alternatively, use a\ntechnology that provides structural elements to represent columnar data.\n\nExamples:\n- **Example 1**  The following example incorrectly uses white space characters to format a paragraph into a two column format.  If this table was to be interpreted and spoken by a screen reader it would speak the following lines:  If the text were reflowed, or changed from a fixed to a variable font, or increased in size until lines no longer fit on the page, similar interpretation issues would arise in the visual presentation.  ```html Web Content Accessibility Guidelines      including blindness and low vision, 2.0 (WCAG 2.0) covers a wide range of     deafness and hearing loss, learning issues and recommendations for making     difficulties, cognitive limitations, limited Web content more accessible. This         movement, speech difficulties, and document contains principles,             others. Following these guidelines will guidelines, Success Criteria, benefits,   also make your Web content more and examples that define and explain      accessible to the vast majority of users, the requirements for making Web-based     including older users. It will also enable information and applications accessible.  people to access Web content using \"Accessible\" means usable to a wide       many different devices - including a range of people with disabilities,        wide variety of assistive technologies. ```    ---",
    "referenced_by": [
      "1.3.1",
      "1.3.2"
    ]
  },
  {
    "id": "F34",
    "type": "technique",
    "code": "F34",
    "text": "[F34] Failure of Success Criterion 1.3.1 and 1.3.2 due to using white space characters to format tables in plain text content\n\nDescription:\nThe objective of this technique is to describe how using white space\ncharacters, such as space, tab, line break, or carriage return, to format tables in text\ncontent is a failure to use structure properly. When tables are created in\nthis manner there is no way to indicate that a cell is intended to be a\nheader cell, no way to associate the table header cells with the table data\ncells, or to navigate directly to a particular cell in a table.\n\nIn addition, assistive technologies will interpret content in the reading\norder of the current language. Using white space to organize data in a\nvisual table does not provide the information in a natural reading order in\nthe source of the document. Thus, the assistive technology user will not be\npresented with the information in a logical reading order.\n\nPlain text is not suitable for displaying complex information like tables\nbecause the structure of the table cannot be perceived. Rather than using\nvisual formatting to represent tabular relations,\ntabular information would need to be presented using a different technology or presented linearly. (See Presenting tabular information in plain text)\n\nExamples:\n- **Example 1**  The following example incorrectly uses white space to format a Menu as a visual table.  If this table was to be interpreted and spoken by a screen reader it would speak the following lines:  This reading order does not make sense since there is no structure in the table for the assistive technology to identify it as a table. If the text were reflowed, or changed from a fixed to a variable font, or increased in size until lines no longer fit on the page, similar issues would arise in the visual presentation.  ```html Menu Breakfast        Lunch           Dinner  Monday   2 fried eggs    tomato soup     garden salad bacon           hamburger       Fried Chicken toast           onion rings     green beans Oatmeal cookie  mashed potatoes  Tuesday   Pancakes       vegetable soup  Caesar salad sausage        hot dogs        Spaghetti with meatballs orange juice   potato salad    Italian bread brownie         ice cream ```    ---",
    "referenced_by": [
      "1.3.1",
      "1.3.2"
    ]
  },
  {
    "id": "F42",
    "type": "technique",
    "code": "F42",
    "text": "[F42] Failure of Success Criteria 1.3.1, 2.1.1, 2.1.3, or 4.1.2 when emulating links\n\nDescription:\nThis failure occurs when JavaScript event handlers are attached to elements\nto emulate links. A link created in this manner cannot be tabbed to from the keyboard and does not gain keyboard focus like other controls and/or links.\nIf scripting events are used to emulate links, user\nagents including assistive technology may not be able to identify the links\nin the content as links. They may be recognized as interactive controls but still not recognized as links.  Such elements do not appear in the links\nlist generated by user agents or assistive technology.\n\n\n\n\n\nThe **a** and **area**\nelements are intended to mark up links.\n\nExamples:\n- **Example 2: Scripting animgelement**  Scripted event handling is added to animgelement so that it functions as a link when clicked with a mouse. Assistive technology does not recognize this element as a link.  ```html <img src=\"go.gif\" alt=\"go to the new page\" onclick=\"location.href='newpage.html'\"> ```\n- **Example 3: Scripting animgelement, with keyboard support**  Scripted event handling is added to animgelement so that it functions as a link. In this example, the link functionality can be invoked with the mouse or via the Enter key if the user agent includes the element in the tab chain. Nevertheless, the element will not be recognized as a link.  The markup for the image is:  ```html function doNav(url){ window.location.href = url; }  function doKeyPress(url){ //if the enter key was pressed if (window.event.type == \"keypress\" && window.event.keyCode == 13){ doNav(url); } } ```  ```html <p> <img src=\"bargain.jpg\" tabindex=\"0\" alt=\"View Bargains\" onclick=\"doNav('viewbargains.html');\" onkeypress=\"doKeyPress('viewbargains.html');\"> </p> ```\n- **Example 1: Scripting aspanelement**  Scripted event handling is added to aspanelement so that it functions as a link when clicked with a mouse. Assistive technology does not recognize this element as a link.  ```html <span onclick=\"location.href='newpage.html'\">Fake link</span> ```\n- **Example 4: Scripting adivelement**  This example uses script to make adivelement behave like a link. Although the author has provided complete keyboard access and separated the event handlers from the markup to enable repurposing of the content, thedivelement will not be recognized as a link by assistive technology.  The markup for thedivelement is:  ```html window.onload = init; function init(){ var objAnchor = document.getElementById('linklike');  objAnchor.onclick = function(event){return changeLocation(event, 'surveyresults.html');}; objAnchor.onkeypress = function(event){return changeLocation(event, 'surveyresults.html');}; }  function changeLocation(objEvent, strLocation){ var iKeyCode;  if (objEvent && objEvent.type == 'keypress'){ if (objEvent.keyCode){ iKeyCode = objEvent.keyCode; } else if (objEvent.which){ iKeyCode = objEvent.which; } if (iKeyCode != 13 && iKeyCode != 32){ return true; } } window.location.href = strLocation; } ```  ```html <div id=\"linklike\">View the results of the survey.</div> ```    ---",
    "referenced_by": [
      "1.3.1",
      "2.1.1",
      "4.1.2"
    ]
  },
  {
    "id": "F43",
    "type": "technique",
    "code": "F43",
    "text": "[F43] Failure of Success Criterion 1.3.1 due to using structural markup in a way that does not represent relationships in the content\n\nDescription:\nThe objective of this technique is to describe a failure that occurs when\nstructural markup is used to achieve a presentational effect, but indicates\nrelationships that do not exist in the content. This is disorienting to\nusers who are depending on those relationships to navigate the content or to\nunderstand the relationship of one piece of the content to another. Note\nthat the use of HTML tables for layout is not an example of this failure as\nlong as the layout table does not include improper structural markup such as\n<th> or <caption>\nelements.\n\nExamples:\n- **Example 1: A heading used only for visual effect**  In this example, a heading element is used to display an address in a large, bold font. The address does not identify a new section of the document, however, so it should not be marked as a heading.  ```html <p>Interested in learning more? Write to us at</p> <h4>3333 Third Avenue, Suite 300 · New York City</h4> <p>And we'll send you the complete informational packet absolutely Free!</p> ```\n- **Example 2: Using heading elements for presentational effect**  In this example, heading markup is used in two different ways: to convey document structure and to create visual effects. The h1 and h2 elements are used appropriately to mark the beginning of the document as a whole and the beginning of the abstract. However, the h3 and h4 elements between the title and the abstract are used only for visual effect — to control the fonts used to display the authors' names and the date.  ```html <h1>Study on the Use of Heading Elements in Web Pages</h1> <h3>Joe Jones and Mary Smith<h3> <h4>March 14, 2006</h4> <h2>Abstract</h2> <p>A study was conducted in early 2006 ...</p> ```\n- **Example 3: Usingblockquoteelements to provide additional indentation**  The following example uses blockquote for text that is not a quotation to give it prominence by indenting it when displayed in graphical browsers.  ```html <p>After extensive study of the company website, the task force identified the following common problem.</p>  <blockquote> <p>The use of markup for presentational effects made Web pages confusing to screen reader users.</p> </blockquote>  <p>The committee lists particular examples of the problems introduced by this practice below.</p> ```\n- **Example 4: Using the fieldset and legend elements to give a border to text**  ```html <fieldset> <legend>Bargain Corner</legend> <p>Buy today, and save 20%</p> </fieldset> ```    ---",
    "referenced_by": [
      "1.3.1"
    ]
  },
  {
    "id": "F46",
    "type": "technique",
    "code": "F46",
    "text": "[F46] Failure of Success Criterion 1.3.1 due to using th elements, layout tables\n\nDescription:\nThe objective of this technique is to describe a failure that occurs when a\ntable used only for layout includes either th elements, a\nsummary attribute, or a caption element. This\nis a failure because it uses structural (or semantic) markup only for\npresentation. The intent of the HTML table elements is to present data.\n\nAlthough not commonly used in a layout table, the following structural markup would also be failures of Success Criterion 1.3.1 if used in a layout table:\n\n- headersattributes\n- scopeattributes\n\nAssistive technologies use the structure of an HTML table to present data to\nthe user in a logical manner. The th element is used to mark\nthe column and row headers of the table. A screen reader uses the\ninformation in th elements to speak the header information that\nchanges as the user navigates the table. The summary attribute on the\ntable element provides a textual description of the table\nthat describes its purpose and function. Assistive technologies make the\nsummary attribute information available to users. The\ncaption element is part of the table and identifies the\ntable.\n\nAlthough WCAG 2 does not prohibit the use of layout tables, CSS-based layouts are recommended in order to retain the defined semantic meaning of the HTML table elements and to conform to the coding practice of separating presentation from content.\nWhen a table is used\nfor layout purposes the th element should not be used. Since\nthe table is not presenting data there is no need to mark any cells as\ncolumn or row headers. Likewise, there is no need for an additional\ndescription of a table which is only used to layout content. Do not include\na summary attribute and do not use the summary\nattribute to describe the table as, for instance, \"layout table\". When\nspoken, this information does not provide value and will only distract users\nnavigating the content via a screen reader. Empty summary\nattributes are acceptable on layout tables, but not recommended.\n\nExamples:\n- **Example 1**  Here is a simple example that uses a table to layout content in a three column format. The navigation bar is in the left column, the main content in the middle column, and an additional sidebar is on the right. At the top is a page title. The example marks the page title as <th>.  ```html <table> <tr> <th colspan=3>Page Title</th> </tr> <tr> <td><div>navigation content</div></td> <td><div>main content</div></td> <td><div>right sidebar content</div></td> </tr> <tr> <td colspan=3>footer</td> </tr> </table> ```    ---",
    "referenced_by": [
      "1.3.1"
    ]
  },
  {
    "id": "F48",
    "type": "technique",
    "code": "F48",
    "text": "[F48] Failure of Success Criterion 1.3.1 due to using the pre element to markup tabular information\n\nDescription:\nThis document describes a failure caused by use of the HTML pre\nelement to markup tabular information. The pre element\npreserves only visual formatting. If the pre element is used to\nmarkup tabular information, the visually implied logical relationships\nbetween the table cells and the headers are lost if the user cannot see the\nscreen or if the visual presentation changes significantly.\n\nInstead, the HTML table element is intended to present tabular\ndata. Assistive technologies use the structure of an HTML table to present\ndata to the user in a logical manner. This structure is not available when\nusing the pre element.\n\nExamples:\n- **Example 1: A schedule formatted with tabs between columns**  ```html <pre> Monday   Tuesday     Wednesday      Thursday         Friday 8:00- 9:00\t          Meet with Sam 9:00- 10:00    \t\t      Dr. Williams   Sam again        Leave for San Antonio </pre> ```\n- **Example 2: Election results displayed using preformatted text**  ```html <pre> CIRCUIT COURT JUDGE BRANCH 3 W R M R E     I A . L     T M L    R   B     E I A    Y   E     - K N        R     I E G        T     N -----   -----   ----- 0001 TOWN OF ALBION WDS 1-2               22      99       0 0002 TOWN OF BERRY WDS 1-2                52     178       0 0003 TOWN OF BLACK EARTH                  16      49       0 0004 TOWN OF BLOOMING GROVE WDS 1-3       44     125       0 0005 TOWN OF BLUE MOUNDS                  33     117       0 0006 TOWN OF BRISTOL WDS 1-3             139     639       1 0007 TOWN OF BURKE WDS 1-4                80     300       0 0008 TOWN OF CHRISTIANA WDS 1-2           22      50       0 </pre> ```    ---",
    "referenced_by": [
      "1.3.1"
    ]
  },
  {
    "id": "F90",
    "type": "technique",
    "code": "F90",
    "text": "[F90] Failure of Success Criterion 1.3.1 for incorrectly associating table headers and content via the headers and id attributes\n\nDescription:\nOne way for authors to explicitly associate header cells to data cells is by using the id and headers attributes. These allow the author to associate multiple header cells to a particular data cell, which can be necessary when complex data tables with more than one level of heading are used.\n\nThe failure occurs when the relationship between data cells and corresponding header cells cannot be programmatically determined correctly because the association of **id** and **headers** attributes is faulty. This can happen, for example, when copying code within tables and forgetting to update the code.\n\nExamples:\n- **Example 1: Table content not correctly associated to nested headers**  In this example, nested headers are used, but the content cells are incorrectly associated via theidandheadersattributes. All cells reference top level header 'Exams' (id=\"e\") - this isn't correct for the last three columns which should reference header 'Projects'. Also, the referencing of the second level column headers has been accidentally swapped even though in this example this makes no difference as the contents (1, 2, Final) are repeated.  Example Code:  Failure example of table incorrectly associating headers attributes in table content (td) to table headers (th).  ```html <table> <tr> <th rowspan=\"2\" id=\"h\">Homework</th> <th colspan=\"3\" id=\"e\">Exams</th> <th colspan=\"3\" id=\"p\">Projects</th> </tr> <tr> <th id=\"e1\" headers=\"e\">1</th> <th id=\"e2\" headers=\"e\">2</th> <th id=\"ef\" headers=\"e\">Final</th> <th id=\"p1\" headers=\"p\">1</th> <th id=\"p2\" headers=\"p\">2</th> <th id=\"pf\" headers=\"p\">Final</th> </tr> <tr> <td headers=\"h\">15%</td> <td headers=\"e p1\">15%</td>  <!-- should be \"e e1\" --> <td headers=\"e p2\">15%</td>  <!-- should be \"e e2\" --> <td headers=\"e pf\">20%</td>  <!-- should be \"e ef\" --> <td headers=\"e e1\">10%</td>  <!-- should be \"p p1\" --> <td headers=\"e e2\">10%</td>  <!-- should be \"p p2\" --> <td headers=\"e ef\">15%</td>  <!-- should be \"p pf\" --> </tr> </table> ```    ---",
    "referenced_by": [
      "1.3.1"
    ]
  },
  {
    "id": "F91",
    "type": "technique",
    "code": "F91",
    "text": "[F91] Failure of Success Criterion 1.3.1 for not correctly marking up table headers\n\nDescription:\nThis failure occurs when data tables do not use header elements (**th**) or other appropriate table mark-up (the **scope** attribute, **headers** and **id** or the ARIA **columnheader** and **rowheader**) roles to make the headers programmatically determinable from within table content.  Making headers programmatically determinable is especially important when data cells are only intelligible together with header information. When screen reader users navigate through the table content horizontally or vertically, the headers that change can be read out to provide the necessary context for the information in the data cells.\n\nExamples:\n- **Example 1: Headers not marked up appropriately**  This table does not useth(or other appropriate header markup) for headers. Instead, it usestdelements for all cells. Navigating cell by cell, screen readers will often fail to read the header cells associated with content.  Example Code:  View example 1 (opens in same browser window)  ```html <table> <tr> <td>Name</td> <td>Age</td> <td>Height (cm)</td> <td>Weight (kg)</td> </tr> <tr> <td>Linda</td> <td>33</td> <td>169</td> <td>59</td> </tr> <tr> <td>Jack</td> <td>37</td> <td>184</td> <td>74</td> </tr> <tr> <td>Kira</td> <td>8</td> <td>120</td> <td>21</td> </tr> <tr> <td>Daniel</td> <td>3</td> <td>79</td> <td>14</td> </tr> </table> ```    ---",
    "referenced_by": [
      "1.3.1"
    ]
  },
  {
    "id": "F92",
    "type": "technique",
    "code": "F92",
    "text": "[F92] Failure of Success Criterion 1.3.1 due to the use of role presentation on content which conveys semantic information\n\nDescription:\nThis failure occurs when a role of presentation is applied to an element whose purpose is to convey information or relationships in the content. Elements such as **table**, can convey information about the content contained in them via their semantic markup. The WAI-ARIA role of [presentation](https://www.w3.org/TR/wai-aria/#presentation) on the other hand, is intended to suppress semantic information of content from the accessibility API and prevent user agents from conveying that information to the user. Use of the **presentation** role for content which should convey semantic information may prevent the user from understanding that content.\n\nExamples:\n- **Example 1**  In this example, tabular data is marked up with role=presentation. Though design layout tables can be marked up in such a way, data tables need to retain their semantic information and should therefore not be marked up with role=presentation.  Example Code:  ```html <table role=\"presentation\"> <caption>Fruits and their colors</caption> <tr> <th>Name</th> <th>Color</th> </tr> <tr> <td scope=\"row\">banana</td> <td>yellow</td> </tr> <tr> <td scope=\"row\">orange</td> <td>orange</td> </tr> </table> ```    ---",
    "referenced_by": [
      "1.3.1"
    ]
  },
  {
    "id": "G57",
    "type": "technique",
    "code": "G57",
    "text": "[G57] Ordering the content in a meaningful sequence\n\nDescription:\nThe objective of this technique is to ensure that the order of content presented to assistive technologies allows the user to make sense of the content. Some techniques permit the content to be rendered visually in a meaningful sequence even if this is different from the order in which the content is encoded in the underlying source file.\n\nFor example, when mixing languages with different directionality in HTML, the bidirectional algorithm may position punctuation in the wrong location in the visual rendering. The visual rendering problem could be corrected by moving the punctuation in the content stream so that the bidirectional algorithm positions it as desired, but this would expose the incorrect content order to assistive technology. The content is both rendered in the correct order visually and exposed to assistive technology in the correct order by using markup to override the bidirectional algorithm.\n\nWhen rendered visually, white space characters such as space or tab may not appear to be part of the content. However, when inserted into the content to control visual formatting, they may interfere with the meaning of the content.\n\nAt a larger granularity, controlling the placement of blocks of content in an HTML document using layout tables may produce a rendering in which related information is positioned together visually, but separated in the content stream. Since layout tables are read row by row, if the caption of an illustration is placed in the row following the illustration, it may be impossible to associate the caption with the image.\n\nExamples:\n- **Example 1**  A web page from a museum exhibition contains a navigation bar containing a long list of links. The page also contains an image of one of the pictures from the exhibition, a heading for the picture, and a detailed description of the picture. The links in the navigation bar form a meaningful sequence. The heading, image, and text of the description also form a meaningful sequence. CSS is used to position the elements on the page.  ```html <h1>My Museum Page</h1> <ul id=\"nav\"> <li><a href=\"#\">Link 1</a></li> ... <li><a href=\"#\">Link 10</a></li> </ul> <div id=\"description\"> <h2>Mona Lisa</h2> <div> <img src=\"img.png\" alt=\"Mona Lisa\"> </div> <p>...detailed description of the picture...</p> </div> ```  ```html ul#nav { float: left; width: 9em; list-style-type: none; margin: 0; padding: 0.5em; color: #fff; background-color: #063; }  ul#nav a { display: block; width: 100%; text-decoration: none; color: #fff; background-color: #063; } div#description { margin-left: 11em; } ```    ---",
    "referenced_by": [
      "1.3.2"
    ]
  },
  {
    "id": "H34",
    "type": "technique",
    "code": "H34",
    "text": "[H34] Using a Unicode right-to-left mark (RLM) or left-to-right mark (LRM) to mix text direction inline\n\nDescription:\nThe objective of this technique is to use Unicode right-to-left marks and left-to-right\nmarks to override the HTML bidirectional algorithm when it produces undesirable results.\nThis may be necessary, for instance, when placing neutral characters such as spaces or\npunctuation between different directional text runs. The concepts used in this technique\nare described in [Inline markup and bidirectional text in HTML](https://www.w3.org/International/articles/inline-bidi-markup/).\n\nUnicode right-to-left marks and left-to-right marks can be entered directly or by means of character entities or numeric character references, as shown here.\n\n- left-to-right mark:&lrm;or&#x200e;(U+200E)\n- right-to-left mark:&rlm;or&#x200f;(U+200F)\n\nDue to the bidi algorithm, a source code editor may not display character entities or numeric character references as expected.\n\nExamples:\n- **Example 1**  This example shows an Arabic phrase in the middle of an English sentence. The exclamation point is part of the Arabic phrase and should appear on its left. Because it is between an Arabic and Latin character and the overall paragraph direction is LTR, the bidirectional algorithm positions the exclamation mark to the right of the Arabic phrase.  The title is \"مفتاح معايير الويب!\" in Arabic.  Visually-orderedASCIIversion (RTL text in uppercase, LTR in lower):  the title is \"HCTIWS SDRADNATS BEW!\" in arabic.  Inserting a Unicode right-to-left mark in the code immediately after the exclamation mark positions it correctly when you view the displayed text (see below). You can use a character escape or the (invisible) control character to insert the right-to-left mark.  The title is \"مفتاح معايير الويب!‏\" in Arabic.  Visually-ordered ASCII version:  the title is \"!HCTIWS SDRADNATS BEW\" in arabic.    ---",
    "referenced_by": [
      "1.3.2"
    ]
  },
  {
    "id": "H56",
    "type": "technique",
    "code": "H56",
    "text": "[H56] Using the dir attribute on an inline element to resolve problems with nested directional runs\n\nDescription:\nThe objective of this technique is to identify changes in the text direction of text that includes nested directional runs by providing the **dir** attribute on inline elements. A nested directional run is a run of text that includes mixed directional text, for example, a paragraph in English containing a quoted Hebrew sentence which in turn includes an English phrase. Use of the **dir** attribute on an enclosing **span** or other inline element may be necessary because the [Unicode bidirectional algorithm](https://www.w3.org/International/articles/inline-bidi-markup/) can produce undesirable results when mixed directional text contains spaces or punctuation. The concepts used in this technique are described in [What you need to know about the bidi algorithm and inline markup](https://www.w3.org/International/articles/inline-bidi-markup/).\n\nExamples:\n- **Example 1: Defining the text direction of a nested, mixed-direction phrase, in Hebrew and English, to be right-to-left**  Because the whole quote is in Hebrew, and therefore runs right to left, the text \"W3C\" and the comma should appear to the left of (i.e., after) the Hebrew text, like this:  The title is \"פעילות הבינאום, W3C\" in Hebrew.  Visually-orderedASCIIversion (RTLtext in uppercase,LTRin lower):  the title is \"w3c ,YTIVITCA NOITAZILANOITANRETNI\" in Hebrew.  The Unicode bidirection algorithm alone is insufficient to achieve the right result, and leaves the text \"W3C\" on the right side of the quote:  The title is \"פעילות הבינאום, W3C\" in Hebrew.  Visually-ordered ASCII version:  the title is \"YTIVITCA NOITAZILANOITANRETNI, w3c\" in hebrew.  The following markup will produce the expected result:  ```html <p>The title says \"<span lang=\"he\" dir=\"rtl\">פעילות הבינאום, W3C</span>\" in Hebrew.</p> ```    ---",
    "referenced_by": [
      "1.3.2"
    ]
  },
  {
    "id": "C6",
    "type": "technique",
    "code": "C6",
    "text": "[C6] Positioning content based on structural markup\n\nDescription:\nThe objective of this technique is to demonstrate how visual appearance may be enhanced via style sheets while still maintaining a meaningful presentation when style sheets are not applied. Using the positioning properties of CSS, content may be displayed at any position on the user's viewport. Using structural elements ensures that the meaning of the content can still be determined when styling is not available.\n\nExamples:\n- **Example 1**  In this example structural markup (description lists) have been applied to the content. CSS has been used to style the content into columnar form. Each class absolutely positions the content into columns and the margins have been set to 0 to override the default behavior of user agents to displayHTMLdefinition lists with theddelement indented.  Here is the content to be displayed:  Here is the CSS which positions and styles the above elements:  When style sheets are applied, the data are displayed in two columns of \"Products\" and \"Locations.\" When the style sheets are not applied, the text appears in a definition list which maintains the structure and reading order.  ```html <div class=\"box\"> <dl> <dt class=\"menu1\">Products</dt> <dd class=\"item1\">Telephones</dd> <dd class=\"item2\">Computers</dd> <dd class=\"item3\">Portable MP3 Players</dd> <dt class=\"menu2\">Locations</dt> <dd class=\"item4\">Idaho</dd> <dd class=\"item5\">Wisconsin</dd> </dl> </div> ```  ```html .item1 { left: 0; margin: 0; position: absolute; top: 7em; } .item2 { left: 0; margin: 0; position: absolute; top: 8em; } .item3 { left: 0; margin: 0; position: absolute; top: 9em; } .item4 { left: 14em; margin: 0; position: absolute; top: 7em; } .item5 { left: 14em; margin: 0; position: absolute; top: 8em; } .menu1 { background-color: #FFFFFF; color: #FF0000; font-family: sans-serif; font-size: 120%; left: 0; margin: 0; position: absolute; top: 3em; } .menu2 { background-color: #FFFFFF; color: #FF0000; font-family: sans-serif; font-size: 120%; left: 10em; margin: 0; position: absolute; top: 3em; } #box { left: 5em; position: absolute; top: 5em; } ```    ---",
    "referenced_by": [
      "1.3.2",
      "1.4.5",
      "1.4.9",
      "2.4.1"
    ]
  },
  {
    "id": "C8",
    "type": "technique",
    "code": "C8",
    "text": "[C8] Using CSS letter-spacing to control spacing within a word\n\nDescription:\nThe objective of this technique is to demonstrate how the visual appearance of spacing in text may be enhanced via style sheets while still maintaining meaningful text sequencing. The CSS **letter-spacing** property helps developers control the amount of white space between characters. This is recommended over adding blank characters to control the spacing, since the blank characters can change the meaning and pronunciation of the word.\n\nExamples:\n- **Example 1: Increasing the spacing between characters in a word**  The following CSS would add the equivalent of a space between each character in a level-2 heading:  ```html h2 { letter-spacing: 1em; } ```  ```html <h2>Museum</h2> ```  ```html M u s e u m ```    ---",
    "referenced_by": [
      "1.3.2",
      "1.4.5",
      "1.4.9"
    ]
  },
  {
    "id": "C27",
    "type": "technique",
    "code": "C27",
    "text": "[C27] Making the DOM order match the visual order\n\nDescription:\nThe objective of this technique is to ensure that the order of content in the source code is the same as the visual presentation of the content. The order of content in the source code can be changed by the author to any number of visual presentations with CSS. Each order may be meaningful in itself but may cause confusion for assistive technology users. This could be due to the user switching off the author-specified presentation, by accessing the content directly from the source code (such as with a screen reader), or by interacting with the content with a keyboard. If a blind user, who reads the page with a screen reader that follows the source order, is working with a sighted user who reads the page in visual order, they may be confused when they encounter information in different orders. A user with low vision who uses a screen magnifier in combination with a screen reader may be confused when the reading order appears to skip around on the screen. A keyboard user may have trouble predicting where focus will go next when the source order does not match the visual order.\n\nThere may also be situations where the visually presented order is necessary to the overall understanding of the page, and if the source order is presented differently, it may be much more difficult to understand.\n\nWhen the source order matches the visual order, everyone will read the content and interact with it in the same (correct) order.\n\nExamples:\n- **Example 1:** An online newspaper has placed a navigation bar visually in the top left corner of the page directly below its initial logo. In the source code, the navigation elements appear after the elements encoding the logo.  ---",
    "referenced_by": [
      "1.3.2",
      "2.4.3"
    ]
  },
  {
    "id": "PDF3",
    "type": "technique",
    "code": "PDF3",
    "text": "[PDF3] Ensuring correct tab and reading order in PDF documents\n\nDescription:\nThe intent of this technique is to ensure that users can navigate\nthrough content in a logical order that is consistent with the meaning\nof the content. Correct tab and reading order is typically accomplished\nusing a tool for authoring PDF.\n\nFor sighted users, the logical order of PDF content is also the visual\norder on the screen. For keyboard and assistive technology users, the\ntab order through content, including interactive elements (form fields\nand links), determines the order in which these users can navigate\nthe content. The tab order must reflect the logical order of the document.\n\nLogical structure is created when a document is saved as tagged PDF.\nThe reading order of a PDF document is determined primarily by the tag order of document elements, including interactive elements, but the order of content within individual tags is determined by the PDF document's content tree structure.\n\nIf the reading order is not correct, keyboard and assistive technology\nusers may not be able to understand the content. For example, some\ndocuments use multiple columns, and the reading order is clear visually\nto sighted users as flowing from the top to the bottom of the first\ncolumn, then to the top of the next column. But if the document is\nnot properly tagged, a screen reader may read the document from top\nto bottom, across both columns, interpreting them as one column.\n\nThe simplest way to ensure correct reading order is to structure the\ndocument correctly in the authoring tool used to create the document,\nbefore conversion to tagged PDF. Note, however, that pages with complex\nlayouts with graphics, tables, footnotes, side-bars, form fields, and\nother elements may not convert to tagged PDF in the correct reading\norder. These inconsistencies must then be corrected with repair tools\nsuch as Acrobat Pro.\n\nWhen a PDF document containing form fields has a correct reading order,\nall form fields are contained in the tab order in the appropriate order,\nand in the correct order relative to other content in the PDF. Common\ntab-order errors include:\n\n- Form fields missing from the tagged content.\n- Form fields in the wrong location in the PDF content; e.g., at\nthe end of non-interactive content.\n\nExamples:\n- **Example 2: Creating a 2-column document using OpenOffice Writer**  This example is shown with OpenOffice Writer. There are other software tools that perform similar functions.  Multi-column documents created using OpenOffice Writer's Columns tool typically are in the correct reading order when converted to tagged PDF. The image below shows Writer's Columns tool. The Columns tool can be found under Format.  This example is shown in operation in theworking example of 2-column document using OpenOffice Writer (OpenOffice file)andworking example of 2-column document using OpenOffice Writer (PDF file).\n- **Example 1: Creating a 2-column document using Microsoft Word**  This example is shown with Microsoft Word. There are other software tools that perform similar functions.  Multi-column documents created using Word's Layout → Columns tool typically are in the correct reading order when converted to tagged PDF. The following image shows Word's Columns tool.  This example is shown in operation in theworking example of 2-column document (Word file)andworking example of 2-column document using Word (PDF file).\n- **Example 4: Repairing the reading order using the Tags panel in Adobe Acrobat Pro**  This example is shown with Adobe Acrobat Pro. There are other software tools that perform similar functions.  Use the Tags panel to correct the reading order. Either:    ---\n- **Example 3: Setting the tab order for one or more pages using Adobe Acrobat Pro**  In a tagged PDF document:  This example is shown in operation in theworking example of setting the tab order (Word file)andworking example of setting the tab order (PDF file).",
    "referenced_by": [
      "1.3.2",
      "2.1.1",
      "2.4.3"
    ]
  },
  {
    "id": "F32",
    "type": "technique",
    "code": "F32",
    "text": "[F32] Failure of Success Criterion 1.3.2 due to using white space characters to control spacing within a word\n\nDescription:\nThe objective of this technique is to describe how using white space characters, such as space, tab, line break, or carriage return, to format individual words visually can be a failure to present meaningful sequences properly. When blank characters are inserted to control letter spacing within a word, they may change the interpretation of the word or cause it not to be programmatically recognized as a single word.\n\nInserting white space characters into an initialism is not an example of this\nfailure, since the white space does not change the interpretation of the\ninitialism and may make it easier to understand.\n\nThe use of white space between words for visual formatting is not a failure,\nsince it does not change the interpretation of the words.\n\nExamples:\n- **Example 1: Failure due to adding white space in the middle of a word**  This example has white spaces within a word to space out the letters in a heading. Screen readers may read each letter individually instead of the word \"Welcome.\"  &nbsp; can also be used to add white space, producing similar failures:  ```html <h1>W e l c o m e</h1> ```  ```html <h1>H&nbsp;E&nbsp;L&nbsp;L&nbsp;O</h1> ```\n- **Example 2: White space in the middle of a word changing its meaning**  In Japanese, Han characters (Kanji) may have multiple readings that mean very different things. In this example, the word is read incorrectly because screen readers may not recognize these characters as a word because of the white space between the characters. The characters mean \"Tokyo,\" but screen readers say \"Higashi Kyo\".  ```html <h1>東　京</h1> ```\n- **Example 3: Using line break characters to format vertical text**  In the row header cell of a data table containing Japanese text, authors often create vertical text by using line break characters. However screen readers are not able to read the words in vertical text correctly because the line breaks occur within the word. In the following example, \"東京都\"(Tokyo-to) will be read \"Higashi Kyo Miyako\".  ```html <table> <caption>表1.　都道府県別一覧表</caption> <tr> <td></td> <th scope=\"col\">（見出しセル 1.）</th> <th scope=\"col\">（見出しセル 2.）</th> </tr> <tr> <th scope=\"row\">東<br />京<br />都</th> <td>（データセル 1.）</td> <td>（データセル 2.）</td> </tr> ... </table> ```    ---",
    "referenced_by": [
      "1.3.2"
    ]
  },
  {
    "id": "F49",
    "type": "technique",
    "code": "F49",
    "text": "[F49] Failure of Success Criterion 1.3.2 due to using an HTML layout table that does not make sense when linearized\n\nDescription:\nAlthough WCAG 2 does not prohibit the use of layout tables, CSS-based layouts are recommended in order to retain the defined semantic meaning of the HTML **table** elements and to conform to the coding practice of separating presentation from content. If a layout table is used, however, it is important that the content make sense when linearized.\n\nThis failure occurs when a meaningful sequence of content conveyed through\npresentation is lost because HTML tables used to control the visual\nplacement of the content do not “linearize\" correctly. Tables present\ncontent in two visual dimensions, horizontal and vertical. However, screen\nreaders present this two-dimensional content in linear order of the content\nin the source, beginning with the first cell in the first row and ending\nwith the last cell in the last row. The screen reader reads the table from\ntop to bottom, reading the entire contents of each row before moving to the\nnext row. The complete content of each cell in each row is spoken—including\nthe complete content of any table nested within a cell. This is called\nlinearization.\n\nSuppose that a web page is laid out using a table with 9 columns and 22 rows.\nThe screen reader speaks the content of the cell at Column 1, Row 1 followed\nby the cells in columns 2, 3, 4 and so on to column 9. However, if any cell\ncontains a nested table, the screen reader will read the entire nested table\nbefore it reads the next cell in the original (outer) table. For example, if\nthe cell at column 3, row 6 contains a table with 6 columns and 5 rows, all\nof those cells will be read before Column 4, Row 6 of the original (outer)\ntable. As a result, the meaningful sequence conveyed through visual\npresentation may not be perceivable when the content is spoken by a screen\nreader.\n\nExamples:\n- **Example 1: A layout table that does not linearize correctly**  An advertisement makes clever use of visual positioning, but changes meaning when linearized.  The reading order from this example would be:  ```html <table> <tr> <td><img src=\"logo.gif\" alt=\"XYZ mountaineering\"></td> <td rowspan=\"2\" valign=\"bottom\">top!</td> </tr> <tr> <td>XYZ gets you to the</td> </tr> </table> ```\n- **Example 2: A layout table that separates a meaningful sequence when linearized**  A web page from a museum exhibition positions a navigation bar containing a long list of links on the left side of the page. To the right of the navigation bar is an image of one of the pictures from the exhibition. To the right of the image is the kind of \"placard\" text you'd see on the wall next to the object if you were at the museum. Below that text is a heading that says \"Description,\" and below that heading is a description of the image. The image, placard text, Description heading, and text of the description form a meaningful sequence.  A layout table is used to position the elements of the page. The links in the navigation bar are split into different cells in the leftmost column.  The reading order from this example would be:  Because the navigation bar links are interleaved with the content describing the image, screen readers cannot present the content in a meaningful sequence corresponding to the sequence presented visually.  ```html <table> <tr> <td><a href=\"#\">Link 1</a></td> <td rowspan=\"20\"><img src=\"img.png\" alt=\"Museum Picture\"></td> <td rowspan=\"6\"><img src=\"placard.png\" alt=\"Placard text\"></td> </tr> <tr> <td><a href=\"#\">Link 2</a></td> </tr> <tr> <td><a href=\"#\">Link 3</a></td> </tr> <tr> <td><a href=\"#\">Link 4</a></td> </tr> <tr> <td><a href=\"#\">Link 5</a></td> </tr> <tr> <td><a href=\"#\">Link 6</a></td> </tr> <tr> <td><a href=\"#\">Link 7</a></td> <td rowspan=\"2\"><h2>Image Heading</h2></td> </tr> <tr> <td><a href=\"#\">Link 8</a></td> </tr> <tr> <td><a href=\"#\">Link 9</a></td> <td rowspan=\"12\">Description of the image</td> </tr> <tr> <td><a href=\"#\">Link 10</a></td> </tr> ... <tr> <td><a href=\"#\">Link 20</a></td> </tr> </table> ```    ---",
    "referenced_by": [
      "1.3.2"
    ]
  },
  {
    "id": "F1",
    "type": "technique",
    "code": "F1",
    "text": "[F1] Failure of Success Criterion 1.3.2 due to changing the meaning of content by positioning information with CSS\n\nDescription:\nThis describes the failure condition that results when CSS, rather than\nstructural markup, is used to modify the visual layout of the content, and\nthe modified layout changes the meaning of the content. Using the\npositioning properties of CSS, content may be displayed at any position on\nthe user's viewport. The order in which items appear on a screen may be\ndifferent than the order they are found in the source document. Assistive\ntechnologies rely on the source code or other programmatically determined\norder to render the content in the correct sequence. Thus, it is important\nnot to rely on CSS to visually position content in a specific sequence if this sequence results in a meaning that is different from the programmatically determined reading order.\n\nExamples:\n- **Example 1**  The following example demonstrates how CSS has been improperly used to create a set of columns. In addition, the text appears visually in the browser in a different order than in the markup.  In this example a class is defined for each object that is being positioned. When style sheets are applied, the text appears in two columns. Elements of class \"menu1\" (Products) and \"menu2\" (Locations) appear as column headings. \"Telephones, Computers, and Portable MP3 Players\" are listed under Products and \"Idaho\" and \"Wisconsin\" are listed under Locations (note the different order for Idaho and Wisconsin in the source code order).  Since appropriate structural elements have not been used, when style sheets are not applied, all of the text appears in one line in the source order, \"Products Locations Telephones Computers Portable MP3 Players Wisconsin Idaho.\"  Here is the HTML content:  Here are the styles for the above content:  A better solution for this content would be to use more meaningful elements, such as a table or a definition list.  ```html <div class=\"box\"> <span class=\"menu1\">Products</span> <span class=\"menu2\">Locations</span> <span class=\"item1\">Telephones</span> <span class=\"item2\">Computers</span> <span class=\"item3\">Portable MP3 Players</span> <span class=\"item5\">Wisconsin</span> <span class=\"item4\">Idaho</span> </div> ```  ```html .menu1 { position: absolute; top: 3em; left: 0em; margin: 0px; font-family: sans-serif; font-size: 120%; color: red; background-color: white } .menu2 { position: absolute; top: 3em; left: 10em; margin: 0px; font-family: sans-serif; font-size: 120%; color: red; background-color: white } .item1 { position: absolute; top: 7em; left: 0em; margin: 0px } .item2 { position: absolute; top: 8em; left: 0em; margin: 0px } .item3 { position: absolute; top: 9em; left: 0em; margin: 0px } .item4 { position: absolute; top: 7em; left: 14em; margin: 0px } .item5 { position: absolute; top: 8em; left: 14em; margin: 0px } #box { position: absolute; top: 5em; left: 5em } ```    ---",
    "referenced_by": [
      "1.3.2"
    ]
  },
  {
    "id": "G96",
    "type": "technique",
    "code": "G96",
    "text": "[G96] Providing textual identification of items that otherwise rely only on sensory information to be understood\n\nDescription:\nThe objective of this technique is to ensure that items within a web page are referenced in the content not only by shape, size, sound or location, but also in ways that do not depend on that sensory perception. For example, a reference may also describe the function of the item or its label.\n\nExamples:\n- **Example 1: Button referenced by shape and accessible name**  A round button is provided on a form to submit the form and move onto the next step in a progression. The button is labeled with the text \"go\". The instructions state, \"to submit the form press the round button labeledgo\". This includes both shape and textual information to locate the button.\n- **Example 2: A section of navigation links referenced by location and heading**  Instructions for a web page providing on-line training state, \"Use the list of links to the right with the heading, 'Class Listing' to navigate to the desired on-line course.\"  This description provides location as well as textual clues to help find the correct list of links.\n- **Example 3: Button referenced by position and accessible name**  The following layout places a button in the lower right corner and indicates it by position. An indication of the text label clarifies which button to use for users for which the position is not meaningful.  ```html <form class=\"wrapper\"> <h1>Sign up to our mailing list</h1> <div role=\"note\"> Complete the form and then press the lower-right (<i>sign up</i>) button. </div> <div class=\"form-group\"> <label for=\"full-name\">Your name</label> <input autocomplete=\"name\" id=\"full-name\" type=\"text\"> </div> <div class=\"form-group\"> <label for=\"email\">Your email address</label> <input autocomplete=\"email\" id=\"email\" type=\"text\"> </div> <button type=\"reset\">Cancel</button> <button type=\"submit\">Sign up</button> </form> ```  ```html .wrapper{ border:1px solid #aeaeae; display:grid; gap:1rem; grid-template-columns:1fr 1fr; padding:1rem; width:50vw; }  label{ display:block; }  input, button{ font:inherit; }  h1, [role=note]{ grid-column:1 / -1; }  .form-group{ grid-column:1; }  input{ width:100%; }  button[type=reset]{ grid-column:1; }  button[type=submit]{ grid-column:2; } ```    ---",
    "referenced_by": [
      "1.3.3"
    ]
  },
  {
    "id": "F14",
    "type": "technique",
    "code": "F14",
    "text": "[F14] Failure of Success Criterion 1.3.3 due to identifying content only by its shape or location\n\nDescription:\nThe objective of this technique is to show how identifying content only by\nits visual shape or location makes content difficult to understand and operate.\nWhen only visual identification or location is used, users with visual\ndisabilities may find it difficult to locate content since they cannot see\nthe screen or may perceive only a small portion of the screen at one time.\nAlso, location of content can vary if page layout varies due to variations\nin font, window, or screen size.\n\nExamples:\n- **Example 1:** The navigation instructions for a site state, \"To go to next page, press the button to the right. To go back to previous page, press the button to the left.\"\n- **Example 2:** A user is reading a news article in an on-line newspaper. The article contains an illustration and additional links for more information. Within the text of the article is a statement, \"Please see sidebar to the left of the illustration for links to additional information.\" An assistive technology user would have difficulty finding the illustration and the sidebar. Some alternatives would be to include the list of links within the text; to provide an in-page link within the text which links to the sidebar; to provide a heading for the sidebar which can be used for navigation and refer to the heading in the instructions.\n- **Example 3:** A user is completing an on-line survey. There are three buttons at the bottom of the survey form. The instructions state, \"Press the square button to exit the survey without saving, Press the triangle button to save in-progress survey results. You may return later to complete the survey. Press the round button to submit the survey results.\" A screen reader user or a user unable to distinguish shapes cannot determine which button is square, triangular, or round. The buttons must have additional information to indicate their functions or their shapes.  ---",
    "referenced_by": [
      "1.3.3"
    ]
  },
  {
    "id": "F26",
    "type": "technique",
    "code": "F26",
    "text": "[F26] Failure of Success Criterion 1.3.3 due to using a graphical symbol alone to convey information\n\nDescription:\nThe objective of this technique is to show how using a graphical symbol to convey information can make content difficult to comprehend. A graphical symbol may be an image, an image of text or a pictorial or decorative character symbol (glyph) which imparts information nonverbally. Examples of graphical symbols include an image of a red circle with a line through it, a \"smiley\" face, or a glyph which represents a check mark, arrow, or other symbol but is not the character with that meaning.\n\nAssistive technology users may have difficulty determining the meaning of the graphical symbol. If a graphical symbol is used to convey information, provide an alternative using features of the technology or use a different mechanism that can be marked with an alternative to represent the graphical symbol. For example, an image with a text alternative can be used instead of the glyph.\n\nExamples:\n- **Example 1: Glyphs Used to Indicate Status**  A shopping cart uses two simple glyphs to indicate whether an item is available for immediate shipment. A circle indicates that the item is in stock and ready to ship. An square indicates that the item is currently on back order and not available for immediate shipment. The instructions above items refer to the circle and square as the sole means to differentiating whether an item is available.    ---",
    "referenced_by": [
      "1.3.3"
    ]
  },
  {
    "id": "G214",
    "type": "technique",
    "code": "G214",
    "text": "[G214] Using a control to allow access to content in different orientations which is otherwise restricted\n\nDescription:\nThe objective of this technique is to allow users to access content in the way the user prefers. A content provider may expect that most users will view content using a specific device orientation or may expect that a user will want to maintain the original view within the device. As a result the provider then prevents the content from rotating. By providing a control to allow the user to rotate the content, someone who needs to use a particular orientation will be able to view the content in a comfortable manner. For example, a person who cannot hold the device and has it mounted attached to a wheelchair or bed.\n\nExamples:\n- **Example 1: An e-Reader application**  Users of an e-Reader web application sometimes read when lying down on their side. In this situation, the device is viewed by the user in portrait mode even though the device is in the landscape orientation with regard to gravity. The developer locks the content into the portrait orientation to allow for this reading behavior, but also provides a control to allow users who have devices mounted in a specific orientation to achieve the desired viewing orientation.    ---",
    "referenced_by": [
      "1.3.4"
    ]
  },
  {
    "id": "F97",
    "type": "technique",
    "code": "F97",
    "text": "[F97] Failure due to locking the orientation to landscape or portrait view\n\nDescription:\nThe objective of this technique is to describe how restricting the view of content to a single orientation is a failure to allow content to be viewed in multiple orientations. When content is presented with a restriction to a specific orientation, users must orient their devices to view the content in the orientation that the author imposed. Some users have their devices mounted in a fixed orientation (e.g. on the arm of a power wheelchair), and if the content cannot be viewed in that orientation it creates problems for the user.\n\nIf a specific orientation is determined to be [essential](https://www.w3.org/TR/WCAG22/#dfn-essential) for the operation and viewing of the content, then this failure technique will not apply.\n\nExamples:\n- **Example 1:** A news app always shows the content in portrait orientation. Users can view the content on a device which supports landscape and portrait display orientations. When the device is turned to landscape view, the content appears sideways to the user.  ---",
    "referenced_by": [
      "1.3.4"
    ]
  },
  {
    "id": "F100",
    "type": "technique",
    "code": "F100",
    "text": "[F100] Failure of Success Criterion 1.3.4 due to showing a message asking to reorient device\n\nDescription:\nThis describes the failure condition that results when an author, having detected a device orientation that is considered undesirable, displays a message telling the user to reorient the device -- instead of the author reorienting all the content.\n\nDetecting and responding to a user's device orientation is not itself a problem. The author decision to only offer one orientation of content is what fails the requirements of Success Criterion (SC) 1.3.4 Orientation. It is inadequate to display only a message in the detected orientation, telling users to rotate their devices (when not essential to the underlying activity). The entirety of the author-controlled content needs to be re-oriented in order to meet the SC.\n\nThere are various methods for devices to determine if the content is in landscape or portrait orientation. One of these methods involves looking at the width-to-height aspect ratio of the viewport. In other words, checking if the width is smaller or larger than the height. The CSS **orientation** media feature is **portrait** when the value of the **height** media feature is greater than or equal to the value of the **width** media feature. Otherwise, **orientation** is **landscape**.\n\nExamples:\n- **Example 1: Block an orientation (\"door slam\") by using HTML and CSS**  The following example uses HTML and CSS to show a message asking to reorient the device if inlandscape.  The message will disappear if the orientation is changed toportrait.  When theportraitproperty matches the viewport space defined via media queries, the message will disappear or vice versa. This particular example uses the CSSlandscape,portraitmedia query properties.  Working example:Show message asking to reorient device  ```html <style> /* Orientation \"door slam\" Styling */  @media all and (orientation: landscape) { .rotate { display: block; } .content { display: none; } }  @media all and (orientation: portrait) { .rotate { display: none; } .content { display: block; } }  .rotate { text-align: center; font-size: 2rem; margin-top: 4rem; } </style> ```  ```html <!-- Orientation \"door slam\" HTML -->  <div class=\"rotate\">Please rotate your device!</div>  <div class=\"content\"> ... </div> ```    ---",
    "referenced_by": [
      "1.3.4"
    ]
  },
  {
    "id": "H98",
    "type": "technique",
    "code": "H98",
    "text": "[H98] Using HTML 5.2 autocomplete attributes\n\nDescription:\nThe objective of this technique is to programmatically link a pre-defined and published taxonomic term to the input, so that the inputs can also be machine-interpreted. This way the input will always have a common, referable and identifiable value associated to it, no matter what language is used, or what visible on-screen term is used to label the input. Then it can be further customized or otherwise machine-manipulated to help users.\n\nThe technique works by adding the appropriate **autocomplete** token to each form field on the form to make the identified inputs Programmatically Determinable. This will help people with cognitive disabilities who may not immediately know the purpose of the field because the label used by the author is not familiar to them. When inputs have been programmatically assigned, third party plugins and software can manipulate these form fields to make them more accessible to people with cognitive disabilities. For instance, a plugin could detect an **autocomplete** token with the text string \"**tel**\" and insert a telephone icon. It will further enable third party software to swap out the existing labels for text labels that the user finds more familiar. For instance, it could change \"Given Name\" to \"First Name\".\n\nThe **autocomplete** attribute also improves the browser's ability to pre-populate form fields with user-preferred values. When the input has been properly \"tagged\" with the known token value, the value entered by the user is stored locally on the host machine and associated with the token value for reuse. It helps those with dexterity disabilities who have trouble typing, those who may need more time, and anyone who wishes to reduce effort to fill out a form.\n\nThe **autocomplete** attribute allows the browser to do a pattern match against a list of values locally stored with the browser, and supplies the appropriate corresponding value when the input is programmatically tagged. This is a user setting that can be turned on or off, or modified by the end user. This reduces typing and reliance on memory because it uses stored values to fill in the fields.\n\nIt's important to note the Success Criterion [Identify Input Purpose](https://www.w3.org/WAI/WCAG22/Understanding/identify-input-purpose.html) and **autocomplete** attribute only place requirements on input fields collecting information about the user.\n\nFor the Success Criterion, it is assumed that the **autocomplete** attribute is not used on form fields that do not correspond to an autocomplete field described in the [HTMLautocompleteattribute specification](https://html.spec.whatwg.org/multipage/form-control-infrastructure.html#autofilling-form-controls:-the-autocomplete-attribute). If the **autocomplete** field is used to describe a \"custom\" taxonomy, rather than that described in the specification, this rule may produce incorrect results.\n\nExamples:\n- **Example 1: A user's credit card information**  This is a simple form that collects contact and credit card information from the user.  ```html <form method=\"post\" action=\"step2\"> <div> <label for=\"fname\">First Name</label> <input autocomplete=\"given-name\" id=\"fname\" type=\"text\"> </div> <div> <label for=\"lname\">Last Name</label> <input autocomplete=\"family-name\" id=\"lname\" type=\"text\"> </div> <div> <label for=\"cc-num\">Credit card number:</label> <input autocomplete=\"cc-number\" id=\"cc-num\" type=\"text\"> </div> <div> <label for=\"exp-date\">Expiry Date:</label> <input autocomplete=\"cc-exp\" id=\"exp-date\" type=\"month\"> </div> <div> <input type=\"submit\" value=\"Continue\"> </div> </form> ```    ---",
    "referenced_by": [
      "1.3.5"
    ]
  },
  {
    "id": "F107",
    "type": "technique",
    "code": "F107",
    "text": "[F107] Failure of Success Criterion 1.3.5 due to incorrect autocomplete attribute values\n\nDescription:\nThe purpose of this technique is to identify a failure condition where form inputs do not have the correct **autocomplete** attribute values for inputs that request information about the user of the form.\n\nSuccess Criterion 1.3.5 uses a fixed list of tokens in [Input Purposes for user interface components](/TR/WCAG/#input-purposes) (based on the HTML 5.2 **autocomplete** attribute's fixed list of token values) because the programmatic association of specified token values (metadata) allows for other machine processing, such as expressing the input label in different modalities.\n\nAnother important part of this success criterion is that the token values are associated with inputs that are scoped directly to the primary end user.\n\nExamples:\n- **Example 1: Incorrect attribute**  An online form used to collect the user's name and birthday which uses incorrectautocompleteattributes. The correct attribute value for the first control isname, and for the second control the made-up attribute valuebirthdaywas used instead ofbday.  ```html <h2>Your details:</h2> <label for=\"uname\">Name:</label> <input autocomplete=\"email\" id=\"uname\" type=\"text\"> <label for=\"ubirthday\">Birthday:</label> <input autocomplete=\"birthday\" id=\"ubirthday\" type=\"text\"> ```    ---",
    "referenced_by": [
      "1.3.5"
    ]
  },
  {
    "id": "C32",
    "type": "technique",
    "code": "C32",
    "text": "[C32] Using media queries and grid CSS to reflow columns\n\nDescription:\nThe objective of this technique is to be able to present content without introducing a horizontal scroll bar at a width equivalent to 320 CSS pixels, or a vertical scroll bar at a height equivalent to 256 CSS pixels for text intended to scroll horizontally. This is done by using layout techniques that adapt to the available viewport space.\n\n[Grid layouts](https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Grid_Layout) define layout regions that reflow as needed to display the region on the screen. Although the exact layout therefore varies, the relationship of elements and the reading order remains the same when done right. This is an effective way to create designs that present well on different devices and for users with different content-size preferences.\n\nThe basic principles of grid layouts are to:\n\nExamples:\n- **Example 1: Grid layout in HTML and CSS - Medium complexity**  The following medium complexity example uses HTML and CSS to create a grid layout. The layout regions adjust their size as the viewport is adjusted. When the total viewport width matches the width defined via media queries, columns wrap to be positioned below, rather than beside each other or vice versa.  The zoom level can be increased to 400% without requiring scrolling in more than one direction. This particular example uses fr units as a fraction of the free space of the grid container for the grid items by using the \"grid-template-columns\" property and are laid out in source order.  Working example:Using media queries and grid CSS to reflow columns  ```html <!DOCTYPE html> <html lang=\"en\"> <head> <meta charset=\"UTF-8\"> <title>CSS: Using media queries and grid CSS to reflow columns</title> <style>  /* Reflow Styling */ header { grid-area: header; } main   { grid-area: main; } aside  { grid-area: aside; } footer { grid-area: footer; }  .grid, .subgrid { display: grid; grid-template-columns: minmax(0, 1fr); }  .grid { grid-template-areas: 'header' 'main' 'aside' 'footer'; width: 100%; }  .subgrid { width: calc(100% + 2rem); margin: 0 -1rem; }  .grid-item, .subgrid-item { padding: 1rem; }  @media all and (min-width: 576px) { .subgrid { grid-template-columns: minmax(0, 1fr) minmax(0, 1fr); margin-bottom: 1rem; } .subgrid-item { padding-bottom: 0.25rem; } }  @media all and (min-width: 992px) { .grid { grid-template-areas: 'header header header' 'main main aside' 'footer footer footer'; grid-template-columns: minmax(0, 1fr) minmax(0, 1fr) minmax(0, 1fr); } }  </style>  </head>  <body class=\"grid\">  <header class=\"grid-item\"> ... </header>  <main class=\"grid-item\"> ... ... <div class=\"subgrid\"> <div class=\"subgrid-item\"> ... </div> <div class=\"subgrid-item\"> ... </div> </div> </main>  <aside class=\"grid-item\"> ... </aside>  <footer class=\"grid-item\"> ... </footer>  </body> </html> ```    ---",
    "referenced_by": []
  },
  {
    "id": "C31",
    "type": "technique",
    "code": "C31",
    "text": "[C31] Using CSS Flexbox to reflow content\n\nDescription:\nThe objective of this technique is to be able to present content without introducing a horizontal scroll bar at a width equivalent to 320 CSS pixels, or a vertical scroll bar at a height equivalent to 256 CSS pixels for text intended to scroll horizontally. This is done by using layout techniques that adapt to the available viewport space.\n\n[Flexbox layouts](https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Flexible_Box_Layout) define layout regions that reflow as needed to display the region on the screen. Although the exact layout therefore varies, the relationship of elements and the reading order remains the same when done right. This is an effective way to create designs that present well on different devices and for users with different zoom preferences.\n\nThe basic principles of flexbox layouts are to:\n\nExamples:\n- **Example 1: Medium complex flexbox layout inHTMLand CSS**  The following medium complex example uses HTML and CSS to create a flexbox layout. The layout regions adjust their size as the viewport is adjusted. When the total viewport width matches the width defined via media queries, columns wrap to be positioned below, rather than beside each other or vice versa.  The zoom level can be increased to 400% without requiring scrolling in more than one direction. This particular example uses percent sizes for the flex items by using the \"flex-basis\" property and are laid out in source order.  Working example:Using CSS Flexbox for Reflow  ```html <!DOCTYPE html> <html lang=\"en\"> <head> <meta charset=\"UTF-8\"> <title>Using CSS Flexbox for Reflow</title> <style>  /* Reflow Styling */  .row { width: 100%; display: flex; flex-flow: row wrap; }  .row-nested { width: calc(100% + 2rem); margin: 0 -1rem 1rem -1rem; }  .col { padding: 1rem; flex: 0 1 100%; }  @media all and (min-width: 576px) { .col-panel { flex: 0 1 50%; padding-bottom: 0.25rem; } }  @media all and (min-width: 992px) { main { flex: 0 1 66.333333%; } aside { flex: 0 1 33.333333%; margin-top: 0; } } </style> </head> <body class=\"row\"> <header class=\"col\"> ... </header> <main class=\"col\"> ... ... <div class=\"row row-nested\"> <div class=\"col col-panel\"> ... </div> <div class=\"col col-panel\"> ... </div> </div> </main> <aside class=\"col\"> ... </aside> <footer class=\"col\"> ... </footer> </body> </html> ```    ---",
    "referenced_by": []
  },
  {
    "id": "C33",
    "type": "technique",
    "code": "C33",
    "text": "[C33] Allowing for Reflow with Long URLs and Strings of Text\n\nDescription:\nLong sets of characters without a space, such as URLs shown as content, can break reflow when the page is zoomed. The objective of this technique is to present URLs without introducing a horizontal scroll bar at a width equivalent to 320 CSS pixels or a vertical scroll bar at a height equivalent to 256 CSS pixels. This is done by using CSS techniques that adapt to the available viewport space. Note: Using a human readable text link, rather than a long URL, is better for usability and accessibility.\n\nBy default most browsers will wrap long URLs at the following characters:\n\n- \"&\" Ampersand\n- \"/\" Forward Slash\n- \"-\" Hyphen\n- \"?\" Question Mark\n\nSometimes these are not enough to ensure that long URLs will not overflow the viewport.\n\nExamples:\n- **Example 1: Breaking long URLs**  Using the following CSS will cause long URLs to break at appropriate places (hyphens, forward slashes, etc.) and within words without causing reflow.  List of CSS declarations used and why they are used:  Working Example  ```html a { overflow-wrap: break-word; word-wrap: break-word; } ```    ---",
    "referenced_by": []
  },
  {
    "id": "C38",
    "type": "technique",
    "code": "C38",
    "text": "[C38] Using CSS width, max-width and flexbox to fit labels and inputs\n\nDescription:\nThe objective of this technique is to be able to present labels and inputs without introducing a horizontal scroll bar at a width equivalent to 320 CSS pixels for content intended to scroll vertically. When space is limited in the viewport for the label and input to sit next to each other horizontally, they will be changed to a vertical alignment. This is done by using CSS properties for **width**, **max-width** and flexbox that adapt to the available space.\n\nResponsive layouts can add or remove columns or layout blocks, and each part of the layout can be wider or smaller at different points. This technique ensures labels and inputs do not break out of their layout area, including in one-column layouts where it would cause horizontal scrolling.\n\nThe basic approach for fitting labels and inputs is to:\n\nAll labels and inputs require design finesse by making sure the original size fits the biggest size of the available spaces to achieve good-looking results at a wide range of viewport sizes and zoom levels. For help on flexbox please see the [MDN article on Flexbox](https://developer.mozilla.org/en-US/docs/Learn/CSS/CSS_layout/Flexbox).\n\nExamples:\n- **Example 1: Fitting labels, inputs and flexbox layout with HTML and CSS.**  The following example uses HTML and CSS to fit labels and inputs within various width containers, including the viewport. The layout regions adjust their size as the viewport is adjusted. The labels and inputs subsequently adjust their size to fit within the layout region containers.  The zoom level can be increased to 400% without requiring horizontal scrolling. This particular example uses a percent size for thewidthandmax-widthfor the labels and inputs. Themax-widthis applied in order to fix elements spilling out of the grid in a cross-browser way, as replaced elements such as theselecthave intrinsic sizing.  Working example:Using Adjustable Labels and Inputs for Reflow  ```html <style>  /* Fitting Inputs Styling */  .form-group { display: flex; flex-flow: row wrap; margin: 0 -1rem 1rem -1rem; }  [class*=\"form-col\"] { flex: 0 1 100%; padding: 0 1rem; }  @media (min-width: 576px) { .form-col-4 { flex: 0 0 33.33333%; max-width: 33.33333%; }  .form-col-8 { flex: 0 0 66.66667%; max-width: 66.66667%; }  .offset-form-col-4 { margin-left: 33.33333%; } }  input { display: block; width: 100%; }  label, select { display: block; width: 100%; max-width: 100%; }  </style>  <div class=\"form-group\"> <div class=\"form-col-4\"> <label for=\"fname\">First Name</label> </div> <div class=\"form-col-8\"> <input type=\"text\" id=\"fname\" autocomplete=\"given-name\"> </div> </div>  <div class=\"form-group\"> <div class=\"form-col-4\"> <label for=\"lname\">Last Name</label> </div> <div class=\"form-col-8\"> <input type=\"text\" id=\"lname\" autocomplete=\"family-name\"> </div> </div>  <div class=\"form-group\"> <div class=\"form-col-4\"> <label for=\"favorite-fruit\">Favorite fruit</label> </div> <div class=\"form-col-8\"> <select id=\"favorite-fruit\"> <option>Banana</option> <option>Pineapple</option> <option>Strawberry</option> </select> </div> </div>  <div class=\"form-group\"> <div class=\"offset-form-col-4 form-col-8\"> <button type=\"submit\">Submit</button> </div> </div> ```    ---",
    "referenced_by": []
  },
  {
    "id": "SCR34",
    "type": "technique",
    "code": "SCR34",
    "text": "[SCR34] Calculating size and position in a way that scales with text size\n\nDescription:\nThe objective of this technique is to calculate the size and position of elements in a way that will scale appropriately as the text size is scaled.\n\nThere are four properties in JavaScript that help determine the size and position of elements:\n\n- offsetHeight(the height of the element in pixels)\n- offsetWidth(the width of the element in pixels)\n- offsetLeft(the distance of the element from the left of its parent (offsetParent) in pixels)\n- offsetTop(the distance of the element from the top of its parent (offsetParent) in pixels)\n\nCalculating the height and width using **offsetHeight** and **offsetWidth** is straightforward, but when calculating an object's left and top position as absolute values, we need to consider the parent element. The **calculatePosition** function below iterates through all of an element's parent nodes to give a final value. The function takes two parameters: **objElement** (the name of the element in question), and the offset property (**offsetLeft** or **offsetTop**):\n\nExamples:\n- **Example 1: Calculating the size and position of elements in a way that will scale appropriately as the text size is scaled**  The following example illustrates using the function above by aligning an object beneath a reference object, the same distance from the left:  ```html function calculatePosition(objElement, strOffset { var iOffset = 0; if (objElement.offsetParent) { do { iOffset += objElement[strOffset]; objElement = objElement.offsetParent; } while (objElement); } return iOffset; } ```  ```html // Get a reference object var objReference = document.getElementById('refobject'); // Get the object to be aligned var objAlign = document.getElementById('lineup');  objAlign.style.position = 'absolute'; objAlign.style.left = calculatePosition(objReference, 'offsetLeft') + 'px'; objAlign.style.top = calculatePosition(objReference, 'offsetTop') + objReference.offsetHeight + 'px'; ```    ---",
    "referenced_by": [
      "1.4.4",
      "1.4.8"
    ]
  },
  {
    "id": "G206",
    "type": "technique",
    "code": "G206",
    "text": "[G206] Providing options within the content to switch to a layout that does not require the user to scroll horizontally to read a line of text\n\nDescription:\nThere may be situations where an author needs to use a layout that requires horizontal scrolling. In that case, it is sufficient to provide options within the content that switch to a layout that does not require the user to scroll horizontally to read a line of text. This may be achieved using standard style switching technology.\n\nIt should be noted that it is also sufficient to lay out the content in such a way that horizontal scrolling is required to access content, but that it is not necessary to scroll horizontally in order to read a line of text.\n\nFor instance, a spreadsheet that requires horizontal scrolling is acceptable if no horizontal scrolling is necessary for each column individually (i.e., scrolling is only necessary to see other columns, but not for the left or right edges of each individual column).\n\nExamples:\n- **Example 1**  A real estate company has an online annual report that has an identical layout to that of their print version, and as such, requires horizontal scrolling to read a line of text. A control is on the page that switches the stylesheet and provides a layout that does not require horizontal scrolling.\n- **Example 2**  A financial spreadsheet is online. It includes text explaining changes in the housing market in January. Off-screen to the right, there is a column with an explanation of changes to the market in September. The user can horizontally scroll to the September area and read each line of text without any further scrolling when the window size is maximized.    ---",
    "referenced_by": [
      "1.4.8"
    ]
  },
  {
    "id": "C34",
    "type": "technique",
    "code": "C34",
    "text": "[C34] Using media queries to un-fixing sticky headers / footers\n\nDescription:\nThe objective of this technique is to be able to present content with sticky headers and footers when there is enough space. This is done by using **min-height**, **max-height**, and **min-width** media queries techniques that adapt to the available space of the viewport.\n\nSticky regions always stay visible in the viewport while the other content will disappear underneath when scrolling. In terms of content visibility, this is often not a problem on the desktop and on mobile devices in portrait orientation. However, when using mobile devices in landscape orientation or when zooming in on the desktop, sticky regions may block a big portion of the screen: the height of the sticky region may leave only a small part of the screen for the display of page content.\n\nDisabling, or un-fixing sticky regions, is an effective way to allow for enough available space when users prefer different reading and zoom preferences or when using landscape mode.\n\nThe basic approach for un-fixing sticky headers / footers is to:\n\nExamples:\n- **Example 1: Un-fix sticky headers / footers in HTML and CSS**  The following example uses HTML and CSS to un-fix sticky headers / footers. The sticky regions get un-fixed as the height of the viewport is limited or the orientation is changed. When themin-heightproperty matches the viewport space defined via media queries, regions which are not sticky get fixed or vice versa. This particular example uses the CSSmin-height,max-heightandmin-widthmedia query properties.  Working example:Using media queries to un-fix sticky headers / footers  ```html <!DOCTYPE html> <html lang=\"en\"> <head> <meta charset=\"UTF-8\"> <title>Using media queries to un-fix sticky headers / footers</title> <style>  /* Sticky Styling */  header { min-height: 130px; }  @media (min-height: 480px) { header { position: -webkit-sticky; position: sticky; top: 0; } }  @media (min-device-width: 576px) and (max-device-width: 1024px) and (orientation: landscape) { header { position: static; } }  footer { min-height: 130px; }  @media (min-height: 480px) { footer { position: sticky; bottom: 0; } }  @media (min-device-width: 576px) and (max-device-width: 1024px) and (orientation: landscape)  { footer { position: static; } }  </style>  </head>  <body class=\"grid\">  <header class=\"grid-item\"> ... </header>  <main class=\"grid-item\"> ... </main>  <aside class=\"grid-item\"> ... </aside>  <footer class=\"grid-item\"> ... </footer>  </body> </html> ```    ---",
    "referenced_by": []
  },
  {
    "id": "C37",
    "type": "technique",
    "code": "C37",
    "text": "[C37] Using CSS max-width and height to fit images\n\nDescription:\nThe objective of this technique is to be able to present images without introducing a horizontal scroll bar at a width equivalent to 320 CSS pixels, or a vertical scroll bar at a height equivalent to 256 CSS pixels for content intended to scroll horizontally. This is done by using CSS **max-width** and **height** property techniques that adapt to the available space and keep the original dimensions of the image.\n\nResponsive layouts can add or remove columns or layout blocks, and each part of the layout can be wider or smaller at different points. This technique ensures images do not break out of their layout area, including in one-column layouts where it would cause scrolling.\n\nThe basic principles of fitting images are to:\n\nAll images require design finesse by making sure the original size fits the biggest size of the available spaces to achieve good-looking results at a wide range of viewport sizes and zoom levels.\n\nExamples:\n- **Example 1: Fitting images in HTML and CSS**  The following simple example uses HTML and CSS to create a fitting image. The layout regions adjust their size as the viewport is adjusted. The images subsequently adjust their size to fit within the layout region containers.  The zoom level can be increased to 400% without requiring scrolling in more than one direction. This particular example uses a percent size for themax-widthand auto size for theheightof the image to remain the original dimensions.  Working example:Using Fitting Images for Reflow  ```html <style> .img-responsive { max-width: 100%; } </style>  <div class=\"panel\"> <img alt=\"\" class=\"img-responsive\" src=\"...\"> ... </div> ```    ---",
    "referenced_by": []
  },
  {
    "id": "F102",
    "type": "technique",
    "code": "F102",
    "text": "[F102] Failure of Success Criterion 1.4.10 due to content disappearing and not being available when content has reflowed\n\nDescription:\nThis document describes a failure that occurs when a change of the viewport width to 320px makes content disappear that was available at wider viewport widths. Some content available at wider widths may not be shown in the same way or at the same position at the viewport width of 320px, simply because there is less space (screen 'real estate') to display it. This content, however, should still be available after reflow to 320px viewport width, either by being repositioned in a single column view, or through some interaction offering the information in some other way, for example, in a disclosure area, a dialog, or via a link to another view.\n\nExamples:\n- **Example 1:** A block of blog entry links in a side column disappears entirely after reflow (i.e., it is not available further down in the single column view).\n- **Example 2:** Labels above text inputs are hidden and replaced by placeholder text after reflow, without a technique showing dedicated labels when focusing the fields.\n- **Example 3:** Sections of content text disappear after reflow, without being available via some disclosure widget.\n- **Example 4:** Information-carrying images disappear after reflow, without link or the availability of an equivalent alternative.\n- **Example 5:** A global search field disappears after reflow, without an icon or menu option to reveal a search function or reach an equivalent search page.  ---",
    "referenced_by": []
  },
  {
    "id": "G195",
    "type": "technique",
    "code": "G195",
    "text": "[G195] Using an author-supplied, visible focus indicator\n\nDescription:\nThe objective of this technique is enhance the focus indicator in the browser, by creating a visible one in the content. The default focus indicator in some browsers is a thin, dotted, black line. It can be difficult to see the line when it is around a form element which already has an outline, when the focused element is inside a table cell, when the focused element is very small, or when the background of the page is a dark color. Some browsers use a pale blue outline, which can be difficult to see on some backgrounds.\n\nIn this technique, when the user places focus on an element using the keyboard, the application makes that focus more visible, using a combination of a highly contrasting color, a thick line, and other visual indicators such as a glow.\n\nExamples:\n- **Example 1: Links**  A web page has a dark background color and light text and links. When focus lands on a link, the link is outlined with a bright yellow line, 3 pixels wide.\n- **Example 3: Menus**  A web page includes an interactive menu with sub-menus. A user can move focus in the menu using the arrow keys. As focus moves, the currently focused menu item changes its background to a different color, which has a 3:1 contrast ratio with the surrounding items and a 4.5:1 contrast ratio with its own text.    ---\n- **Example 2: Form Elements**  A web page includes a form inside a table. The borders of both the table and the form elements are thin, black lines. When focus lands on a form element, the element is outlined with a 5 pixel red line that is partially transparent. The red is equivalent to a hex color of #FF3838, providing a 3.6:1 contrast ratio with the white background.",
    "referenced_by": [
      "2.4.7"
    ]
  },
  {
    "id": "G174",
    "type": "technique",
    "code": "G174",
    "text": "[G174] Providing a control with a sufficient contrast ratio that allows users to switch to a presentation that uses sufficient contrast\n\nDescription:\nWhen the contrast between the text and its background for some portion of the page has not been designed to meet the contrast level for\n[Success Criterion 1.4.3](https://www.w3.org/WAI/WCAG22/Understanding/contrast-minimum)\nor\n[1.4.6](https://www.w3.org/WAI/WCAG22/Understanding/contrast-enhanced), it is possible to meet these guidelines using the \"Alternate Version\" clause in the conformance requirements ([Conformance Requirement 1](https://www.w3.org/WAI/WCAG22/Understanding/conformance#conf-req1)). A link or control on the page can either change the page so that all aspects conform, or it could take the viewer to a new version of the page that does conform at the desired level. Placing the link or control prominently on the page will assist users in accessing the conforming content readily.\n\nFor this technique to be used successfully, three things must be true:\n\nThis technique can be used to meet Success Criterion 1.4.3 by having text (or images of text) on the alternate version of the page be 4.5:1 contrast and any large text (or images of large text) be 3:1 contrast with its background. If the alternate version of the page has all text (or images of text) with 7:1 contrast and large text (or images of large text) with 4.5:1 contrast then it would satisfy both Success Criterion 1.4.3 and 1.4.6.\n\nExamples:\n- **Example 2:** A page uses shaded backgrounds for effect but results in text to background contrast of 4:1. A control at the top of the page says \"high contrast\". Clicking on it causes different styles to be used and dropping the background colors to achieve 7:1 contrast.  ---\n- **Example 1:** A page with some headlines that do not meet the 3:1 contrast requirements has a high contrast (5:1) link at the top of the page that takes the user to a new version of the page with minimum 4.5:1 contrast on all text and images of text.",
    "referenced_by": [
      "1.4.3",
      "1.4.6"
    ]
  },
  {
    "id": "G207",
    "type": "technique",
    "code": "G207",
    "text": "[G207] Ensuring that a contrast ratio of 3:1 is provided for icons\n\nDescription:\nThe objective of this technique is to ensure graphical icons provide enough contrast for people with vision impairments. Not all graphics are within the scope of [SC 1.4.11 Non-text contrast](https://www.w3.org/WAI/WCAG22/Understanding/non-text-contrast.html) but if the icons are required to understand the content, then the icons need to have a contrast ratio of at least 3:1.\n\nThe success criteria for non-text contrast uses the term [\"graphical object\"](https://www.w3.org/WAI/WCAG22/Understanding/non-text-contrast.html#graphical-objects) to cover small simple graphics, and parts of larger complex graphics. This technique focuses on solid color icons used on solid or gradient backgrounds.\n\nWhen choosing the colors for graphics, consider the color(s) adjacent to that graphic, and test that the contrast ratio is at least 3:1.\n\nExamples:\n- **Example 1: Solid icon color against the background**  A solid icon such as a telephone symbol uses orange on a white background. The color orange (#E3660E) is tested against the white background (#FFFFFF) and it has a contrast ratio of 3.4:1.\n- **Example 2: Solid icon color against a custom background**  A solid icon such as a telephone symbol used within an orange background. The orange and white colors are the same as in example 1, in this case the contrast against the white background is not relevant, the white icon within the orange background is what provides the information in the icon and as a result needs to meet the contrast requirement.\n- **Example 3: Solid icon with a gradient background**  A solid icon such as a telephone symbol using a dark blue icon on a white-to-blue gradient background. The first test of the icon should be against the darkest (least contrasting) background that is adjacent to the icon color. If that is at least 3:1, it passes the success criterion.\n- **Example 4: Solid icon with gradient background overlapping in contrast**  A solid icon on a gradient background can overlap in contrast if the graphic is still understandable where it does not have contrast against all of the background. If you find the part of the gradient where it does not meet a 3:1 ratio with the graphic and treat that part as if it was removed, does the icon still convey the appropriate meaning?  A method of visualizing this is to remove the non-contrasting area and check that you can still understand the icon. If so, it is sufficient. The images below shows an icon on a gradient background, and a second version where it removes the area of the icon  that does not meet the 3:1 contrast ratio. It is still recognizable as a phone icon, so passes the success criterion.      ---",
    "referenced_by": []
  },
  {
    "id": "G209",
    "type": "technique",
    "code": "G209",
    "text": "[G209] Provide sufficient contrast at the boundaries between adjoining colors\n\nDescription:\nThe objective of this technique is to ensure people with moderately low vision can distinguish boundaries between adjoining segments of color.\n\nThe success criteria for non-text contrast uses the term \"graphical object\" to cover small simple graphics, and parts of larger complex graphics. This technique focuses on solid color segments where the boundaries between colors convey meaning.\n\nWhen selecting colors for graphics with multiple colors, consider adjoining colors and test that the contrast ratio is at least 3:1. If adjoining colors have less than 3:1 color contrast ratio difference add a border with at least a 3:1 color contrast with each color.\n\nExamples:\n- **Example 1: Pie chart with alternative light/dark colors**\n- **Example 2: Pie chart with borders between segments**\n- **Example 3: Map with border boundaries**\n- **Example 4: Pie chart with black and white borders**    ---",
    "referenced_by": []
  },
  {
    "id": "F78",
    "type": "technique",
    "code": "F78",
    "text": "[F78] Failure of Success Criterion 2.4.7 due to styling element outlines and borders in a way that removes or renders non-visible the visual focus indicator\n\nDescription:\nThis describes a failure condition that occurs when the user agent's default visual indication of keyboard\nfocus is turned off or rendered non-visible by other styling on the page without providing an author-supplied\nvisual focus indicator. Turning off the focus indicator instructs the user agent not to present the focus\nindicator. Other styling may make it difficult to see the focus indicator even though it is present, such as\noutlines that look the same as the focus outline, or thick borders that are the same color as the focus\nindicator so it cannot be seen against them.\n\nExamples:\n- **Example 3: Elements have a border that occludes the focus indicator**  The following CSS example creates a border around links that does not have enough contrast for the focus indicator to be seen when drawn on top of it. In this case the focus indicator is drawn just outside the border, but as both are black and the border is thicker than the focus indicator, it no longer meets the definition of \"visible\".  ```html a {border: medium solid black} ```    ---\n- **Example 1: The focus indicator is turned off with CSS**  The following CSS example will remove the default focus indicator, which fails the requirement to provide a visible focus indicator.  ```html :focus {outline: none} ```\n- **Example 2: The outline of elements is visually similar to the focus indicator**  The following CSS example will create an outline around links that looks the same as the focus indicator. This makes it impossible for users to determine which one in fact has the focus, even though the user agent does draw the focus indicator.  ```html a {outline: thin dotted black} ```",
    "referenced_by": [
      "2.4.7"
    ]
  },
  {
    "id": "C36",
    "type": "technique",
    "code": "C36",
    "text": "[C36] Allowing for text spacing override\n\nDescription:\nThe objective of this technique is to allow a user to override text spacing via user stylesheet, bookmarklet, extension, or application. Increased spacing between paragraphs, lines, words, and characters benefits people with low vision or some cognitive disabilities. Content needs to allow spacing changes without loss of content or functionality, so text containers must either have room for the text to expand or the container must be able to expand. This technique will typically apply to short strings of text such as in a navigation bar, as longer strings of text are increasingly likely to require wrapping to be readable when styles are changed.\n\nIn English languages, if authors do not set the CSS **height** property, it can help ensure paragraphs expand. Paragraphs need to allow text to increase vertically for languages or scripts such as English which are read horizontally or to increase horizontally for languages or scripts which are read vertically.\n\nExamples:\n- **Example 1: A paragraph expands vertically within container**  None of the paragraphs on this page have a height specified, so all are effectively using this technique.  ```html <style> /* CSS: No height property is set.*/ </style> ```  ```html <div class=\"card\"> <img alt=\"\" src=\"image.png\"> <h3>Heading</h3> <p class=\"lede\">Long lede paragraph...</p> </div> ```    ---",
    "referenced_by": []
  },
  {
    "id": "C35",
    "type": "technique",
    "code": "C35",
    "text": "[C35] Allowing for text spacing without wrapping\n\nDescription:\nThe objective of this technique is to allow a user to override text spacing via user stylesheet, bookmarklet, extension, or application. Increased spacing between paragraphs, lines, words, and characters benefits people with low vision or some cognitive disabilities. Content needs to allow spacing changes without loss of content or functionality by allowing the elements containing the text to expand as needed.\n\nWhere text is not intended to wrap, authors should either:\n\n- size containers to a have a value greater than the default width of the text, or\n- allow the containers to expand in the direction of text.\n\nThere is some variability in the width that words or phrases will grow to when setting the letter and word spacing. If elements must use a fixed width, a safe value is 20% wider than the default maximum width. For example, if a small text-container allows for 20 characters, allowing enough width for 24 characters should allow enough space for text-spacing to be applied.\n\nFor boxes which can expand with the text, authors can take advantage of the **inline-block** value of the CSS **display** property and not set negative margins to allow for text-spacing overrides.\n\nExamples:\n- **Example 1: A box sized with space to allow for expansion**  The containers are sized to a value greater than the default width of the text.  If the navigation element used fix-width containers of the same size, the width would need to allow for text 20% larger than the longest word.  ```html <style> /* Links are less than 8ex wide, so 10ex width of each li allows for expanded letter and word width */ nav li { width: 10em; } </style> ```  ```html <nav> <ul> <li><a href=\"/\">Home</a></li> <li><a href=\"/contact/\">Contact</a></li> <ul> </nav> ```\n- **Example 2: A box which expands with the text size**  In the case of variable-width text containers for each item, the parent item may need to allow for wrapping of the items.  Working examples of #1 and #2are available.  ```html <style> /* CSS containers are given a display of inline-block. No negative margins set. */ nav li { display: inline-block; } </style> ```  ```html <nav> <ul> <li><a href=\"/\">Home</a></li> <li><a href=\"/contact/\">Contact</a></li> <ul> </nav> ```    ---",
    "referenced_by": []
  },
  {
    "id": "C21",
    "type": "technique",
    "code": "C21",
    "text": "[C21] Specifying line spacing in CSS\n\nDescription:\nMany people with cognitive disabilities have trouble tracking lines of text when a block of text is single spaced. Providing spacing between 1.5 to 2 allows them to start a new line more easily once they have finished the previous one.\n\nExamples:\n- **Example 1: Setting the element to 1.5 line height**  In the style sheet set the characteristics of the element.  This sets the line height of everything in the body of the document to 1.5.  ```html body { line-height: 1.5; } ```    ---",
    "referenced_by": [
      "1.4.8"
    ]
  },
  {
    "id": "C28",
    "type": "technique",
    "code": "C28",
    "text": "[C28] Specifying the size of text containers using em units\n\nDescription:\nThe objective of this technique is to specify the width and/or height of containers, that contain text or that will accept text input, in **em** units. This will allow user agents that support text resizing to resize the text containers in line with changes in text size settings.\n\nThe width and/or height of text containers that have been specified using other units risk text cropping because it falls outside the container boundaries when the text size has been increased.\n\nThe containers generally control the placement of text within the web page and can include layout elements, structural elements and form controls.\n\nExamples:\n- **Example 3:emunits in dropdown boxes**  In this example,selectelements have been given the class name \"pick.\" CSS rules are used to define the font size in percent units and width in em units. This will allow the text within the form control to resize in response to changes in text size settings without being cropped.  ```html select.pick { font-size: 100%; width: 10em; } ```\n- **Example 2:emunits for text-based form controls**  In this example,inputelements that contain text or accept text input by the user have been given the class name \"form1\". CSS rules are used to define the font size in percent units and width for these elements inemunits. This will allow the text within the form control to resize in response to changes in text size settings without being cropped (because the width of the form control itself also resizes according to the font size).  ```html input.form1 { font-size: 100%; width: 15em; } ```\n- **Example 1:emunits for sizes for layout container containing text**  In this example, adivelement, withidvalue of\"nav_menu\", is used to position the navigation menu along the left-hand side of the main content area of the web page. The navigation menu consists of a list of text links, withidvalue of\"nav_list\". The text size for the navigation links and the width of the container are specified inemunits.  ```html #nav_menu { width: 20em; height: 100em; } #nav_list { font-size: 100%; } ```\n- **Example 4:emunits for non-text-based form controls**  In this example,inputelements that define checkboxes or radio buttons have been given the class name \"choose.\" CSS rules are used to define the width and height for these elements inemunits. This will allow the form control to resize in response to changes in text size settings.  ```html input.choose { width: 1.2em; height: 1.2em; } ```    ---",
    "referenced_by": [
      "1.4.4"
    ]
  },
  {
    "id": "F104",
    "type": "technique",
    "code": "F104",
    "text": "[F104] Failure of Success Criterion 1.4.12 due to clipped or overlapped content when text spacing is adjusted\n\nDescription:\nThe purpose of this technique is to identify and test a failure condition where part of the content clips and is unreadable when the user overrides the spacing of the text within the boundaries set out in the Text Spacing success criterion. In general, this failure occurs when text is presented in a size-constrained block which does not expand if the size of the content increases. Some of the ways in which this can occur include:\n\n- Setting theoverflowproperty of the enclosing element tohidden\n- Using absolutely positioned content\n- Creating borders that are not large enough for the content when using the new font spacing\n\nExamples:\n- **Example 1: Text inside a box overflows and overlaps text below it when text spacing is implemented.**  The code below is what is implemented in the DOMbeforethe user implements any CSS test spacing overrides. The text renders correctly in the box and doesn't interfere with the next paragraph.  The quick brown fox jumps over the lazy dog.  Here is the view AFTER the text spacing has been overridden by the user with the text spacing in the success criterion. The text overlaps the paragraph below it.  The quick brown fox jumps over the lazy dog.  ```html <div style=\"font-size:100%; width:130px; height:125px; border: thin solid gray;\"> <p style=\"margin:0;\">Now is the time for all good men to come to the aid of their country.</p> </div> <p style=\"margin:0;\">The quick brown fox jumps over the lazy dog.</p> ```\n- **Example 2: Text inside a box is clipped when text spacing is implemented.**  The code below is what is implemented in the DOMbeforethe user implements any CSS test spacing overrides. The text renders correctly in the box and doesn't interfere with the next paragraph.  Here is the default view before the text spacing has been overridden by the user, The text renders properly in the box.  The quick brown fox jumps over the lazy dog.  Here is the  view AFTER the text spacing has been overridden by the user with the maximum text spacing in the success criterion,  the text is clipped.  The quick brown fox jumps over the lazy dog.  ```html <div style=\"font-size:100%; width:130px; height:95px; overflow:hidden; border:thin solid gray;\"> <p>Now is the time for all good men to come to the aid of their country.</p> </div> <p>The quick brown fox jumps over the lazy dog.</p> ```    ---",
    "referenced_by": []
  },
  {
    "id": "SCR39",
    "type": "technique",
    "code": "SCR39",
    "text": "[SCR39] Making content on focus or hover hoverable, dismissible, and persistent\n\nDescription:\nAdditional content that is displayed when a user moves the pointer over a trigger or moves the keyboard focus to the trigger (for example, a pop-up) must remain visible to allow users time to read and interact with the content and must allow the user to move the pointer over the additional content.\n\nLow vision users who magnify their screens often see only a small part of the screen at a time (their viewport).\nThis means that the additional content may not be fully visible in the current viewport and users may need to move\ntheir mouse over the additional content to read it. web authors should therefore ensue that additional content stays visible\nwhen the pointer moves away from the trigger to the (mostly adjacent) additional content. additional content should also be\ndismissible without moving the focus, so that users can read content covered by the additional content.\n\nExamples:\n- **Example 1: Content preview for links**  When hovering over or focusing on a link, a content preview for the link appears just above or below that link. Users can move the pointer over the additional content (pop-up) so that they can fully read the additional content. Pressing theEsckey dismisses (closes) the additional content.  Working example of content on hover or focus  ```html <p>This is the <a class=\"a-and-tooltip\" id=\"parent\" href=\"index.html\">trigger <span id=\"popup\" role=\"tooltip\">And this additional text gives additional context on the trigger term </span> </a>. Text and popup are <strong>in one link (a)</strong> element. </p> ```  ```html [role=\"tooltip\"] { display: none; padding: 0.5em; background:white; color: black; border:solid black 2px; width:10em; }  .a-and-tooltip { position: relative; }  [role=\"tooltip\"] { position: absolute; left:0; top:1em; } ```  ```html // trigger and popup inside the same link  var parent = document.getElementById(\"parent\");  parent.onmouseover = function() { document.getElementById(\"popup\").style.display = \"block\"; }  parent.onmouseout = function() { document.getElementById(\"popup\").style.display = \"none\"; }  parent.onfocus = function() { document.getElementById(\"popup\").style.display = \"block\"; }  parent.onblur = function() { document.getElementById(\"popup\").style.display = \"none\"; }  // hide when ESC is pressed  document.addEventListener(\"keydown\", (e) => { if ((e.keyCode || e.which) === 27) document.getElementById(\"popup\").style.display = \"none\"; }); ```    ---",
    "referenced_by": []
  },
  {
    "id": "F95",
    "type": "technique",
    "code": "F95",
    "text": "[F95] Failure of Success Criterion 1.4.13 due to content shown on hover not being hoverable\n\nDescription:\nThe objective of this failure is to describe a situation where users find it difficult or impossible to move the pointer over additional content that appears on hover. For users of screen magnification software, the new content is often not fully visible in the current magnifed section. In order to perceive it, it is therefore critical for these users to be able to move the pointer away from the trigger and over the additional content, and thereby change the position of the magnified section, without this content disappearing.\n\nExamples:\n- **Example 1:** A pop-up opens on pointer hover. Due to the chosen screen magnification, the content is only partially visible. However, as soon as the pointer is moved away from the trigger towards the pop-up content so it can be read, the pop-up automatically closes.\n- **Example 2:** Hovering over a chart with data points, pop-ups open to show details of the respective data point, somewhat offset from the data point itself. When moving the pointer towards the pop-up so it can be fully read with magnification, the pointer travels over other data points that cause the appearance of other pop-ups that replace the particular pop-up the user wanted to see.  ---",
    "referenced_by": []
  },
  {
    "id": "G14",
    "type": "technique",
    "code": "G14",
    "text": "[G14] Ensuring that information conveyed by color differences is also available in text\n\nDescription:\nThe objective of this technique is to ensure that when color differences are used to convey information, such as required form fields, the information conveyed by the color differences are also conveyed explicitly in text.\n\nExamples:\n- **Example 1: A color-coded schedule**  The schedule for sessions at a technology conference is organized into three tracks. Sessions for Track 1 are displayed over a blue background. Sessions in Track 2 are displayed over a yellow background. Sessions in Track 3 are displayed on a green background. After the name of each session is a code identifying the track in text: T1 for Track 1, T2 for Track 2, and T3 for Track 3.\n- **Example 2: A color-coded schedule with icons**  The schedule for sessions at a technology conference is organized into three tracks. Next to the title of each session is an icon consisting of a colored circle with a number in the middle showing what track it belongs to: blue circles with the number 1 represent track 1, yellow circles with the number 2 represent Track 2, and green circles with the number 3 represent Track 3. Each icon is associated with a text alternative reading \"Track 1,\" \"Track 2,\" or \"Track 3,\" as appropriate.\n- **Example 3: A form with required fields**  A form contains several required fields. The labels for the required fields are displayed in red. In addition, at the end of each label is an asterisk character, *. The instructions for completing the form indicate that \"all required fields are displayed in red and marked with an asterisk *\", followed by an example.\n- **Example 4: A form with a green submit button**  An on-line loan application explains that green buttons advance in the process and red buttons cancel the process. A form contains a green button containing the textGo. The instructions say \"Press the button labeledGoto submit your results and proceed to the next step.\"    ---",
    "referenced_by": [
      "1.4.1"
    ]
  },
  {
    "id": "G205",
    "type": "technique",
    "code": "G205",
    "text": "[G205] Including a text cue for colored form control labels\n\nDescription:\nThe objective of this technique is to combine color and text or character cues to convey information. Most users can quickly scan the content to locate information conveyed by using color differences. Users who cannot see color can look or listen for text cues; people using Braille displays or other tactile interfaces can detect text cues by touch.\n\nThe text cue must be included as part of the programmatically determinable name for the control.\n\nExamples:\n- **Example 1: Required fields in anHTMLform**  The instructions for an online form say, \"Required fields are shown in red and marked with (required).\" The cue \"(required)\" is included within the label element.  ```html <style> .required { color:#ec0000; } </style> <label for=\"lastname\" class=\"required\">Last name (required):</label> <input autocomplete=\"family-name\" id=\"lastname\" type=\"text\" value=\"\"> ```    ---",
    "referenced_by": [
      "1.4.1"
    ]
  },
  {
    "id": "G182",
    "type": "technique",
    "code": "G182",
    "text": "[G182] Ensuring that additional visual cues are available when text color differences are used to convey information\n\nDescription:\nThe intent of this technique is to provide a redundant visual cue for users who may not be able to discern a difference in text color. Color is commonly used to indicate the different status of words that are part of a paragraph or other block of text or where special characters or graphics cannot be used to indicate which words have special status. For example, scattered words in text may be hypertext links that are marked as such by being printed in a different color. This technique describes a way to provide cues in addition to color so that users who may have difficulty perceiving color differences or have low vision can identify them.\n\nTo use this technique, an author incorporates a visual cue in addition to color for each place where color alone is used to convey information. Visual cues can take many forms including changes to the font style, the addition of underlines, bold, or italics, or changes to the font size.\n\nExamples:\n- **Example 1:** The default formatting for links on a page includes presenting them both in a different color than the other text on the page underlining them to make the links identifiable even without color vision.\n- **Example 2:** An article comparing the use of similar elements in different markup languages uses colored text to identify the elements from each language. Elements from the first markup language are identified using BLUE, bolded text. Elements from the second are presented as RED, italicized text.\n- **Example 3:** A news site lists links to the articles appearing on its site. Additional information such as the section the article appears in, the time the article was posted, a related location or an indication that it is accompanied by live video appears in some cases. The links to the articles are in a different color than the additional information but the links are not underlined, and each link is presented in a larger font than the rest of the information so that users who have problems distinguishing between colors can identify the links more easily.\n- **Example 4:** Short news items sometimes have sentences that are also links to more information. Those sentences are printed in color and use a sans-serif font face while the rest of the paragraph is in black Times-Roman.  ---",
    "referenced_by": [
      "1.4.1"
    ]
  },
  {
    "id": "G183",
    "type": "technique",
    "code": "G183",
    "text": "[G183] Using a contrast ratio of 3:1 with surrounding text and providing additional visual cues on hover for links or controls where color alone is used to identify them\n\nDescription:\nThe intent of this technique is to provide a redundant visual cue for users who may not be able to discern a difference in text color. Color (generally defined as a combination of hue, saturation and luminance) is commonly used to indicate words that are links within a paragraph or other block of text. For example, scattered words in text may be hypertext links that are identified only by a difference in color with surrounding text. This technique describes a way to provide a difference in contrast rather than relying on hue.\n\nTo meet success criterion 1.4.1: Use of Color a [relative luminance](https://www.w3.org/TR/WCAG22/#dfn-relative-luminance) (lightness) difference of 3:1 or greater with the text around can be used. This technique goes beyond the success criterion and asks for visual highlights when the user hovers over each link, such as an underline, a change in font style such as bold or italics, or an increase in font size. Such a hover effect provides confirmation to pointer users that the text is a link, similar to how the link alters its appearance for keyboard users when it receives focus, in order to meet [2.4.7 Focus Visible](sensory-characteristics).\n\nWhile using this technique is sufficient to meet this success criterion, it is not the preferred technique to differentiate link text. This is because links that use the relative luminance of color alone may not be obvious to people with low vision. If there are not a large number of links in the block of text, underlines are recommended for links in blocks of text.\n\nExamples:\n- **Example 1: Colors that would provide 3:1 contrast with black words and 4.5:1 contrast with a white background**  Refer toLinks with a 3:1 contrast ratio with surrounding text\n- **Example 2**  The hypertext links in a document are medium-light blue (#3366CC) and the regular text is black (#000000). Beyond the difference in color, the links have no other styles differences compared with the regular text. Because the blue text is light enough, it has a contrast of 3.9:1 with the surrounding text and can be identified as being different from the surrounding text by people with all types of color blindness, including those individuals who cannot see color at all. In addition to the contrast difference, the links have:focusand:hoverstyles that reintroduce the underline when the links receive keyboard focus or when a mouse pointer hovers over them. Hover or focus style changes alone are not sufficient to meet the criterion.    ---",
    "referenced_by": [
      "1.4.1"
    ]
  },
  {
    "id": "G111",
    "type": "technique",
    "code": "G111",
    "text": "[G111] Using color and pattern\n\nDescription:\nThe objective of this technique is to ensure that when color differences are used to convey information within non-text content, patterns are included to convey the same information in a manner that does not depend on color.\n\nExamples:\n- **Example 1**  A real estate site provides a bar chart of average housing prices in several regions of the United States. The bar for each region is displayed with a different solid color and a different pattern. The legend uses the same colors and patterns to identify each bar.\n- **Example 2**  An on-line map of a transportation system displays each route in a different color. The stops on each route are marked with a distinctive icon such as a diamond, square, or circle to help differentiate each route.\n- **Example 3**  A flow chart describes a set of iterative steps to complete a process. It uses dashed, arrowed lines with a green background to point to the next step in the process when the specified condition passes. It uses dotted arrowed lines with a red background to point to the next step in the process when the specified condition fails.\n- **Example 4**  The content includes an interactive game. The game pieces for the 4 players are distinguished from one another using both color and pattern.    ---",
    "referenced_by": [
      "1.4.1"
    ]
  },
  {
    "id": "C15",
    "type": "technique",
    "code": "C15",
    "text": "[C15] Using CSS to change the presentation of a user interface component when it receives focus\n\nDescription:\nThe objective of this technique is to demonstrate how visual appearance may be enhanced via style sheets to provide visual feedback when an interactive element has focus or when a user hovers over it using a pointing device. Highlighting the element that has focus or is hovered over can provide information such as the fact that the element is interactive or the scope of the interactive element.\n\nProviding visual feedback may be possible through more than one mode. Usually, it is attained through using a mouse to hover over the element or a keyboard to tab to the element.\n\nExamples:\n- **Example 1: Link elements**  In this example, mouse and keyboard focus indicators have been applied to the link elements. CSS has been used to apply a background color when the link elements receive focus.  Here is the content to be displayed:  Here is the CSS that changes the background color for the above elements when they receive mouse or keyboard focus:  ```html <nav id=\"main-nav\"> <ul> <li>Home</li> <li><a href=\"/services\">Services</a></li> <li><a href=\"/projects\">Projects</a></li> <li><a href=\"/demos\">Demos</a></li> <li><a href=\"/about-us\">About us</a></li> <li><a href=\"/contact-us\">Contact us</a></li> <li><a href=\"/links\">Links</a></li> </ul> <nav> ```  ```html #main-nav a:hover, #main-nav a:active, #main-nav a:focus-visible { background-color: #DCFFFF; color:#000066; } ```\n- **Example 2: Highlighting elements that receive focus**  In this example, the :focus pseudo-class is used to change the style applied to input fields when they receive focus by changing the background color.  Working example of this code:Example of highlighting elements that receive focus.  ```html <!doctype html> <html lang=\"en\"> <head> <style> input[type=text]:focus-visible { outline:2px solid #0054AE; outline-offset:2px; }  input[type=checkbox]:focus + label, input[type=radio]:focus + label { background-color:#1E2EB8; color:#FFF; } </style> </head> <body> <form> <div> <label for=\"fname\">Name: </label> <input autocomplete=\"name\" type=\"text\" name=\"fname\" id=\"fname\"> </div> <div> <input type=\"radio\" name=\"sex\" value=\"male\" id=\"sm\"> <label for=\"sm\">Male</label> </div> <div> <input type=\"radio\" name=\"sex\" value=\"female\" id=\"sf\"> <label for=\"sf\">Female</label> </div> </form> </body> </html> ```    ---",
    "referenced_by": [
      "1.4.1",
      "2.4.7"
    ]
  },
  {
    "id": "F73",
    "type": "technique",
    "code": "F73",
    "text": "[F73] Failure of Success Criterion 1.4.1 due to creating links that are not visually evident without color vision\n\nDescription:\nThe objective of this failure is to avoid situations in which people who cannot perceive color differences cannot identify links (when people with color vision can identify links). Link underlines or some other non-color visual distinction are required (when the links are discernible to those with color vision).\n\nWhile some links may be visually evident from page design and context, such as navigational links, links within text are often visually understood only from their own display attributes. Removing the underline and leaving only the color difference for such links would be a failure because there would be no other visual indication (besides color) that it is a link.\n\nExamples:\n- **Example 1: Links with no underlines and similar contrast to body text**  A web page includes a large number of links within the body text. The links are styled so that they do not have underlines and are very similar in color to the body text. This would be a failure because users would be unable to differentiate the links from the body text.\n- **Example 2: Removing the underline from a link in a sentence or paragraph without providing another visual cue besides color**  ```html <head> <style> p a:link {text-decoration: none} p a:visited {text-decoration: none} p a:active {text-decoration: none} p a:hover {text-decoration: underline; color: red;} </style> </head> <body> <p>There are many resources to find out more about the <a href=\"rain-in-spain.html\">rain in Spain</a>. </p> </body> ```    ---",
    "referenced_by": [
      "1.4.1"
    ]
  },
  {
    "id": "F81",
    "type": "technique",
    "code": "F81",
    "text": "[F81] Failure of Success Criterion 1.4.1 due to identifying required or error fields using color differences only\n\nDescription:\nThis objective of this technique is to describe the failure that occurs when a required field or an error field is marked with color differences only, without an alternate way to identify the required field or error field. This can cause problems for people who are blind or colorblind, because they may not be able to perceive the color differences that indicate which field is required or which field is causing an error.\n\nExamples:\n- **Example 1:** A user is completing an online form, and the phone number field is required. To indicate that the phone number field is required, the label \"Phone Number\" is displayed in a color different from the color used for optional fields, without any other indication that \"Phone Number\" is a required field. A blind or colorblind user may not be able to identify that \"Phone Number\" is a required field.\n- **Example 2:** A user submits an online form and leaves a required field blank, resulting in an error. The form field that caused the error is indicated by red text only, without an additional non-color indication that the field caused an error.  ---",
    "referenced_by": [
      "1.4.1"
    ]
  },
  {
    "id": "G60",
    "type": "technique",
    "code": "G60",
    "text": "[G60] Playing a sound that turns off automatically within three seconds\n\nDescription:\nThe purpose of this technique is to allow authors to play a sound on their\nWeb page but avoid the problem of users not being able to use their screen\nreaders due to interference by the content sound. It also allows the author\nto avoid putting controls on the web page to control the sound - and the problem\nfaced by users with screen readers in finding the control (when unable\nto hear their screen reader).\n\nThe technique is simple. The sound plays for 3 or less seconds and stops\nautomatically.\n\nExamples:\n- **Example 1:** Example 1: A web page opens with a trumpet fanfare and then goes silent\n- **Example 2:** Example 2: A homepage opens with the chairman saying \"Binfor, where quality is our business.\"  then going silent.\n- **Example 3:** Example 3: A web page opens with instructions on how to get started:  \"To begin, press the enter key.\"\n- **Example 4:** Example 4: A web page opens with a warning and then goes silent.  ---",
    "referenced_by": [
      "1.4.2"
    ]
  },
  {
    "id": "G170",
    "type": "technique",
    "code": "G170",
    "text": "[G170] Providing a control near the beginning of the Web page that turns off sounds that play automatically\n\nDescription:\nThe intent of this technique is to allow a user to turn off sounds that start automatically when a page loads. The control to turn off the sounds should be located near the beginning of the page to allow the control to be easily and quickly discovered by users. This is useful for those who utilize assistive technologies (such as screen readers, screen magnifiers, switch mechanisms, etc.) and those who may not (such as those with cognitive, learning and language disabilities).\n\nIn this technique, an author includes a control that makes it possible for users to turn off any sounds that are played automatically. The control should be keyboard operable, located early in the tab and reading order, and clearly labeled to indicate that it will turn off the sounds that are playing.\n\nExamples:\n- **Example 1**  A web page contains a time-based media presentation that includes an audio track as well as an animated video describing how to repair a lawnmower engine. The page contains 2 buttons that say \"Pause\" and \"Stop\", which give the user control over when and if the time-based media plays.\n- **Example 2**  A web page contains an embedded short film. The page contains a button that says \"Pause the movie\", which allows the user to pause the film.\n- **Example 3**  A web page contains a presentation that includes video and audio. The page contains a button that says \"Turn off multimedia\", which allows the user to stop any video and audio from playing.    ---",
    "referenced_by": [
      "1.4.2"
    ]
  },
  {
    "id": "G171",
    "type": "technique",
    "code": "G171",
    "text": "[G171] Playing sounds only on user request\n\nDescription:\nThe intent of this technique is to allow a user to control the use of sounds in Web content. Someone that uses a screen reader may find it very distracting and difficult to listen to their screen reader if there are also sounds coming from Web content. Providing a way to play sounds only upon request will give a user the control needed to listen to any sounds or other audio without interfering with the output from a screen reader.\n\nExamples:\n- **Example 1**  A web page from a grey whale conservation society has a looping background sound of grey whales singing. There are also sounds of water splashing. The sounds do not start automatically. Instead, the Web content provides a link at the top of the page to allow the user to start the sounds manually. The button says \"Turn sounds on.\" After pressing the \"turn sounds on\" button, the sounds are heard. The user is then presented with an option to \"turn sounds off.\"\n- **Example 2**  A link is provided to a sound file that includes the sounds of the grey whales. The link text says, \"Hear the song of the grey whale (mp3).\"    ---",
    "referenced_by": [
      "1.4.2"
    ]
  },
  {
    "id": "F23",
    "type": "technique",
    "code": "F23",
    "text": "[F23] Failure of 1.4.2 due to playing a sound longer than 3 seconds where there is no mechanism to turn it off\n\nDescription:\nThis describes a failure condition for Success Criteria involving sound. If sound does not\nturn off automatically within 3 seconds and there is no way to turn the\nsound off, independently from the overall system volume level, then Success Criterion 1.4.2 would not be met.\nThe sound would fall within this failure condition.\n\nExamples:\n- **Example 1**\n- **Example 2**    ---",
    "referenced_by": [
      "1.4.2"
    ]
  },
  {
    "id": "F93",
    "type": "technique",
    "code": "F93",
    "text": "[F93] Failure of Success Criterion 1.4.2 for absence of a way to pause or stop an HTML5 media element that autoplays\n\nDescription:\nThis failure occurs when an **audio** or **video** element with an audio track contains the **autoplay** attribute and does not contain the **muted** attribute, and no controls or commands have been provided to pause or stop the media resource.\n\nWhen the **autoplay** attribute is present, the user agent will automatically begin playback of the media resource as soon as it can do so without stopping. When the **muted** attribute is present, the user agent will initially mute the media resource's audio output, overriding any user preference.\n\nIf the media element is shorter than 3 seconds, the failure does not occur. If the user agent provides user preferences to override autoplay behavior, the failure does not occur.\n\nThe HTML spec contains the following notes:\n\n- User agents do not need to support autoplay, and it is suggested that user agents honor user preferences on the matter. Authors are urged to use theautoplayattribute rather than using script to force the video to play, so as to allow the user to override the behavior if so desired.\n- Authors are urged to use theautoplayattribute rather than using script to trigger automatic playback, as this allows the user to override the automatic playback when it is not desired, e.g. when using a screen reader. Authors are also encouraged to consider not using the automatic playback behavior at all, and instead to let the user agent wait for the user to start playback explicitly.\n\nExamples:\n- **Example 1: An auto-playing audio track**  In this example, the advertising video contains an audio track. The video will play continuously because of theloopattribute, and the video will start automatically because of theautoplayattribute and because there does not appear to be any controls to allow the user to stop the video.  ```html <video src=\"ads.cgi?kind=video\" autoplay loop></video> ```    ---",
    "referenced_by": [
      "1.4.2"
    ]
  },
  {
    "id": "G18",
    "type": "technique",
    "code": "G18",
    "text": "[G18] Ensuring that a contrast ratio of at least 4.5:1 exists between text (and images of text) and background behind the text\n\nDescription:\nThe objective of this technique is to make sure that users can read text\nthat is presented over a background. For Success Criterion 1.4.3, this technique describes the minimum contrast ratio for text that is less than 18 point (if not bold) and less than 14 point (if bold). For Success Criterion 1.4.6, this technique relaxes the 7:1 contrast ratio requirement  for text that is at least 18 point (if not bold) or at least 14 point (if bold).\n\nIf the background is a solid color (or all black or all white) then the\nrelative luminance of the text can be maintained by making sure that each\nof the text letters have 4.5:1 contrast ratio with the background.\n\nIf the background or the letters vary in relative luminance (or are patterned) then\nthe background around the letters can be chosen or shaded so that the\nletters maintain a 4.5:1 contrast ratio with the background behind them\neven if they do not have that contrast ratio with the entire background.\n\nFor example, if a letter is lighter at the top than it is a the bottom, it may be difficult to maintain the contrast ratio between the letter and the background over the full letter. In this case, the designer might darken the background behind the letter, or add a thin black outline (at least one pixel wide) around the letter in order to keep the contrast ratio between the letter and the background above 4.5:1.\n\nThe contrast ratio can sometimes be maintained by changing the\nrelative luminance of the letters as the relative luminance of the background changes across\nthe page.\n\nFor example, if a page is very light on one edge and fades to very dark on the other edge, there is no color that can run across the page and meet the contrast guidelines on both edges. One way of addressing this would be to change the lightness of the letters as well so that each letter always meets the contrast ratio for the background that is immediately behind the letter.\n\nAnother method is to provide a halo around the text that provides the\nnecessary contrast ratio if the background image or color would not\nnormally be sufficiently different in relative luminance.\n\nExamples:\n- **Example 2:** Text is placed over a picture of the college campus. Since a wide variety of colors and shades appear in the picture, the area behind the text is fogged white so that the picture is very faint and the maximum darkness is still light enough to maintain a 4.5:1 contrast ratio with the black text written over the picture.See also the contrast samples in related resources.  ---\n- **Example 1:** A black background is chosen so that light colored letters that match the company logo can be used.",
    "referenced_by": [
      "1.4.3",
      "1.4.6"
    ]
  },
  {
    "id": "G148",
    "type": "technique",
    "code": "G148",
    "text": "[G148] Not specifying background color, not specifying text color, and not using technology features that change those defaults\n\nDescription:\nThe objective of this technique is to make sure that users can read text\nthat is presented over a background. With this technique the author avoids\nhaving to do any contrast measures by simply not specifying the text color\nand not specifying the background. As a result the colors of both are\ncompletely determined by the user agent.\n\nSome people who have vision disabilities set their user agent to override certain colors that they have trouble seeing. This technique will help avoid a situation where the user agent and website conflict with each other over the foreground and/or background colors resulting in the same color for text and background, which would make it invisible for user who set their own colors in their browser or Assistive Technology.\n\nExamples:\n- **Example 1**  The author specifies neither text color nor background, and does not use CSS. As a result the user can set their browser defaults to provide the colors and contrasts that work well for them.    ---",
    "referenced_by": [
      "1.4.3",
      "1.4.6",
      "1.4.8"
    ]
  },
  {
    "id": "G145",
    "type": "technique",
    "code": "G145",
    "text": "[G145] Ensuring that a contrast ratio of at least 3:1 exists between text (and images of text) and background behind the text\n\nDescription:\nThe objective of this technique is to make sure that users can read text\nthat is presented over a background. This technique relaxes the 4.5:1\ncontrast ratio requirement for text that is at least 18 point (if not bold) or at least 14 point (if bold).\n\nIf the background is a solid color (or all black or all white) then the\ncontrast ratio of the larger-scale text can be maintained by making sure that each\nof the text letters have a 3:1 contrast ratio with the background.\n\nIf the background or the letters vary in relative luminance (or are patterned), then\nthe background around the letters can be chosen or shaded so that the\nletters maintain a 3:1 contrast ratio with the background behind them\neven if they do not have that contrast ratio with the entire background.\n\nThe contrast ratio can sometimes be maintained by changing the\nrelative luminance of the letters as the relative luminance of the background changes across\nthe page.\n\nAnother method is to provide a halo around the text that provides the\nnecessary contrast ratio if the background image or color would not\nnormally be sufficiently different in relative luminance.\n\nExamples:\n- **Example 1:** A black background is chosen so that light colored letters that match the company's logo can be used.Larger-scale text is placed over a picture of the college campus. Since a wide variety of colors and darknesses appear in the picture, the area behind the text is fogged white so that the picture is very faint and the maximum darkness is still light enough to maintain a 3:1 contrast ratio with the black text written over the picture.  ---",
    "referenced_by": [
      "1.4.3"
    ]
  },
  {
    "id": "G156",
    "type": "technique",
    "code": "G156",
    "text": "[G156] Using a technology that has commonly-available user agents that can change the foreground and background of blocks of text\n\nDescription:\nSome people with cognitive disabilities require specific color combinations of foreground text and background to help them successfully understand the contents of the web page. Most popular browsers provide the option to change colors settings globally within the browser. In this case the colors selected by the user override the foreground and background colors specified by the web author.\n\nIn order to meet this success criterion, the web author would design the page so that it works with browsers that have these controls, and the author does not override these controls.\n\nNote that overriding the foreground and background colors of all text on a page may hide visual clues to the grouping and organization of the web page, making it much more difficult to understand and use. This technique may not be appropriate when background colors are used to delineate areas of the page. This technique may be appropriate for technologies and user agents that do not alter border colors when background colors are overridden. If background colors are used to delineate areas of the page, \"[Specifying text and background colors of secondary content such as banners, features and navigation in CSS while not specifying text and background colors of the main content](../css/C23)\" may be used to permit the user to control the colors of the main text while retaining the visual structure of the web page.\n\nExamples:\n- **Example 1:** A web page is designed using HTML and CSS to specify the foreground and background colors. The user sets their own colors in the browser and they can view the content with their chosen foreground and background colors.\n- **Example 2:** A web page is designed using HTML and CSS. There is a link on the page to instructions on how to set colors in various browsers.  ---",
    "referenced_by": [
      "1.4.3",
      "1.4.6",
      "1.4.8"
    ]
  },
  {
    "id": "F24",
    "type": "technique",
    "code": "F24",
    "text": "[F24] Failure of Success Criterion 1.4.3, 1.4.6 and 1.4.8 due to specifying foreground colors without specifying background colors or vice versa\n\nDescription:\nUsers with vision loss or cognitive, language and learning challenges often prefer specific foreground and background color combinations. In some cases, individuals with low vision will find it much easier to see a web page that has white text on a black background, and they may have set their user agent to present this contrast. Many user agents make it possible for users to choose a preference about the foreground or background colors they would like to see without overriding all author-specified styles. This makes it possible for users to view pages where colors have not been specified by the author in their preferred color combination.\n\nUnless an author specifies both foreground and background colors, then they (the author) can no longer guarantee that the user will get a contrast that meets the contrast requirements. If, for example, the author specifies, that text should be grey, then it may override the settings of the user agent and render a page that has grey text (specified by the author) on a light grey background (that was set by the user in their user agent). This principle also works in reverse. If the author forces the background to be white, then the white background specified by the author could be similar in color to the text color preference expressed by the user in their user agent settings, thus rendering the page unusable to the user. Because an author can not predict how a user may have configured their preferences, if the author specifies a foreground text color then they should also specify a background color which has sufficient contrast with the foreground and vice versa.\n\nIt is not necessary that the foreground and background colors both be defined on the same CSS rule. Since CSS color properties inherit from ancestor elements, it is sufficient if both foreground and background colors are defined either directly or through inheritance by the time that color is applied to a given element.\n\nExamples:\n- **Example 1: Specifying only background color with CSS**  In the example below the background color is defined on the CSS stylesheet, however the foreground color is not defined. Therefore, the example fails the Success Criterion.  ```html <!doctype> <html lang=\"en\"> <head> <title>Setting the canvas background</title> <style> body {background-color:white} </style> </head> <body> <p>My background is white.</p> </body> </html> ```\n- **Example 2: Specifying only foreground color with CSS**  In the example below the foreground color is defined on the CSS stylesheet, however the background color is not defined. Therefore, the example fails the Success Criterion.  ```html <!doctype> <html lang=\"en\"> <head> <title>Setting the canvas foreground</title> <style> body {color:white} </style> </head> <body> <p>My foreground is white.</p> </body> </html> ```\n- **Example 3: Specifying foreground color of link text with CSS**  In the example below the link text (foreground) color is defined on the body element. However, the background color is not defined. Therefore, the example fails the Success Criterion.  ```html <!doctype> <html lang=\"en\"> <head> <title>A study of population dynamics</TITLE> <style> a:link { color: red } a:visited { color: maroon } a:active { color: fuchsia } </style> </head> <body> <p>... document body... <a href=\"foo.htm\">Foo</a></p> </body> </html> ```    ---",
    "referenced_by": [
      "1.4.3",
      "1.4.6",
      "1.4.8"
    ]
  },
  {
    "id": "F83",
    "type": "technique",
    "code": "F83",
    "text": "[F83] Failure of Success Criterion 1.4.3 and 1.4.6 due to using background images that do not provide sufficient contrast with foreground text (or images of text)\n\nDescription:\nThis failure occurs when people with low vision are not able to read text that is displayed over a background image. When there is not sufficient contrast between the background image and the text, features of the background image can be confused with the text making it difficult to accurately read the text.\n\nTo satisfy Success Criterion 1.4.3 and 1.4.6, there must be sufficient contrast between the text and its background. For pictures, this means that there would need to be sufficient contrast between the text and those parts of the image that are most like the text and behind the text.",
    "referenced_by": [
      "1.4.3",
      "1.4.6"
    ]
  },
  {
    "id": "G142",
    "type": "technique",
    "code": "G142",
    "text": "[G142] Using a technology that has commonly-available user agents that support zoom\n\nDescription:\nThe objective of this technique is to ensure content can be scaled uniformly by using a Web technology supported by user agents that change text size via a Zoom tool.\n\nContent authored in technologies that are supported by user agents that can scale content uniformly (that is, zoom into content) satisfy this Success Criterion. Because this technique relies completely on user agent functionality, it is critical to test with a wide variety of user agents.\n\nThis technique requires that the zoom function preserve all spatial relationships on the page and that all functionality continues to be available.\n\nExamples:\n- **Example 1:** Most modern browsers provide a zoom function that scales HTML/CSS page content uniformly.\n- **Example 2:** To allow users to resize text, Adobe Reader provides a magnification tool that scales PDF pages uniformly.  ---",
    "referenced_by": [
      "1.4.4"
    ]
  },
  {
    "id": "C12",
    "type": "technique",
    "code": "C12",
    "text": "[C12] Using percent for font sizes\n\nDescription:\nThe objective of this technique is to specify text font size proportionally so that user agents can scale content effectively. If a **font-size** is specified for the **body** element, all other elements inherit that value, unless overridden by a more specific selector.\n\nExamples:\n- **Example 1: Percent font sizes in CSS**  This example defines the font size for thestrongelement so that its text will always be larger than the surrounding text, in whatever context it is used. Assuming that headings and paragraphs use different font sizes, the emphasized words in this example will each be larger than their surrounding text.  ```html <style> strong {font-size: 120%} </style>  <h1>Letting the <strong>user</strong> control text size</h1> <p>Since only the user can know what size text works for them, it is <strong>very</strong> important to let them configure the text size.</p> ```    ---",
    "referenced_by": [
      "1.4.4",
      "1.4.5",
      "1.4.8",
      "1.4.9"
    ]
  },
  {
    "id": "C13",
    "type": "technique",
    "code": "C13",
    "text": "[C13] Using named font sizes\n\nDescription:\nThe objective of this technique is to specify a named font size that expresses the relative font size desired. These values provide hints so that the user agent can choose a **font-size** relative to the inherited **font-size**.\n\nExamples:\n- **Example 1: Named font sizes in CSS**  This example selects a larger font size forstrongelements so that their text will always be larger than the surrounding text, in whatever context they are used. Assuming that headings and paragraphs use different font sizes, the emphasized words in this example will each be larger than their surrounding text.  ```html <style> strong {font-size: larger} </style> ... <h1>Letting the <strong>user</strong> control text size</h1> <p>Since only the user can know what size text works for them, it is <strong>very</strong> important to let them configure the text size. ... ```    ---",
    "referenced_by": [
      "1.4.4",
      "1.4.5",
      "1.4.8",
      "1.4.9"
    ]
  },
  {
    "id": "C14",
    "type": "technique",
    "code": "C14",
    "text": "[C14] Using em units for font sizes\n\nDescription:\nThe objective of this technique is to specify text font size in **em** units so that user agents can scale content effectively. Since the **em** is a property of the font, it scales as the font changes size. If a **font-size** is specified for the **body** element, all other elements inherit that value, unless overridden by a more specific selector.\n\nExamples:\n- **Example 1:emfont sizes in CSS**  This example defines the font size for strong element so that its text will always be larger than the surrounding text, in whatever context it is used. Assuming that headings and paragraphs use different font sizes, the strong words in this example will each be larger than their surrounding text.  ```html <style> strong {font-size: 1.6em} </style> ... <h1>Letting the <strong>user</strong> control text size</h1> <p>Since only the user can know what size text works for them, it is <strong>very</strong> important to let them configure the text size.</p> … ```    ---",
    "referenced_by": [
      "1.4.4",
      "1.4.5",
      "1.4.8",
      "1.4.9"
    ]
  },
  {
    "id": "G146",
    "type": "technique",
    "code": "G146",
    "text": "[G146] Using liquid layout\n\nDescription:\nThe objective of this technique is to be able to present content without introducing horizontal scroll bars by using layout techniques that adapt to the available horizontal space. Liquid layouts define layout regions that both resize with text, and reflow as needed to display the region on the screen. Although the exact layout therefore varies, the relationship of elements and the reading order remains the same. This is an effective way to create designs that present well on different devices and for users with different font size preferences.\n\nThe basic principles of liquid layouts are to:\n\nComplex liquid layouts may be achieved by nesting layout regions, thus creating localized liquid layouts within a larger liquid layout. Even simple liquid layouts require design finesse to achieve good-looking results at a wide range of text sizes, but well-designed liquid layouts can be the most effective page design.\n\nExamples:\n- **Example 1: Simple liquid layout inHTMLandCSS**  The following fairly simple example uses HTML and CSS to create a liquid layout. The three columns adjust their size as text size is adjusted. When the total horizontal width exceeds the available width of the columns, the last column wraps to be positioned below, rather than beside, the previous column. The font size can be increased without either clipping or introducing horizontal scrolling until the longest word no longer fits in a column. This particular example uses percent sizes for the columns and defines them as floating regions using the \"float\" property.  ```html <!DOCTYPE html> <html lang=\"en\"> <head> <meta charset=\"utf-8\"> <title>Example of Basic Liquid Layout</title> <style> .column { border-left: 1px solid green; padding-left:1%; float: left; width: 32%; }  .column:nth-of-type(1){ border:0; }  footer { border-top: 1px solid green; clear: both; } </style> </head> <body> <h1>WCAG Example</h1> <h2>Text in Three Columns</h2> <div class=\"column\"> <h3>Block 1</h3> <p>The objective of this technique is to be able to present content without introducing horizontal scroll bars by using layout techniques that adapt to the available horizontal space.</p> </div> <div class=\"column\"> <h3>Block 2</h3> <p>This is a very simple example of a page layout that adapts as the text size changes.</p> </div> <div class=\"column\"> <h3>Block 3</h3> <p>For techniques that support more complex page layouts, see the Resources listed below.</p> </div> <footer> <p>Footer text</p> </footer> </body> </html> ```    ---",
    "referenced_by": [
      "1.4.4",
      "1.4.8"
    ]
  },
  {
    "id": "G178",
    "type": "technique",
    "code": "G178",
    "text": "[G178] Providing controls on the Web page that allow users to incrementally change the size of all text on the page up to 200 percent\n\nDescription:\nThe purpose of this technique is to provide a mechanism on the web page to incrementally increase the size of text. Many people with low vision do not use magnifying software, and they may not be familiar with their browser's text size adjustments. This may be particularly true of older people who are learning about computers later in life and who may be experiencing age related vision loss. It may also be true of some people with cognitive disabilities who require increased font size.\n\nThis technique provides a mechanism that some users will find easier to use. The mechanism may include links or buttons that will switch the visual presentation to a different style sheet or use scripts to change the text size dynamically.\n\nTo implement this technique, an author provides controls that allow the user to incrementally increase or decrease the text size of all of the text on the page to a size up to 200% of the default text size.\n\nThis can be achieved by providing links, buttons or linked images and the controls themselves should be as easy to find (e.g. prominently positioned within the page, presented in a larger text size, high contrast, etc.) as possible.\n\nThis technique can also be used in circumstances where scalable fonts cannot be used, such as legacy code situations.\n\nExamples:\n- **Example 1:** A newspaper article has two buttons near the top of the page. The \"increase text size\" button has a big letter \"T\" with an upward arrow and the \"decrease text size\" button has a small letter \"T\" with a down arrow. There isalttext on each button.\n- **Example 2:** A site has a number of style sheets with different text size. The user can choose any of the style sheets if their browser provides this functionality. Each page also includes the links \"Increase text size\" and \"Decrease text size\" that will change the style sheet currently applied to the appropriate alternate style sheet.\n- **Example 3:** A site includes the text \"Change text size:\" followed by text links \"Up\" and \"Down\" on every web page. The links trigger a Javascript that alters the value of the text-size property accordingly.\n- **Example 4:** A site includes a link on every page that reads \"Change text size.\" The resulting page includes a series of links that includes options representing the available sizes. The links read, \"Smallest font size,\" \"Small font size,\" \"Default font size,\" \"Large font size,\" etc. Instructions preceding the list direct users to choose a link to change to the desired font size.  ---",
    "referenced_by": [
      "1.4.4"
    ]
  },
  {
    "id": "G179",
    "type": "technique",
    "code": "G179",
    "text": "[G179] Ensuring that there is no loss of content or functionality when the text resizes and text containers do not change their width\n\nDescription:\nSome user agents support changing the size of text without changing other dimensions of the text container. Loss of content or functionality can occur when the text overflows the space that was allocated for it. However, the layout properties may provide a way to continue to display the content effectively. The block sizes may be defined wide enough that the text does not overflow when resized by 200%. Text may wrap when it no longer fits within the block, and the block may be tall enough that all the text continues to fit in the block. The block may provide scrollbars when the resized text no longer fits.\n\nExamples:\n- **Example 1: A multi-column page layout**  HTML and CSS are used to create a two-column layout for a page of text. Using the default value of the white-space property, normal, causes text to wrap. So as the size of the text is increased to 200%, the text reflows and the column of text grows longer. If the column is too long for the viewport, the user agent provides scrollbars so the user can scroll text into view because the author has specified the CSS rule overflow:scroll or overflow:auto.\n- **Example 2**  A newspaper layout with blocks of text in columns. The blocks have a fixed width, but no height set. When the text is resized in the browser, the text wraps and makes the blocks taller.    ---",
    "referenced_by": [
      "1.4.4"
    ]
  },
  {
    "id": "C17",
    "type": "technique",
    "code": "C17",
    "text": "[C17] Scaling form elements which contain text\n\nDescription:\nThe objective of this technique is to ensure text-based form controls resize when text size is changed in the user agent. This will allow users to enter text and read what they have entered in input boxes because the text is displayed at the size required by the user.\n\nText-based form controls include **input** boxes (**text** and **textarea**) as well as buttons.\n\nExamples:\n- **Example 1: A Contact Form**  A Contact Us form has some introductory information and then form controls for users to enter their first name, last name, telephone number and email address. All of the text and form controls have been implemented in a scalable way.  Working example of this code:Example of resizing input with CSS.  ```html <h1>Contact Us</h1> <p>Please provide us with your details and we will contact you as soon as we can. Note that all of the form fields are required.</p> <div> <label for=\"fname\">First Name</label> <input autocomplete=\"given-name\" id=\"fname\" name=\"fname\" type=\"text\"> </div> <div> <label for=\"lname\">Last Name</label> <input autocomplete=\"family-name\" id=\"lname\" name=\"lname\" type=\"text\"> </div> <div> <label for=\"phone\">Telephone</label> <input autocomplete=\"tel\" id=\"phone\" name=\"phone\" type=\"text\"> </div> <div> <label for=\"email\">Email</label> <input autocomplete=\"email\" id=\"email\" name=\"email\" type=\"text\"> </div> <input id=\"submit\" name=\"submit\" type=\"submit\" value=\"Submit\"> ```  ```html h1 { font-size: 2em; } p, label { font-size: 1em; } label { display:block; } input { font: inherit; } div { margin-bottom: 1rem; } ```    ---",
    "referenced_by": [
      "1.4.4"
    ]
  },
  {
    "id": "C20",
    "type": "technique",
    "code": "C20",
    "text": "[C20] Using relative measurements to set column widths so that lines can average 80 characters or less when the browser is resized\n\nDescription:\nThe purpose of this technique is to ensure that CSS is used in a way that allows users to view content in such a way that line length can average 80 characters or less. This makes it possible for users with certain reading or vision disabilities that have trouble keeping their place when reading long lines of text to view and interact with the content more efficiently. This technique also allows for column width to grow wider as font sizes increase, which will reduce the possibility of clipping as the text size increases.\n\nNote that this technique does not require authors to use CSS to limit the width of lines of text to less than 80 characters in the default view. Rather, the recommendation to use relative measurements in CSS layouts helps to ensure that authors do not set column widths in such a way that makes it impossible for users to view content with line lengths of 80 characters or less.\n\nExamples:\n- **Example 2**  In this example thedivwidth is set in percent in the stylesheet  And the text block would be placed inside thedivin the content  ```html #main-content {width: 90%} ```  ```html <div id=\"main-content\"> <p>Lorem ipsum dolor sit amet, consectetur adipisicing ...</p> </div> ```    ---\n- **Example 1**  In this example thedivwidth is set in ems in the stylesheet.  And the text block would be placed inside thedivin the content  ```html #main-content {max-width: 70em} ```  ```html <div id=\"main-content\"> <p>Lorem ipsum dolor sit amet, consectetur adipisicing ...</p> </div> ```",
    "referenced_by": [
      "1.4.4",
      "1.4.8"
    ]
  },
  {
    "id": "F69",
    "type": "technique",
    "code": "F69",
    "text": "[F69] Failure of Success Criterion 1.4.4 when resizing visually rendered text up to 200 percent causes the text, image or controls to be clipped, truncated or obscured\n\nDescription:\nThe objective of this failure condition is to describe a problem that occurs when changing the size of text causes text to be clipped, truncated, or obscured, so that it is no longer available to the user. In general, this failure occurs when there is no way for a user agent's layout engine to honor all the layout hints in the HTML at the new font size. Some of the ways in which this can occur include:\n\n- Setting the overflow property of the enclosing element to hidden\n- Using absolutely positioned content\n- Creating popups that aren't big enough for their content at the new font size\n\nExamples:\n- **Example 1: Overflowing text**  The font size is set in a scalable way, but the container is set to a fixed pixel size. A gray border shows the boundaries of the text container. When the text is resized, it spills out of its container, and obscures the next paragraph.  Illustration of example 1:  ```html <div style=\"font-size:100%; width:120px; height:100px; border: thin solid gray;\"> Now is the time for all good men to come to the aid of their country. </div> <p>The quick brown fox jumps over the lazy dog.</p> ```\n- **Example 2: Truncated text**  This example is identical to the last one, except that the container is set to clip the text. The text is no longer bleeding into the next paragraph, but now it is truncated. This is also a failure.  Illustration of example 2:  ```html <div style=\"font-size:100%; width:120px; height:100px; overflow: hidden; border: thin solid gray;\"> Now is the time for all good men to come to the aid of their country. </div> <p>The quick brown fox jumps over the lazy dog.</p> ```    ---",
    "referenced_by": [
      "1.4.4"
    ]
  },
  {
    "id": "F80",
    "type": "technique",
    "code": "F80",
    "text": "[F80] Failure of Success Criterion 1.4.4 when text-based form controls do not resize when visually rendered text is resized up to 200%\n\nDescription:\nThe objective of this failure condition is to describe a problem that occurs when changing the size of text does not cause the text-based form controls to resize accordingly. This means that the user may have difficulty entering text and being able to read what they have entered because the text is not displayed at the text size required by the user.\n\nText-based form controls include input boxes (text and textarea) as well as buttons.\n\nExamples:\n- **Example 1: A Contact Form**  A Contact Us form has some introductory information and then form controls for users to enter their first name, last name, telephone number and email address. The heading, introductory text and form control labels have been implemented in a scalable way but the form controls themselves have not.  The HTML component:  The CSS component:  ```html <h1>Contact Us</h1> <p>Please provide us with your details and we will contact you as soon as we can. Note that all of the form fields are required.</p> <div> <label for=\"fname\">First Name</label> <input type=\"text\" name=\"fname\" id=\"fname\"> </div> <div> <label for=\"lname\">Last Name</label> <input type=\"text\" name=\"lname\" id=\"lname\"> </div> <div> <label for=\"phone\">Telephone</label> <input type=\"text\" name=\"phone\" id=\"phone\"> </div> <div> <label for=\"email\">Email</label> <input type=\"text\" name=\"email\" id=\"email\"> </div> <input type=\"submit\" name=\"Submit\" value=\"Submit\" id=\"Submit\"> ```  ```html h1 { font-size: 2em; } p, label { font-size: 1em; } input {font-size: 12pt;} ```    ---",
    "referenced_by": [
      "1.4.4"
    ]
  },
  {
    "id": "F94",
    "type": "technique",
    "code": "F94",
    "text": "[F94] Failure of Success Criterion 1.4.4 due to incorrect use of viewport units to resize text\n\nDescription:\nThe objective of this technique is to document the failure of text to re-scale when [viewport units](https://developer.mozilla.org/en-US/docs/Web/CSS/length) are used on text. As these units are relative to the viewport, it means they cannot be resized by zooming or adjusting text-size.\n\nThere are various methods to increase and decrease the size of text and other content, but viewport units applied to text (generally via **font-size** in CSS) prevent most available methods. Attempts to use browser controls to zoom or adjust text-size will not work. Only methods that completely override the CSS will work, and those could cause other issues such as layouts collapsing or text overlapping.\n\nSome uses of viewport units may not prevent text-size adjustments, but if they are used as the primary method for defining text-size, they are likely to cause a failure of [Success Criterion 1.4.4](https://www.w3.org/WAI/WCAG22/Understanding/resize-text).",
    "referenced_by": [
      "1.4.4"
    ]
  },
  {
    "id": "C30",
    "type": "technique",
    "code": "C30",
    "text": "[C30] Using CSS to replace text with images of text and providing user interface controls to switch\n\nDescription:\nThe objective of this technique is to demonstrate how CSS can be used to replace structured HTML text with images of text in a way that makes it possible for users to view content according to their preferences. To use this technique, an author starts by creating an HTML page that uses semantic elements to mark up the structure of the page. The author then designs two or more stylesheets for that page. One stylesheet presents the HTML text as text and the second uses CSS features to replace some of the HTML text with images of text. Finally, through the use of server-side or client-side scripting, the author provides a control that allows the user to switch between the available views.\n\nThis technique can be used to meet Success Criterion 1.4.5 or 1.4.9 if a presentation that does not include images of text is available and as long as the user interface control that is provided to allow users to switch to an alternate presentation meets the relevant criteria. Where possible, authors should deliver the presentation that does not include images of text as the default presentation. In addition, the control used to switch should be located near the beginning of the page.\n\nA variety of \"image replacement\" techniques have been developed to address a variety of user agent, configuration and compatibility with assistive technology issues (See resources for more information). While there are a variety of approaches authors may use to replace text, it is important to consider compatibility with assistive technology, whether the technique will work correctly if scripting, CSS, images (or combinations of these) are turned off. Since it can be difficult to find a single solution that works in all cases, this technique recommends the use of a control that allows users to switch to a presentation that does not include an image replacement technique.\n\nExamples:\n- **Example 1: Replacing heading text with images of text**  A design studio site uses a style switcher to allow users to view two presentations of their home page. For the default version, the heading text is replaced with images of text. A control on the page allows users to switch to a version that presents the headings as text.  ```html <div id=\"Header\"> <h1><span>Pufferfish Design Studio</span></h1> <h2><span>Surprising Identity and Design Solutions</span></h2> </div> ```  ```html #Header h1 { background-image: url(pufferfish-logo.png); height: 195px; width: 290px; background-repeat: no-repeat; margin-top: 0; position: absolute; } #Header h1 span { position: absolute; left: -999em; } #Header h2 { background-image: url(beauty.png); background-repeat: no-repeat; height: 234px; width: 33px; margin-left: 8px; position: absolute; margin-top: 250px; } #Header h2 span { position: absolute; left: -999em; } ```  ```html #Header h1 { font: normal 200%/100% Garamond, \"Times New Roman\", serif; margin-bottom: 0; color: #000099; background: #ffffff; } #Header h2 { font: normal 160%/100% Garamond, \"Times New Roman\", serif; margin-bottom: 0; color: #336600; background: #ffffff; } ```    ---",
    "referenced_by": [
      "1.4.5",
      "1.4.9"
    ]
  },
  {
    "id": "PDF7",
    "type": "technique",
    "code": "PDF7",
    "text": "[PDF7] Performing OCR on a scanned PDF document to provide actual text\n\nDescription:\nThe intent of this technique is to ensure that visually rendered text\nis presented in such a manner that it can be perceived without its\nvisual presentation interfering with its readability.\n\nA document that consists of scanned images of text is inherently inaccessible\nbecause the content of the document is images, not searchable text.\nAssistive technologies cannot read or extract the words; users cannot\nselect, edit, resize, or reflow text nor can they change text and background\ncolors; and authors cannot manipulate the PDF for accessibility.\n\nFor these reasons, authors should use actual text rather than images\nof text, using an authoring tool such as Microsoft Word or Oracle Open\nOffice to author and convert content to PDF.\n\nIf authors do not have access to the source file and authoring tool,\nscanned images of text can be converted to PDF using optical character\nrecognition (OCR). Adobe Acrobat Pro can then be used to create accessible\ntext.\n\nExamples:\n- **Example 1: Generating actual text rather than images of text using Adobe Acrobat Pro**  This example is shown with Adobe Acrobat Pro. There are other software tools that perform similar functions.  This example uses a simple one-page scanned image of text. To ensure that actual text is stored in the document, perform the following steps:  The following image shows a scanned one-page document in Adobe Acrobat Pro.  The next image shows the converted content after adding tags to the document. It will be necessary to use the Reading Order tool and the Tags panel to tag the content properly. The Reading Order tool was used in this example to hide the image of the hand as decorative image / artifact (seePDF4). The recipe title was tagged as a first level header.  Note: Acrobat Pro may automatically add tags when the file is run through OCR.  This example is shown in operation in theworking example of generating actual textand theresult of tagging text created with OCR.    ---",
    "referenced_by": [
      "1.4.5",
      "1.4.9"
    ]
  },
  {
    "id": "G17",
    "type": "technique",
    "code": "G17",
    "text": "[G17] Ensuring that a contrast ratio of at least 7:1 exists between text (and images of text) and background behind the text\n\nDescription:\nThe objective of this technique is to make sure that users can read text\nthat is presented over a background. This technique goes beyond the 4.5:1\ncontrast technique to provide a higher level of contrast to make it easier\nfor people with low vision to read.\n\nIf the background is a solid color (or all black or all white) then the\ncontrast ratio of the text can be maintained by making sure that each\nof the text letters have a 7:1 contrast ratio with the background.\n\nIf the background or the letters vary in relative luminance (or are patterned), then\nthe background around the letters can be chosen or shaded so that the\nletters maintain a 7:1 contrast ratio with the background behind them\neven if they do not have that contrast ratio with the entire background.\n\nThe contrast ratio can sometimes be maintained by changing the\nrelative luminance of the letters as the relative luminance of the background changes across\nthe page.\n\nAnother method is to provide a halo around the text that provides the\nnecessary contrast ratio if the background image or color would not\nnormally be sufficiently different in relative luminance.\n\nExamples:\n- **Example 1:** A black background is chosen so that light colored letters that match the company's logo can be used.\n- **Example 2:** Text is placed over a picture of the college campus. Since a wide variety of colors and darknesses appear in the picture the area behind the text is fogged white so that the picture is very faint and the maximum darkness is still light enough to maintain a 7:1 contrast ratio with the black text written over the picture.  ---",
    "referenced_by": [
      "1.4.6"
    ]
  },
  {
    "id": "G56",
    "type": "technique",
    "code": "G56",
    "text": "[G56] Mixing audio files so that non-speech sounds are at least 20 decibels lower than the speech audio content\n\nDescription:\nThe objective of this technique is to allow authors to include sound behind\nspeech without making it too hard for people with hearing problems to\nunderstand the speech. Making sure that the foreground speech is 20 db louder than the\nbackgound sound makes the speech 4 times louder than the background audio. For information on Decibels (dB), refer to\n[About Decibels](https://ds.gpii.net/content/about-decibels-db).\n\nExamples:\n- **Example 1: An announcer speaking over a riot scene**\n- **Example 2: Sufficient audio contrast between a narrator and background music**  This example demonstrates a voice with music in the background in which the voice is the appropriate 20 DB above the background. The voice (foreground) is recorded at -17.52 decibels (average RMS) and the music (background) is at -37.52 decibels, which makes the foreground 20 decibels louder than the background.\n- **Example 3: Insufficient Audio Contrast between a narrator and background music**    ---",
    "referenced_by": [
      "1.4.7"
    ]
  },
  {
    "id": "C23",
    "type": "technique",
    "code": "C23",
    "text": "[C23] Specifying text and background colors of secondary content such as banners, features and navigation in CSS while not specifying text and background colors of the main content\n\nDescription:\nSome web pages use colors to identify different groupings. The objective of this technique is to allow users to select specific color combinations for the text and background of the main content while retaining visual clues to the groupings and organization of the web page. When a user overrides the foreground and background colors of all the text on a page, visual clues to the grouping and organization of the web page may be lost, making it much more difficult to understand and use.\n\nWhen an author does not specify the colors of the text and background of the main content, it is possible to change the colors of those regions in the browser without the need to override the colors with a user style sheet. Specifying the text and background colors of secondary content means that the browser will not override those colors.\n\nWith this technique the author uses the default text color and background color of the main area. As a result the colors are completely determined by the user agent via the user's color preferences. The user can ensure that the color selection best meets their needs and provides the best reading experience.\n\nExamples:\n- **Example 1**  AnHTMLweb page uses CSS to specify the text and background colors of all secondary content such as navigation bars, menu bars, and the table of contents. Neither the text color nor background of the main content is specified. The user sets their own color preferences in the browser so that they view the main content in colors and contrasts that work well for them. The distinction between the separate sections of the page are still visually obvious.\n- **Example 2**  A music magazine has an article that is blue text on a white background. The site provides a link near the beginning of the page which assigns a different style sheet to the page. The new style sheet does not have any colors specified for the text or background.    ---",
    "referenced_by": [
      "1.4.8"
    ]
  },
  {
    "id": "C25",
    "type": "technique",
    "code": "C25",
    "text": "[C25] Specifying borders and layout in CSS to delineate areas of a Web page while not specifying text and text-background colors\n\nDescription:\nThe intent of this technique is to specify borders and layout using CSS and leave text and background colors to render according to the user's browser and/or operating system settings. This allows users to view the text in the colors they require while maintaining other aspects of the layout and page design such as columns of text, borders around sections or vertical lines between a menu and main content area. It will also prevent some display issues in some browsers when pages contain Javascript pop-up boxes or drop-down menus and have the colors overridden.\n\nBorders and layout indicators help many people with cognitive disabilities, as does flexibility over the text and background colors. Sometimes these two needs are in conflict when the user has to over-ride the author's color selection of text and background in the browser and the browser also removes the borders and the intended layout. This can mean the page is displayed in a single column with one block of content below the other, which can result in unnecessary whitespace and long lines of text. It can also mean that pop-up boxes gain a transparent background, superimposing the text of the box on the text of the page, and drop-down menus either become transparent or gain a dark-grey background. When a web author does not specify the colors of any text and background, while specifying border colors and layout, it is possible, in most popular browsers, to change the text and background colors without affecting the other (author-specified) CSS declarations.\n\nExamples:\n- **Example 1**  A web page is designed using HTML. CSS is used to specify border colors around discrete areas of the page and to layout the content so that the menu floats to the left of the main content area. Neither the text color nor background is specified. The user sets their own colors in the browser. They can view the page in colors and contrasts that work well for them without disrupting the layout.    ---",
    "referenced_by": [
      "1.4.8"
    ]
  },
  {
    "id": "G175",
    "type": "technique",
    "code": "G175",
    "text": "[G175] Providing a multi color selection tool on the page for foreground and background colors\n\nDescription:\nThe objective of this technique is to include a control on a web page or set of web pages that allows users to specify preferred foreground and background colors for the content. This technique can be implemented using any technology that allows users to store preferences that can be used across pages. Using this technique, an author includes a color picker control on the site which allows users to select and save foreground and background color preferences for use on other pages in a site. Pages are designed to look for these preferences and adapt accordingly when saved settings are found.\n\nMany users with cognitive disabilities have trouble with standard black text on a white background. Sometimes, they can read the text a lot better using different colors for the text and background and sometimes these color combinations are very specific and not what would be expected by someone else (for instance brown on blue).\n\nSome of these users will have difficulty setting colors using the browser's color settings or the operating systems color settings. Providing a tool on the web page that provides a wide range of foreground and background colors will allow them to easily change the colors without digging into the browser settings.\n\nExamples:\n- **Example 1**  The user may type hex values into the text fields. The \"pick\" link will open a color selection tool for the adjoining field.  The color selection tool opened for selecting a color.  Here is a working example of this technique implemented using PHP, Javascript, CSS and HTML:Color Picker Example.    ---",
    "referenced_by": [
      "1.4.8"
    ]
  },
  {
    "id": "G204",
    "type": "technique",
    "code": "G204",
    "text": "[G204] Not interfering with the user agent's reflow of text as the viewing window is narrowed\n\nDescription:\nThis technique helps avoid situations where horizontal scrolling may occur. Many people with cognitive disabilities and low vision users who do not use assistive technology have a great deal of trouble with blocks of text that require horizontal scrolling. It involves not interfering with the reflow of text if the window is narrowed. One of the best ways to do this is to define widths of text block containers in percentages.\n\nHTML user agents automatically reflow text as the browser window is narrowed as long as the author does not specify widths using absolute measurements such as pixels or points.\n\nExamples:\n- **Example 1**  A newspaper site includes articles with columns that adjust with the user agents window width. Users with cognitive disabilities can narrow the column to a width that makes it easier to read.    ---",
    "referenced_by": [
      "1.4.8"
    ]
  },
  {
    "id": "C19",
    "type": "technique",
    "code": "C19",
    "text": "[C19] Specifying alignment either to the left OR right in CSS\n\nDescription:\nThis technique describes how to align blocks of text either left or right by setting the CSS text-align property.\n\nExamples:\n- **Example 1: Aligning text to the left**  In the following example, text is aligned left. In the style sheet, define the class:  In the content call the up the class.  ```html p.left {text-align: left} ```  ```html <p class=\"left\"> Lorem ipsum dolor sit ...</p> ```\n- **Example 2: Aligning text to the right**  In the following example, text is aligned right.  In the content call the up the class.  ```html p.right {text-align: right} ```  ```html <p class=\"right\"> Lorem ipsum dolor sit ...</p> ```    ---",
    "referenced_by": [
      "1.4.8"
    ]
  },
  {
    "id": "G172",
    "type": "technique",
    "code": "G172",
    "text": "[G172] Providing a mechanism to remove full justification of text\n\nDescription:\nThe objective of this technique is to provide a version of the page that does not have full justification (justified both left and right).\n\nThere may be circumstances when for layout purposes an author may want to have the text fully justified. In these cases, it is sufficient to provide a feature that removes the justification of text. The control should be easy to find and access and near the beginning of the page.\n\nExamples:\n- **Example 1**  A classic novel online is on a site that attempts to duplicate the look of the originally published work, which includes full justification. A button is provided near the top of the page saying \"remove full justification\" and a style switching technique is used to swap out the style sheet. The new style sheet aligns the text only on the left.    ---",
    "referenced_by": [
      "1.4.8"
    ]
  },
  {
    "id": "G169",
    "type": "technique",
    "code": "G169",
    "text": "[G169] Aligning text on only one side\n\nDescription:\nMany people with cognitive disabilities have a great deal of trouble with blocks of text that are justified (aligned to both the left and the right margins). The spaces between words create \"rivers of white\" running down the page, which can make the text difficult for some people to read. This failure describes situations where this confusing text layout occurs. The best way to avoid this problem is not to create text layout that is fully justified.\n\nExamples:\n- **Example 1**  For most technologies, simply leave out any alignment declarations. For example, the following text will be justified to the left by default inHTMLwhere the language of the page is left to right.  ```html <p>Lorem ipsum dolor sit amet, ...</p> ```\n- **Example 2**  A web page includes sections with mixed alignment. Paragraphs in the body of the page are aligned to the left margin. The text also includes a number of pulled quotations which are aligned to the right margin.    ---",
    "referenced_by": [
      "1.4.8"
    ]
  },
  {
    "id": "G188",
    "type": "technique",
    "code": "G188",
    "text": "[G188] Providing a button on the page to increase line spaces and paragraph spaces\n\nDescription:\nMany people with cognitive disabilities have trouble reading text that is single spaced. A button that increases the line height will help them read the content. In order to retain the separation of paragraphs, the space between paragraphs should also increase so that it is at least 1.5 times as high as the line spacing.\n\nExamples:\n- **Example 1**  Use standard style page switching and have a button or link on the page that switches the stylesheet. The new stylesheet contains a rule to increase the line height and a class to increase the paragraph spacing.  ```html p { line-height: 1.5; margin-bottom: 2em; } ```    ---",
    "referenced_by": [
      "1.4.8"
    ]
  },
  {
    "id": "C24",
    "type": "technique",
    "code": "C24",
    "text": "[C24] Using percentage values in CSS for container sizes\n\nDescription:\nThe objective of this technique is to enable users to increase the size of text without having to scroll horizontally to read that text. To use this technique, an author specifies the width of text containers using percent values.\n\nExamples:\n- **Example 1**  A newspaper has content in the middle of the window. The width of the container for the content is specified in page percentages, so that when a person with low vision increases the font size the text reflows inside the browser window at the new size and there is no need to scroll horizontally.    ---",
    "referenced_by": [
      "1.4.8"
    ]
  },
  {
    "id": "F88",
    "type": "technique",
    "code": "F88",
    "text": "[F88] Failure of Success Criterion 1.4.8 due to using text that is justified (aligned to both the left and the right margins)\n\nDescription:\nMany people with cognitive disabilities have a great deal of trouble with blocks of text that are justified (aligned to both the left and the right margins). The spaces between words create \"rivers of white\" running down the page, which can make the text difficult for some people to read. This failure describes situations where this confusing text layout occurs. The best way to avoid this problem is not to create text layout that is fully justified (aligned to both the left and the right margins).\n\nExamples:\n- **Example 1**  In the following example of a failure, the HTMLalignattribute is used to create justified text.  ```html <p align=\"justify\"> Peter Piper picked a peck of pickled peppers A peck of pickled peppers Peter Piper picked If Peter Piper picked a peck of pickled peppers Where's the peck of pickled peppers Peter Piper picked? </p> ```\n- **Example 2**  In this example of a failure, the CSS text-align property is used to create justified text.  ```html p {text-align: justify} <p> How much wood would a woodchuck chuck if a woodchuck could chuck wood? He would chuck, he would, as much as he could, and chuck as much wood As a woodchuck would if a woodchuck could chuck wood. </p> ```    ---",
    "referenced_by": [
      "1.4.8"
    ]
  },
  {
    "id": "G202",
    "type": "technique",
    "code": "G202",
    "text": "[G202] Ensuring keyboard control for all functionality\n\nDescription:\nThe objective of this technique is to provide keyboard operation for all the functionality of the page. When all functionality of content can be operated through a keyboard or keyboard interface, it can be operated by those with no vision as well as by those who must use alternate keyboards or input devices that act as keyboard emulators like speech input software or on-screen keyboards.\n\nA [keyboard interface](https://www.w3.org/TR/WCAG22/#dfn-keyboard-interface) allows users to provide keystroke input to programs even if the computing device that they are using does not contain a hardware keyboard. For example, many mobile devices have keyboard interfaces within their operating system as well the option to connect external wireless keyboards. Applications can use the interface to obtain keyboard input either from an external keyboard or from other services that provide simulated keyboard output, such as switch devices, handwriting interpreters or speech-to-text applications.\n\nTo implement this technique, first determine what functionality is available to users on the page. In this step, it is important to consider functions performed using both the mouse and the keyboard together. Examples of functionality include the use of physical controls such as links, menus, buttons, checkboxes, radio buttons and form fields as well as the use of features like drag and drop, selecting text, resizing regions or bringing up context menus. Other examples of functionality may based on tasks such as adding or removing an item from a shopping cart or initiating a chat session with a sales representative.\n\nOnce the functionality of the content has been determined, the author verifies that each of the functions identified can be performed using only the keyboard.\n\nExamples:\n- **Example 1:** A page with images used as links changes when the user hovers over the image with a mouse. To provide keyboard users with a similar experience, the image is also changed when a user tabs to it.\n- **Example 2:** A page that allows users to click and drag items in a list to reorder them also includes a series of controls that allows keyboard users to move items up, down or to the beginning and end of the list.\n- **Example 3:** The mobile version of a website includes a menu button that is tapped to open a site menu, which is implemented as a floating overlay. To provide access to people using external keyboards or ability switches with their mobile device, the menu button and the site menu are both implemented such that they can be operated via the mobile device's keyboard interface.  ---",
    "referenced_by": [
      "2.1.1"
    ]
  },
  {
    "id": "H91",
    "type": "technique",
    "code": "H91",
    "text": "[H91] Using HTML form controls and links\n\nDescription:\nThe objective of this technique is to use standard HTML form controls and link elements to provide keyboard operation and assistive technology interoperability of interactive user interface elements.\n\nUser agents provide the keyboard operation of HTML form controls and links. In addition, the user agent maps the form controls and links to an accessibility API. Assistive technologies use the accessibility API to extract appropriate accessibility information, such as role, name, state, and value, and present them to users. The role is provided by the HTML element, and the name is provided by the text associated with that element. Elements for which values and states are appropriate also expose the values and states via multiple mechanisms.\n\nIn some cases, the text is already associated with the control through a required attribute. For example, submit buttons use the **button** element text or image **alt** attribute as the name. In the case of form controls, **label** elements; the **aria-label** or **aria-labelledby** properties; or the **title** attribute are used.\n\nExamples:\n- **Example 1: Links**  User agents provide mechanisms to navigate to and select links. In each of the following examples, the role is \"link\" because theaelement has anhrefattribute. Anaelement without anhrefisn't a link. The link's value is theURIin thehrefattribute.  ```html <a href=\"https://example.com\">Example Site</a> ```  ```html <a href=\"https://example.com\"><img alt=\"Example\" src=\"example-logo.gif\"></a> ```  ```html <a href=\"https://example.com\"><img alt=\"Example \" src=\"example_logo.gif\">Text</a> ```\n- **Example 2: Buttons**  There are several ways to create a button in HTML.  ```html <button type=\"button\">Save</button> ```  ```html <input type=\"button\" value=\"Save\"> <input type=\"submit\" value=\"Submit\"> <input type=\"reset\" value=\"Reset\"> ```  ```html <input alt=\"save\" src=\"save.gif\" type=\"image\"> ```  ```html <input alt=\"save\" src=\"save.gif\" title=\"save the file\" type=\"image\"> ```\n- **Example 3: Text Input**  ```html <label for=\"text-1\">Type of fruit</label> <input id=\"text-1\" type=\"text\" value=\"bananas\"> ```  ```html <input aria-label=\"Type of fruit\" id=\"text-1\" type=\"text\"> ```\n- **Example 4: Checkbox**  This example has a role ofcheckbox, from thetypeattribute of theinputelement. Thelabelelement is associated with theinputelement via theforattribute which refers to theidattribute of theinputelement. The name comes from thelabelelement, in this case \"cheese\". Its state can becheckedoruncheckedand comes from thecheckedattribute. The state can be changed by the user's interaction with the control.  ```html <label for=\"cb-1\">Cheese</label> <input checked id=\"cb-1\" type=\"checkbox\"> ```\n- **Example 5: Radio Buttons**  This example has a role of \"radio button\" from thetypeattribute on theinputelement. Its name comes from thelabelelement. Its state can becheckedoruncheckedand comes from thecheckedattribute. The state can be changed by the user's interaction with the control.  ```html <input checked id=\"r1\" name=\"color\" type=\"radio\"><label for=\"r1\">Red</label> <input id=\"r2\" name=\"color\" type=\"radio\"><label for=\"r2\">Blue</label> <input id=\"r3\" name=\"color\" type=\"radio\"><label for=\"r3\">Green</label> ```\n- **Example 6: Radio Fieldset**  The radiofieldsethas a role of \"grouping\". The name comes from thelegendelement.  ```html <fieldset> <legend>Choose a Color:</legend> <div> <input id=\"red\" name=\"color\" type=\"radio\" value=\"red\"> <label for=\"red\">Red</label> </div> <div> <input id=\"blue\" name=\"color\" type=\"radio\" value=\"blue\"> <label for=\"blue\">Blue</label> </div> <div> <input id=\"green\" name=\"color\" type=\"radio\" value=\"green\"> <label for=\"green\">Green</label> </fieldset> ```\n- **Example 7: Select Element**  ```html <label for=\"s1\">Numbers</label> <select id=\"s1\"> <option>One</option> <option selected>Two</option> <option>Three</option> </select> ```  ```html <select aria-label=\"Numbers\" id=\"s1\"> <option>One</option> <option selected>Two</option> <option>Three</option> </select> ```    ---",
    "referenced_by": [
      "2.1.1",
      "4.1.2"
    ]
  },
  {
    "id": "PDF23",
    "type": "technique",
    "code": "PDF23",
    "text": "[PDF23] Providing interactive form controls in PDF documents\n\nDescription:\nThe objective of this technique is to ensure that interactive form controls in PDF documents allow keyboard operation. Interactive PDF forms are generally created using a tool for authoring PDF.\n\nThe types of PDF form controls are: text input field, check box, radio button, combo box, list box, and button.\n\nForm controls allow users to interact with a PDF document by filling\nin information or indicating choices, which can then be submitted\nfor processing. Users who rely on keyboard access must be able to\nrecognize and understand the form fields, make selections, and provide\ninput to complete the forms, and submit the form, just as sighted\nusers can.\n\nInteractive form controls can be provided for forms created by\nconverting a scanned paper form to tagged PDF or by creating a form\nin an authoring application such as Microsoft Word or Open Office\nand converting it to tagged PDF.\n\nHowever, documents created by authoring applications that provide\nform design features might not fully retain their fillable form\nfields on conversion to PDF. Complex forms in particular may not\nhave properly converted form fields and labels when tagged in conversion.\n\nUsing Adobe Acrobat Pro with forms in converted documents, you\ncan ensure that form fields are keyboard accessible and usable by:\n\n- Opening tagged PDF documents with form fields and creating interactive PDF form elements with the Identify Form Fields tool.\n- Modifying fillable form fields, or adding form fields, using Adobe Acrobat Pro\n\nExamples:\n- **Example 1: Adding interactive controls to existing forms in PDF documents using Adobe Acrobat Pro**  This example is shown with Adobe Acrobat Pro. There are other software tools that perform similar functions.  If you have a form in a tagged PDF document (created by scanning a paper form or using an authoring tool to generate tagged PDF), you can use Adobe Acrobat Pro to make the form elements keyboard accessible in the same page locations as the static form.  This example is shown in operation in theworking example of Interactive Controls in Acrobat(PDF).\n- **Example 2: Adding form controls in PDF documents using Adobe Acrobat Pro**  This example is shown with Adobe Acrobat Pro. There are other software tools that perform similar functions.  You can add keyboard accessible form controls to your form as follows:\n- **Example 3: Adding a text field in a PDF document using the/Txfield type**  The following code fragment illustrates code that is typical for a simple text field such as shown in Examples 1 and 2. This is typically accomplished by an authoring tool.  ```html << /AP -dict- /DA /Helv  0 Tf 0 g /DR -dict- /F 0x4 /FT Tx              % FT key set to Tx for Text Field /P -dict- /Rect -array- /StructParent 0x1 /Subtype Widget /T Date you are available   % Partial field name Date /TU Date you are available: use mm/dd/yyyy format % TU tool tip value serves as short description /Type Annot /V Pat Jones >> ... <Start Stream> BT /P <</MCID 0 >>BDC /CS0 cs 0  scn /TT0 1 Tf -0.001 Tc 0.003 Tw 11.04 0 0 11.04 72 709.56 Tm [(P)-6(le)-3(as)10(e)-3( )11(P)-6(rin)2(t)-3( Y)8(o)-7(u)2(r N)4(a)11(m)-6(e)]TJ 0 Tc 0 Tw 9.533 0 Td ( )Tj -0.004 Tc 0.004 Tw 0.217 0 Td [(\\()-5(R)-4(e)5(q)-1(u)-1(i)-3(r)-3(e)-6(d)-1(\\))]TJ EMC /P <</MCID 1 >>BDC 0 Tc 0 Tw 4.283 0 Td [( )-2( )]TJ EMC /ArtifactSpan <</MCID 2 >>BDC 0.002 Tc -0.002 Tw 0.456 0 Td [(__)11(___)11(___)11(___)11(___)11(_)11(____)11(___)11(___)11(__)]TJ 0 Tc 0 Tw 13.391 0 Td ( )Tj EMC ET <End Stream> ```    ---",
    "referenced_by": [
      "2.1.1"
    ]
  },
  {
    "id": "G90",
    "type": "technique",
    "code": "G90",
    "text": "[G90] Providing keyboard-triggered event handlers\n\nDescription:\nThe objective of this technique is to permit individuals who rely on a keyboard or keyboard interface to access the functionality of the content. To do this, make sure that all event handlers triggered by non-keyboard UI events are also associated with a keyboard-based event, or provide redundant keyboard-based mechanisms to accomplish the functionality provided by other device-specific functions.\n\nExamples:\n- **Example 1:** Example 1: A drag and drop featureA photo application includes a \"drag\" and \"drop\" feature to allow users to re-order photographs in an on-line album for presentation as a slide show. It also includes a feature that allows users to select a photo and 'cut' and 'paste' the items into the list at the appropriate point using only the keyboard.\n- **Example 2:** Example 2: A reorder featureA web application that allows users to create surveys by dragging questions into position includes a list of the questions followed by a text field that allows users to re-order questions as needed by entering the desired question number.  ---",
    "referenced_by": [
      "2.1.1"
    ]
  },
  {
    "id": "SCR20",
    "type": "technique",
    "code": "SCR20",
    "text": "[SCR20] Using both keyboard and other device-specific functions\n\nDescription:\nThe objective of this technique is to illustrate the use of both keyboard-specific and mouse-specific events with code that has a scripting function associated with an event. Using both keyboard-specific and mouse-specific events together ensures that content can be operated by a wide range of devices. For example, a script may perform the same action when a keypress is detected that is performed when a mouse button is clicked. This technique goes beyond the success criterion requirement for keyboard access by including not only keyboard access but access using other devices as well.\n\nIn JavaScript, commonly used event handlers include, **onblur**, **onchange**, **onclick**, **ondblclick**, **onfocus**, **onkeydown**, **onkeypress**, **onkeyup**, **onload**, **onmousedown**, **onmousemove**, **onmouseout**, **onmouseover**, **onmouseup**, **onreset**, **onselect**, **onsubmit**, **onunload**. Some mouse-specific functions have a logical corresponding keyboard-specific function (such as '**onmouseover**' and '**onfocus**'). A keyboard event handler should be provided that executes the same function as the mouse event handler.\n\nThe following table suggests keyboard event handlers to pair mouse event handlers.\n\n1 Although click is in principle a mouse event handler, most HTML user agents also process this event when a native HTML control (e.g. a button or a link) is activated, regardless of whether it was activated with the mouse or the keyboard. In practice, therefore, it is not necessary to duplicate this event when adding handlers to natively focusable HTML elements. However, it is necessary when adding handlers to other events, such as in Example 2 below.\n\n2 Since the keypress event handler reacts to any key, the event handler function should check first to ensure the Enter key was pressed before proceeding to handle the event. Otherwise, the event handler will run each time the user presses any key, even the tab key to leave the control, and this is usually not desirable.\n\nSome mouse-specific functions (such as dblclick and mousemove) do not have a corresponding keyboard-specific function. This means that some functions may need  to be implemented differently for each device (for example, including a series of buttons to execute, via keyboard, the equivalent mouse-specific functions implemented).\n\nExamples:\n- **Example 1**  In this example of an image link, the image is changed when the user positions the pointer over the image. To provide keyboard users with a similar experience, the image is also changed when the user tabs to it.  ```html <a href=\"menu.php\" onmouseover=\"swapImageOn('menu')\" onfocus=\"swapImageOn('menu')\" onmouseout=\"swapImageOff('menu')\" onblur=\"swapImageOff('menu')\"> <img id=\"menu\" src=\"menu_off.gif\" alt=\"Menu\"> </a> ```\n- **Example 2**  This example shows a custom link control where both the mouse and the keyboard can be used to activate the function. The mouse onclick event is duplicated by an appropriate keyboard onkeypress event. The tabindex attribute ensures that the keyboard will have a tab stop on the span element. Note that in this example, the nextPage() function should check that the key pressed was Enter, otherwise it will respond to all keyboard actions while the span has focus, which is not the desired behavior.  ```html <span onclick=\"nextPage();\" onkeypress=\"nextPage();\" role=\"link\" tabindex=\"0\"> <img alt=\"Go to next page\" src=\"arrow.gif\"> </span> ```    ---",
    "referenced_by": [
      "2.1.1"
    ]
  },
  {
    "id": "SCR35",
    "type": "technique",
    "code": "SCR35",
    "text": "[SCR35] Making actions keyboard accessible by using the onclick event of anchors and buttons\n\nDescription:\nThe objective of this technique is to demonstrate how to invoke a scripting function in a way that is keyboard accessible by attaching it to a keyboard-accessible control. In order to ensure that scripted actions can be invoked from the keyboard, they are associated with \"natively actionable\" HTML elements (links and buttons). The onclick event of these elements is device independent. While \"**onclick**\" sounds like it is tied to the mouse, the **onclick** event is actually mapped to the default action of a link or button. The default action occurs when the user clicks the element with a mouse, but it also occurs when the user focuses the element and hits enter or space, and when the element is triggered via the accessibility API.\n\nThis technique relies on client-side scripting. However, it is beneficial to provide a backup implementation or explanation for environments in which scripting is not available. When using anchor elements to invoke a JavaScript action, a backup implementation or explanation is provided via the **href** attribute. When using buttons, it is provided via a form post.\n\nExamples:\n- **Example 1: Link that runs a script and has no fallback for non-scripted browsers**  This approach should only be used when script is relied upon as an Accessibility Supported Technology.  Even though we do not want to navigate from this link, we must use the href attribute on theaelement in order to make this a true link and get the proper eventing. In this case, we're using\"#\"as the link target, but you could use anything. This link will never be navigated.  The \"return false;\" at the end of thedoStuff()event handling function tells the browser not to navigate to theURI. Without it, the page would refresh after the script ran.  ```html <script> function doStuff() { //do stuff return false; } </script> <a href=\"#\" onclick=\"return doStuff();\">do stuff</a> ```\n- **Example 2: Link that runs script, but navigates to another page when script is not available**  This approach can be used to create sites that don't rely on script, if and only if the navigation target provides the same functionality as the script. This example is identical to the example 1, except that itshrefis now set to a real page, dostuff.html. The dostuff.html page must provide the same functionality as the script. The \"return false;\" at the end of thedoStuff()event handling function tells the browser not to navigate to the URI. Without it, the browser would navigate to dostuff.html after the script ran.  A working example of this code is available. Refer toCreating Action Links using JavaScript.  ```html <script> function doStuff() { //do stuff return false; } </script> <a href=\"dostuff.html\" onclick=\"return doStuff();\">do stuff</a> ```\n- **Example 3: Button that runs a script and falls back to a form post for users without script**  This approach can be used by sites that do not rely on script, if and only if the form post provides the same functionality as the script. The onsubmit=\"return false;\" prevents the form from submitting.  A working example of this code is available. Refer toCreating Action Buttons using JavaScript.  ```html <script> function doStuff() { //do stuff } </script> <form action=\"doStuff.aspx\" onsubmit=\"return false;\"> <input type=\"submit\" value=\"Do Stuff\" onclick=\"doStuff();\"> </form> ```\n- **Example 4: Button that runs a script, implemented withinput type=\"image\"**  Note that analtattribute must be added to theinputto provide a text equivalent for the image. This approach should only be used when script is relied upon.  ```html <script> function doStuff() { //do stuff return false; } </script> <input type=\"image\" src=\"stuff.gif\" alt=\"Do stuff\" onclick=\"return doStuff();\"> ```\n- **Example 5: Button that runs a script, implemented withinput type=\"submit\",input type=\"reset\"orinput type=\"button\"**  This approach should only be used when script is relied upon.  ```html <input type=\"submit\" onclick=\"return doStuff();\" value=\"Do Stuff\"> ```\n- **Example 6: Button that runs a script, implemented withbutton**  This is valuable when you want more control over the look of your button. In this particular example, the button contains both an icon and some text. This approach should only be used when script is relied upon.  ```html <button onclick=\"return doStuff();\"> <img src=\"stuff.gif\" alt=\"stuff icon\"> Do Stuff </button> ```    ---",
    "referenced_by": [
      "2.1.1"
    ]
  },
  {
    "id": "SCR2",
    "type": "technique",
    "code": "SCR2",
    "text": "[SCR2] Using redundant keyboard and mouse event handlers\n\nDescription:\nThe objective of this technique is to demonstrate using device independent events to change a decorative image in response to a mouse or focus event. Use the **onmouseover** and **onmouseout** events to change a decorative image when the mouse moves on top of or away from an element on the page. Also, use the **onfocus** and **onblur** events to change the image when the element receives and loses focus.\n\nThe example below has a decorative image in front of an anchor element. When the user mouses over the anchor tag, the decorative image in front of the anchor is changed. When the mouse moves off of the anchor, the image is changed back to its original version. The same image change effect occurs when the user gives keyboard focus to the anchor element. When focus is received the image changes, when focus is lost the image is changed back. This is accomplished by attaching **onmouseover**, **onmouseout**, **onfocus** and **onblur** event handlers to the anchor element. The event handler is a JavaScript function called **updateImage()**, which changes the **src** attribute of the image. The **updateImage()** is called in response to the **onmouseover**, **onmouseout**, **onfocus**, and **onblur** events.\n\nEach image is given a unique **id**. This unique **id** is passed to **updateImage()** along with a boolean value indicating which image is to be used: **updateImage(imgId, isOver)**;. The boolean value of true is passed when the mouse is over the anchor element or it has focus. A false value is passed when the mouse moves off of the anchor element or it loses focus. The **updateImage()** function uses the image **id** to load the image and then changes the **src** attribute based on the boolean value. Note that since the image is for decorative purposes, it has a null **alt** attribute.\n\nExamples:\n- **Example 1**  ```html <!doctype html> <html lang=\"en\"> <head> <meta charset=\"utf-8\"> <title>Changing Image Source in a Device Independent Manner</title> <script> /* This function will change the image src of an image element. * param imgId - the id of the image object to change * param isOver - true when mouse is over or object has focus, false when mouse move out or focus is lost */ function updateImage(imgId, isOver) { var theImage = document.getElementById(imgId); if (theImage != null) { if (isOver) { theImage.setAttribute(\"src\",\"yellowplus.gif\"); } else { theImage.setAttribute(\"src\",\"greyplus.gif\"); } } } </script> </head> <body> <p>Mouse over or tab to the links below and see the image change.</p> <a href=\"https://www.w3.org/WAI/\" onmouseover=\"updateImage('wai', true);\" onfocus=\"updateImage('wai', true);\" onmouseout=\"updateImage('wai',false);\" onblur=\"updateImage('wai',false);\"> <img alt=\"\" id=\"wai\" src=\"greyplus.gif\"> W3C Web Accessibility Initiative</a> &amp; <a href=\"https://www.w3.org/International/\" onmouseover=\"updateImage('i18n', true);\" onfocus=\"updateImage('i18n',true);\" onmouseout=\"updateImage('i18n',false);\" onblur=\"updateImage('i18n',false);\"> <img alt=\"\" id=\"i18n\" src=\"greyplus.gif\"> W3C Internationalization</a> </body> </html> ```    ---",
    "referenced_by": [
      "2.1.1"
    ]
  },
  {
    "id": "SCR29",
    "type": "technique",
    "code": "SCR29",
    "text": "[SCR29] Adding keyboard-accessible actions to static HTML elements\n\nDescription:\nThe objective of this technique is to demonstrate how to provide keyboard access to a user interface control that is implemented by actions to static HTML elements such as **div** or **span**. This technique ensures that the element is focusable by setting the **tabindex** attribute, and it ensures that the action can be triggered from the keyboard by providing an **onkeyup** or **onkeypress** handler in addition to an **onclick** handler.\n\nWhen the **tabindex** attribute has the value **0**, the element can be focused via the keyboard and is included in the tab order of the document. When the **tabindex** attribute has the value **-1**, the element cannot be tabbed to, but focus can be set programmatically, using **element.focus()**.\n\nBecause static HTML elements do not have actions associated with them, it is not possible to provide a backup implementation or explanation in environments in which scripting is not available. This technique should only be used in environments in which client-side scripting can be relied upon.\n\nExamples:\n- **Example 1: Adding a JavaScript action to adivelement**  Thedivelement on the page is given a uniqueidattribute and atabindexattribute with value0. A script uses the Document Object Model (DOM) to find thedivelement by itsidand add theonclickhandler and theonkeyuphandler. Theonkeyuphandler will invoke the action when theEnterkey is pressed. Note that thedivelement must be loaded into the DOM before it can be found and modified. This is usually accomplished by calling the script from theonloadevent of the body element. The script to add the event handlers will only execute if the user agent supports and has JavaScript enabled.  Working example of this code:Creating Divs with Actions using JavaScript.  ```html <script> // this is the function to perform the action. This simple example toggles a message. function doSomething(event) { var msg=document.getElementById(\"message\"); msg.style.display = msg.style.display==\"none\" ? \"\" : \"none\";  //return false from the function to make certain // that the href of the link does not get invoked return false; }  // this is the function to perform the action when the Enter key has been pressed. function doSomethingOnEnter(event) { var key = 0;  // Determine the key pressed, depending on whether window.event // or the event object is in use if (window.event) { key = window.event.keyCode; } else if (event) { key = event.keyCode; }  // Was the Enter or Space key pressed? if (key == 13 || key == 32) { return doSomething(event); }  // The event has not been handled, so return true return true; }  // This setUpActions() function must be called to set the onclick and onkeyup // event handlers onto the existing div element. // This function must be called after the div element with id=\"active\" // has been loaded into the DOM. // In this example the setUpActions() function is called from the onload event // for the body element. function setUpActions() {  // get the div object var active=document.getElementById(\"active\");  // assign the onclick handler to the object. active.onclick=doSomething;  // assign the onkeyup handler to the object. active.onkeyup=doSomethingOnEnter; } </script>  <body onload=\"setUpActions();\"> <p>Here is the link to modify with a javascript action:</p> <div> <span id=\"active\" role=\"button\" tabindex=\"0\">Do Something</span> </div> <div aria-live=\"polite\"> <div id=\"message\">Hello, world!</div> </div> </body> ```    ---",
    "referenced_by": [
      "2.1.1"
    ]
  },
  {
    "id": "F54",
    "type": "technique",
    "code": "F54",
    "text": "[F54] Failure of Success Criterion 2.1.1 due to using only pointing-device-specific event handlers (including gesture) for a function\n\nDescription:\nWhen pointing device-specific event handlers are the only mechanism available\nto invoke a function of the content, users with no vision (who cannot use\ndevices such as mice that require eye-hand coordination) as well as users\nwho must use alternate keyboards or input devices that act as keyboard\nemulators will be unable to access the function of the content.\n\nFor Success Criterion 2.1.1 there is an exception for functions that require a path-dependant pointer movement.\n\nExamples:\n- **Example 1: An image that responds to a mouse click to go to another page**  This is a failure because the keyboard cannot be used to move to the next page.  ```html <p><img onmousedown=\"nextPage();\" src=\"nextarrow.gif\" alt=\"Go to next page\"></p> ```    ---",
    "referenced_by": [
      "2.1.1"
    ]
  },
  {
    "id": "F55",
    "type": "technique",
    "code": "F55",
    "text": "[F55] Failure of Success Criteria 2.1.1, 2.4.7, and 3.2.1 due to using script to remove focus when focus is received\n\nDescription:\nContent that normally receives focus when the content is accessed by keyboard may have this focus removed by\nscripting. This is sometimes done when designer considers the system focus indicator to be unsightly. However,\nthe system focus indicator is an important part of accessibility for keyboard users. In addition, this practice\nremoves focus from the content entirely, which means that the content can only be operated by a pointing device\nsuch as a mouse.\n\nExamples:\n- **Example 3**  ```html <a href=\"link.html\" onfocus=\"if(this.blur)this.blur();\">Link Phrase</a> ```    ---\n- **Example 1**  ```html <input type=\"submit\" onFocus=\"this.blur();\"> ```\n- **Example 2**  ```html <a onFocus=\"this.blur()\" href=\"Page.html\"><img src=\"myImage.gif\"></a> ```",
    "referenced_by": [
      "2.1.1",
      "2.4.7",
      "3.2.1"
    ]
  },
  {
    "id": "G21",
    "type": "technique",
    "code": "G21",
    "text": "[G21] Ensuring that users are not trapped in content\n\nDescription:\nThe objective of this technique is to ensure that keyboard users do not become trapped in a subset of the content that can only be exited using a mouse or pointing device. A common example is content rendered by plug-ins. Plug-ins are user agents that render content inside the user agent host window and respond to all user actions that takes place while the plug-in has the focus. If the plug-in does not provide a keyboard mechanism to return focus to the parent window, users who must use the keyboard may become trapped in the plug-in content.\n\nThis problem can be avoided by using one of the following mechanisms to provide a way for users to escape the subset of the content:\n\n- Ensuring that the keyboard function for advancing focus within content (commonly the tab key) exits the subset of the content after it reaches the final navigation location.\n- Providing a keyboard function to move the focus out of the subset of the content. Be sure to document the feature in an accessible manner within the subset.\n- If the technology used in the subset of the content natively provides a \"move to parent\" keyboard command, documenting that command before the user enters the plug-in so they know how to get out again.\n\nIf the author uses a technology that allows users to enter the sub-content with keyboard and does not allow users to exit the sub-content with keyboard by default (i.e., it is not a feature of the Web content technology or its user agents) then, in order to implement this technique the author would either build such a capability into their content or not use the technology.\n\nExamples:\n- **Example 1:** Once a user tabs into an applet, further tabs are handled by the applet preventing the person from tabbing out. However, the applet is designed so that it returns keyboard focus back to the parent window when the person finishes tabbing through the tab sequence in the applet.\n- **Example 2:** A page that includes content that is not accessibility-supported contains instructions about how to move focus back to the accessibility-supported content via the keyboard. The instructions precede the non accessibility-supported content.\n- **Example 3:** The help information available from the content that is not accessibility supported documents how to move focus back to the accessibility-supported content via the keyboard, and the help information can be accessed via the keyboard.\n- **Example 4:** The help information available for the web page documents how to move focus from the content that is not accessibility supported to the accessibility-supported content via the keyboard, and the help information can be accessed via the keyboard.  ---",
    "referenced_by": [
      "2.1.2"
    ]
  },
  {
    "id": "F10",
    "type": "technique",
    "code": "F10",
    "text": "[F10] Failure of Success Criterion 2.1.2 and Conformance Requirement 5 due to combining multiple content formats in a way that traps users inside one format type\n\nDescription:\nWhen content includes multiple formats, one or more user agents or plug-ins\nare often needed in order to successfully present the content to users. For\nexample, a page that includes HTML, SVG, SMIL and XForms may require a\nbrowser to load as many as three different plug-ins in order for a user to\nsuccessfully interact with the content. Some plug-ins create a common\nsituation in which the keyboard focus can become \"stuck\" in a\nplug-in, leaving a keyboard-only user with no way to return to the\nother content.\n\nExamples:\n- **Example 1:** A plug-in traps the user:A user tabs into a plug-in and is unable to return to content outside the plug-in content with the keyboard. The user has to restart their browser in order to regain control and navigate to a new page and is unable to access any content that appears beyond the plug-in content.  ---",
    "referenced_by": [
      "2.1.2"
    ]
  },
  {
    "id": "G217",
    "type": "technique",
    "code": "G217",
    "text": "[G217] Providing a mechanism to allow users to remap or turn off character key shortcuts\n\nDescription:\nSome authors provide shortcuts in their applications to allow for faster user interaction. However, where such shortcuts involve only character keys (letters, numbers, punctuation or symbol characters) without modifiers, they create challenges for speech input users as well as some keyboard users who lack the ability to type accurately.\n\nTo prevent accidental activation, authors must allow users to turn off or reconfigure shortcuts that are made up of only character keys. Reconfiguring the shortcut may involve the ability to add a modifier key such as Ctrl, or authors may elect to allow users to alter the character keys assigned in addition to adding a modifer. Providing a mechanism to turn off or reassign the shortcut ensures more users can successfully interact with the application.\n\nAn initial challenge for testers is identifying if author-created shortcuts exist, and then determining if existing shortcuts are triggered by character keys without modifiers. Where testers have access to the develop team, the existence and nature of shortcut keys can often be determined simply by asking involved designers and developers. Where reliable information from the authors is not available, the presence of shortcuts can possibly be identified by checking code (for example, in javascript, the presence of **keydown**, **keyup** and **keypress** listeners). Another means of identifying shortcuts is to review documentation. Where none of these strategies provide information on the presence of keyboard shortcuts, manual tests will need to be completed to search for the existence of character key shortcuts. Review the test procedure in [failure technique F99](../failures/F99) for guidance.\n\nExamples:\n- **Example 1: Author provides a simple mechanism to disable shortcuts in a web-based email client**  An email client contains single-character shortcuts so that keyboard users can more rapidly interact with the application (e.g., the R key replies to the current item in the inbox, the D key deletes it, the S key stars it). These keys do not apply while users are composing emails; however, users may become confused about whether the keyboard focus is in a compose pane or the inbox and, while in the inbox, inadvertently delete a message by trying to compose a word containing the letter D. To overcome this problem, the author provides a toggle button for the shortcuts, allowing users to easily turn them off or on.\n- **Example 2: Author provides a menu option where users can remap shortcuts**  A web-based application has single-character shortcuts for functions which are different than those a user regularly uses with a software application installed locally. Since the author has provided a menu where the user can reassign both the shortcut keys and the modifiers, the user is able to reassign the shortcut to a familiar combination.    ---",
    "referenced_by": [
      "2.1.4"
    ]
  },
  {
    "id": "F99",
    "type": "technique",
    "code": "F99",
    "text": "[F99] Failure of Success Criterion 2.1.4 due to implementing character key shortcuts that cannot be turned off or remapped\n\nDescription:\nWhen keyboard shortcuts using only character keys are implemented, voice commands can inadvertently trigger functionality. Character key shortcuts use a single key such as a letter key (including upper- and lower-case letters),\npunctuation, number, or symbol characters.\n\nContent must either not implement single character key shortcuts, or offer settings to either turn off these\nshortcuts or to map them to keyboard shortcuts that employ an additional modifier key, such Alt or\nCtrl.\n\nThe test procedure suggests asking the author (often the developer of the site) whether keyboard shortcuts are used. If that information is trusted then the procedure can be simpler than pressing all the keys.\n\nThe success criterion does not apply when single key shortcuts are only active when interface elements have the focus, for example, a **select** element. Here, pressing a letter key is used for fast navigation within the select options.\n\nViewing page scripts and searching for typical keyboard event handlers like **document.addEventListener('keydown' ...)** or the presence of the **.keycode** attribute\nmay establish the presence of scripts that intercept keyboard shortcuts without modification keys like ALT or Ctrl being held down at the same time. As there are several ways of implementing character key events, this method is not considered reliable.\n\nSome browsers employ single key shortcuts with Shift. For example, Firefox opens a page search when pressing Shift + / and a search in page links when pressing Shift+'. In these cases, it will be necessary to press Esc or click an empty part of the page to remove the focus from the browser input.",
    "referenced_by": [
      "2.1.4"
    ]
  },
  {
    "id": "G133",
    "type": "technique",
    "code": "G133",
    "text": "[G133] Providing a checkbox on the first page of a multipart form that allows users to ask for longer session time limit or no session time limit\n\nDescription:\nThe objective of this technique is to minimize the risk that users with disabilities will lose their work by providing a checkbox to request additional time to complete multipart forms. The checkbox can allow the user to request a specific amount of additional time (for example 15 minutes) or an indefinite extension. (Note that allowing an indefinite extension would be inappropriate if it jeopardized user privacy or network security.)\n\nExamples:\n- **Example 1: A checkbox for requesting a specific extension**  A web page contains the first part of a five-part form. Immediately following the general instructions for completing the form is a checkbox with the label, “Allow an additional 15 minutes to complete each part of this form.\"\n- **Example 2: Requesting an indefinite extension**  A web page contains the first part of a three-part form. Each part of the form includes more than 10 items. Some items require users to follow links for additional information. Immediately following the general instructions for completing the form is a checkbox with the label, “Allow as much time as I need to complete this form. I understand that I must close (quit) the Web browser if I choose to stop before completing the last part of the form.\"    ---",
    "referenced_by": [
      "2.2.1"
    ]
  },
  {
    "id": "G198",
    "type": "technique",
    "code": "G198",
    "text": "[G198] Providing a way for the user to turn the time limit off\n\nDescription:\nThe objective of this technique is to provide a mechanism for people who cannot complete tasks within a specified time limit to turn off the time limit.\n\nIt is essential that the mechanism for turning off the time limit can be completed without a time limit itself and before the time limit for the page expires. To do this - the mechanism should be available at or near the top of the page so that it can be found and activated quickly by people with a wide range of disabilities.\n\nExamples:\n- **Example 1:** A page has a listing of news headlines that automatically update every minute. At the top of the page is a link that turns off the updating.  ---",
    "referenced_by": [
      "2.2.1"
    ]
  },
  {
    "id": "G180",
    "type": "technique",
    "code": "G180",
    "text": "[G180] Providing the user with a means to set the time limit to 10 times the default time limit\n\nDescription:\nThe objective of this technique is to give people with disabilities enough time to complete tasks which may take them longer than someone without those challenges. Some mechanism such as a preference setting or a control on the page lets the user change the time limits to at least 10 times the default time limit. Preferably, the mechanism would have a variable adjustment that lets the user change the time limit to any value in its range, but could also provide ways to change the time limit by discrete increments. The user changes the time limit at the beginning of their session, before any activity that has a time limit.\n\nExamples:\n- **Example 1:** An airline has an online ticket purchasing application. By default, the application has a 1 minute time limit for each step of the purchase process. At the beginning of the session, a web page includes information that says, \"We expect that each step in the purchasing process will take users one minute to complete. Would you like to adjust the time limit?\" followed by several radio buttons \"1 minute, 2 minutes, 5 minutes, 10 minutes.\"\n- **Example 2:** A Web based email application automatically logs users out when there has been no activity for 30 minutes. The application includes a preference that allows users to adjust the amount of time to any value.  ---",
    "referenced_by": [
      "2.2.1"
    ]
  },
  {
    "id": "SCR16",
    "type": "technique",
    "code": "SCR16",
    "text": "[SCR16] Providing a script that warns the user a time limit is about to expire\n\nDescription:\nThe objective of this technique is to notify users that they are almost out of time to complete an interaction. When scripts provide functionality that has time limits, the script can include functionality to warn the user of imminent time limits and provide a mechanism to request more time. 20 seconds or more before the time limit occurs, the script provides a confirm dialog that states that a time limit is imminent and asks if the user needs more time. If the user answers \"yes\" then the time limit is reset. If the user answers \"no\" or does not respond, the time limit is allowed to expire.\n\nThis technique involves time limits set with the **window.setTimeout()** method. If, for example, the time limit is set to expire in 60 seconds, you can set the time limit for 40 seconds and provide the confirm dialog. When the confirm dialog appears, a new time limit is set for the remaining 20 seconds. Upon expiry of the \"grace period time limit\" the action that would have been taken at the expiry of the 60 second time limit in the original design is taken.\n\nExamples:\n- **Example 1**  A page of stock market quotes uses script to refresh the page every five minutes in order to ensure the latest statistics remain available. 20 seconds before the five minute period expires, a confirm dialog appears asking if the user needs more time before the page refreshes. This allows the user to be aware of the impending refresh and to avoid it if desired.  ```html <!doctype html> <html lang=\"en\"> <head> <meta charset=\"utf-8\"> <title>Stock Market Quotes</title> <script> function timeControl() { // set timer for 4 min 40 sec, then ask user to confirm. setTimeout('userCheck()', 280000); }  function userCheck() { // set page refresh for 20 sec var id=setTimeout('pageReload()', 20000); // If user selects \"OK\" the timer is reset // else the page will refresh from the server. if (confirm(\"This page is set to refresh in 20 seconds. Would you like more time?\")) { clearTimeout(id); timeControl(); } }  function pageReload() { window.location.reload(true); }  timeControl(); </script> </head> <body> <h1>Stock Market Quotes</h1> ... </body> </html> ```    ---",
    "referenced_by": [
      "2.2.1"
    ]
  },
  {
    "id": "SCR1",
    "type": "technique",
    "code": "SCR1",
    "text": "[SCR1] Allowing the user to extend the default time limit\n\nDescription:\nThe objective of this technique is to allow user to extend the default time limit by providing a mechanism to extend the time when scripts provide functionality that has default time limits. In order to allow the user to request a longer time limit, the script can provide a form allowing the user to enter a larger time limit or indicating that more time is needed. If the user is being warned that a time limit is about to expire (see [providing a script that warns the user a time limit is about to expire](SCR16)), this form can be made available from the warning dialog. The user can extend the time limit to at least 10 times the default time limit, either by allowing the user to indicate how much additional time is needed or by repeatedly allowing the user to extend the time limit.\n\nExamples:\n- **Example 1:** A web page contains current stock market statistics and is set to refresh periodically. When the user is warned prior to refreshing the first time, the user is provided with an option to extend the time period between refreshes.\n- **Example 2:** In an online chess game, each player is given a time limit for completing each move. When the player is warned that time is almost up for this move, the user is provided with an option to increase the time.  ---",
    "referenced_by": []
  },
  {
    "id": "G4",
    "type": "technique",
    "code": "G4",
    "text": "[G4] Allowing the content to be paused and restarted from where it was paused\n\nDescription:\nThe objective of this technique is to provide a way to pause movement or scrolling of content. If the user needs to pause the movement, to reduce distraction or to have time to read it, they can do so, and then restart it as needed. This mechanism can be provided either through interactive controls that conform to WCAG or through keyboard shortcuts. If keyboard shortcuts are used, they are documented.\n\nExamples:\n- **Example 2:** A web page contains a link labeled \"How to tie a shoe\" which links to an animation. Text  immediately preceding the link informs the user that pressing the spacebar will pause the animation and restart it again.  ---\n- **Example 1:** A site contains a scrolling news banner at the top of the page. Users who need more time to read it can press the Escape key to pause the scrolling. Pressing Escape again restarts it.",
    "referenced_by": [
      "2.2.1",
      "2.2.2"
    ]
  },
  {
    "id": "SCR33",
    "type": "technique",
    "code": "SCR33",
    "text": "[SCR33] Using script to scroll content, and providing a mechanism to pause it\n\nDescription:\nThe objective of this technique is to provide a way for users to stop scrolling content when the scrolling is created by a script. Scrolling content can be difficult or impossible to read by users with low vision or with cognitive disabilities. The movement can also be distracting for some people making it difficult for them to concentrate on other parts of the web page.\n\nExamples:\n- **Example 1**  In this exampleCSSand JavaScript are used to visually present some text in a scrolling format. A link is included to pause the scrolling movement.  This implementation will display the full text and omit the link when JavaScript or CSS are unsupported or inactive.  A working example of this code,Example of using script to scroll content and providing a mechanism to pause it, is available.  ```html ... <div id=\"scroller\"> <p id=\"tag\">This text will scroll and a Pause/Scroll link will be present when JavaScript and CSS are supported and active.</p> </div> ... ```  ```html ... body { font:1em verdana,sans-serif; color:#000; margin:0 }  #scroller { position:relative; overflow:hidden; width:15em; border:1px solid #008080; }  #tag { margin:2px 0; }  #testP { visibility:hidden; position:absolute; white-space:nowrap; }  #top { width:350px; margin:auto; } ... ```  ```html var speed=50        // speed of scroller var step=3          // smoothness of movement var StartActionText= \"Scroll\"  // Text for start link var StopActionText = \"Pause\"   // Text for stop link  var x, scroll, divW, sText=\"\"  function onclickIE(idAttr,handler,call){ if ((document.all)&&(document.getElementById)){idAttr[handler]=\"Javascript:\"+call} }  function addLink(id,call,txt){ var e=document.createElement('a'); e.setAttribute('href',call); var linktext=document.createTextNode(txt); e.appendChild(linktext); document.getElementById(id).appendChild(e); }  function getElementStyle() { var elem = document.getElementById('scroller'); if (elem.currentStyle) { return elem.currentStyle.overflow; } else if (window.getComputedStyle) { var compStyle = window.getComputedStyle(elem, ''); return compStyle.getPropertyValue(\"overflow\"); } return \"\"; }  function addControls(){  // test for CSS support first // test for the overlow property value set in style element or external file if (getElementStyle()==\"hidden\") { var f=document.createElement('div'); f.setAttribute('id','controls'); document.getElementById('scroller').parentNode.appendChild(f); addLink('controls','Javascript:clickAction(0)',StopActionText); onclickIE(document.getElementById('controls').childNodes[0],\"href\",'clickAction(0)'); document.getElementById('controls').style.display='block'; } }  function stopScroller(){clearTimeout(scroll)}  function setAction(callvalue,txt){ var c=document.getElementById('controls') c.childNodes[0].setAttribute('href','Javascript:clickAction('+callvalue+')') onclickIE(document.getElementById('controls').childNodes[0],\"href\",'clickAction  ('+callvalue+')') c.childNodes[0].firstChild.nodeValue=txt }  function clickAction(no){ switch(no) { case 0: stopScroller(); setAction(1,StartActionText); break; case 1: startScroller(); setAction(0,StopActionText); } }  function startScroller(){ document.getElementById('tag').style.whiteSpace='nowrap' var p=document.createElement('p') p.id='testP' p.style.fontSize='25%' //fix for mozilla. multiply by 4 before using x-=step if (document.getElementById('tag').className) p.className=document.getElementById  ('tag').className p.appendChild(document.createTextNode(sText)) document.body.appendChild(p) pw=p.offsetWidth document.body.removeChild(p) if (x<(pw*4)*-1){x=divW} document.getElementById('tag').style.left=x+'px' scroll=setTimeout('startScroller()',speed) }  function initScroller(){ if (document.getElementById && document.createElement && document.body.appendChild) { addControls(); divW=document.getElementById('scroller').offsetWidth; x=divW; document.getElementById('tag').style.position='relative'; document.getElementById('tag').style.left=divW+'px'; var ss=document.getElementById('tag').childNodes; for (i=0;i<ss.length;i++) {sText+=ss[i].nodeValue+\" \"}; scroll=setTimeout('startScroller()',speed); } }  function addLoadEvent(func) { if (!document.getElementById | !document.getElementsByTagName) return var oldonload = window.onload if (typeof window.onload != 'function') { window.onload = func; } else { window.onload = function() { oldonload() func() } } }  addLoadEvent(initScroller) ```    ---",
    "referenced_by": [
      "2.2.1",
      "2.2.2"
    ]
  },
  {
    "id": "SCR36",
    "type": "technique",
    "code": "SCR36",
    "text": "[SCR36] Providing a mechanism to allow users to display moving, scrolling, or auto-updating text in a static window or area\n\nDescription:\nSome web pages display scrolling text because there is limited space available. Scrolling the text in a small text window makes the content available for users who can read quickly enough, but causes problems for users who read more slowly or use assistive technology. This technique provides a mechanism to stop the movement and make the entire block of text available statically. The text may be made available in a separate window or in a (larger) section of the page. Users can then read the text at their own speed.\n\nThis technique does not apply when the text that is moving can not be displayed all at once on the screen (e.g., a long chat conversation).\n\nExamples:\n- **Example 1: Expanding Scrolling Text in Place**  A large block of text is scrolled through a small marquee area of the page. A button lets the user stop the scrolling and display the entire block of text.  Working example of this code:Expanding Scrolling Text in Place.  ```html #scrollContainer { background-color: darkblue; left: 10px; overflow: hidden; top: 50px; visibility: visible; }  .scrolling { height: 50px; position: absolute; width: 200px; }  .notscrolling { margin:10px; width: 500px; }  #scrollingText { color: white; top: 0px; }  .scrolling #scrollingText { position: absolute; } ```  ```html <script> var tid; function init() { var st = document.getElementById('scrollingText'); st.style.top = '0px'; initScrolling(); }  function initScrolling () { tid = setInterval('scrollText()', 300); }  function scrollText () { var st = document.getElementById('scrollingText'); if (parseInt(st.style.top) > (st.offsetHeight*(-1) + 8)) { st.style.top = (parseInt(st.style.top) - 5) + 'px'; } else { var sc = document.getElementById('scrollContainer'); st.style.top = parseInt(sc.offsetHeight) + 8 + 'px'; } }  function toggle() { var scr = document.getElementById('scrollContainer'); if (scr.className == 'scrolling') { scr.className = 'notscrolling'; clearInterval(tid); document.getElementById('scrollButton').value=\"Shrink\"; } else { scr.className = 'scrolling'; initScrolling(); document.getElementById('scrollButton').value=\"Expand\"; } }  <input type=\"button\" id=\"scrollButton\" value=\"Expand\" onclick=\"toggle()\"> <div id=\"scrollContainer\" class=\"scrolling\"> <div id=\"scrollingText\" class=\"on\"> ... Text to be scrolled ... </div> </div> ... ```    ---",
    "referenced_by": [
      "2.2.1"
    ]
  },
  {
    "id": "F40",
    "type": "technique",
    "code": "F40",
    "text": "[F40] Failure due to using meta redirect with a time limit\n\nDescription:\n**meta http-equiv content=\"{time} url=...\"** is often used to\nautomatically redirect users. When this occurs after a time delay, it is an\nunexpected change of context that may interrupt the user.\n\nIt is acceptable to use the meta element to create a redirect\nwhen the time-out is set to zero, since the redirect is instant and will not\nbe perceived as a change of context. However, it is preferable to use\nserver-side methods to accomplish this. See [Implementing automatic redirects on the server side\ninstead of on the client side](../server-side-script/SVR1).\n\nExamples:\n- **Example 1**  The page below is a failure because it will redirect to theURIhttps://www.example.com/newpage after a time limit of 5 seconds.  ```html <!doctype> <html lang=\"en\"> <head> <title>Do not use this!</title> <meta http-equiv=\"refresh\" content=\"5; url=https://www.example.com/newpage\"> </head> <body> <p> If your browser supports Refresh, you'll be transported to our <a href=\"https://www.example.com/newpage\">new site</a> in 5 seconds, otherwise select the link manually. </p> </body> </html> ```    ---",
    "referenced_by": [
      "2.2.1",
      "2.2.4",
      "3.2.5"
    ]
  },
  {
    "id": "F41",
    "type": "technique",
    "code": "F41",
    "text": "[F41] Failure of Success Criterion 2.2.1, 2.2.4, and 3.2.5 due to using meta refresh to reload the page\n\nDescription:\n**meta http-equiv** of **refresh** is often used to periodically refresh pages or to redirect users to another page. If the time interval is too short, and there is no way to turn auto-refresh off, people who are blind will not have enough time to make their screen readers read the page before the page refreshes unexpectedly and causes the screen reader to begin reading at the top. Sighted users may also be disoriented by the unexpected refresh.\n\nExamples:\n- **Example 1**  This is a deprecated example that changes the user's page at regular intervals. Content developers should not use this technique to simulate \"push\" technology. Developers cannot predict how much time a user will require to read a page; premature refresh can disorient users. Content developers should avoid periodic refresh and allow users to choose when they want the latest information. (The number in the content attribute is the refresh interval in seconds.)  ```html <!doctype> <html lang=\"en\"> <head> <title>HTML Techniques for WCAG 2</title> <meta http-equiv=\"refresh\" content=\"60\" /> </head> <body> ... </body> </html> ```    ---",
    "referenced_by": [
      "2.2.1",
      "2.2.4",
      "3.2.5"
    ]
  },
  {
    "id": "F58",
    "type": "technique",
    "code": "F58",
    "text": "[F58] Failure of Success Criterion 2.2.1 due to using server-side techniques to automatically redirect pages after a time-out\n\nDescription:\nServer-side scripting languages allow developers to set the non-standard\nHTTP header \"Refresh\" with a time-out (in seconds) and a URI to which the\nbrowser is redirected after the specified time-out. If the time interval is\ntoo short, people who are blind will not have enough time to make their\nscreen readers read the page before the page refreshes unexpectedly and\ncauses the screen reader to begin reading at the top. Sighted users may also\nbe disoriented by the unexpected refresh.\n\nThe HTTP header that is set is Refresh: {time in seconds}; url={URI of\nnew location}. It is also possible to omit the URI and obtain a\nperiodically refreshing page, which causes the same problem. The HTTP header\nthat is set is Refresh: {time in seconds}.\n\nExamples:\n- **Example 1**  The following example is a failure because a timed server-side redirect is implemented in Java Servlets or JavaServer Pages (JSP).  ```html public void doGet (HttpServletRequest request, HttpServletResponse response) throws IOException, ServletException { response.setContentType(\"text/html\"); PrintWriter out = response.getWriter(); response.setHeader(\"Refresh\", \"10; URL=TargetPage.html\"); out.println(\"<!DOCTYPE html>\"); out.println(\"<html><head><title>Redirect</title></head><body>\"); out.println(\"<p>This page will redirect you in 10 seconds.</p>\"); out.println(\"</body></html>\"); } ```    ---",
    "referenced_by": [
      "2.2.1"
    ]
  },
  {
    "id": "G11",
    "type": "technique",
    "code": "G11",
    "text": "[G11] Creating content that blinks for less than 5 seconds\n\nDescription:\nThe objective of this technique is to minimize the distraction caused by blinking content and enable users to re-focus on the other content on the page.\n\nBlinking content can be created using a variety of technologies, many of which include options to loop blinking content continuously or to otherwise specify the amount of time the blinking content is displayed. Limiting the blinking of content to five seconds minimizes the distraction that blinking can cause. This will benefit people with certain types of learning disabilities and people with low vision.\n\nExamples:\n- **Example 1:** An animated image is used to highlight items on sale. Within a list of items for purchase, an image of a red tag followed by the phrase \"On sale\" is used to indicate items being offered at a reduced price. The image of the red tag blinks on loading of the page and stops within five seconds.  ---",
    "referenced_by": [
      "2.2.2"
    ]
  },
  {
    "id": "G152",
    "type": "technique",
    "code": "G152",
    "text": "[G152] Setting animated gif images to stop blinking after n cycles (within 5 seconds)\n\nDescription:\nThe objective of this technique is to ensure that animated gif images stop blinking within five seconds. There are three aspects of the design of animated gif images that work together to determine how long the image blinks (or otherwise animates):\n\n- the number offramesin the image, which are discrete images in the animation sequence;\n- theframe rate, which is how long each image is displayed;\n- the number ofrepetitions, which is how many times the entire animation is performed;\n\nAt its simplest, the duration of the animation is the number of frames times the frame rate times the number of repetitions. For example, a simple blinking image with 2 frames, a frame rate of .5 seconds, and 3 repetitions will have a duration of (2 * 0.5 * 3) seconds, or exactly 3 seconds.\n\nMany animated gif images have a constant frame rate, i.e., the amount of time each frame is displayed is the same. However, it is possible to set a different frame rate for each frame, to allow certain frames to be displayed longer than others. In this case, the duration of the animation is the sum of the frame rates times the number of repetitions. For example, a simple image with two frames, the first of which displays for .75 seconds and the second for .25 seconds, and three repetitions will have a duration of ((.75 + .25) * 3) seconds, also exactly 3 seconds.\n\nFor an image to stop blinking within 5 seconds, one of the three variables must be adjusted. Most commonly, set the number of repetitions to five seconds divided by the product of the number of frames times the frame rate (or by the sum of the frame rate). Truncate this number down to the nearest integer, do not round up to the next integer, to ensure that the image will stop within five seconds.\n\nIf even one repetition results in more than five seconds of animation, one of the other factors must be adjusted. Reduce the number of frames in the image, or increase the frame rate. Be careful when increasing the frame rate that the resulting image does not fail the requirement not to exceed the general flash or red flash thresholds; attention to this is especially important for large images.\n\nExamples:\n- **Example 1:** A simple blinking image.An image has 2 frames, a frame rate of .5 seconds, and 3 repetitions. The animation has a duration of (2 * 0.5 * 3) seconds, or exactly 3 seconds, and therefore meets the requirements of the success criterion.  ---",
    "referenced_by": [
      "2.2.2"
    ]
  },
  {
    "id": "SCR22",
    "type": "technique",
    "code": "SCR22",
    "text": "[SCR22] Using scripts to control blinking and stop it in five seconds or less\n\nDescription:\nThe objective of this technique is to control blinking with script so it can be set to stop in less than five seconds by the script. Script is used to start the blinking effect of content, control the toggle between visible and hidden states, and also stop the effect at five seconds or less. The setTimeout() function can be used to toggle blinking content between visible and hidden states, and stop when the number of iterations by the time between them adds up to nearly five seconds.\n\nExamples:\n- **Example 1**  This example uses JavaScript to control blinking of some HTML and XHTML content. JavaScript creates the blinking effect by changing the visibility status of the content. It controls the start of the effect and stops it within five seconds.  Working example of this code:Using script to control blinking.  ```html ... <div id=\"blink1\" class=\"highlight\">New item!</div> <script> // blink \"on\" state function show() { if (document.getElementById){ document.getElementById(\"blink1\").style.visibility = \"visible\"; } }  // blink \"off\" state function hide() { if (document.getElementById){ document.getElementById(\"blink1\").style.visibility = \"hidden\"; } }  // toggle \"on\" and \"off\" states every 450 ms to achieve a blink effect // end after 4500 ms (less than five seconds) for(let i=900; i < 4500; i=i+900) { setTimeout(\"hide()\",i); setTimeout(\"show()\",i+450); } </script> ... ```    ---",
    "referenced_by": [
      "2.2.2"
    ]
  },
  {
    "id": "G186",
    "type": "technique",
    "code": "G186",
    "text": "[G186] Using a control in the Web page that stops moving, blinking, or auto-updating content\n\nDescription:\nThe objective of this technique is to provide the user a control that allows him to stop moving or blinking content. Since the control is in the web page, the control itself meets the appropriate level of WCAG conformance e.g., it has appropriate contrast, it has a name that identifies it, it is keyboard accessible. The control is either at the top of the page or adjacent to the moving content. A single control may stop all moving or blinking content on the page, or there may be separate controls for separate parts of the content.\n\nExamples:\n- **Example 1: Stock Market Ticker Tape**  A web page displays the latest stock market results in a \"ticker tape\" that automatically scrolls across the bottom of the screen. A \"Pause\" button lets the user stop the ticker tape. When the ticker tape is unpaused, it resumes displaying the current stock market information.\n- **Example 2: Teleconferencing Tool**  A teleconferencing web page displays a speaker queue of people who wish to speak. A checkbox on the page lets the user choose whether the display of the queue should be updated automatically when a new person is added or removed, or whether it should only be updated when the user presses the \"Refresh\" button. When the queue is being updated automatically, the Refresh button is deactivated.    ---",
    "referenced_by": [
      "2.2.2"
    ]
  },
  {
    "id": "G191",
    "type": "technique",
    "code": "G191",
    "text": "[G191] Providing a link, button, or other mechanism that reloads the page without any blinking content\n\nDescription:\nThis is a general technique for allowing people who cannot use a page with blinking content to turn the blinking content off.\n[Conformance Requirement 1](https://www.w3.org/WAI/WCAG22/Understanding/conformance#conf-req1)\nallows for conforming alternate pages to be used to meet conformance. This technique is an example of that approach applied to success criteria 2.2.2.\n\nIt is important that the page without blinking content contain all of the information that was on the page with blinking content.\n\nExamples:\n- **Example 1:** A page has blinking text at the top warning users that they should not submit the page without first registering. A link at the very top of the page reloads the page with the blinking text replaced with text that is styled to be highly visible but does not blink.  ---",
    "referenced_by": [
      "2.2.2"
    ]
  },
  {
    "id": "F16",
    "type": "technique",
    "code": "F16",
    "text": "[F16] Failure of Success Criterion 2.2.2 due to including scrolling content where movement is not essential to the activity without also including a mechanism to pause and restart the content\n\nDescription:\nIn this failure technique, there is moving or scrolling content that cannot\nbe paused and resumed by users. In this case, some users with low vision or\ncognitive disabilities will not be able to perceive the content.\n\nExamples:\n- **Example 1:** A page has a scrolling news ticker without a mechanism to pause it. Some users are unable to read the scrolling content.  ---",
    "referenced_by": [
      "2.2.2"
    ]
  },
  {
    "id": "F47",
    "type": "technique",
    "code": "F47",
    "text": "[F47] Failure of Success Criterion 2.2.2 due to using the blink element\n\nDescription:\nThe blink element, while not part of the official HTML specification, is supported by many user agents. It causes any text inside the element to blink at a predetermined rate. This cannot be interrupted by the user, nor can it be disabled as a preference. The blinking continues as long as the page is displayed. Therefore, content that uses blink fails the success criterion because blinking can continue for more than three seconds.\n\nExamples:\n- **Example 1**  A product list page uses the blink element to draw attention to sale prices. This fails the success criterion because users cannot control the blink.  ```html <p>My Great Product <blink>Sale! $44,995!</blink></p> ```    ---",
    "referenced_by": []
  },
  {
    "id": "F4",
    "type": "technique",
    "code": "F4",
    "text": "[F4] Failure of Success Criterion 2.2.2 due to using text-decoration:blink without a mechanism to stop it in less than five seconds\n\nDescription:\nCSS defines the blink value for the text-decoration property. When used, it causes any text in elements with this property to blink at a predetermined rate. This cannot be interrupted by the user, nor can it be disabled as a user agent preference. The blinking continues as long as the page is displayed. Therefore, content that uses text-decoration:blink fails the success criterion because blinking can continue for more than five seconds.\n\nExamples:\n- **Example 1**  A product list page uses the text-decoration:blink style on an element to draw attention to sale prices. This fails the success criterion because users cannot control the blink.  ```html <p>My Great Product <span style=\"text-decoration:blink\">Sale! $44,995!</span></p> ```    ---",
    "referenced_by": []
  },
  {
    "id": "F50",
    "type": "technique",
    "code": "F50",
    "text": "[F50] Failure of Success Criterion 2.2.2 due to a script that causes a blink effect without a mechanism to stop the blinking at 5 seconds or less\n\nDescription:\nScripts can be used to blink content by toggling the content's visibility on and off at regular intervals. It is a failure for the script not to include a mechanism to stop the blinking at 5 seconds or earlier. See [Using scripts to control blinking and stop it in five seconds or less](../client-side-script/SCR22) for information about how to modify the technique to stop the blinking.\n\nExamples:\n- **Example 1**  The following example uses script to blink content, but the blink continues indefinitely rather than stopping after five seconds.  ```html <script> // blink \"on\" state function show(){ document.getElementById(\"blink1\").style.visibility = \"visible\"; window.setTimeout(hide, 450); }  // blink \"off\" state function hide(){ document.getElementById(\"blink1\").style.visibility = \"hidden\"; window.setTimeout(show, 450); }  // kick it off show(); </script> ... <span id=\"blink1\">This content will blink</span> ```    ---",
    "referenced_by": [
      "2.2.2"
    ]
  },
  {
    "id": "F7",
    "type": "technique",
    "code": "F7",
    "text": "[F7] Failure of Success Criterion 2.2.2 due to an object or applet for more than five seconds\n\nDescription:\nWhen content that is rendered by a plug-in or contained in an applet blinks,\nthere may be no way for the user agent to pause the blinking. If neither the\nplug-in, applet, nor the content itself provides a mechanism to pause the\ncontent, the user may not have sufficient time to read the content between\nblinks or it may be so distracting that the user will not be able to read\nother content on the page.\n\nExamples:\n- **Example 1:** An applet displays an advertisement on a news site. The applet blinks key words in the advertisement in order to call the user's attention to it. The blinking cannot be paused through any user agent settings and the applet does not provide a mechanism to stop it.  ---",
    "referenced_by": [
      "2.2.2"
    ]
  },
  {
    "id": "G5",
    "type": "technique",
    "code": "G5",
    "text": "[G5] Allowing users to complete an activity without any time limit\n\nDescription:\nThe objective of this technique is to provide users with all the time they need to complete an activity. This technique involves providing a specified activity which does not require timed interaction. Users are allowed as much time as they need to interact with the activity.\n\nExamples:\n- **Example 1:** An interactive exam for a course provides all questions on one web page. Users can take as much time as they need to complete it.\n- **Example 2:** In an interactive game, users can take as much time as they like on their turn instead of having to complete their move within a limited amount of time.\n- **Example 3:** In an online auction, each bidder can submit only one bid rather than submitting multiple competitive bids based on timing. The bidding is open for a full day, providing enough time for anyone to complete the simple bid form. Once bidding is closed, the best bid wins.  ---",
    "referenced_by": [
      "2.2.3"
    ]
  },
  {
    "id": "G75",
    "type": "technique",
    "code": "G75",
    "text": "[G75] Providing a mechanism to postpone any updating of content\n\nDescription:\nThe objective of this technique is to ensure that users can postpone automatic updates of content, or other non-emergency interruptions. This can be accomplished either through a preference or by alerting users of an imminent update and allowing them to suppress it. If a preference is provided, automatic content update can be disabled by default and users can specify the frequency of automatic content updates if they choose to enable the setting.\n\nExamples:\n- **Example 1:** A web page provides stock quotes and automatically updates from time to time. The page provides a short form with a field \"Refresh data frequency (minutes):\" so users can adjust the frequency of the updating.  ---",
    "referenced_by": [
      "2.2.4"
    ]
  },
  {
    "id": "G76",
    "type": "technique",
    "code": "G76",
    "text": "[G76] Providing a mechanism to request an update of the content instead of updating automatically\n\nDescription:\nThe objective of this technique is to let the user control if and when\ncontent is updated, in order to avoid confusion or disorientation caused by\nautomatic refreshes that cause a change of context. Users of screen readers\nmay find automatic updates confusing because it is not always clear what is\nhappening. When a page is refreshed, the screen reader's “virtual cursor\",\nwhich marks the user's current location on the page, is moved to the top of\nthe page. People who use screen magnification software and people with\nreading disabilities may also be disoriented when pages are refreshed\nautomatically.\n\nSome content is frequently updated with new data or information. Some\ndevelopers force automatic updates by inserting code in the content that\ncauses the content to request a new copy of itself from the server. These\nupdates and the frequency of these updates are not always under the user's\ncontrol. Instead of triggering updates automatically, authors can provide a\nmechanism that allows the user to request an update of the content as\nneeded.\n\nExamples:\n- **Example 1: Providing a button to update content**  InHTML, a developer can provide a button or link that allows the user to update the content. For example, on a page with news items.  ```html <button type=\"button\">Update this page</button> ```    ---",
    "referenced_by": [
      "2.2.4",
      "3.2.5"
    ]
  },
  {
    "id": "SCR14",
    "type": "technique",
    "code": "SCR14",
    "text": "[SCR14] Using scripts to make nonessential alerts optional\n\nDescription:\nThe objective of this technique is to toggle announcements to screen readers of changes in a stock-price alert component. By default, when the stock price changes, the change is announced by screen readers. This could be annoying to some users, so there are buttons to allow users to toggle the announcements on or off.\n\nThis technique uses the **aria-live** property to turn the stock component into a live region and the **aria-atomic** property to tell screen readers to announce all of the component's content rather than just what was updated when the stock is updated. For the sake of this demo, the stock updates every 10 seconds. If announcements are turned on, the **aria-live** property is set to **assertive**; if announcements are turned off, the **aria-live** property is set to **off**. The two buttons used to control the announcements use the **aria-pressed** property, updated to either **true** or **false**, to inform screen reader users which button is pressed and therefore whether their screen reader will announce the stock updates or not. In a real-life situation, an author should consider setting a cookie (or equivalent) to store the user's preference so that it's set over multiple visits to the page.\n\nExamples:\n- **Example 1: Updating screen reader settings for stock price update alerts**  The script below will update a stock value in an aria-live component every 10 seconds. If the user presses the \"Turn Announcements Off\" button, their screen reader will stop making announcements when the stock value changes; if they press the \"Turn Announcements On\" button, the announcements will start again.  Working example of this code:Demonstration of toggling ARIA alerts.  ```html <script> document.addEventListener(\"DOMContentLoaded\", function (e) { const stockBox = document.querySelector(\"#stock-box\"); const stockMovement = document.querySelector(\"#stock-movement\"); const onBtn = document.querySelector(\"#live-on\"); const offBtn = document.querySelector(\"#live-off\"); const stocks = new Array(\"stock went down\", \"stock stayed the same\", \"stock went up\"); let loopCount = 0;  onBtn.addEventListener(\"click\", modifyLive, false); offBtn.addEventListener(\"click\", modifyLive, false);  function modifyLive(e){ let elm = e.currentTarget; let liveState = elm.getAttribute(\"id\"); if (liveState === \"live-off\"){ stockBox.setAttribute(\"aria-live\", \"off\"); onBtn.setAttribute(\"aria-pressed\", \"false\"); offBtn.setAttribute(\"aria-pressed\", \"true\"); } else{ stockBox.setAttribute(\"aria-live\", \"assertive\"); onBtn.setAttribute(\"aria-pressed\", \"true\"); offBtn.setAttribute(\"aria-pressed\", \"false\"); } }  setInterval(() => { if(loopCount >2){ loopCount = 0; } stockMovement.innerHTML = stocks[loopCount]; loopCount++; }, 10000) }); </script> ```  ```html <body> <h1>Turbo Encabulator Stock Information</h1> <div id=\"stock-box\" aria-atomic=\"true\" aria-live=\"assertive\"> <span>Turbo Encabulator Stock Price: </span> <span id=\"stock-movement\">stock went up</span> </div> <p>Use the buttons to toggle screen reader announcements of stock changes:</p> <div> <button aria-pressed=\"true\" id=\"live-on\" type=\"button\"> Turn Announcements On</button> <button aria-pressed=\"false\" id=\"live-off\" type=\"button\"> Turn Announcements Off</button> </div> </body> ```    ---",
    "referenced_by": [
      "2.2.4",
      "4.1.3"
    ]
  },
  {
    "id": "G105",
    "type": "technique",
    "code": "G105",
    "text": "[G105] Saving data so that it can be used after a user re-authenticates\n\nDescription:\nWeb servers that require user authentication often terminate the session after a set period of time if there is no activity from the user. If the user is unable to input the data quickly enough and the session times out before they submit, the server will require re-authentication before proceeding. When this happens, the server stores the data in a temporary cache while the user logs in, and when the user has re-authenticated, the data is made available from the cache and the form is processed as if there had never been a session time-out. The server does not keep the cache indefinitely, merely long enough to ensure success after re-authentication in a single user session, such as one day.\n\nExamples:\n- **Example 1:** A user logs in to use a forum and replies to a post. The time taken to write the reply  is longer than the time allowed by the server for a session of inactivity. The user submits the reply and is informed of the time out and prompted to log in again to submit the response. The user's post reply is retained by the server and if the user log-in is successful the reply  is processed as normal. If the log-in cannot be successfully completed the reply is discarded.\n- **Example 2:** A user logs in to a secure area and fills out a form. The session times out for security reasons. The form data is retained by the server and the user is informed of the time  out and is prompted to log-in again. If the user logs in correctly, the form is presented to the user with all of the data previously entered and user can submit the form. If the log-in cannot be successfully completed the form data is discarded.  ---",
    "referenced_by": [
      "2.2.5"
    ]
  },
  {
    "id": "G181",
    "type": "technique",
    "code": "G181",
    "text": "[G181] Encoding user data as hidden or encrypted data in a re-authorization page\n\nDescription:\nWeb servers that require user authentication often terminate the session after a set period of time if there is no activity from the user. If the user is unable to input the data quickly enough and the session times out before they submit, the server will require re-authentication before proceeding. When this happens, the server passes (as hidden data) the information from the form into the page that is used for re-authentication. Then, when the user re-authenticates, the server can use the information passed on from the re-authentication page to submit the form directly or to present a page that includes the data that is to be submitted for review. In this technique, the server does not have to store any user-submitted data on server. This is an important technique for those cases where it is either illegal or a security risk for the server to store information temporarily. It also is useful in that it frees the server from having to maintain the stored information and reconnect it with the newly authenticated session.\n\nExamples:\n- **Example 1:** A user has logged in to use a wiki and begins editing a page. The time taken to complete the edits exceeds the time allowed by the server for session inactivity. When the user submits the edits, the user is notified that the session has timed out and is redirected to a login page. The script that handles the original form submission passes the edits as a variable to the login page and when the user successfully logs in, passes the users edits back to the script that handles form submissions and the edits are processed as though no session timeout had occurred.\n- **Example 2:** A user had logged in to a secure shopping site and fills out some of the information on an order form. For security reasons, the session times out after 30 minutes, but the user does not submit the form until 45 minutes after loading the page. The user is informed of the time out and is prompted to log-in again. If the user logs in correctly, the order form is presented to the user with all of the data previously entered and the user is able to review their submission and submit the form. If the log-in is not successfully completed, then the form data is discarded by the server.  ---",
    "referenced_by": [
      "2.2.5"
    ]
  },
  {
    "id": "F12",
    "type": "technique",
    "code": "F12",
    "text": "[F12] Failure of Success Criterion 2.2.5 due to having a session time limit without a mechanism re-authentication\n\nDescription:\nWeb servers that require user authentication usually have a session mechanism\nin which a session times out after a period of inactivity from the user.\nThis is sometimes done for security reasons, to protect users who are\nassumed to have left their computer exposed in a state where someone could\ndo something harmful to them such as transfer bank funds or make an\nunauthorized purchase. Users with disabilities may actually still be\nworking to complete the form as it may take them longer to complete\nthe form than would normally be expected. Upon re-authentication, if the\nstate of users' sessions are not restored, including all data that had\nbeen previously entered into the form, they will have to start over.\nAnd for these users, it is likely that the session will time out again\nbefore they can complete the form. This sets up a situation where a user who\nneeds more time to complete the form can never complete it.\n\nExamples:\n- **Example 1:** A user submits a form on an authenticated site after their login has expired. On submitting the form, they are prompted to log in again, and then taken to a general welcome page. The data is not processed and they must try again.\n- **Example 2:** A user submits a form on an authenticated site after their login has expired. On submitting the form, they are prompted to log in again, and then taken back to the page they were on just before the login, which in this case contains the form they attempted to submit. However, the form is not populated with the data they just entered, and they must re-enter it.  ---",
    "referenced_by": [
      "2.2.5"
    ]
  },
  {
    "id": "G19",
    "type": "technique",
    "code": "G19",
    "text": "[G19] Ensuring that no component of the content flashes more than three times in any 1-second period\n\nDescription:\nThe objective of this technique is to avoid flashing at rates that are known to cause seizures if the flashes are bright and large enough. Since some users may be using screen enlargers, this technique limits the flashing of any size content to no more than three flashes in any 1-second period.\n\nExamples of 3.5 flashes or seven transitions:\n\n- STARTING DARK-LIGHT-DARK-LIGHT-DARK-LIGHT-DARK-LIGHT  or\n- STARTING LIGHT-DARK-LIGHT-DARK-LIGHT-DARK-LIGHT-DARK.\n\nExamples:\n- **Example 1:** Content has lightning flashes.  Content is designed so that lightning only flashes two or three times without a pause in flashing.  ---",
    "referenced_by": [
      "2.3.1",
      "2.3.2"
    ]
  },
  {
    "id": "G176",
    "type": "technique",
    "code": "G176",
    "text": "[G176] Keeping the flashing area small enough\n\nDescription:\nThe purpose of this technique is to provide an easy way to pass the success criterion for things that flash, but are small.\n\nIf you have something that flashes\nmore\nthan 3 times in a one second period (so G19 can't be used), but the area that is flashing is less than 25% of 10 degrees of visual field (which represents the central area of vision in the eye), then it would automatically pass.\n\nThe 10 degree of visual field represents the central area of vision in the eye. This area is highly packed with visual sensors. Flashes in this area are transmitted to the visual cortex. For those with photosensitivity, this flashing of activity on the visual cortex can cause seizures. Flashing on other areas of the eye (which have far fewer sensors) has much less effect on the cortex. Hence, the focus on just the 10 degrees of central vision.\n\n- If the content is for general Web use, you can useFormula 1: Small Safe Area for Web Content.\n- If the content is for a known display (e.g., in a company foyer) thenFormula 2: Small Safe Area for Known Displaysshould be used.\n\nFormula 1: Small Safe Area for Web Content\n\nMost web authors do not know how to translate visual field to pixels, which is what they generally can deal with. This technique provides that translation.\n\nAt this point in time, the most prevalent display is 1024 x 768 and about 15-17 inches diagonally. When viewed at a typical viewing distance (22-26 inches) a 10 degree visual field will capture an area approximately 341 x 256 pixels. This is not circular, but neither is the central vision of most users, and the difference is so small (and at the edge of the central vision where sensors are fewer) that it is not important.\n\nSince the criterion is 25% of any 10 degree visual field,\nany single flashing event on a screen (there is no other flashing on screen) that is smaller than a contiguous area of 21,824 sq pixels (any shape), would pass the General and Red Flash Thresholds.\n\n1024 x 768 was chosen because it represents the most common screen size. It also works with higher resolution screens since the tighter pixel density would result in a smaller and safer image size.\n\nUsers with lower resolution displays or that enlarge or view their screens closely would have a higher risk depending on the viewing distance. To address the needs of this group,\n[G19](../general/G19)\nshould be used since it is independent of screen resolution or viewing distance.\n\nFormula 2: Small Safe Area for Known Displays\n\nTo calculate the\nsmall safe area\n(in pixels) on the screen when the screen size, resolution, and viewing distance is known, use the following procedure.\n\nExamples:\n- **Example 1:** An author creates an animation that will be displayed on a screen in the entrance lounge at a company. Using the size and resolution of the display and the closest distance that a person can stand when viewing the display, they calculate the size of 25% of the 10 degree of central vision in pixels (using the formula above). This would be thesmall safe area. They then are careful to never flash any area larger than thesmall safe area.  ---",
    "referenced_by": [
      "2.3.1"
    ]
  },
  {
    "id": "G15",
    "type": "technique",
    "code": "G15",
    "text": "[G15] Using a tool to ensure that content does not violate the general flash threshold or red flash threshold\n\nDescription:\nThe purpose of testing for violations of the general and red flash thresholds is to allow people who have photosensitive seizures to view websites without encountering material that is likely to cause a seizure. Warnings can be provided but people may miss them and children may not be able to read or understand them. With this technique all material is checked and if it violates flash or red flash thresholds it is either not put on the site or it is modified so that it does not violate the thresholds.\n\nExamples:\n- **Example 1:** An animation of a thunderstorm shows six flashes of lightning. The flashes are so fast and large that the general flash threshold is violated when tested with a flash analysis tool. The animation is modified to create a short pause after each pair of lightning flashes. After the changes are made, the animation does not violate the general flash threshold.  ---",
    "referenced_by": [
      "2.3.1"
    ]
  },
  {
    "id": "C39",
    "type": "technique",
    "code": "C39",
    "text": "[C39] Using the CSS reduce-motion query to prevent motion\n\nDescription:\nThe objective of this technique is to allow users to prevent animation from being displayed on web pages, via the use of the **prefers-reduced-motion** CSS Media Query.\n\nSome users experience distraction or nausea from animated content. For example, if scrolling a page causes elements to move (other than the essential movement associated with scrolling) it can trigger vestibular disorders. Enclosing the CSS that creates the animations in a media query allows people to prevent those symptoms.\n\nA typical example is 'parallax scrolling', where backgrounds move at different rates. The movement due to scrolling the page is essential (and under the users control), but additional movement triggered by the scrolling can also trigger vestibular symptoms.\n\nThe understanding document for [Motion Actuation](https://www.w3.org/WAI/WCAG22/Understanding/motion-actuation.html#resources) includes links for changing the reduce motion setting.\n\nExamples:\n- **Example 1: 'prefers-reduced-motion' CSS Media Query**  Users can indicate their motion preference for interfaces in their system and the 'prefers-reduced-motion' CSS Media Query will respect that choice. CSS can then be applied to disable that motion for users that request it.  Working example of 'prefers-reduced-motion' CSS Media Query  ```html @media (prefers-reduced-motion: reduce) { /* CSS to disable motion goes here */ } ```    ---",
    "referenced_by": [
      "2.3.3"
    ]
  },
  {
    "id": "H69",
    "type": "technique",
    "code": "H69",
    "text": "[H69] Providing heading elements at the beginning of each section of content\n\nDescription:\nThe objective of this technique is to use section headings to convey the structure of the content. Heading markup can be used:\n\n- to indicate start of main content;\n- to mark up section headings within the main content area;\n- to demarcate different navigational sections like top or main navigation, left or secondary navigation and footer navigation;\n- to mark up images of text that are used as headings;\n- to allow users the ability to navigate a page by sections or skip repeated blocks of information.\n\nHeadings are designed to convey logical hierarchy. Skipping levels in the sequence of headings may create the impression that the structure of the document has not been properly thought through or that specific headings have been chosen for their visual rendering rather than their meaning. Authors are encouraged to nest headings hierarchically. When headings are nested hierarchically, the most important information is given the highest logical level, and subsections are given subsequent logical levels.(i.e., **h2** is a subsection of **h1**). Providing this type of structure will help users understand the overall organization of the content more easily.\n\nSince headings indicate the start of important sections of content, it is possible for users with assistive technology to jump directly to the appropriate heading and begin reading the content. This significantly speeds interaction for users who would otherwise access the content slowly. Headings create chunks of information that can be found easily by people with disabilities, such as a blind person using a screen reader, or a person with a cognitive disability who uses assistive technology that delineates groups of information, or someone with a communication disability or illiteracy, who uses a screen reader to assist them in their reading.\n\nExamples:\n- **Example 1: Organizing the sections of a search page**  This example marks up each section heading usingh2elements.  ```html <h1>Search Technical Periodicals</h1> <h2>Search</h2> <form action=\"/search\" role=\"search\"> <label for=\"searchInput\">Enter search topic:</label> <input id=\"searchInput\" type=\"text\"> <input type=\"submit\" value=\"Search\"> </form> <section> <h2>Available Periodicals</h2> <ul> <li><a href=\"https://example.com/pcoder\">Professional Coder</a></li> <li><a href=\"https://example.com/algo\">Algorithms</a></li> <li><a href=\"https://example.com/jse\">Journal of Software Engineering</a></li> </ul> </section> <section> <h2>Search Results</h2> ... search results are returned in this section ... </section> ```\n- **Example 3: Headings show the organization of material within the main content**  ```html <!doctype html> <html lang=\"en\"> <head> <meta charset=\"utf-8\"> <title>Cooking techniques</title> </head> <body> <main> <h1>Cooking techniques</h1> <p>... some text here ...</p> <h2>Cooking with oil</h2> <p>... text of the section ...</p> <h2>Cooking with butter</h2> <p>... text of the section ...</p> </main> </body> </html> ```    ---\n- **Example 2: Headings show the overall organization of the content**  In this example, heading markup is used to make the navigation and main content sections perceivable.  ```html <main> <h1>Why Monday Monkey Lives For The Weekend</h1> ... text, images, and other material making up the main content ... </main> <nav aria-labelledby=\"nav-heading\"> <h2 id=\"nav-heading\">More About Monday Monkey, Ltd.</h2> <ul> <li><a href=\"/about\">About us</a></li> <li><a href=\"/contact\">Contact us</a></li> ... </ul> </nav> ```",
    "referenced_by": [
      "2.4.1"
    ]
  },
  {
    "id": "C43",
    "type": "technique",
    "code": "C43",
    "text": "[C43] Using CSS scroll-padding to un-obscure content\n\nDescription:\nThe objective of this technique is to ensure that user interface components (for example: links, buttons, and form fields) that are initially completely obscured by a fixed-position component can still be accessed by users. In this example, this is achieved using CSS **padding** and **scroll-padding** properties to create space underneath the site footer and allow the link in the footer to scroll into view when it is focused with a keyboard.\n\nExamples:\n- **Example 1: Using CSSscroll-paddingto un-obscure content**  This example shows a situation where there is a fixed-position banner at the bottom of the screen that is covering up the site footer, which contains a link. This type of fixed-position banner is a common design for cookie-consent banners.  Working example:Using CSSscroll-paddingto un-obscure content.  ```html <!doctype html> <html lang=\"en\"> <head> <meta charset=\"utf-8\"> <meta name=\"viewport\" content=\"width=device-width, initial-scale=1, shrink-to-fit=no\"> <title>Using CSS scroll-padding to un-obscure content</title> <style> ...  :root{ --height-dialog: 400px; --breathing-room: 20px; --scroll-padding: calc(var(--height-dialog) + var(--breathing-room)); }  .wrapper { display:grid; gap:1rem; grid-template-columns:repeat(9, 1fr); grid-template-rows:8rem auto minmax(10rem, max-content); min-block-size: 100vh; }  .wrapper > * { border:1px solid var(--black); padding:1rem; }  header { grid-column:1 / -1; grid-row:1; }  main { grid-column:1 / 8; }  aside { grid-column:8 / 10; }  footer { grid-column:1 / -1; }  @media (max-width:50rem) { main { grid-column:1 / -1; }  aside { grid-column:1 / -1; } }  .fixed-position-banner { background:var(--banner-background); border:3px solid var(--banner-border); margin-block-end:0.5rem; padding:1rem 1rem 5rem; position:relative; width:calc(100vw - 1rem); }  @media (min-width: 50rem) { html { padding-bottom:var(--height-dialog); scroll-padding-bottom:var(--scroll-padding); }  .fixed-position-banner { margin-block-end:0; position:fixed; inset:auto 0 0 0; } } ... </style> </head> <body> <dialog class=\"fixed-position-banner\"> <h2 tabindex=\"-1\">Fixed-Position Banner</h2> <button aria-label=\"close fixed-position banner\" class=\"close-banner\" type=\"button\"> ... </button> </dialog> <div class=\"wrapper\"> <header> <p>Header Content</p> </header> <main> <h1>Main Content</h1> </main> <aside> <h2>Sidebar Content</h2> <p><a href=\"https://example.com\">Here's an example link in the sidebar</a>.</p> </aside> <footer> <h2>Footer Content</h2> <p><a href=\"https://example.com\">Here's an example link in the footer</a>.</p> </footer> </div> <script> window.addEventListener('DOMContentLoaded', () => { const elFixedBanner = document.querySelector('dialog'); const elCloseBannerBtn = document.querySelector(\".close-banner\");  elFixedBanner.show();  const getDialogHeight = () => { const height = elFixedBanner.offsetHeight; document.documentElement.style.setProperty('--height-dialog', `${height}px`); document.documentElement.style.setProperty('--breathing-room', `${height ? 20 : 0}px`); }  const observer = new ResizeObserver(getDialogHeight); observer.observe(elFixedBanner);  elCloseBannerBtn.addEventListener(\"click\", function(e){ elFixedBanner.close(); }, false); }); </script> </body> </html> ```    ---",
    "referenced_by": []
  },
  {
    "id": "F110",
    "type": "technique",
    "code": "F110",
    "text": "[F110] Failure of Success Criterion 2.4.12 Focus Not Obscured (Minimum) due to a sticky footer or header completely hiding focused elements\n\nDescription:\nThe objective of this failure is to avoid situations in which people using a keyboard interface (e.g. tabbing through links and controls) cannot see where the indicator is due to other authored content.\n\nAny 'sticky' content that moves with the viewport can potentially obscure other elements on the page, including controls the user may tab to.\n\nExamples:\n- **Example 1: Sticky footer**  A web page has a sticky footer, an element that stays visible at the bottom of the viewport as the user scrolls the page. The footer is tall enough to completely cover the element in focus as a user tabs down the page.  Failure example of sticky footer that completely cover elements in focus as a user tabs down the page.\n- **Example 2: Sticky header**  A web page has a sticky header, an element that stays visible at the top of the viewport as the user scrolls the page. The header is tall enough to completely cover the element in focus as a user tabs up the page.  Failure example of sticky header that completely cover elements in focus as a user tabs up the page.    ---",
    "referenced_by": []
  },
  {
    "id": "C40",
    "type": "technique",
    "code": "C40",
    "text": "[C40] Creating a two-color focus indicator to ensure sufficient contrast with all components\n\nDescription:\nThe objective of this technique is to create a two-color focus indicator that has sufficient contrast against any solid background color. This technique can avoid the need for multiple classes to ensure sufficient contrast of the focus indicator when viewed against different backgrounds.\n\nAuthors may apply this technique to sites that use a variety of different colored backgrounds. Although it is possible to create different colored focus indicators for different parts of a page, this can be time consuming and it can be easy to miss some components. However, if the focus indicator uses two highly-contrasting colors - a light color and a dark color - then the same indicator can be re-used, since at least one of the two colors will always have enough contrast against any background color.\n\nAs long as the two indicator colors have a contrast ratio of at least 9:1 with each other, at least one of the two colors is guaranteed to meet 3:1 contrast with any solid background color.\n\nIn CSS, two-color indicators can be implemented by combining the **outline** and **box-shadow** properties with the **:focus** or **:focus-visible** pseudo-classes.\n\nExamples:\n- **Example 1: A thick two-color indicator**  In this example, the indicator consists of two solid bands of color. Because each color band is 2 CSS pixels thick, either color band is large enough to meet the minimum indicator size requirement on its own. As long as one of the two colors has 3:1 change contrast with the pixels behind and around the focus indicator, the indicator will satisfy both the Focus Appearance and Non-Text Contrast success criteria.  Working example of a thick two-color indicator  ```html *:focus { /* inner indicator */ outline: 2px #F9F9F9 solid; outline-offset: 0; /* outer indicator */ box-shadow: 0 0 0 4px #193146; } ```    ---",
    "referenced_by": [
      "2.4.7"
    ]
  },
  {
    "id": "C41",
    "type": "technique",
    "code": "C41",
    "text": "[C41] Creating a strong focus indicator within the component\n\nDescription:\nThe objective of this technique is to create a highly visible focus indicator that has sufficient contrast against the internal background color of a component.\n\nExamples:\n- **Example 1: Inner border**  ```html <button type=\"button\">Example button</button> ```  ```html button { background-color: #236AB8; /* medium-dark blue */ color: white; padding: 10px; }  main button:focus { outline: 3px #fff5be solid; /* light yellow */ outline-offset: -4px; } ```    ---",
    "referenced_by": []
  },
  {
    "id": "G1",
    "type": "technique",
    "code": "G1",
    "text": "[G1] Adding a link at the top of each page that goes directly to the main content area\n\nDescription:\nThe objective of this technique is to provide a mechanism to bypass blocks of material that are repeated on multiple web pages by skipping directly to the main content of the web page. The first interactive item in the web page is a link to the beginning of the main content. Activating the link sets focus beyond the other content to the main content. This technique is most useful when a web page has one main content area, rather than a set of content areas that are equally important, and when there are not multiple navigation sections on the page.\n\nExamples:\n- **Example 1: An online newspaper**  An on-line newspaper contains many sections of information: a search function, a corporate banner, sidebars, minor stories, how to contact the newspaper, etc. The lead story is located in the middle of the page. The first link that the user reaches when tabbing through the page is titled \"Skip to Lead Story\". Activating the link moves visual focus to the story. Pressing tab again takes the user to the first link in the main story.\n- **Example 2: A \"Skip to main content\" link**  A web page includes a variety of navigation techniques on each page: a bread crumb trail, a search tool, a site map, and a list of related resources. The first link on the page is titled \"Skip to Main Content\". A user activates the link to skip over the navigation tools.    ---",
    "referenced_by": [
      "2.4.1"
    ]
  },
  {
    "id": "G123",
    "type": "technique",
    "code": "G123",
    "text": "[G123] Adding a link at the beginning of a block of repeated content to go to the end of the block\n\nDescription:\nThe objective of this technique is to provide a mechanism to bypass a block of material by skipping to the end of the block. The first link in the block or the link directly preceding the block moves focus to the content immediately after the block. Activating the link advances the keyboard focus past the block. When there are multiple blocks to be skipped, the user skips from block to block via these links.\n\nExamples:\n- **Example 1: Skip navigation links**  The pages on an organization's website include a navigation bar or main menu containing links to major sections of the site, the site map, information about the organization, and how to contact the organization. The first link in this area is titled \"Skip Navigation Links\". A user activates the link to skip over these links.\n- **Example 2: A book index**  A book contains an index that is divided into a set of pages. In the content at the beginning of each page of the index are links for each letter of the alphabet, linking into the index where the entries start with that letter. The first link in the set is titled \"Skip Links into Index\". A user activates this link to skip over the links.\n- **Example 3: Several sets of links**  All the pages on a website include a section containing links to the site map, information about the organization, and how to contact the organization. All the pages in each section of the site also contain a set of links to its subsections. The first link in the first block is titled \"Skip Navigation Links\" and skips over the first set of links. The first link in the second block is titled \"Skip Section Links\" and skips over the subsection links.\n- **Example 4:HTMLpage with several blocks of navigation**  This example demonstrates both the use of heading elements at the beginning of each section (H69) and links that skip to the end of each section. This allows people to skip blocks of repeated content using keyboard navigation or using heading navigation, depending on the capabilities of their user agents.  ```html <a href=\"#content\">skip navigation</a> <h2><span id=\"main-label\">Main</span> Navigation</h2> <nav aria-labelledby=\"main-label\"> <ul> <li><a href=\"#subnav\">Sub Navigation</a></li> <li><a href=\"/a/\">Link A</a></li> <li><a href=\"/b/\">Link B</a></li> <li><a href=\"/c/\">Link C</a></li> </ul> <nav>  <h2 id=\"subnav\"><span id=\"sub-label\">Sub</span> Navigation</h2> <nav aria-labelledby=\"sub-label\"> <ul> <li><a href=\"#ultranav\">Ultra Sub Navigation</a></li> <li><a href=\"/suba/\">Sub A</a></li> <li><a href=\"/subb/\">Sub B</a></li> <li><a href=\"/subc/\">Sub C</a></li> </ul> </nav>  <main id=\"content\"> <h1>Content title</h1> <p>Now that I have your attention...</p> </main> ```    ---",
    "referenced_by": [
      "2.4.1"
    ]
  },
  {
    "id": "G124",
    "type": "technique",
    "code": "G124",
    "text": "[G124] Adding links at the top of the page to each area of the content\n\nDescription:\nThe objective of this technique is to provide a mechanism to bypass blocks of material by providing a list of links to the different sections of the content. The links in this list, like a small table of contents at the beginning of the content, set focus to the different sections of the content. This technique is particularly useful for pages with many independent sections, such as portals. It may also be combined with other techniques for skipping blocks within a section.\n\nExamples:\n- **Example 1**  The web pages on a site all start with three links that navigate to the main content of that web page, the search field, and the navigation bar.    ---",
    "referenced_by": [
      "2.4.1"
    ]
  },
  {
    "id": "H64",
    "type": "technique",
    "code": "H64",
    "text": "[H64] Using the title attribute of the frame and iframe elements\n\nDescription:\nThe objective of this technique is to demonstrate the use of the **title** attribute of the **iframe** element to describe its contents. This provides a label for the frame so users can determine which frame to enter and explore in detail. It does not label the content inside the **iframe**.\n\nThe **title** attribute is not interchangeable with the **name** attribute. The **title** labels the frame for users; the **name** labels it for scripting and window targeting. The **name** is not presented to the user, only the **title** is.\n\nExamples:\n- **Example 1: Using thetitleattribute with aniframeto describe theiframe's content**  ```html <!doctype html> <html lang=\"en\"> <head> <title>A document using an iframe</title> </head> ... <iframe src=\"banner-ad.html\" name=\"ad-iframe\" title=\"Advertisement\"></iframe> ... </html> ```    ---",
    "referenced_by": [
      "2.4.1",
      "4.1.2"
    ]
  },
  {
    "id": "SCR28",
    "type": "technique",
    "code": "SCR28",
    "text": "[SCR28] Using an expandable and collapsible menu to bypass block of content\n\nDescription:\nThis technique allows users to skip repeated material by placing that material in a menu that can be expanded or collapsed under user control. The user can skip the repeated material by collapsing the menu. The user invokes a user interface control to hide or remove the elements of the menu. The resources section lists several techniques for menus, toolbars and trees, any of which can be used to provide a mechanism for skipping navigation.\n\nExamples:\n- **Example 1: Toggling a table of contents**  The table of contents for a set of web pages is repeated near the beginning of each web page. A button at the beginning of the table of contents lets the user remove or restore it on the page.  Working example of this code:Toggle table of contents with a button.  ```html ... <script> let tocToggle = document.querySelector(\".toc-toggle\"); let toc = document.querySelector(\"#toc\"); tocToggle.addEventListener(\"click\", toggle, false);  function toggle(e){ let elm = e.currentTarget; if(elm.getAttribute(\"aria-expanded\") === \"false\"){ elm.setAttribute(\"aria-expanded\", \"true\"); } else{ elm.setAttribute(\"aria-expanded\", \"false\"); } } </script>  ...  <button aria-controls=\"toc\" aria-expanded=\"true\" class=\"toc-toggle\" type=\"button\"> Toggle Table Of Contents </button> <nav aria-labelledby=\"toc-header\" id=\"toc\"> <h2 id=\"toc-header\">Table of Contents</h2> <ul> <li><a href=\"#sec1\">Section 1</a></li> <li><a href=\"#sec2\">Section 2</a></li> <li><a href=\"#sec3\">Section 3</a></li> <li><a href=\"#sec4\">Section 4</a></li> </ul> </nav> ... ```    ---",
    "referenced_by": [
      "2.4.1"
    ]
  },
  {
    "id": "G88",
    "type": "technique",
    "code": "G88",
    "text": "[G88] Providing descriptive titles for Web pages\n\nDescription:\nThe objective of this technique is to give each web page a descriptive title. Descriptive titles help users find content, orient themselves within it, and navigate through it. A descriptive title allows a user to easily identify what web page they are using and to tell when the web page has changed. The title can be used to identify the web page without requiring users to read or interpret page content. Users can more quickly identify the content they need when accurate, descriptive titles appear in site maps or lists of search results. When descriptive titles are used within link text, they help users navigate more precisely to the content they are interested in.\n\nThe title of each web page  should:\n\n- Identify the subject of the web page\n- Make sense when read out of context, for example by a screen reader or in a site map or list of search results\n- Be short\n\nIt may also be helpful for the title to\n\n- Identify the site or other resource to which the web page belongs\n- Be unique within the site or other resource to which the web page belongs\n\nExamples:\n- **Example 1: A title that lists the most important identifying information first**  A web page is published by a group within a larger organization. The title of the web page first identifies the topic of the page, then shows the group name followed by the name of the parent organization.  ```html <title>Working with us: The Small Group: The Big Organization</title> ```\n- **Example 2: A synchronized media presentation with a descriptive title**  A synchronized media presentation about the 2004 South Asian tsunami is titled \"The Tsunami of 2004.\"\n- **Example 3: A web page with a descriptive title in three parts**  A web page provides guidelines and suggestions for creating closed captions. The web page is part of a \"sub-site\" within a larger site. The title is separated into three parts by dashes. The first part of the title identifies the organization. The second part identifies the sub-site to which the web page belongs. The third part identifies the web page itself.  ```html <title>Computer Hardware Corporation - Laptop Division - Laptop FAQs</title> ```\n- **Example 4: A newspaper web page**  A website that only permits viewing of the current edition titles its web page \"National News, Front Page\". A website that permits editions from different dates to be viewed titles its web page, \"National News, Front Page, Oct 17, 2005\".    ---",
    "referenced_by": [
      "2.4.2"
    ]
  },
  {
    "id": "H25",
    "type": "technique",
    "code": "H25",
    "text": "[H25] Providing a title using the title element\n\nDescription:\nAll HTML documents, including those in frames, have a **title** element in the **head** section that defines in a simple phrase the purpose of the document. This helps users to orient themselves within the site quickly without having to search for orientation information in the body of the page.\n\nNote that the (mandatory) **title** element, which only appears once in a document, is different from the **title** attribute, which may be applied to almost every HTML element.\n\nExamples:\n- **Example 1**  This example defines a document's title.  ```html <!doctype html> <html lang=\"en\"> <head> <title>The World Wide Web Consortium</title> </head> <body> ... </body> </html> ```    ---",
    "referenced_by": [
      "2.4.2"
    ]
  },
  {
    "id": "PDF18",
    "type": "technique",
    "code": "PDF18",
    "text": "[PDF18] Specifying the document title using the Title entry in the document information dictionary of a PDF document\n\nDescription:\nThe intent of this technique is to show how a descriptive title for\na PDF document can be specified for assistive technology by using the\n**/Title** entry in the document information dictionary and by setting\nthe DisplayDocTitle flag to True in a viewer preferences dictionary.\nThis is typically accomplished by using a tool for authoring PDF.\n\nDocument titles identify the current location without requiring users\nto read or interpret page content. User agents make the title of the\npage easily available to the user for identifying the page. For instance,\na user agent may display the page title in the window title bar or\nas the name of the tab containing the page.\n\nExamples:\n- **Example 1: Setting the document title in the metadata and specifying that the title be displayed in the title bar using Adobe Acrobat Pro**  This example is shown with Adobe Acrobat Pro. There are other software tools that perform similar functions.  Open the PDF document in Adobe Acrobat Pro:  Note that, with Adobe Acrobat installed, you can also enter and read the data properties information from the desktop. Access the file's context menu, choose Properties, and select the PDF tab. Any information you type or edit in this dialog box also appears in the Document Properties Description when you open the file.  To display the document title in the title bar of a user agent:  The title is now displayed in the title bar.\n- **Example 2: A/Titleentry in the document information dictionary of a PDF document**  The following code fragment illustrates code that is typical for providing a/Titleentry in a document information dictionary that contains a document title.  ```html 1 0 obj << /Title (Applying Guerrilla Tactics to Usability Testing by People with Disabilities) /Author (Mary Smith) /CreationDate (D:19970915110347-08'00') >> endobj ```    ---",
    "referenced_by": [
      "2.4.2"
    ]
  },
  {
    "id": "G127",
    "type": "technique",
    "code": "G127",
    "text": "[G127] Identifying a Web page's relationship to a larger collection of Web pages\n\nDescription:\nThe objective of this technique is to enable users to identify the relationship between the current web page and other web pages in the same collection (e.g., on the same website). In some cases this can be done programmatically—for example by using the\n\nrel\n\nattribute of the\n\nlink\n\nelement in HTML. In other cases the information is provided by including the relevant information in the title of the web page.\n\nExamples:\n- **Example 3: Chapters in an online textbook**  An online textbook is divided into chapters. The title of each web page includes the number and title of the chapter as well as the title of the textbook.    ---\n- **Example 1: The title of a web page includes the name of the sub-site**  A large website includes tutorials and reference materials for numerous technologies. The title of each web page includes the name of the sub-site as well as the organization that produces the site.\n- **Example 2: Including identifying information in metadata**  A web page includes metadata that identifies it as the table of contents for a collection of documents. The metadata for each document in the collection identifies the document's position in the collection and provides a reference to the table of contents.",
    "referenced_by": [
      "2.4.2",
      "2.4.8"
    ]
  },
  {
    "id": "F25",
    "type": "technique",
    "code": "F25",
    "text": "[F25] Failure of Success Criterion 2.4.2 due to the title of a Web page not identifying the contents\n\nDescription:\nThis describes a failure condition when the web page has a title, but the\ntitle does not identify the contents or purpose of the web page.\n\nExamples:\n- **Example 1**  Examples of text that are not titles include:\n- **Example 2**  A site generated using templates includes the same title for each page on the site. So the title cannot be used to distinguish among the pages.    ---",
    "referenced_by": [
      "2.4.2"
    ]
  },
  {
    "id": "G59",
    "type": "technique",
    "code": "G59",
    "text": "[G59] Placing the interactive elements in an order that follows sequences and relationships within the content\n\nDescription:\nThe objective of this technique is to ensure that interactive elements receive focus in an order that follows sequences and relationships in the content. When designing the content, the interactive elements such as links and form controls are placed in the content so that the default tab order follows the sequences and relationships in the content. Each technology defines its default tab order, so the mechanism for placing the controls in the content will depend on the technology used.\n\nAs an example, in HTML, the default focus order follows the order in which elements appear in the content source. When the order of the HTML source matches the visual order of the web page, tabbing through the content follows the visual layout of the content. When the source order does not match the visual order, the tab order through the content must reflect the logical relationships in the content that are displayed visually.\n\nExamples:\n- **Example 1:** A form contains two text input fields that are to be filled in sequentially. The first text input field is placed first in the content, the second input field is placed second.\n- **Example 2:** A form contains two, side-by-side sections of information. One section contains information about an applicant; the other section contains information about the applicant's spouse. All the interactive elements in the applicant section receive focus before any of the elements in the spouse section. The elements in each section receive focus in the reading order of that section.  ---",
    "referenced_by": [
      "2.4.3"
    ]
  },
  {
    "id": "SCR26",
    "type": "technique",
    "code": "SCR26",
    "text": "[SCR26] Inserting dynamic content into the Document Object Model immediately following its trigger element\n\nDescription:\nThe objective of this technique is to place inserted user interface elements into the Document Object Model (DOM) in such a way that the tab order and screen-reader reading order are set correctly by the default behavior of the user agent. This technique can be used for any user interface element that is hidden and shown, such as menus and dialogs.\n\nThe reading order in a screen-reader is based on the order of the HTML elements in the Document Object Model, as is the default tab order. This technique inserts new content into the DOM immediately following the element that was activated to trigger the script. The triggering element must be a link or a button, and the script must be called from its **onclick** event. These elements are natively focusable, and their **onclick** event is device independent. Focus remains on the activated element and the new content, inserted after it, becomes the next thing in both the tab order and screen-reader reading order.\n\nNote that this technique works for synchronous updates. For asynchronous updates (sometimes called AJAX), an additional technique is needed to inform the assistive technology that the asynchronous content has been inserted.\n\nExamples:\n- **Example 1**  This example creates a menu when a link is clicked and inserts it after the link. Theonclickevent of the link is used to call the ShowHide script, passing in anidfor the new menu as a parameter.  The ShowHide script creates adivcontaining the new menu, and inserts a link into it. The last line is the core of the script. It finds the parent of the element that triggered the script, and appends the div it created as a new child to it. This causes the newdivto be in the DOM after the menu. When the user hits tab, the focus will go to the first focusable item in the menu, the link we created.  CSS is used to make thedivand link look like a menu.  ```html <button aria-expanded=\"false\" type=\"button\" onclick=\"ShowHide('foo',this)\"> Toggle </button> ```  ```html function ShowHide(id,src){ var el = document.getElementById(id); if (!el){ el = document.createElement(\"div\"); el.id = id; var link = document.createElement(\"a\"); link.href = \"/laptops\"; link.appendChild(document.createTextNode(\"Laptops\")); el.appendChild(link); src.parentElement.appendChild(el); src.setAttribute(\"aria-controls\", id); src.setAttribute(\"aria-expanded\", \"true\"); } else if (el && src.getAttribute(\"aria-expanded\") === \"false\"){ el.style.display = 'block'; src.setAttribute(\"aria-expanded\", \"true\"); } else{ el.style.display = 'none'; src.setAttribute(\"aria-expanded\", \"false\"); } } ```    ---",
    "referenced_by": [
      "2.4.3"
    ]
  },
  {
    "id": "H102",
    "type": "technique",
    "code": "H102",
    "text": "[H102] Creating modal dialogs with the HTML dialog element\n\nDescription:\nWebsite authors often use modal dialogs to focus a user's attention on information, or a task-related activity beyond the scope of the primary page's content. Modal dialogs can be built in markup using [ARIA's dialog role and related attributes](https://www.w3.org/WAI/ARIA/apg/patterns/dialog-modal/), or the HTML's **dialog** element. As well as meeting [the first rule of ARIA](https://www.w3.org/TR/using-aria/#rule1), the HTML **dialog** element offers several advantages to its ARIA counterpart, with the browser handling these features:\n\n- keyboard focus is moved to the newly-opened modaldialog;\n- keyboard focus returns to the invoking element (assuming the element is still on the page) when the modaldialogis closed;\n- keyboard focus is limited to the contents of the modaldialogand the browser's chrome (e.g., the browser-specific UI, such as the address bar, etc.);\n- the page's content 'outside' of the modal dialog becomesinert, resulting in the content becoming hidden from assistive technologies, and inoperable to all users, so long as the modaldialogremains open;\n- the use of theEscapekey to close the modaldialog.\n\nThis technique uses the HTML **dialog** element rather than a custom ARIA implementation, reducing the level of effort to create an accessible modal dialog.\n\nExamples:\n- **Example 1: A dialog to sign up to a mailing list**  This is an example of using a modaldialogelement to show a mailing-list sign-up form to a user. The main part of the page contains abuttonelement that, when activated, invokes the modaldialog. Thebuttonuses thetypeattribute to tell the browser that this isn't asubmitbutton.  When the modaldialogis opened, the browser will treat all content outside of the modal dialog as inert, rendering it inoperable and hiding the content from assistive technology. For example, a screen reader will not be able to reach or announce any of the inert content. Additionally, because the page content is inert, keyboard focus will only be able to reach focusable elements within thedialogelement, and the browser's controls. When invoked, the browser automatically sets focus to the first focusable element in the dialog'sDOM. In this example theh1element will receive focus because it has atabindex=\"-1\"attribute. Note that, although thedialog's closebuttonis visibly before theh1, it is the last item in thedialog's DOM. If thebuttonwas first, it would receive focus when dialog was opened.  ```html <!doctype html> <html lang=\"en\"> <head> <meta charset=\"utf-8\"> <meta name=\"viewport\" content=\"width=device-width, initial-scale=1, shrink-to-fit=no\"> <title>Turbo Encabulator News</title> </head> <body> <main> <h1>All The News About Turbo Encabulators</h1> <button class=\"open-modal\" type=\"button\">Sign up to our mailing list!</button> </main> <dialog aria-labelledby=\"dialog-heading\" id=\"mailing-list-dialog\"> <h1 id=\"dialog-heading\" tabindex=\"-1\">Sign up to our mailing list</h1> <form> <p class=\"req-note\">All form fields are required.</p> <div> <label for=\"fname\">First Name</label> <input aria-required=\"true\" autocomplete=\"given-name\" id=\"fname\" type=\"text\"> </div> <div> <label for=\"lname\">Last Name</label> <input aria-required=\"true\" autocomplete=\"family-name\" id=\"lname\" type=\"text\"> </div> <div> <label for=\"email\">Email address</label> <input aria-required=\"true\" autocomplete=\"email\" id=\"email\" type=\"text\"> </div> <button class=\"sign-up\" type=\"submit\">Sign up</button> </form> <form method=\"dialog\"> <button aria-label=\"close\" class=\"close-modal\">&times;</button> </form> </dialog> </body> </html> ```  ```html *, *::after, *::before { box-sizing: inherit; }  body { background:#fff; color:#000; font:1rem/1.5 system-ui, Helvetica, Roboto, sans-serif; }  *:focus-visible { outline:1px solid #0054AE; outline-offset:1px; }  dialog { border:1px solid #000; padding:2rem; position:relative; }  dialog::backdrop { background-color:hsla(0, 0%, 0%, .5); }  .close-modal { inset-block-start:1.5rem; inset-inline-end:1.5rem; line-height:1.3; padding:0.25em 0.5em; position:absolute; }  .sign-up { background:#000; color:#fff; padding:0.25em; }  dialog h1 { display:inline-block; line-height:1.3333; margin:0; max-inline-size:95%; }  form { display:grid; grid-gap:20px; grid-template-columns:repeat(auto-fit, minmax(150px, 1fr)); }  .req-note, .sign-up { grid-column:1 / -1; }  label { display:block; }  input { border:1px solid hsl(0, 0%, 50%); font:inherit; inline-size:calc(100% - 4px); }  button { background:#fff; border:1px solid hsl(0, 0%, 50%); border-radius:3px; color:inherit; font:inherit; margin:0; } ```  ```html document.addEventListener(\"DOMContentLoaded\", function(e){ const d = document.querySelector(\"dialog\"); const btnOpen = document.querySelector(\".open-modal\");  btnOpen.addEventListener(\"click\", function(){ d.showModal(); }, false);  }); ```    ---",
    "referenced_by": [
      "2.4.3"
    ]
  },
  {
    "id": "SCR27",
    "type": "technique",
    "code": "SCR27",
    "text": "[SCR27] Reordering page sections using the Document Object Model\n\nDescription:\nThe objective of this technique is to provide a mechanism for re-ordering component which is both highly usable and accessible. The two most common mechanisms for reordering are to send users to a set-up page where they can number components, or to allow them to drag and drop components to the desired location. The drag and drop method is much more usable, as it allows the user to arrange the items in place, one at a time, and get a feeling for the results. Unfortunately, drag and drop relies on the use of a mouse. This technique allows users to interact with a menu on the components to reorder them in place in a device independent way. It can be used in place of, or in conjunction with drag and drop reordering functionality.\n\nThe menu is a list of links using the device-independent onclick event to trigger scripts which re-order the content. The content is re-ordered in the Document Object Model (DOM), not just visually, so that it is in the correct order for all devices.\n\nExamples:\n- **Example 1**  This example does up and down reordering. This approach can also be used for two-dimensional reordering by adding left and right options.  The components in this example are list items in an unordered list. Unordered lists are a very good semantic model for sets of similar items, like these components. The menu approach can also be used for other types of groupings.  The modules are list items, and each module, in addition to content indivelements, contains a menu represented as a nested list.  Since we've covered the showing and hiding of menus in the simple tree samples, we'll focus here just on the code that swaps the modules. Once we harmonize the events and cancel the default link action, we go to work. First, we set a bunch of local variables for the elements with which we'll be working: the menu, the module to be reordered, the menuLink. Then, after checking the reorder direction, we try to grab the node to swap. If we find one, we then callswapNode()to swap our two modules, andPositionElement()to move the absolutely-positioned menu along with the module, and then set focus back on the menu item which launched the whole thing.  TheCSSfor the node swap is not much different than that of our previous tree samples, with some size and color adjustment for the modules and the small menu.  ```html <ul id=\"swapper\"> <li id=\"black\"> <div class=\"module\"> <div class=\"module_header\"> <!-- menu link --> <a href=\"#\" onclick=\"ToggleMenu(event);\">menu</a> <!-- menu --> <ul class=\"menu\"> <li><a href=\"#\" onclick=\"OnMenuClick(event)\" onkeypress=\"OnMenuKeypress(event);\">up</a></li> <li><a href=\"#\" onclick=\"OnMenuClick(event)\" onkeypress=\"OnMenuKeypress(event);\">down</a></li> </ul> </div> <div class=\"module_body\"> Text in the black module </div> </div> </li> ... </ul> ```  ```html function MoveNode(evt,dir){  HarmonizeEvent(evt); evt.preventDefault();  var src = evt.target; var menu = src.parentNode.parentNode; var module = menu.parentNode.parentNode.parentNode; var menuLink = module.getElementsByTagName(\"a\")[0]; var swap = null;  switch(dir){ case 'up': { swap = module.previousSibling; while (swap && swap.nodeType != 1){ swap = swap.previousSibling; } break; } case 'down': { swap = module.nextSibling; while (swap && swap.nodeType != 1){ swap = swap.nextSibling; } break; } } if (swap && swap.tagName == node.tagName){ module.swapNode(swap); PositionElement(menu,menuLink,false,true); } src.focus(); } ```  ```html ul#swapper { list-item-style:none; margin:0px; padding:0px; }  ul#swapper li { border:1px solid black; height:5em; list-style:none; margin:1em; padding:0; width:15em; }  ul#swapper li a { color:white; font-size:90%; text-decoration:none; }  ul#swapper li div.module_header { padding:0 0.2em; text-align:right; }  ul#swapper li div.module_body { padding:0.2em; }  ul#swapper ul.menu { background-color:#eeeeee; border:1px solid gray; display:none; height:auto; list-style:none; margin:0; padding:0; position:absolute; text-align:left; }  ul#swapper ul.menu li { border:none; font-weight:normal; height:auto; margin:0; text-align:left; width:5em; }  ul#swapper ul.menu li a { color:black; display:block; padding:0 0.1em; text-decoration:none; width:100%; } ```    ---",
    "referenced_by": [
      "2.4.3"
    ]
  },
  {
    "id": "F44",
    "type": "technique",
    "code": "F44",
    "text": "[F44] Failure of Success Criterion 2.4.3 due to using tabindex to create a tab order that does not preserve meaning and operability\n\nDescription:\nThis document describes a failure that occurs when the tab order does not\nfollow logical relationships and sequences in the content.\n\nFocusable elements like links and form elements have a tabindex\nattribute. The elements receive focus in ascending order of the value of the\ntabindex attribute. When the values of the\ntabindex attribute are assigned in a different order than the\nrelationships and sequences in the content, the tab order no longer follows\nthe relationships and sequences in the content.\n\nOne of the most common causes of this failure occurs when editing a page\nwhere tabindex has been used. It is easy for the tab order and\nthe content order to fall out of correspondence when the content is edited\nbut the tabindex attributes are not updated to reflect the\nchanges to the content.\n\nExamples:\n- **Example 1**  The following example incorrectly uses tabindex to specify an alternative tab order:  If this list is navigated by the tab key, the list is navigated in the order Homepage, chapter 3, chapter 2, chapter 1, which does not follow the sequence in the content.  ```html <ol> <li><a href=\"main.html\" tabindex=\"1\">Homepage</a></li> <li><a href=\"chapter1.html\" tabindex=\"4\">Chapter 1</a></li> <li><a href=\"chapter2.html\" tabindex=\"3\">Chapter 2</a></li> <li><a href=\"chapter3.html\" tabindex=\"2\">Chapter 3</a></li> </ol> ```\n- **Example 2**  The tab order has been set explicitly in a web page by providing tabindex attributes for all fields. Later, the page is modified to add a new field in the middle of the page, but the author forgets to add a tabindex attribute to the new field. As a result, the new field is at the end of the tab order.    ---",
    "referenced_by": [
      "2.4.3"
    ]
  },
  {
    "id": "F85",
    "type": "technique",
    "code": "F85",
    "text": "[F85] Failure of Success Criterion 2.4.3 due to using dialogs or menus that are not adjacent to their trigger control in the sequential navigation order\n\nDescription:\nThis describes the failure condition that results when a web page opens a dialog or menu interface component embedded on the page in a way that makes it difficult for a keyboard user to operate because of its position in the sequential navigation order. When the user opens the dialog or menu embedded on the page by activating a button or link, their next action will be to interact with the dialog or menu. If focus is not set to the dialog or menu, or a logical focusable descendent of these widgets, and the widget or a focusable descendent is not next in the sequential navigation order, it will be difficult for the keyboard user to operate the dialog or menu.\n\nExamples:\n- **Example 1: Adding a dialog to the page at the end of the sequential navigation order**  A non-native HTML dialog is created, with it being marked up at the end of the DOM (Document Object Model). Script was created to reveal the dialog, but no script was added to move focus to it. The dialog is visually positioned above the content of the page and the user's focus isn't moved to the dialog. Since the dialog is found at the end of the DOM, it is at the end of the keyboard navigation order. Because a user's focus isn't managed, or a keyboard mechanism isn't provided to allow them to immediately move to the invoked dialog, the user will need to tab through the rest of the web page before they can interact with the dialog.\n- **Example 2: Setting focus to the document after dismissing a menu embedded on the page**  When a menu is dismissed, it is removed or hidden from the web page and focus is set to the document. The user must tab from the beginning of the navigation sequence to reach the point from which the menu was opened.    ---",
    "referenced_by": [
      "2.4.3"
    ]
  },
  {
    "id": "G91",
    "type": "technique",
    "code": "G91",
    "text": "[G91] Providing link text that describes the purpose of a link\n\nDescription:\nThe objective of this technique is to describe the purpose of a link in the text of the link. The description lets a user distinguish this link from links in the web page that lead to other destinations and helps the user determine whether to follow the link. The URI of the destination is generally not sufficiently descriptive.\n\nExamples:\n- **Example 1: Describing the purpose of a link inHTMLin the text content of theaelement**  ```html <a href=\"routes.html\">Current routes at Boulders Climbing Gym</a> ```    ---",
    "referenced_by": [
      "2.4.4",
      "2.4.9"
    ]
  },
  {
    "id": "G189",
    "type": "technique",
    "code": "G189",
    "text": "[G189] Providing a control near the beginning of the Web page that changes the link text\n\nDescription:\nThe objective of this technique is to provide the user with a control near the beginning of the page that takes the user to a conforming alternate version of the web page where the link text alone of each link is sufficient to determine its purpose out of context.\n\nSome users prefer to have links that are self-contained, where there is no need to explore the context of the link. Other users find including the context information in each link to be repetitive and to reduce their ability to use a site. Among users of assistive technology, the feedback to the working group on which is preferable has been divided. This technique allows users to pick the approach that works best for them. Users who need or prefer potentially longer but complete link text use this version.\n\nIf the control for switching to the alternate version is a link, it must always be possible to understand the purpose of the control directly from its link text.\n\nThis technique provides the alternate version for the current page view. It is also possible, and in some cases would be advisable, to save this preference in a cookie or server-side user profile, so that users would only have to make the selection once per site and would automatically be taken to their preferred version.\n\nExamples:\n- **Example 1: Providing a Link to another Version**  A web page lists books for download in different formats. Alternate versions of the web page use just the book format as the link text or the book title and format type.  Version with short link text:  ```html <h1>Books for download</h1> <p><a href=\"books-full-links.html\">Full link Version</a></p> <ul> <li>The History of the Web: <a href=\"history.docx\">Word</a>, <a href=\"history.pdf\">PDF</a>, <a href=\"history.html\">HTML</a> </li> </ul> ```  ```html <h1>Books for download</h1> <p><a href=\"books-short-links.html\">Short link Version</a></p> <ul> <li>The History of the Web: <a href=\"history.docx\" class=\"hist\">The History of the Web (Word)</a>, <a href=\"history.pdf\" class=\"hist\">The History of the Web (PDF)</a>, <a href=\"history.html\" class=\"hist\">The History of the Web (HTML)</a> </li> </ul> ```    ---",
    "referenced_by": [
      "2.4.4",
      "2.4.9"
    ]
  },
  {
    "id": "SCR30",
    "type": "technique",
    "code": "SCR30",
    "text": "[SCR30] Using scripts to change the link text\n\nDescription:\nThe purpose of this technique is to allow users to choose to have additional information added to the text of links so that the links can be understood out of context.\n\nSome users prefer to have links that are self-contained, where there is no need to explore the context of the link. Other users find including the context information in each link to be repetitive and to reduce their ability to use a site. Among users of assistive technology, the feedback to the working group on which is preferable has been divided. This technique allows users to pick the approach that works best for them.\n\nA link is provided near the beginning of the page that will expand the link text of the links on the page so that no additional context is needed to understand the purpose of any link. It must always be possible to understand the purpose of the expansion link directly from its link text.\n\nThis technique expands the links only for the current page view. It is also possible, and in some cases would be advisable, to save this preference in a cookie or server-side user profile, so that users would only have to make the selection once per site.\n\nExamples:\n- **Example 1**  This example uses Javascript to add contextual information directly to the text of a link. The link class is used to determine which additional text to add. When the \"Expand Links\" link is activated, each link on the page is tested to see whether additional text should be added.  Working example of this code:Providing link expansions on demand.  ```html ... <script> var expanded = false; var linkContext = { \"hist\":\" version of The History of the Web\", \"cook\":\" version of Cooking for Nerds\" };  function doExpand() { var links = document.links;  for (var i=0; i<links.length; i++) { var link = links[i]; var cn = link.className; if (linkContext[cn]) { span = link.appendChild(document.createElement(\"span\")); span.setAttribute(\"class\", \"linkexpansion\"); span.appendChild(document.createTextNode(linkContext[cn])); } } objUpdate = document.getElementById('expand'); if (objUpdate) { objUpdate.childNodes[0].nodeValue = \"Collapse links\"; } expanded = true; }  function doCollapse() { objUpdate = document.getElementById('expand'); var spans = document.getElementsByTagName(\"span\"); var span;  // go backwards through the set as removing from the front changes indices // and messes up the process for (i = spans.length - 1; i >= 0; i--) { span = spans[i]; if (span.getAttribute(\"class\") == \"linkexpansion\") span.parentNode.removeChild(span); } if (objUpdate) { objUpdate.childNodes[0].nodeValue = \"Expand links\"; } expanded = false; }  function toggle() { if (expanded) doCollapse(); else doExpand(); } </script>  ...  <h1>Books for download</h1> <p><button id=\"expand\" onclick=\"toggle(); type=\"button\">Expand Links</button></p> <ul> <li>The History of the Web: <a href=\"history.docx\" class=\"hist\">Word</a>, <a href=\"history.pdf\" class=\"hist\">PDF</a>, <a href=\"history.html\" class=\"hist\">HTML</a> </li> <li>Cooking for Nerds: <a href=\"history.docx\" class=\"cook\">Word</a>, <a href=\"history.pdf\" class=\"cook\">PDF</a>, <a href=\"history.html\" class=\"cook\">HTML</a> </li> </ul>  ... ```    ---",
    "referenced_by": [
      "2.4.4",
      "2.4.9"
    ]
  },
  {
    "id": "G53",
    "type": "technique",
    "code": "G53",
    "text": "[G53] Identifying the purpose of a link using link text combined with the text of the enclosing sentence\n\nDescription:\nThe objective of this technique is to identify the purpose of a link from the link and its sentence context. The sentence enclosing the link provides context for an otherwise unclear link. The description lets a user distinguish this link from links in the web page that lead to other destinations and helps the user determine whether to follow the link. Note that simply providing the URI of the destination is generally not sufficiently descriptive.\n\nExamples:\n- **Example 1**  A web page contains the sentence \"To advertise on this page,click here.\"  Although the link phrase 'click here' is not sufficient to understand the link, the information needed precedes the link in the same sentence.\n- **Example 2**  In the news summary containing the sentence \"The Smallville Timesreports thatthe School Board chose a 2007 school calendar that starts on August 27.\", the words \"reports that\" are a link to an article in the Smallville Times about the School Board meeting.    ---",
    "referenced_by": [
      "2.4.4"
    ]
  },
  {
    "id": "H33",
    "type": "technique",
    "code": "H33",
    "text": "[H33] Supplementing link text with the title attribute\n\nDescription:\nThe objective of this technique is to demonstrate how to use a **title** attribute on an anchor element to provide additional text describing a link. The **title** attribute is used to provide additional information to help clarify or further describe the purpose of a link. If the supplementary information provided through the **title** attribute is something the user should know before following the link, such as a warning, then it should be provided in the link text rather than in the **title** attribute.\n\nBecause of the extensive user agent limitations in supporting access to the title attribute, authors should use caution in applying this technique. For this reason, it is preferred that the author use technique [C7: Using CSS to hide a portion of the link text](../css/C7) or [H30: Providing link text that describes the purpose of a link for anchor elements](H30).\n\nExamples:\n- **Example 1: Clarifying the purpose of a link**  ```html <a href=\"https://example.com/world/africa/kenya.elephants.ap/index.html\" title=\"Read more about failed elephant evacuation\"> Evacuation Crumbles Under Jumbo Load </a> ```    ---",
    "referenced_by": [
      "2.4.4",
      "2.4.9"
    ]
  },
  {
    "id": "C7",
    "type": "technique",
    "code": "C7",
    "text": "[C7] Using CSS to hide a portion of the link text\n\nDescription:\nThe objective of this technique is to supplement the link text by adding additional text that describes the unique function of the link and styling the additional text so that it is not rendered on the screen by user agents that support CSS. When information in the surrounding context is needed to interpret the displayed link text, this technique provides a complete description of the link's input function while permitting the less complete text to be displayed.\n\nThis technique works by creating a CSS selector to target text that is to be hidden. The rule set for the selector places the text to be hidden in a 1-pixel box with **overflow:hidden**. This ensures the text does not display on screen but remains accessible to assistive technologies such as screen readers and braille displays. Note that the technique does not use **visibility:hidden** or **display:none** properties, since these have the effect of hiding the text from assistive technology in addition to preventing on-screen display.\n\nThis technique is not a method for hiding complete links, only a section of text within a link. The [resources](#resources) section includes methods for hiding and showing links aimed at screen reader users.\n\nExamples:\n- **Example 1: A news site with \"full story\" links**  This example describes a news site that has a series of short synopsis of stories followed by a link that says \"full story\". Hidden link text describes the purpose of the link.  ```html <p>Washington has announced plans to stimulate economic growth. <a href=\"/washington-growth/\"><span class=\"visually-hidden\">Washington stimulates economic growth </span>Full Story</a> </p> ```\n- **Example 2: A list of books in different formats**  This example describes a resource that has electronic books in different formats. The title of each book is followed by links that say \"HTML\" and \"PDF.\" Visually-hidden text describes the purpose of each link.  ```html <dl> <dt>Winnie the Pooh</dt> <dd><a href=\"winnie-the-pooh.html\"> <span class=\"visually-hidden\">Winnie the Pooh </span>HTML</a></dd> <dd><a href=\"winnie_the_pooh.pdf\"> <span class=\"visually-hidden\">Winnie the Pooh </span>PDF</a></dd> <dt>War and Peace</dt> <dd><a href=\"war-and-peace.html\"> <span class=\"visually-hidden\">War and Peace </span>HTML</a></dd> <dd><a href=\"war_and_peace.pdf\"> <span class=\"visually-hidden\">War and Peace </span>PDF</a></dd> </dl> ```    ---",
    "referenced_by": [
      "2.4.4",
      "2.4.9"
    ]
  },
  {
    "id": "ARIA7",
    "type": "technique",
    "code": "ARIA7",
    "text": "[ARIA7] Using aria-labelledby for link purpose\n\nDescription:\nWith the **aria-labelledby** attribute, authors can use a visible text element on the page as a label for a focusable element (a form control or a link). For example, a \"read more...\" link could be associated with the text of the heading of the preceding section to make the purpose of the link unambiguous (see example 1).\n\nWhen associating text to a focusable element with the help of **aria-labelledby**, the target text element is given an **id** which is referenced in the value of the **aria-labelledby** attribute of the focusable element.\n\nIt is also possible to use several text elements on the page as a label for a focusable element. Each of the text elements used must be given a unique ID which is referenced as a string of **id**s (IDREF) in the value of the **aria-labelledby** attribute. The label text should then be concatenated following the order of **id**s in the value of the **aria-labelledby** attribute.\n\nWhen applied on links, **aria-labelledby** can be used to identify the purpose of a link that may be readily apparent for sighted users, but less obvious for screen reader users.\n\nThe specified behavior of **aria-labelledby** is that the associated label text is announced instead of the link text (not in addition to the link text). When the link text itself should be included in the label text, the ID of the link should be referenced as well in the string of IDs forming the value of the **aria-labelledby** attribute.\n\nFor more information on the naming hierarchy please consult the [Accessible Name and Description Computation](https://www.w3.org/TR/accname/).\n\nExamples:\n- **Example 1: Providing additional information for links**  This example will mean that the link text as shown on screen is then used as the start of the accessible name for the link. Screen readers will announce this as: \"Read more ...Storms hit east coast\" and will display that same text in the links list which is very useful for screen reader users who may browse by links.  ```html <h2 id=\"headline\">Storms hit east coast</h2> <p>Torrential rain and gale force winds have struck the east coast, causing flooding in many coastal towns. <a id=\"p123\" href=\"news.html\" aria-labelledby=\"p123 headline\">Read more...</a> </p> ```\n- **Example 2: Concatenating link text from multiple sources**  There may be cases where an author will place a tag around a section of code that will be referenced.  ```html <p>Download <span id=\"report-title\">2012 Sales Report</span>: <a aria-labelledby=\"report-title pdf\" href=\"#\" id=\"pdf\">PDF</a> | <a aria-labelledby=\"report-title doc\" href=\"#\" id=\"doc\">Word</a> | <a aria-labelledby=\"report-title ppt\" href=\"#\" id=\"ppt\">PowerPoint</a> </p> ```    ---",
    "referenced_by": [
      "2.4.4"
    ]
  },
  {
    "id": "ARIA8",
    "type": "technique",
    "code": "ARIA8",
    "text": "[ARIA8] Using aria-label for link purpose\n\nDescription:\nThe objective of this technique is to describe the purpose of a link using the **aria-label** attribute. The **aria-label** attribute provides a way to place a descriptive text label on an object, such as a link, when there are no elements visible on the page that describe the object. If descriptive elements are visible on the page, the **aria-labelledby** attribute should be used instead of **aria-label**. Providing a descriptive text label lets a user distinguish the link from links in the web page that lead to other destinations and helps the user determine whether to follow the link. In some assistive technologies the **aria-label** value will show in the list of links instead of the actual link text.\n\nPer the [Accessible Name and Description Computation](https://www.w3.org/TR/accname/) and the [Accessible Name and Description Computation](https://www.w3.org/TR/html-aam-1.0/#accessible-name-and-description-computation) in the HTML Accessibility API Mappings 1.0, the **aria-label** text will override the text supplied within the link. As such the text supplied will be used instead of the link text by assistive technology. Due to this it is recommended to start the text used in **aria-label** with the text used within the link. This will allow consistent communication between users.\n\nExamples:\n- **Example 1: Describing the purpose of a link in HTML using aria-label.**  In some situations, designers may choose to lessen the visual appearance of links on a page by using shorter, repeated link text such as \"read more\". These situations provide a good use case for aria-label in that the simpler, non-descriptive \"read more\" text on the page can be replaced with a more descriptive label of the link. The words 'read more' are repeated in the aria-label (which replaces the original anchor text of \"[Read more...]\") to allow consistent communication between users.  ```html <h4>Neighborhood News</h4> <p>Seminole tax hike: Seminole city managers are proposing a 75% increase in property taxes for the coming fiscal year. <a href=\"taxhike.html\" aria-label=\"Read more about Seminole tax hike\"> [Read more...]</a> </p>  <p>Baby Mayor: Seminole voters elect the city's youngest mayor ever by voting in 3 year old Willy \"Dusty\" Williams in yesterday's mayoral election. <a href=\"babymayor.html\" aria-label=\"Read more about Seminole's new baby mayor\"> [Read more...]</a> </p> ```    ---",
    "referenced_by": [
      "2.4.4",
      "2.4.9"
    ]
  },
  {
    "id": "H77",
    "type": "technique",
    "code": "H77",
    "text": "[H77] Identifying the purpose of a link using link text combined with its enclosing list item\n\nDescription:\nThe objective of this technique is to identify the purpose of a link from the link and\nits list item context. The list item enclosing the link provides context for an\notherwise unclear link when the list item is the nearest enclosing block-level ancestor\nelement. The description lets a user distinguish this link from links in the web page\nthat lead to other destinations and helps the user determine whether to follow the link.\nNote that simply providing the URI of the destination is generally not sufficiently\ndescriptive.\n\nExamples:\n- **Example 1**  ```html <ul> <li> Check out the video report for last year's <a href=\"festival.html\">National Folk Festival</a>. </li> <li> <a href=\"listen.html\">Listen to the instruments</a> </li> <li> Guitar Man: George Golden talks about <a href=\"mkguitars.html\">making guitars</a>. </li> </ul> ```\n- **Example 2: A list of video games for download**  ```html <ul> <li> <a href=\"zelda-tears.html\">Legend Of Zelda: Tears Of The Kingdom</a> <a href=\"zelda-tears-images.html\">See Images</a> <a download href=\"zelda-tears-demo.mp4\">Download Demo</a> </li> <li> <a href=\"metroid-prime.html\">Metroid Prime</a> <a href=\"metroid-prime-images.html\">See Images</a> <a download href=\"metroid-prime-demo.mp4\">Download Demo</a> </li> <li> <a href=\"grand-theft-auto.html\">Grand Theft Auto</a> <a href=\"grand-theft-auto-images.html\">See Images</a> <a download href=\"grand-theft-auto.mp4\">Download Demo</a> </li> </ul> ```    ---",
    "referenced_by": [
      "2.4.4"
    ]
  },
  {
    "id": "H78",
    "type": "technique",
    "code": "H78",
    "text": "[H78] Identifying the purpose of a link using link text combined with its enclosing paragraph\n\nDescription:\nThe objective of this technique is to identify the purpose of a link from the link in its paragraph context. The paragraph enclosing the link provides context for an otherwise unclear link when the paragraph is the nearest enclosing block-level ancestor element. The description lets a user distinguish this link from links in the web page that lead to other destinations and helps the user determine whether to follow the link. Note that simply providing the URI of the destination is generally not sufficiently descriptive.\n\nExamples:\n- **Example 1: Announcements content on a folk festival web page**  ```html <h3>The final 15</h3> <p> Coming soon to a town near you: the final 15 in the National Folk Festival lineup. <a href=\"final-15.html\">Read more</a> </p>  <h3>Folk artists get awards</h3> <p> Performers from the upcoming National Folk Festival receive National Heritage Fellowships. <a href=\"national-heritage.html\">Read more</a> </p> ```    ---",
    "referenced_by": [
      "2.4.4"
    ]
  },
  {
    "id": "H79",
    "type": "technique",
    "code": "H79",
    "text": "[H79] Identifying the purpose of a link in a data table using the link text combined with its enclosing table cell and associated table header cells\n\nDescription:\nThe objective of this technique is to identify the purpose of a link from the link in its data table context. This context is the table cell enclosing the link and the cell's associated table header cells. The data table context provides the purpose for an otherwise unclear link when the table cell is the nearest enclosing block-level ancestor element. It lets a user distinguish this link from other links in the web page that lead to other destinations and helps the user determine whether to follow the link. Note that simply providing the URI of the destination is not sufficiently descriptive for people with disabilities, especially those with cognitive disabilities.\n\nExamples:\n- **Example 1: A table of rental car choices**  ```html <table> <caption>Available rental cars with cost per day</caption> <tr> <th>Type of car</th> <th>Alamo</th> <th>Budget</th> <th>National</th> <th>Avis</th> <th>Hertz</th> </tr> <tr> <th scope=\"row\">Economy</th> <td><a href=\"econ-ala.html\">$67</a></td> <td><a href=\"econ-bud.html\">$68</a></td> <td><a href=\"econ-nat.html\">$72</a></td> <td><a href=\"econ-av.html\">$74</a></td> <td><a href=\"econ-hz.html\">$74</a></td> </tr> <tr> <th scope=\"row\">Compact</th> <td><a href=\"comp-ala.html\">$68</a></td> <td><a href=\"comp-bud.html\">$69</a></td> <td><a href=\"comp-nat.html\">$74</a></td> <td><a href=\"comp-av.html\">$76</a></td> <td><a href=\"comp-hz.html\">$76</a></td> </tr> <tr> <th scope=\"row\">Mid-sized</th> <td><a href=\"mid-ala.html\">$79</a></td> <td><a href=\"mid-bud.html\">$80</a></td> <td><a href=\"mid-nat.html\">$83</a></td> <td><a href=\"mid-av.html\">$85</a></td> <td><a href=\"mid-hz.html\">$85</a></td> </tr> <tr> <th scope=\"row\">Full-sized</th> <td><a href=\"full-ala.html\">$82</a></td> <td><a href=\"full-bud.html\">$83</a></td> <td><a href=\"full-nat.html\">$89</a></td> <td><a href=\"full-av.html\">$91</a></td> <td><a href=\"full-hz.html\">$91</a></td> </tr> </table> ```    ---",
    "referenced_by": [
      "2.4.4"
    ]
  },
  {
    "id": "H81",
    "type": "technique",
    "code": "H81",
    "text": "[H81] Identifying the purpose of a link in a nested list using link text combined with the parent list item under which the list is nested\n\nDescription:\nThe objective of this technique is to describe the purpose of a link in a nested list\nfrom the context provided by the list item under which the list is nested. This list\nitem provides context for an otherwise unclear link. The description lets a user\ndistinguish this link from links in the web page that lead to other destinations and\nhelps the user determine whether to follow the link.\n\nBecause current assistive technologies do not include commands to query contextual information provided by parent list items, use of this technique requires users to navigate the list one item at a time. Therefore, this technique may not be appropriate for very long or deeply nested lists.\n\nExamples:\n- **Example 1: A document provided in three formats**  ```html <ul> <li>Annual Report 2021 <ul> <li> <a href=\"ar-2021.html\"><abbr title=\"HyperText Markup Language\">HTML</abbr></a> </li> <li> <a href=\"ar-2021.pdf\"><abbr title=\"Portable Document Format\">PDF</abbr></a> </li> <li> <a href=\"ar-2021.rtf\"><abbr title=\"Rich Text Format\">RTF</abbr></a> </li> </ul> </li> <li>Annual Report 2022 <ul> <li> <a href=\"ar-2022.html\">HTML</a> </li> <li> <a href=\"ar-2022.pdf\">PDF</a> </li> <li> <a href=\"ar-2022.rtf\">RTF</a> </li> </ul> </li> </ul> ```\n- **Example 2: Blocks of information about hotels**  The information for each hotel consists of the hotel name, a description and a series of links to a map, photos, directions, guest reviews and a booking form.  ```html <nav> <ul> <li><a href=\"royal-palm-hotel.html\">Royal Palm Hotel</a> <ul> <li><a href=\"royal-palm-hotel-map.html\">Map</a></li> <li><a href=\"royal-palm-hotel-photos.html\">Photos</a></li> <li><a href=\"royal-palm-hotel-directions.html\">Directions</a></li> <li><a href=\"royal-palm-hotel-reviews.html\">Guest reviews</a></li> <li><a href=\"royal-palm-hotel-book.html\">Book now</a></li> </ul> </li> <li><a href=\"hotel-three-rivers.html\">Hotel Three Rivers</a> <ul> <li><a href=\"hotel-three-rivers-map.html\">Map</a></li> <li><a href=\"hotel-three-rivers-photos.html\">Photos</a></li> <li><a href=\"hotel-three-rivers-directions.html\">Directions</a></li> <li><a href=\"hotel-three-rivers-reviews.html\">Guest reviews</a></li> <li><a href=\"hotel-three-rivers-book.html\">Book now</a></li> </ul> </li> </ul> </nav> ```    ---",
    "referenced_by": [
      "2.4.4"
    ]
  },
  {
    "id": "PDF13",
    "type": "technique",
    "code": "PDF13",
    "text": "[PDF13] Providing replacement text using the /Alt entry for links in PDF documents\n\nDescription:\nThe objective of this technique is to provide replacement link text\nvia the **/Alt** entry in the property list for a tag. This is usually\nnot necessary, but in some situations, additional information beyond\nthe visible link text is needed, particularly for screen reader users.\nScreen readers can read visible link text, but replacing the screen\ntext with meaningful alternate text for links in a PDF document can\nmake links more accessible.\n\nLinks in PDF documents are represented by a **Link** tag and objects in\nits sub-tree, consisting of a link object reference (or Link annotation)\nand one or more text objects. The text object or objects inside the\nLink tag are used by assistive technologies to provide a name for the\nlink.\n\nAuthors can replace the default link text by providing an **/Alt** entry\nfor the **Link** tag. When the **Link** tag has an **/Alt** entry, screen readers ignore the value of any visible text objects in the **Link** tag and use the **/Alt** entry value for the link text.\n\nThe simplest way to provide context-independent link text that complies\nwith the WCAG 2.0 success criteria is to create them when authoring\nthe document, before conversion to PDF. In some cases, it may not be\npossible to create the links using the original authoring tool. When editing PDF documents with Adobe Acrobat Pro, the best way to create accessible links is to use the Create Link command.\n\nAuthors should make sure that the alternate text makes sense in context of the screen text before and after the link.\n\nExamples:\n- **Example 1: Adding alternate link text using Adobe Acrobat 9 Pro**  This example is shown with Adobe Acrobat Pro. There are other software tools that perform similar functions.  The image below shows a document converted to PDF from Oracle Open Office. Note that the visible link text is theURLfor the link target. A screen reader will read the entireURIas the link text.  To create more accessible link text for assistive technology:  The next image shows the Link tag structure in the Tag panel.  The last image shows the Alternate Text specified in the Link tag's TouchUp Properties dialog. A screen reader will read the Alternate Text as the link text.  This example is shown in operation in theworking example of adding alternate link text (OpenOffice file)andworking example of adding alternate link text (PDF file).\n- **Example 2: Adding alternate link text in a PDF document using the/Altentry**  The following code fragment illustrates code that is typical for alternative text for a link. This is typically accomplished by an authoring tool.  The following illustrates how to specify alternate text for the URL in the above link:  ```html 32 0 obj << /S/URI                                       %Action type (required), must be URI for a URI action /URI(http://www.boston.com/business/technology/)  %Uniform resource identifier(required), the URI to be resolved >> endobj ```  ```html 11 0 obj << /Alt(Boston Globe technology page)    %Alternate text entry /K [ 1 << /Obj 27 0 R /Type /OBJR            %Object reference to the link >> ] /P 12 0 R /Pg 18 0 R /S /Link >> endobj ```    ---",
    "referenced_by": [
      "2.4.4",
      "2.4.9"
    ]
  },
  {
    "id": "H80",
    "type": "technique",
    "code": "H80",
    "text": "[H80] Identifying the purpose of a link using link text combined with the preceding heading element\n\nDescription:\nThe objective of this technique is to describe the purpose of a link from the context\nprovided by its heading context. The preceding heading provides context for an otherwise\nunclear link. The description lets a user distinguish this link from links in the Web\npage that lead to other destinations and helps the user determine whether to follow the\nlink.\n\nExamples:\n- **Example 1: Blocks of information on hotels**  The information for each hotel consists of the hotel name, a description and a series of links to a map, photos, directions, guest reviews and a booking form.  ```html <h2><a href=\"royal_palm_hotel.html\" id=\"royal-heading\">Royal Palm Hotel</a></h2> <nav aria-labelledby=\"royal-heading\"> <ul> <li><a href=\"royal-palm-hotel_map.html\">Map</a></li> <li><a href=\"royal-palm-hotel-photos.html\">Photos</a></li> <li><a href=\"hroyal-palm-hotel-directions.html\">Directions</a></li> <li><a href=\"royal-palm-hotel-reviews.html\">Guest reviews</a></li> <li><a href=\"royal-palm-hotel-book.html\">Book now</a></li> </ul> </nav>  <h2><a href=\"hotel-three-rivers.html\" id=\"rivers-heading\">Hotel Three Rivers</a></h2> <nav aria-labelledby=\"rivers-heading\"> <ul> <li><a href=\"hotel-three-rivers-map.html\">Map</a></li> <li><a href=\"hotel-three-rivers-photos.html\">Photos</a></li> <li><a href=\"hotel-three-rivers-directions.html\">Directions</a></li> <li><a href=\"hotel-three-rivers-reviews.html\">Guest reviews</a></li> <li><a href=\"hotel-three-rivers-book.html\">Book now</a></li> </ul> </nav> ```\n- **Example 2: A document provided in three formats**  ```html <h2>Annual Report 2006-2007</h2> <p> <a href=\"annual-report-0607.html\">HTML</a> <a href=\"annual-report-0607.pdf\">PDF</a> <a href=\"annual-report-0607.rtf\">RTF</a> </p> ```\n- **Example 3: Newspaper website**  A script is used to find each element with a class ofcard-linkand append an additional paragraph with a \"Read more\" link at the end of the div with the class.card-linkthat goes to the same location as the link in the heading.  ```html <div class=\"card-link\"> <h2><a href=\"market-2023-09-27.html\">Stock market soars as bullishness prevails</a></h2> <p>This week was a stellar week for the stock market as investing in gold rose 2%.</p> </div> ```    ---",
    "referenced_by": [
      "2.4.4"
    ]
  },
  {
    "id": "F63",
    "type": "technique",
    "code": "F63",
    "text": "[F63] Failure of Success Criterion 2.4.4 due to providing link context only in content that is not related to the link\n\nDescription:\nThis describes a failure condition when the context needed for understanding the purpose of a link is located in content that is not programmatically determined link context.  If the context for the link is not provided in one of the following ways:\n\n- in the same sentence, paragraph, list item, or table cell as the link\n- via a suitable ARIA property such asaria-labeloraria-labelledby\n\nthen the user will not be able to find out where the link is going with any ease. If the user must leave the link to search for the context, the context is not programmatically determined link context and this failure condition occurs.\n\nExamples:\n- **Example 1: A Link in an Adjacent Paragraph**  A news service lists the first few sentences of an article in a paragraph. The next paragraph contains the link \"Read More...\". Because the link is not in the same paragraph as the lead sentence, the user cannot easily discover what the link will let the user read more about.  ```html <p>A British businessman has racked up 2 million flyer miles and plans to travel on the world's first commercial tourism flights to space.</p> <p><a href=\"ff.html\">Read More...</a></p> ```\n- **Example 2: A Link in an Adjacent Cell Within a Layout Table**  An audio site provides links to where its player can be downloaded. The information about what would be downloaded by the link is in the preceding row of the layout table, which is not programmatically determined context for the link.  ```html <table> <tr> <td>Play music from your browser</td> </tr> <tr> <td> <a href=\"https://www.example.com/download.htm\"> <img src=\"download.jpg\" width=\"165\" height=\"32\" alt=\"Download now\"> </a> </td> </tr> </table> ```    ---",
    "referenced_by": [
      "2.4.4"
    ]
  },
  {
    "id": "F89",
    "type": "technique",
    "code": "F89",
    "text": "[F89] Failure of Success Criteria 2.4.4, 2.4.9 and 4.1.2 due to not providing an accessible name for an image which is the only content in a link\n\nDescription:\nThis failure condition occurs when a link contains only non-text content, such as an image, and that link cannot be identified by an accessible name. The accessible name for a link is defined according to the [Accessible Name and Description Computation](https://www.w3.org/TR/accname/).\n\nThis also applies when both text and images are used separately on a page to link to the same target. In this case success technique [H2: Combining adjacent image and text links for the same resource](../html/H2) is the recommended approach to reduce the number of separate links and the undesirable redundancy.\n\nExamples:\n- **Example 1: Search Results**  A search site returns search results that include both a text link and an image link to the match site. The image has a nullaltattribute, since the result already contains a link with a text description. However, the screen reader does not ignore the image link but uses heuristics to find some text that might describe the purpose of the link. For example, the screen reader might announce, \"football dot gif Football Scorecard.\"  ```html <a href=\"scores.html\"> <img src=\"football.gif\" alt=\"\"> </a> <a href=\"scores.html\">Football Scoreboard</a> ```    ---",
    "referenced_by": [
      "2.4.4",
      "2.4.9",
      "4.1.2"
    ]
  },
  {
    "id": "G125",
    "type": "technique",
    "code": "G125",
    "text": "[G125] Providing links to navigate to related Web pages\n\nDescription:\nThe objective of this technique is to make it possible for users to locate additional information by providing links to related web pages.\nIt is one of a series of techniques for locating content that are sufficient for addressing Success Criterion 2.4.5.\nLinks are a basic component of the World Wide Web. They are the mechanism that makes the web an interconnected Web of content. Most authors employ this technique automatically when creating web pages.\n\nExamples:\n- **Example 1**  TheWeb Content Accessibility Guidelines 2.0contains links to definitions of terms used in guidelines and Success Criteria, links to documents explaining how to meet different Success Criteria, a table of contents for each section containing links to different subsections of that section, and  aComparison of WCAG 1.0 checkpoints to WCAG 2.0. As users browse the document, they can follow these links to find related information.    ---",
    "referenced_by": [
      "2.4.5"
    ]
  },
  {
    "id": "G64",
    "type": "technique",
    "code": "G64",
    "text": "[G64] Providing a Table of Contents\n\nDescription:\nThis is one of a series of techniques for locating content that are sufficient for addressing Success Criterion 2.4.5.\nA table of contents provides links to sections and subsections of the same document. The information in the document is usually organized hierarchically, and is intended to be read sequentially. Just as there could be many books in a library, each with its own table of contents, a website may contain many documents, each with its own table of contents.\n\nThe table of contents serves two purposes:\n\n- It gives users an overview of the document's contents and organization.\n- It allows readers to go directly to a specific section of an on-line document.\n\nThe table of contents typically includes only major sections of the document, though in some cases an expanded table of contents that provides a more detailed view of a complex document may be desirable.\n\nThe sections of the document could be located on the same web page or divided into multiple web pages. A table of contents is particularly useful when a document is divided into multiple web pages.\n\nThere is a distinction between a table of contents and other Navigational elements such as a Navigation Bar or Site Map. A table of contents provides links to sections of the same document. Those sections could be located on the same web page or spread across multiple web pages. But together, they make a complete idea. To better understand this, consider a hard copy book which has sections. Each section belongs to the book. There could be many books in a library. In this example, the \"library\" is the entire website.\n\nExamples:\n- **Example 1**  TheWeb Content Accessibility Guidelines 2.0contains atable of contentsthat is a hierarchical list of links to the sections and subsections of the document. The hierarchy of the table of contents reflects the organization of the sections, and each item in the table of contents is a link that takes the user directly to that section.\n- **Example 2**  The table of contents forAccessing PDF Documents with Assistive Technology: A Screen Reader User's Guidebegins on the second page.    ---",
    "referenced_by": [
      "2.4.5"
    ]
  },
  {
    "id": "G63",
    "type": "technique",
    "code": "G63",
    "text": "[G63] Providing a site map\n\nDescription:\nThis is one of a series of techniques for locating content that are sufficient for addressing Success Criterion 2.4.5.\nA site map is a web page that provides links to different sections of the site. To make the site map available within the site, at a minimum every page that is listed in the site map contains a link to the site map.\n\nThe site map serves several purposes.\n\n- It provides an overview of the entire site.\n- It helps users understand what the site contains and how the content is organized.\n- It offers an alternative to complex navigation bars that may be different at different parts of the site.\n\nThere are different types of site maps. The simplest and most common kind of site map is an outline that shows links to each section or sub-site. Such outline views do not show more complex relationships within the site, such as links between pages in different sections of the site. The site maps for some large sites use headings that expand to show additional detail about each section.\n\nA site map describes the contents and organization of a site. It is important that site maps be updated whenever the site is updated. For example, a web page is not a valid site map when any one of the following is true:\n\nExamples:\n- **Example 2**  The site map for an on-line magazine lists all the sections of the magazine and the subsections in each section. It also include links for Help, How to Contact Us, Privacy Policy, Employment Opportunities, How to Subscribe, and the home page for the magazine.    ---\n- **Example 1**  The Web Accessibility Initiative provides aWAI site mapthat lists different sections of its website. The site map shows the different sections of the website, and shows some of the substructure within those sections.",
    "referenced_by": [
      "2.4.5",
      "2.4.8"
    ]
  },
  {
    "id": "G161",
    "type": "technique",
    "code": "G161",
    "text": "[G161] Providing a search function to help users find content\n\nDescription:\nProviding a search function that searches your web pages is a design strategy that offers users a way to find content. Users can locate content by searching for specific words or phrases, without needing to understand or navigate through the structure of the website. This can be a quicker or easier way to find content, particularly on large sites.\n\nSome search companies offer sites free access to their search applications. Search engines are available that can be installed on your own server. Some web hosting companies offer search scripts that customers can include on their web pages. Most services also offer paid versions of their tools with more advanced features.\n\nImplementing a search function that will spell-check the terms, include different endings for the terms (stemming), and allow for the use of different terminology (synonyms) will further increase the accessibility of the search function.\n\nThe search functionality is added by either including a simple form on the web page, usually a text field for the search term and a button to trigger the search or by adding a link to a page that includes a search form. The search form itself must be accessible, of course.\n\nTechniques that are used to optimize search engine results for external searches also support internal search engines and make them more effective: use keywords,\n\nMETA\n\ntags, and an accessible navigation structure. Search sites provide guidance on how to create content that is optimized for search, for instance\n\n[Google Webmaster Guidelines](https://support.google.com/webmasters/answer/35769), and\n[Yahoo! Search Content Quality Guidelines](https://help.yahoo.com/kb/search/SLN2245.html?impressions=true).\n\nExamples:\n- **Example 1: A Shopping Site**  A shopping site organizes its products into different categories, such as women's clothes, men's clothes, and children's clothes. These have subcategories, such as tops, pants, shoes, and accessories. Each page also contains a search form. Users can type the product number or product description into the search field and go directly to that product, rather than needing to navigate the product categories to find it.\n- **Example 2: A Help Center**  A Help Center contains thousands of pages of Help information about a company's products. A search form allows users to search just the Help Center pages to find articles that contain the search terms.    ---",
    "referenced_by": [
      "2.4.5"
    ]
  },
  {
    "id": "G126",
    "type": "technique",
    "code": "G126",
    "text": "[G126] Providing a list of links to all other Web pages\n\nDescription:\nThe objective of this technique is to provide a list of links to all the web pages in the set on each web page. It is one of a series of techniques for locating content that are sufficient for addressing Success Criterion 2.4.5.\nThis technique is only effective for small sets of web pages; if the list of links is longer than the rest of the content in the web page, it may make the web page more difficult for users to understand and use.\n\nExamples:\n- **Example 1**  A family website contains home pages for all the members of the family. Each page contains a list of links to the home pages of the other family members.\n- **Example 2**  An electonic book is broken into separate web pages for each chapter. Each web page starts with a small table of contents that contains links to all the chapters in the book.    ---",
    "referenced_by": [
      "2.4.5"
    ]
  },
  {
    "id": "G185",
    "type": "technique",
    "code": "G185",
    "text": "[G185] Linking to all of the pages on the site from the home page\n\nDescription:\nThe objective of this technique is to make it possible for users to locate all the information in a small website by providing links to all web pages from the home page. When the number of pages in the site is small enough, the home page can contain site map information directly. The other pages in the website contain links to the home page.\n\nIn this way, the home page serves as two mechanisms in one. It provides the usual navigation to pages. It also is a de facto site map to the site.\n\nAll the web pages in the site may contain links to all the other pages, and those sets of links satisfy\n[Success Criterion 3.2.3 (Consistent Navigation)](https://www.w3.org/WAI/WCAG22/Understanding/consistent-navigation).\n\nExamples:\n- **Example 1:** A small commercial website for a consultant contains a home page, a Contacts page for contacting the consultant, a page describing the consultant's background, and a page with examples of the consultant's work. Each page contains a navigation bar that links to all the other pages in the site.  ---",
    "referenced_by": [
      "2.4.5"
    ]
  },
  {
    "id": "PDF2",
    "type": "technique",
    "code": "PDF2",
    "text": "[PDF2] Creating bookmarks in PDF documents\n\nDescription:\nThe intent of this technique is to make it possible for users to locate content using bookmarks (outline entries in an Outline dictionary) in long documents.\n\nA person with cognitive disabilities may prefer a hierarchical outline that provides an overview of the document rather than reading and traversing through many pages. This is also a conventional means of navigating a document that benefits all users.\n\nExamples:\n- **Example 1: Converting a table of contents created with Microsoft Word to bookmarks in a PDF**  This example is shown with Microsoft Word and Adobe Acrobat Pro. There are other software tools that perform similar functions.  The table-of-contents entries in the converted document will be linked to the headings in the document. In addition, the headings will appear as PDF Bookmarks in the Acrobat navigation pane.  If the document provides a glossary and/or index, these sections should have headings that appear in the table of contents (and thus as bookmarks in the Navigation pane). The table of contents also should be marked up with a heading so it is bookmarked as well.  If this markup has not been done in the authoring tool, Adobe Acrobat Pro can be used to provide the tags. SeePDF9if you need to modify converted headings or add new ones.  This example is shown in operation in theworking example of creating bookmarks with Word.\n- **Example 2: Converting a table of contents created with OpenOffice and Writer to bookmarks in a PDF**  This example is shown with OpenOffice Writer and Adobe Acrobat Pro and Reader. There are other software tools that perform similar functions.  The table-of-contents entries in the converted document will be linked to the headings in the document, and will appear as PDF Bookmarks in the left-hand Navigation pane. The OpenOffice.org Table of Contents and Bookmarks look the same as they appeared in Example 1.  This example is shown in operation in theworking example of creating bookmarks with OpenOffice Writer.\n- **Example 3: Adding bookmarks using Adobe Acrobat Pro after conversion**  This example is shown with Adobe Acrobat Pro. There are other software tools that perform similar functions.  After conversion to tagged PDF, you may decide to add bookmarks that were not automatically generated. Like the converted bookmarks, tagged bookmarks use the underlying structural information in the document.  This example is shown in operation in theworking example of creating bookmarks with Acrobat Pro.\n- **Example 4: Creating bookmarks with the outline hierarchy**  The following code fragment illustrates part of an outline hierarchy used to create bookmarks This is typically accomplished by an authoring tool.  ```html 121 0 obj << /Type /Outlines /First 22 0 R /Last 29 0 R /Count 6 >> endobj 22 0 obj << /Title (Applying Guerrilla Tactics to Usability Testing by People with Disabilities) /Parent 21 0 R /Next 29 0 R /First 25 0 R /Last 28 0 R /Count 4 /Dest [3 0 R /XYZ 0 792 0] >> endobj 25 0 obj << /Title (Getting started) /Parent 22 0 R /Next 26 0 R /Dest [3 0 R /XYZ null 701 null] >> endobj ```    ---",
    "referenced_by": [
      "2.4.5"
    ]
  },
  {
    "id": "G130",
    "type": "technique",
    "code": "G130",
    "text": "[G130] Providing descriptive headings\n\nDescription:\nThe objective of this technique is to make section headings within Web content descriptive. Descriptive headings and titles (see [Providing descriptive titles for web pages](../general/G88)) work together to give users an overview of the content and its organization. Descriptive headings identify sections of the content in relation both to the web page as a whole and to other sections of the same web page.\n\nDescriptive headings help users find specific content and orient themselves within the web page.\n\nAuthors may also want to consider putting the most important information at the beginning of each heading. This helps users \"skim\" the headings to locate the specific content they need, and is especially helpful when browsers or assistive technology allow navigation from heading to heading.\n\nExamples:\n- **Example 1: AnHTMLpage that describes the range of tasks for disaster preparation**  Note that the level 2 headings have the distinguishing information at the beginning (i.e., instead of \"Preparation for floods\", \"Preparation for fires\", etc).  ```html <h1>Disaster preparation</h1> <h2>Flood preparation</h2> <h2>Fire preparation</h2> ```\n- **Example 2: An article**  A short article about the history of a town that explains about the founding and expansion of the town and then goes into some depth about the current situation. The title of the web page is \"History of Ourtown\". The first section is called \"The founding of Ourtown\". The second section is called \"Expansion of Ourtown\". The third section is called \"Ourtown today\" which has the following subsections: \"People in Ourtown\", \"Organizations in Ourtown\" and \"Buildings in Ourtown\".    ---",
    "referenced_by": [
      "2.4.6"
    ]
  },
  {
    "id": "G131",
    "type": "technique",
    "code": "G131",
    "text": "[G131] Providing descriptive labels\n\nDescription:\nThe objective of this technique is to ensure that the label for any interactive component within Web content makes the component's purpose clear. Using the appropriate technology-specific techniques for technologies for associating labels with interactive controls allows assistive technology to recognize the label and present it to the user, therefore allowing the user to identify the purpose of the control.The label may also be used to include text or a text symbol indicating that input is required.\n\nExamples:\n- **Example 2: A form asking the name of the user**  A form asks the name of the user. It consists of two input fields to ask for the first and last name. The first field is labeled \"First name\", the second is labeled \"Last name\".\n- **Example 1: Online maps with controls for zooming in and out**  A web application presents maps of a city. Users can “zoom in\" to view part of the map in greater detail, and can “zoom out\" to make it show a larger part of the city. The controls can be operated using either a mouse or a keyboard. The controls are labeled “Zoom in (Ctrl + Shift + L)\" And “Zoom out (Ctrl + Shift + R).\"\n- **Example 3: A form with required fields**  A purchasing form includes several fields that are required. In addition to identifying the field, the label for each required field includes the word “required\" in parentheses.    ---",
    "referenced_by": [
      "2.4.6",
      "3.3.2"
    ]
  },
  {
    "id": "G149",
    "type": "technique",
    "code": "G149",
    "text": "[G149] Using user interface components that are highlighted by the user agent when they receive focus\n\nDescription:\nThe objective of this technique is to ensure that the focused component can be visually identified by the user by relying on user agent support. It is common for user agents to highlight standard controls in some way when they receive focus. UAAG-conformant user agents do so when they satisfy checkpoint 10.2 \"Highlight selection, content focus, enabled elements, visited links\". When authors use standard controls for which the user agent provides this support, users are informed of the focus location in a standard, predictable way.\n\nExamples:\n- **Example 1:** When html text input fields receive focus, browsers display a blinking vertical bar at the insertion point in the text field.\n- **Example 2:** When html links receive focus, they are surrounded by a dotted focus highlight rectangle.  ---",
    "referenced_by": [
      "2.4.7"
    ]
  },
  {
    "id": "G165",
    "type": "technique",
    "code": "G165",
    "text": "[G165] Using the default focus indicator for the platform so that high visibility default focus indicators will carry over\n\nDescription:\nOperating systems have a native indication of focus, which is available in many user agents. The default rendering of the focus indicator isn't always highly visible and may even be difficult to see against certain backgrounds. However, many platforms allow the user to customize the rendering of this focus indicator. Assistive technology can also change the appearance of the native focus indicator. If you use the native focus indicator, any system-wide settings for its visibility will carry over to the web page. If you draw your own focus indicator, for example by coloring sections of the page in response to user action, these settings will not carry over, and AT will not usually be able to find your focus indicator.\n\nExamples:\n- **Example 1**  The default focus indicator on Microsoft Windows is a one-pixel, black dotted line around the focused element. On a page with a dark background, this can be very difficult to see. The creator of the page uses the default, and the user customizes it in Windows to make it a bright color.\n- **Example 2**  In HTML, form elements and links can be focused by default. In addition, any element with a tabindex attribute >= 0 can take focus. Both types of focused elements use the system focus indicator and will pick up platform changes in the focus indicator style.    ---",
    "referenced_by": [
      "2.4.7"
    ]
  },
  {
    "id": "SCR31",
    "type": "technique",
    "code": "SCR31",
    "text": "[SCR31] Using script to change the background color or border of the element with focus\n\nDescription:\nThis purpose of this technique is to allow the author to use JavaScript to apply CSS, in order to make the focus indicator more visible than it would ordinarily be. When an element receives focus, the background color or border is changed to make it visually distinct. When the element loses focus, it returns to its normal styling. This technique can be used on any HTML user agent that supports Script and CSS, regardless of whether it supports the :focus pseudo class.\n\nExamples:\n- **Example 1**  In this example, when the link receives focus, its background turns yellow. When it loses focus, the yellow is removed. Note that if the link had a background color to begin with, you would use that color rather than \"\" in the script.  ```html <script>function toggleFocus(el) { el.style.backgroundColor =  el.style.backgroundColor==\"yellow\" ? \"inherit\" : \"yellow\"; } </script> ... <a href=\"example.html\" onfocus=\"toggleFocus(this)\" onblur=\"toggleFocus(this)\">focus me</a> ... ```    ---",
    "referenced_by": [
      "2.4.7"
    ]
  },
  {
    "id": "G65",
    "type": "technique",
    "code": "G65",
    "text": "[G65] Providing a breadcrumb trail\n\nDescription:\nA breadcrumb trail (or 'breadcrumb navigation') helps the user to visualize how content has been structured and how to navigate back to previous web pages. Many even identify the current location in the series of web pages, commmonly as the last element in the trail and with a variation in its visual style. A breadcrumb trail either displays locations in the path the user took to reach the web page, or it displays the location of the current web page within the organization of the site.\n\nBreadcrumb trails are implemented using links to the web pages that have been accessed in the process of navigating to the current web page. They are placed in the same location within each web page in the set.\n\nIt can be helpful to users to separate the items in the breadcrumb trailing with a visible separator. Examples of separators include \">\", \"|\", \"/\", and \"→\". Alternatively, one could use decorative iconography or create separators with CSS.\n\nExamples:\n- **Example 1: Photographer's portfolio**  A photographer's portfolio website has been organized into different galleries and each gallery has further been divided into categories. A user who navigates through the website to a particular page containing a photo of a Gentoo penguin would see the following breadcrumb trail at the top of the web page:  The markup for this example implements all of the text items except \"Gentoo Penguin\" as links. To provide semantic structure to the breadcrumb trail, the links are contained within a list element, which is nested within anavelement with anaria-label. The current location, Gentoo Penguin, is included as the last item in the breadcrumb trail but it is not implemented as a link to visually and semantically differentiate it from the previous items in the trail.  Thearia-currentattribute is specified on the last list item in the trail to programmatically identify it as the item that reprsents the current web page. The markup would be styled using CSS to display the breadcrumb trail horizontally.  Working example:Breadcrumb example  ```html Home / Galleries / Antarctica / Penguins / Gentoo Penguin ```  ```html <nav aria-label=\"Breadcrumbs\"> <ul> <li><a href=\"/\">Home</a> /</li> <li><a href=\"/galleries\">Galleries</a> /</li> <li><a href=\"/galleries/antarctica\">Antarctica</a> /</li> <li><a href=\"/galleries/antarctica/penguins\">Penguins</a> /</li> <li aria-current=\"page\">Gentoo Penguin</li> </ul> </nav> ```\n- **Example 2: E-commerce site**  The information architecture of an e-commerce website is categorized from general to increasingly more specific product subsections.  You are here: Acme Company → Electronics → Computers → Laptops  The trail begins with \"You are here\" and ends with the current page. Items in the trail are clickable or tappable links with the exception of \"You are here\", which is a static heading. This example uses a right arrow symbol (→) as a separator.  In this example ah2element, anavelement with anaria-labelattribute, and an unordered list are used to provide semantics. The markup would be styled using CSS to display the breadcrumb trail horizontally.  Working example:Breadcrumb example  ```html <nav aria-label=\"Breadcrumbs\"> <h2>You are here:</h2> <ul> <li><a href=\"/\">Acme Company</a> &#8594;</li> <li><a href=\"/electronics/\">Electronics</a> &#8594;</li> <li><a href=\"/electronics/computers/\">Computers</a> &#8594;</li> <li><a href=\"/electronics/computers/laptops/\" aria-current=\"page\">Laptops</a></li> </ul> </nav> ```  ```html h2, ul, ul li{ display: inline;} nav > h2{ font-size: 1em; } ul { padding-left: 0em; } ```    ---",
    "referenced_by": [
      "2.4.8"
    ]
  },
  {
    "id": "G128",
    "type": "technique",
    "code": "G128",
    "text": "[G128] Indicating current location within navigation bars\n\nDescription:\nThe objective of this technique is to help orient the user by providing information about the current location via the navigational user interface component. This technique is especially useful when the web pages are steps in a task that must be processed in order. Providing this indication helps the user to better understand their place in the sequence. The location may be indicated by adding an icon or text, or by changing the state of the item.\n\nExamples:\n- **Example 1**  A web page implements tab panel style navigation. A list of panel tabs is displayed horizontally across the page. The current content is displayed in a panel below the list of panel tabs. When the user navigates to and selects a particular panel tab the content in the panel is updated to reflect the topic of the selected tab. In addition, the background color of the selected tab is changed from the default color and a check mark icon is displayed next to the tab panel text to indicate it is the active panel. The check mark icon includes an appropriate text alternative.\n- **Example 2**  The navigation bar for a site is implemented as a list of links. The navigation bar appears on all web pages within a collection of web pages. As the user gives focus to or hovers over a particular link in the navigation bar the background color of the link is changed. This change in styling on mouseover or focus is specified via the cascading style sheet for the web page. When focus is removed from the link the style is reset to the normal link style. When the link is activated to change the contents of the page, the selected link within the navigation bar is disabled since the result of following this link is the web page currently being displayed. Changing the background color gives sighted users visual notification of the link to be selected. Disabling the link provides information to all users that it is the currently selected topic.    ---",
    "referenced_by": [
      "2.4.8"
    ]
  },
  {
    "id": "PDF14",
    "type": "technique",
    "code": "PDF14",
    "text": "[PDF14] Providing running headers and footers in PDF documents\n\nDescription:\nThe objective of this technique is to help users locate themselves\nin a document by providing running headers and footers via pagination artifacts. This is normally accomplished using a tool for authoring PDF.\n\nRunning headers and footers help make content easier to use and understandable\nby providing repeated information in a consistent and predictable way.\nThe content of headers and footers will vary widely depending on the\ndocument scope and content, the audience, and design decisions. Some\nexamples of location information that may be used in headers and footers\nare listed below. Whether the information appears in a header or a\nfooter is often a design decision; page numbers often appear in footers\nbut they may alternatively appear in headers.\n\n- Document title\n- Current chapter and/or section in the document\n- Page numbers with location information such as, \"Page 3-4\" or \"Page\n9 of 15.\"\n- Author and/or date information.\n\nConsistency helps users with cognitive limitations, screen-reader\nusers and low-vision magnifier users, and users with intellectual disabilities\nunderstand content more readily.\n\nThe easiest way to provide page headers and footers is in the authoring\ntool for the document. Authoring tools typically provide features for\ncreating header and footer text and information (such as page numbers).\nHowever, if after converting your document to PDF, you need to add\nor modify page headers and footers, authoring or repair tools like Adobe Acrobat Pro's Header & Footer\ntools can be used. In all cases, the tools generate page headers and\nfooters in consistent and predictable layout, format, and text.\n\nExamples:\n- **Example 2: Adding running headers and footers using OpenOffice Writer**  This example is shown with OpenOffice Writer. There are other software tools that perform similar functions.  In OpenOffice Writer, use the Insert → Header and Insert → Footer tools, which allow you to specify header and footer information and layout, as shown in the following images.  When converted to PDF, the page headers and footers appear in the document as they do in the converted Word document in Example 1.  This example is shown in operation in theworking example of adding running headers using OpenOffice Writer (OpenOffice file)andworking example of adding running headers using OpenOffice Writer (PDF file).\n- **Example 1: Adding running headers and footers using Microsoft Word**  This example is shown with Microsoft Word. There are other software tools that perform similar functions.  In Microsoft Word, use the Header and Footer tools in the Insert ribbon. When the Word document is converted into a PDF, the headers and footers will be tagged as pagination artifacts.  This example is shown in operation in theworking example of adding running headers using Word (Word file)andworking example of adding running headers using Word (PDF file).\n- **Example 3: Adding running headers and footers to PDF documents using Adobe Acrobat Pro**  This example is shown with Adobe Acrobat Pro. There are other software tools that perform similar functions.  In Adobe Acrobat Pro, you can add or modify headers and footers:  The image below shows Acrobat Pro's Add Header and Footer tool.    ---",
    "referenced_by": [
      "2.4.8",
      "3.2.3"
    ]
  },
  {
    "id": "F84",
    "type": "technique",
    "code": "F84",
    "text": "[F84] Failure of Success Criterion 2.4.9 due to using a non-specific link such as \"click here\" or \"more\" without a mechanism to change the link text to specific text.\n\nDescription:\nThis failure describes a common condition where links such as \"click here\" or \"more\" are used as anchor elements where you need to have the surrounding text to understand their purpose and where there isn't any mechanism to make the destination clear by itself, such as a button to expand the link text.\n\nMany blind people who use screen readers call up a dialog box that has a list of links from the page. They use this list of links to decide where they will go. But if many of the links in that list simply say \"click here\" or \"more\" they will be unable to use this feature in their screen reader, which is a core navigation strategy. That's why it's a failure of 2.4.9 to not provide any way of allowing them to know the destination from the link text alone. It is also true for people who tab through links. If all they hear as they tab through the document is \"click here, click here, click here etc.\" they will become confused.\n\nExamples:\n- **Example 1**  ```html <a href=\"file110.html\">Click here</a> for more information on the Rocky Mountains. ```\n- **Example 2**  ```html <h2>News headlines</h2> <p>Bishops Tickle Darwin's Monkey Theory</p> <a href=\"btdmt.html\">read more</a> ```    ---",
    "referenced_by": [
      "2.4.9"
    ]
  },
  {
    "id": "G215",
    "type": "technique",
    "code": "G215",
    "text": "[G215] Providing controls to achieve the same result as path based or multipoint gestures\n\nDescription:\nThe objective of this technique is to ensure that users who have difficulties performing path-based gestures can operate a content slider with a single pointer (e.g., a single tap on a touch screen or a single mouse click). A content slider contains chunks of content in a row. Usually several chunks of content are hidden, and only one chunk is visible at any time. Left and right horizontal swiping over the visible part of the slider brings adjacent hidden chunks of content into view. Providing controls (for example, arrow buttons) as alternative means of input allows advancing the slider with single pointer input.\n\nExamples:\n- **Example 1:** A content slider allows users to swipe left and right to reveal adjacent chunks of content. There are also next and previous buttons that enable users to advance to the next or previous chunks of content.  ---",
    "referenced_by": [
      "2.5.1"
    ]
  },
  {
    "id": "G216",
    "type": "technique",
    "code": "G216",
    "text": "[G216] Providing single point activation for a control slider\n\nDescription:\nThe objective of this technique is to ensure that users who have difficulties performing path-based gestures can operate a control slider. A control slider is a track with a \"thumb\" that you move along the track to set a value.\n\nIt allows a user to set a value in a certain range, e.g. setting the volume, changing the hue value of a color, putting in the amount of money needed in a loan calculator, or picking a sum to be donated to a charity. A slider that requires path-based gestures would use swiping left or right to change the value, or dragging the thumb of the slider in a specific direction to change the value.\n\nA simple fallback for activation without a path-based gesture is to make the control slider track clickable. This way, a value can be specified using a single tap or click on the track.\n\nProviding controls (e.g., arrow buttons) as alternative also allows incrementing or decrementing the value with taps or clicks. This can allow for a more fine-grained setting of the value.",
    "referenced_by": [
      "2.5.1"
    ]
  },
  {
    "id": "F105",
    "type": "technique",
    "code": "F105",
    "text": "[F105] Failure of Success Criterion 2.5.1 due to providing functionality via a path-based gesture without simple pointer alternative\n\nDescription:\nThe objective of this Failure is to describe situations where authors have implemented a function that is operated via a path-based gesture, and no alternative ways of operating this function via simple pointer gestures exist.\n\nIf you did not create the content and functionality you can find path-based gestures by exploring the content on a touch screen, or checking the page code for the existence of specific event handlers such as touchstart or touchend. See the [Understanding document for Pointer Gestures](https://www.w3.org/WAI/WCAG22/Understanding/pointer-gestures.html) for more on the path-based gestures.\n\nNote: For functionality implemented with a path-based gesture, the possibility of also operating it via the keyboard is beneficial (and may serve to meet [Success Criterion 2.1.1 Keyboard](https://www.w3.org/WAI/WCAG22/Understanding/keyboard)). The point of Success Criterion 2.5.1, however, is to ensure that pointer users who on many devices will have no keyboard available, have alternative ways of operating the function via simple pointer input.\n\nExamples:\n- **Example 1**    ---",
    "referenced_by": [
      "2.5.1"
    ]
  },
  {
    "id": "G210",
    "type": "technique",
    "code": "G210",
    "text": "[G210] Ensuring that drag-and-drop actions can be cancelled\n\nDescription:\nThe objective of this technique is to ensure that users who use a path-based drag-and-drop action to move an item from the initial location to a drop target can abort the action after picking up the target. This can be done either by releasing the item outside a drop area, or by moving the item back to its original position in a separate action that undoes the first action. A third option is to have a step after the element is dropped onto target, either with a dialog asking for confirmation of the action when the item is dropped, or providing an undo command.\n\nOn touch screen devices, author-supplied path-based and multipoint gestures usually do not work when OS level assistive technologies (AT) like a built-in screenreader is turned on. AT generally consumes path-based or multipoint gestures so they would not reach the authored content. For example, a horizontal drag gesture may not move a slider thumb as intended by the author, but move the screen reader focus to the next or previous element. Some gestures may work if the user operates \"pass through gestures\" which are often unreliable as they may depend on factors of hardware, operating system, operating system \"skin\", operating system setting, or user agent.\n\nExamples:\n- **Example 1:** A site shows a file directory. Files can be picked up and moved over a trash can icon. When the picked-up file is released outside this target, it reverts to the old position.\n- **Example 2:** A site shows a file directory. Files can be picked up and moved over a trash can icon to delete it. When the picked-up file is released over the trash can, a modal dialog asks the user to confirm or cancel the delete action.\n- **Example 3:** A kanban implementation of a project planning site shows different columns for phases of an activity. Users can pick up and move icons representing planning items to another column. When an item has been picked up and now follows the pointer, it can be moved outside the drop targets (columns) and dropped there to cancel the action. The item will then jump back to the old position.\n- **Example 4:** A kanban implementation of an issue tracking system shows columns that indicate different phases in handling issues (such as new / processed / done / closed). There is no screen space outside the kanban columns. Users can pick up and move icons representing issues between columns. When an item has been dropped in another column, the action can be reversed by dragging the icon back to the original column where it will return to its original position (defined by sorting preferences).  ---",
    "referenced_by": [
      "2.5.2"
    ]
  },
  {
    "id": "G212",
    "type": "technique",
    "code": "G212",
    "text": "[G212] Using native controls to ensure functionality is triggered on the up-event.\n\nDescription:\nThe objective of this technique is to ensure that users who attempt to interact with a control do not trigger the action of the event accidentally. This can be accomplished most directly by relying on the pointer's up-event (for example, the onclick or mouseup event).\n\nThe easiest way to meet this success criterion is simply to use the default behavior of controls and not override that behaviour with an explicit down-event trigger. The up-event is the default behaviour for almost all controls and any programming or markup language.\n\nIn native languages where a control is fired on the down event it is usually for good reason and is easily recoverable. For instance, an HTML input element could have the cursor enter the editable area on the “pointer down” event, because the action is trivially reversible, and as such meets the requirements of the Pointer Cancellation SC. This is because if the user realizes they made a mistake after pressing down the control, they can simply move their pointer away from the hit area while still holding down the pointer, then release their pointer and the event is not triggered.\n\nExamples:\n- **Example 1: Using an native onclick event in JavaScript**  In JavaScript native onclick events are triggered on the up-event by default.\n- **Example 2: Using a native button or link in HTML**  In HTML native<button>or<a href ....>onclick events are triggered on the up-event by default.\n- **Example 3: Using a native button in iOS or Android**  In native buttons in iOS and Android onclick events are triggered on the up-event by default.    ---",
    "referenced_by": [
      "2.5.2"
    ]
  },
  {
    "id": "F101",
    "type": "technique",
    "code": "F101",
    "text": "[F101] Failure of Success Criterion 2.5.2 due to activating a control on the down-event\n\nDescription:\nThe objective of this Failure is to describe situations where:\n\nRather than taking advantage of the **click** event, authors may use down-events such as **mousedown**, **touchstart** or **pointerdown**. As a result, functionality will be executed as soon as a mouse button is pressed (but not released yet), or a finger or stylus makes contact with a touchscreen.\n\nIt is possible to use the down event and mitigate potential issues to avoid failing the Success Criterion. For example, provide a method to easily undo or abort the functionality, or reverse the outcome on the up-event (when the mouse button is released, or when the finger or stylus are lifted from the touchscreen). And note that some uses of the down-event are essential for the functionality (e.g., where the control simulates the operation of a musical instrument like a set of piano keys, or when the control is used as an on-screen control for a game where a fast and immediate response is required), in which case they would not fail this Success Criterion.\n\nExamples:\n- **Example 1: A close button that triggers on down-events**  A modal dialog contains a lengthy form that a user needs to complete. The modal provides a simple \"Close\" control that closes the dialog and loses all information the user may already have entered in the form. However, instead of simply listening to theclickevent - which in most user agents is triggered on the up-event - the author decided to close the dialog on the down-event. This may lead to the user accidentally closing the dialog and losing all the data they entered into the form up to that point.  ```html <!-- modal dialog with a form --> ... <button id=\"close\" type=\"button\">Close</button> ... ```  ```html const trigger = document.getElementById(\"close\");  function closeDialog() { /* close the modal dialog */ ... }  trigger.addEventListener('mousedown', closeDialog); trigger.addEventListener('touchstart', closeDialog); trigger.addEventListener('pointerdown', closeDialog); ```    ---",
    "referenced_by": [
      "2.5.2"
    ]
  },
  {
    "id": "G208",
    "type": "technique",
    "code": "G208",
    "text": "[G208] Including the text of the visible label as part of the accessible name\n\nDescription:\nThe objective of this technique is to ensure that speech input users can operate web content reliably.\n\nWhen speech input users interact with a web page, they usually speak a command followed by the reference to some visible label (like text in a button, the link text, or the text labelling input fields). For example, they may speak \"click search\" to activate a search button.\n\nWhen speech recognition software processes speech input and looks for matches, it uses the \"accessible name\" of controls, which can be different from the visible label. For example, a  button following a search input field may contain the text \"go\" but uses an invisible **aria-label** attribute with the value \"search\". Since aria-label takes precedence over the text included in the button, the accessible name of this button will be \"search\", not \"go\". The [Accessible Name and Description Computation](https://www.w3.org/TR/accname/) defines how the accessible name is constructed.\n\nIn situations where the visible label is considered inadequate as the accessible name, it is possible to supplement text in the accessible name. However, in order to meet 2.5.3 Label in Name, the text string that makes up the visible label must occur in its entirety in the accessible name. In most situations, where it is felt that additional context is needed, it is recommended that the visible text should precede the additional text. When authors make sure that the visible label of a control is included, intact, in the accessible name of that control, speech input users can be confident that their input will be correctly interpreted.\n\nExamples:\n- **Example 1: Link text matches the beginning of the accessible name**  A link contains visible text and hidden link text. Both together make up the link's accessible name. The visible text comes first. The idea is to make the link more descriptive for users of assistive technologies.\n- **Example 2: Generic link text concatenated with heading**  A generic link is combined with the heading of the paragraph to give context. It is a variation on the first example, this time usingaria-labelledby. The advantage of this implementation is that it uses existing visible text on the page, and so is more likely to be properly translated during any localization transformations.\n- **Example 3: Link text included inaria-label**  Where two strings cannot be grammatically or seamlessly combined usingaria-labelledby,aria-labelcan be used to make a new name which includes the visible label.\n- **Example 4: The visible button text matches the beginning of the accessible name**  The visible text inside abuttonelement matches the beginning of accessible name, which also includes hidden text. The idea of the hidden text is to make the button more descriptive for users of assistive technologies.    ---",
    "referenced_by": [
      "2.5.3"
    ]
  },
  {
    "id": "G211",
    "type": "technique",
    "code": "G211",
    "text": "[G211] Matching the accessible name to the visible label\n\nDescription:\nThe objective of this technique is to ensure that speech input users can operate web content reliably while not adversely affecting other users of assistive technology.\n\nWhen speech input users interact with a web page, they usually speak a command followed by the reference to some visible label (such as text beside an input field or inside a button or link). For example, they may say \"click search\" to activate a button labelled Search. When speech recognition software processes speech input and looks for matches, it uses the [accessible name](https://www.w3.org/TR/accname/) of controls. Where there is a mismatch between the text in the label and the text in the accessible name, it can cause issues for the user. The simplest way to enable speech input users and meet 2.5.3 Label in Name is to ensure that the accessible name matches the visible text label.\n\nSometimes more than one text string will be positioned in the vicinity of a control that could be considered a candidate for its label. For example, a set of inputs that each have their own labels may also be preceded by a heading, an instruction or a group label (such as an HTML legend/fieldset or an ARIA group or radiogroup). Note that the term \"group label\" means something different than \"label\", both programmatically and in regard to 2.5.3 Label in Name.\n\nThe [Understanding 2.5.3 Label in Name document](https://www.w3.org/WAI/WCAG22/Understanding/label-in-name) recommends that only the text string adjacent to or in close proximity to an input should be treated as the label when assessing a control's label for the purposes of meeting 2.5.3 (see the section \"Identifying label text for components\"). There are both practical and technical reasons for restricting the designation of an input's label in this way. The technical reasons are discussed in the Understanding document's section called Accessible Name and Description Computation specification.\n\nExamples:\n- **Example 1: Anchor text provides both the link's label and its accessible name**  Using conventional HTML, the text between theaelement's tags provides both the link's visible text and the accessible name \"Code of conduct\":\n- **Example 2: Text inlabelelement provides name for input viaforattribute**  The text between thelabeltags also serves as the checkbox input's accessible name \"Notify me of delays\" by using theforattribute which references theidof theinput.  ```html <input type=\"checkbox\" id=\"notification\" name=\"notify\" value=\"delays\"> <label for=\"notification\">Notify me of delays</label> ```\n- **Example 3: The button text provides the accessible name**  The text inside abuttonelement becomes both its visible label and its accessible name:\n- **Example 4: Simple Radio Button Group**  Radio buttons typically appear in a group, where each button is labelled and the group of buttons is preceded by information which explains or categorizes the group.  The label for each component should be restricted to \"Yes\" and \"No\". To meet1.3.1 Information and Relationshipsand3.3.2 Labels or Instructions, the \"Call me…\" text can be coded to convey the relationship to ATs, in this example by using afieldsetandlegend.  If the label is not restricted to the string adjacent to the radio button, multiple interpretations of what constitutes the label can result in less uniform functionality. If \"Yes\" alone is not the label for the first radio button, is it \"Call me when balance exceeds $10,000\"? Or is it a combination of text strings, in which case is the order \"Call me when balance exceeds $10,000 Yes\" or \"Yes, Call me when balance exceeds $10,000\"? Decisions to combine text strings can have negative effects on screen reader users since the order of concatenation can affect meaning. In this example, \"No, call me when balance exceeds $10,000\" could be very confusing to a screen reader user.  Working example of Simple Radio Button Group\n- **Example 5: Checkbox Groupings**  For checkbox groupings, implementations that attempt to incorporate more than just the immediate checkbox label into the accessible name can also be problematic if not isolated to the adjacent text string.  In Figure 2, there is a long text string that combines a group label and instruction, \"What do you value in our service (check all that apply)?\" Each of the checkboxes also has its own one- or two-word label. In regard to 2.5.3, the labels for the components should be restricted to \"Courtesy\", \"Promptness\", \"Store Hours\" and \"Knowledge\".  Attempting to include the preceding text as part of the accessible name can potentially make it more difficult to isolate a control by spoken commands for speech-input users. Such a construction will also negatively increase verbosity for screen reader users (with the combined text strings read out for each of the inputs before the input's state). The simplest solution is to restrict the accessible name to the text immediately beside the checkboxes, using similar techniques to those for the standard radio button group.\n- **Example 6: Stacked Labels**  Although labels for comboboxes, dropdown lists, text inputs, and other widgets are typically oriented immediately to the left of the component, there is an alternative established convention where labels are stacked above the inputs, aligned with their left edge.  In Figure 3, the inputs are stacked and left-aligned, with the labels immediately preceding each input, also left-aligned. There is additional white space between the label and the preceding input so that the label is closest to its associated text input. Stacked labels are relatively common in mobile designs, where horizontal space is constrained.  Figure 4 shows a variation on stacked labels, where hints and guidance are included between the label and the input. This design does not provide an adjacent label. However, the \"New Password\" label is still considered to be in close enough proximity, especially given its size and boldness relative to the smaller and lower-contrast guidance text. The associations are reinforced programmatically, where the hint text is given a role ofaria-describedbyand the label is properly associated with the input.  The hint text in such implementations should be kept to a single line where possible, since accessibility issues can arise where a more lengthy hint separates the label from its input. Figure 4 illustrates that the concept of \"adjacent text\" is a guide for label interpretation, but cannot always serve as a hard rule.  Working example of stacked labels\n- **Example 7: Range of inputs with few labels**  A less common disparity between labels and inputs can occur when a group of radio buttons is set up to elicit a choice across a range. The labels may only be located at each end of the range or may be interspersed at various points in the range.  The two labels, \"Hated it\" and \"Loved it\", are adjacent to the first and last radio buttons, and should be their accessible names. Speech-input users can speak either of these labels to select a radio button, and then use arrow navigation (e.g., \"Press right arrow\") to modify the selection. \"Rate your response\" is the text describing the whole widget and can be associated as the group label (here usinglegend). The three middle radio buttons do not have visible labels. In the code example they are given title attributes of \"Disliked\", \"So-so\" and \"Liked\" in order to meet 3.3.2 Labels or Instructions.  Working example of range of inputs  ```html <fieldset> <legend>Rate your response</legend> <label for=\"hated\">Hated it</label> <input type=\"radio\" name=\"meal\" id=\"hated\" value=\"hated\"> <input type=\"radio\" name=\"meal\" id=\"poor\" value=\"poor\" title=\"Disliked\"> <input type=\"radio\" name=\"meal\" id=\"neutral\" value=\"neutral\" title=\"So-so\"> <input type=\"radio\" name=\"meal\" id=\"okay\" value=\"okay\" title=\"Liked\"> <input type=\"radio\" name=\"meal\" id=\"loved\" value=\"loved\"> <label for=\"loved\">Loved it</label> </fieldset> ```\n- **Example 8: Text in parentheses and punctuation**  Technique G211 is not intended to complicate existing conventions for the construction of accessible form inputs. As described in thePunctuation and capitalizationandText in parenthesessubsections of the Understanding document, information does not always need to be included in the accessible name in an attempt to meet the Label in Name requirement, especially where the text would not normally be spoken when using speech recognition to navigate to controls. Where there are established ways of ensuring information and relationships conveyed visually are present programmatically, it is acceptable to leave text in parentheses and punctuation out of the accessible name.  The following snippet demonstrates possible techniques mentioned in the Understanding document. Since the required field is programmatically indicated, and the input restrictions on the date are surfaced througharia-describedby, the asterisk and parenthetical information has been left out of the accessible name.  <fieldset><legend>Rate your response</legend><label for=\"hated\">Hated it</label><input type=\"radio\" name=\"meal\" id=\"hated\" value=\"hated\"><input type=\"radio\" name=\"meal\" id=\"poor\" value=\"poor\" title=\"Disliked\"><input type=\"radio\" name=\"meal\" id=\"neutral\" value=\"neutral\" title=\"So-so\"><input type=\"radio\" name=\"meal\" id=\"okay\" value=\"okay\" title=\"Liked\"><input type=\"radio\" name=\"meal\" id=\"loved\" value=\"loved\"><label for=\"loved\">Loved it</label></fieldset>  Working example of range of inputs  ```html <label for=\"name\">Name</label> * <input type=\"text\" name=\"name\" id=\"name\" required> <label for=\"birth\">Birth date</label> <span id=\"mask\">(YYYY-MM-DD)</span> <input type=\"text\" name=\"birth\" id=\"birth\" aria-describedby=\"mask\"> ```    ---",
    "referenced_by": [
      "2.5.3"
    ]
  },
  {
    "id": "F96",
    "type": "technique",
    "code": "F96",
    "text": "[F96] Failure due to the accessible name not containing the visible label text\n\nDescription:\nThe objective of this Failure is to describe situations where speech input users cannot reliably speak the name of a control because it differs from the visible label.\n\nWhen speech input users interact with a web page, they usually speak a command followed by the reference to some visible label (like the text in a button or a link, or the text labelling some input). If the visible label does not match the accessible name of the control, speech users may be unable to directly activate that control.\n\nThere are techniques that go beyond the visible label text of elements. The idea is to provide more context for users of assistive technologies to whom the visible context may not be available. Examples are the use of accessible hidden (e.g., offscreen-positioned) text, the use of the aria-label attribute to overwrite the label text, or the use of the aria-labelledby attribute to compose a label text from one or more strings strings on the page.\n\nWhen the use of these techniques results in an accessible name in which the exact string of the visible label does not occur in the accessible name, speech users may be unable to activate that control. Refer to the [Accessible Name and Description Computation](https://www.w3.org/TR/accname/) algorithm to work out the order of precedence in computing the accessible name of a control.\n\nExamples:\n- **Example 1: Mismatch of visible button text and accessible name supplied via aria-label**  The text in a search button reads \"Go\" but the accessible name provided in an aria-label attribute is \"Find in this site\"  ```html <button id=\"sitesearch\" aria-label=\"Find in this site\">Go</button> ```\n- **Example 2: Invisible link text disrupts visible label text string in accessible name**  A download link reads \"Download specification\" but there is invisible link text so that the accessible name of that link is \"Download gizmo specification\". While the visible label text is contained in the accessible name, there is no string match which may prevent the link from being activated by speech input.  ```html <a href=\"#\">Download <span class=\"accessibly-hidden\">gizmo</span> specification</a> ```\n- **Example 3: Input with a hidden label carrying text that differs from the input's value attribute**  An input of type=\"submit\" with the value=\"search\" which is exposed as visible label of the input, has a programmatically linked and accessibly hidden label enclosing the text \"Find in this site\" referenced by aria-labelledby. Because aria-labelledby takes precedence over the value of the input, the accessible name of the input in most browser / screen reader combinations will be \"Find in this site\". Speech users speaking a command such as \"Click search\" will be unable to activate the input.  ```html <div id=\"hidden-label\">Find in this site</div> <input type=\"submit\" aria-labelledby=\"hidden-label\" value=\"search\"> ```    ---",
    "referenced_by": [
      "2.5.3"
    ]
  },
  {
    "id": "G213",
    "type": "technique",
    "code": "G213",
    "text": "[G213] Provide conventional controls and an application setting for motion activated input\n\nDescription:\nThe objective of this technique is to ensure that:\n\nWhen a device sensor such as an accelerometer or gyroscope is used to gather input:\n\nExamples:\n- **Example 1: Shake to undo**  After text is entered in a field, shaking a device shows a dialog offering users to undo the entry. Supporting use of the backspace key and/or providing a clear button next to the text field offers the same functionality.  Shake to undo can be turned off in a settings page.\n- **Example 2: Motion Activated Slider**  A slider can be adjusted by tipping the device to the left and right. There are also buttons to achieve the same functionality, and a tick-box that prevents the motion from having an effect.  Working example of aslider with motion actuation.    ---",
    "referenced_by": [
      "2.5.4"
    ]
  },
  {
    "id": "F106",
    "type": "technique",
    "code": "F106",
    "text": "[F106] Failure due to inability to deactivate motion actuation\n\nDescription:\nThis describes the failure condition that results when motion actuation can not be deactivated.  People who may accidentally activate sensors due to tremors or other motor impairments need the ability to turn off motion actuation to prevent such accidental triggering of functions.\n\nExamples:\n- **Example 1: Motion Activated Slider**  A slider which uses tilting motion to increase or decrease the value of an input, with no mechanism to deactivate the motion detection.  Working example of a motion activated slider that can not be deactivated    ---",
    "referenced_by": [
      "2.5.4"
    ]
  },
  {
    "id": "F98",
    "type": "technique",
    "code": "F98",
    "text": "[F98] Failure due to interactions being limited to touch-only on touchscreen devices\n\nDescription:\nThe objective of this Failure is to describe situations where users on devices that have a touchscreen are unable to use other input modalities available to them (such as an additional/external mouse or keyboard).\n\nThere are various methods and heuristics for web content to determine if a user's device has a touchscreen. However, even when a touchscreen is present, other input modalities may be available to users. It is not necessarily the case that the user will be interacting with the web content (exclusively, or at all) using the touchscreen.\n\nIf, when a touchscreen is detected, web content is designed to be operated exclusively through touch, these users will be unable to operate the content using their other (possibly preferred) input mechanisms.\n\nExamples:\n- **Example 1: Only using touch-specific JavaScript event listeners when a touchscreen is detected**  These types of approaches have historically been popular for \"mobile\" specific development, to ensure that touchscreen interactions are more responsive and immediate (due to the way that touch interactions used to add a delay of approximately 300ms between a \"tap\" interaction and the generic click event being fired).  Similarly, web content that omits relevant/necessary keyboard event listeners (e.g. for the correct keyboard interaction with a complex widget, such as a tab interface) when a touchscreen is detected - under the assumption that on a touch device, keyboard support won't be necessary.  ```html /* inferring the presence of a touchscreen based on support for the Touch Events API */  if (window.TouchEvent || ('ontouchstart' in window)) { /* set up event listeners for touch */ target.addEventListener('touchend', ...); ... } else { /* set up event listeners for mouse/keyboard */ target.addEventListener('click', ...); ... } ```  ```html /* inferring the presence of a touchscreen based on the CSS Media Queries 4 Interaction Media Features match for a \"coarse\" primary input mechanism */  if (window.matchMedia && window.matchMedia(\"(pointer:coarse)\").matches) { /* set up event listeners for touch */ target.addEventListener('touchend', ...); ... } else { /* set up event listeners for mouse/keyboard */ target.addEventListener('click', ...); ... } ```  ```html /* inferring the presence of a touchscreen based on the navigator.maxTouchPoints property defined in the Pointer Events API */  if (window.PointerEvent && ('maxTouchPoints' in navigator) && (navigator.maxTouchPoints > 0)) { /* no need to listen to keyboard - there's a touchscreen... */ ... } else { /* set up event listeners for keyboard interactions */ target.addEventListener('keyup', ...); ... } ```\n- **Example 2: Hiding/omitting controls for mouse and keyboard users when a touchscreen is detected**  Web content containing interactive widgets such as content carousels, with visible buttons to operate the widget (such as previous/next buttons, or a visible scrollbar/slider). These visible controls are hidden/omitted when a touchscreen is detected, under the assumption that users will simply use touch gestures to operate the widgets, and no other alternatives are then provided for keyboard or mouse users.  Depending on the specific implementation, authors may allow mouse interactions with widgets that mirror touch gestures - for instance, allowing mouse users to also drag/swipe carousels, rather than just relying on clickable previous/next controls or scrollbars. In these cases, hiding controls when a touchscreen is detected will still allow users to operate the widget with the mouse (unless this interaction has also been suppressed/omitted when the touchscreen was detected, as per the previous example). However, if the only keyboard-operable controls for the widget were hidden, and no alternative for keyboard users was provided (such as allowing cursor key operation), this situation would still fail Success Criterion 2.5.6.  ```html /* using CSS Media Queries 4 Interaction Media Features to hide particular elements in the page (such as a container with visible controls) when a \"coarse\" primary input is present */  @media (pointer: coarse) { #widget .controls { display: none; } } ```    ---",
    "referenced_by": [
      "2.5.6"
    ]
  },
  {
    "id": "G219",
    "type": "technique",
    "code": "G219",
    "text": "[G219] Ensuring that an alternative is available for dragging movements that operate on content\n\nDescription:\nThe objective of this Technique is to ensure that people with motor impairments who cannot carry out [dragging movements](https://www.w3.org/TR/WCAG22/#dfn-dragging-movements) are presented with an alternative [single pointer](https://www.w3.org/TR/WCAG22/#dfn-single-pointer) interaction that does not involve dragging.\n\nSome direct manipulation interfaces allow users to pick up targets and use dragging movements to move them to another position, for example, to change the position of an item in a priority list, or to move a task on a Kanban or planning board.\n\nSuch dragging movements are difficult or impossible to carry out for some users with motor disabilities. The alternative to dragging movements operates the underlying function by one or several [single pointer](https://www.w3.org/TR/WCAG22/#dfn-single-pointer) activations that don't require dragging. A single tap or click may reveal controls (arrows) to move a target in a stepwise fashion; open a drop-down menu where the drop position can be selected; or allow moving it to an ajacent postion by a swipe gesture.\n\nExamples:\n- **Example 1**    ---",
    "referenced_by": [
      "2.5.7"
    ]
  },
  {
    "id": "F108",
    "type": "technique",
    "code": "F108",
    "text": "[F108] Failure of Success Criterion 2.5.7 Dragging Movements due to not providing a single pointer method for the user to operate a function that does not require a dragging movement\n\nDescription:\nThe objective of this failure is to avoid situations in which people with motor impairments who cannot operate content because the only way to actuate a function is by dragging a target element from its initial position to some other position. The failure occurs when there is no alternative single pointer input available to actuate the function. The alternative may involve a series of single pointer interactions (for example, activating a target to be moved; opening a dropdown menu; and selecting a drop destination from the list of menu items offered).\n\nExamples:\n- **Example 1: List re-ordering**  A list of items can be re-ordered by picking up an item and dragging it upwards or downwards. Other elements move dynamically to open a gap where the picked-up target can be dropped. There is no alternative way to re-order the list that can be executed via asingle pointerinput.\n- **Example 2: Kanban board**  In a Kanban implementation for process management, tasks can be dragged horizontally across from one ‘swimming lane’ to another in order to change the status of tasks (for example, to change the status of a task from “in process” to “completed”). There is no alternative way to move targets between lanes that can be executed via asingle pointerinput.    ---",
    "referenced_by": [
      "2.5.7"
    ]
  },
  {
    "id": "C42",
    "type": "technique",
    "code": "C42",
    "text": "[C42] Using min-height and min-width to ensure sufficient target spacing\n\nDescription:\nThe objective of this technique is to ensure that links in navigation or pagination menus will be spaced so that they fall within an area that measures at least 44 × 44 CSS pixels if the target area itself is smaller than that. The aim is to provide an adequate target clearance so the offset to adjacent targets is sufficient to prevent accidental pointer activation of adjacent targets.\n\nExamples:\n- **Example 1: Using a display value ofinline-block,min-height, andmin-width**  The first example shows a situation where the targets (in this case, the linked numbers in the pagination navigation) are smaller than 44 × 44 CSS pixels. However, the list items that contain them have a minimum height and width of 44 px set, so that sufficient target spacing is assured.  ```html <nav aria-label=\"pagination\"> <ol class=\"pagination-1\"> <li><a class=\"previous\">previous</a></li> <li><a aria-current=\"page\">1</li> <li><a href=\"/page-2\">2</a></li> <li><a href=\"/page-3\">3</a></li> <li><a href=\"/page-4\">4</a></li> <li><a href=\"/page-5\">5</a></li> <li><a href=\"/pages-6-10\">next</a></li> </ol> </nav> ```  ```html .pagination-1 li { display: inline-block; min-height: 44px; min-width: 44px; } ```\n- **Example 2: Using adisplayvalue offlexandmin-height/width**  The second example usesmin-widthandmin-heighton the targets (the linked numbers in the pagination menu) and not on the parent container, thereby meeting this target spacing success criterion and incidentally also the AAA Success Criterion 2.5.5 Target Size.  ```html <nav aria-label=\"pagination\"> <ol class=\"pagination-2\"> <li><a class=\"previous\">previous</a></li> <li><a aria-current=\"page\">1</li> <li><a href=\"/page-2\">2</a></li> <li><a href=\"/page-3\">3</a></li> <li><a href=\"/page-4\">4</a></li> <li><a href=\"/page-5\">5</a></li> <li><a href=\"/pages-6-10\">next</a></li> </ol> </nav> ```  ```html .pagination-2 { display: flex; flex-wrap: wrap; }  ol.pagination-2 a { display: block; line-height: 44px; min-height: 44px; min-width: 44px; } ```    ---",
    "referenced_by": [
      "2.5.8"
    ]
  },
  {
    "id": "H57",
    "type": "technique",
    "code": "H57",
    "text": "[H57] Using the language attribute on the HTML element\n\nDescription:\nThe objective of this technique is to identify the default language of a document by providing the **lang** attribute on the **html** element.\n\nIdentifying the language of the document is important for a number of reasons:\n\n- It allows braille translation software to substitute control codes for accented characters, and insert control codes necessary to prevent erroneous creation of Grade 2 braille contractions.\n- Speech synthesizers that support multiple languages will be able to orient and adapt to the pronunciation and syntax that are specific to the language of the page, speaking the text in the appropriate accent with proper pronunciation.\n- Marking the language can benefit future developments in technology, for example users who are unable to translate between languages themselves will be able to use machines to translate unfamiliar languages.\n- Marking the language can also assist user agents in providing definitions using a dictionary.\n\nExamples:\n- **Example 1: Defining the content of an HTML document to be in French**  ```html <!doctype html> <html lang=\"fr\"> <head> <meta charset=\"utf-8\"> <title>document écrit en français</title> </head> <body> ... document écrit en français ... </body> </html> ```    ---",
    "referenced_by": [
      "3.1.1"
    ]
  },
  {
    "id": "PDF16",
    "type": "technique",
    "code": "PDF16",
    "text": "[PDF16] Setting the default language using the /Lang entry in the document catalog of a PDF document\n\nDescription:\nThe objective of this technique is to specify a document's default language by setting the **/Lang** entry in the document catalog. This is normally accomplished using a tool for authoring PDF.\n\nBoth assistive technologies and conventional user agents can render\ntext more accurately when the language of the document is identified.\nScreen readers can load the correct pronunciation rules. Visual browsers\ncan display characters and scripts correctly. Media players can show\ncaptions correctly. As a result, users with disabilities are better\nable to understand the content.\n\nExamples:\n- **Example 1: Adding a/Langentry to specify the default document language using Adobe Acrobat Pro**  This example is shown with Adobe Acrobat Pro. There are other software tools that perform similar functions.\n- **Example 2: Specifying the default document language in a PDF document using a/Langentry**  The natural language used for text in a document is determined in a hierarchical fashion, based on whether an optional/Langentry is present in any of several possible locations. At the highest level, the document's default language may be specified by a/Langentry in the document catalog.  The following code fragment illustrates code that is typical for using the/Langentry in the document catalog for a document's default language (in this case English). (This is typically accomplished by an authoring tool.)  ```html 1 0 obj << /Type /Catalog ... /Lang (en) ... >> endobj ```    ---",
    "referenced_by": [
      "3.1.1"
    ]
  },
  {
    "id": "PDF19",
    "type": "technique",
    "code": "PDF19",
    "text": "[PDF19] Specifying the language for a passage or phrase with the Lang entry in PDF documents\n\nDescription:\nThe objective of this technique is to specify the language of a passage,\nphrase, or word using the **/Lang** entry to provide information in the\nPDF document that user agents need to present text and other linguistic\ncontent correctly. This is normally accomplished using a tool for authoring\nPDF.\n\nBoth assistive technologies and conventional user agents can render\ntext more accurately when the language is identified. Screen readers\ncan load the correct pronunciation rules. As a result, users with disabilities are better able to understand the content.\n\nExamples:\n- **Example 3: Specifying the language for a word or phrase in a PDF document using a/Langentry**  Below the level of the default document language, the language for a passage may be specified for the following items:  The following code fragment illustrates code that is typical for using the/Langentry to override the default document language by specifying a marked-content sequence within a page's content stream:  The following code fragment illustrates code that is typical for using the/Langentry in the structure element dictionary. In this case, the/Langentry applies to the marked-content sequence having an MCID (marked-content identifier) value of 0 within the indicated page's content stream.  ```html /P % Start of marked-content sequence BDC (See you later, or in Spanish you would say, ) Tj /Span << /Lang (es-MX) >>% Start of nested marked-content sequence BDC (Hasta la vista.) Tj EMC% End of nested marked-content sequence EMC% End of marked-content sequence ```  ```html 1 0 obj% Structure element << /Type /StructElem /S /Span% Structure type /P /P% Parent in structure hierarchy /K<< /Type /MCR /Pg 2 0 R% Page containing marked-content sequence /MCID 0% Marked-content identifier >> /Lang (es-MX)% Language specification for this element >> endobj 2 0 obj% Page object << /Type /Page /Contents 3 0 R% Content stream … >> endobj 3 0 obj% Page's content stream << /Length … >> stream BT /P % Start of marked-content sequence BDC (See you later, or in Spanish you would say, ) Tj /Span << /MCID 0 >>% Start of nested marked-content sequence BDC (Hasta la vista.) Tj EMC% End of nested marked-content sequence EMC% End of marked-content sequence ET endstream endobj ```    ---\n- **Example 2: Adding a/Langentry to specify the language for a specific word or phrase using Adobe Acrobat Pro**  This example is shown with Adobe Acrobat Pro. There are other software tools that perform similar functions.  When you tag a word or phrase, Acrobat splits the original content into three document content tags: one for the text that precedes your selection, one for the selection, and one for the text that follows the selection. As needed, drag the document content tag for the selected text into position between the other two tags, so that the text reads in the proper order. All three tags must also be at the same level beneath their parent tag. Drag them into place if they are not.  This example is shown in operation in theworking example of marking a specific word or phrase in Acrobat Pro (PDF).\n- **Example 1: Adding a/Langentry to specify the language for a paragraph using Adobe Acrobat Pro**  This example is shown with Adobe Acrobat Pro. There are other software tools that perform similar functions.",
    "referenced_by": [
      "3.1.1",
      "3.1.2"
    ]
  },
  {
    "id": "SVR5",
    "type": "technique",
    "code": "SVR5",
    "text": "[SVR5] Specifying the default language in the HTTP header\n\nDescription:\nThe objective of this technique is to provide information on the  primary language or languages in a web page, in order to identify the  audience of the content. The **Content-Language** HTTP header can contain a  list of one or more language codes, which can be used for language  negotiation between a user agent and a server. If the language  preferences in a user agent are set correctly, language negotiation can  help the user to find a language version of the content that suits their preferences.\n\nNote that the Content-Language HTTP header does not serve to  identify the language used for processing the content. The content  processing language can be identified by means of other techniques, such as the attributes **lang** and **xml:lang** in markup languages.\n\nThis technique ensures that the primary language of the  document, as specified for example in the **lang** or **xml:lang** attribute, is listed in the **Content-Language** HTTP header.\n\nExamples:\n- **Example 1: Setting content language in Java Servlet andJSP**  In Java Servlet or JavaServer Pages (JSP), developers can useresponse.setHeader(\"Content-Language\", lang), in which \"lang\" stands for a language tag (for example,\"en\"for English):  ```html ... public void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { ... response.setHeader(\"Content-Language\", \"en\"); PrintWriter out = response.getWriter(); ... } ```\n- **Example 2: Setting content language inPHP**  In PHP, developers can send a rawHTTPheader with the header method. The following example sets the language to French:  ```html <?php header('Content-language: fr'); ... ?> ```    ---",
    "referenced_by": [
      "3.1.1"
    ]
  },
  {
    "id": "H58",
    "type": "technique",
    "code": "H58",
    "text": "[H58] Using language attributes to identify changes in the human language\n\nDescription:\nThe objective of this technique is to clearly identify any changes in language on a page by using the **lang** attribute.\n\nAllowed values for the **lang** attribute are indicated in the resources referenced below. Language tags use a primary code to indicate the language, and optional sub-codes (separated by hyphen characters) to indicate variants of the language. For instance, English is indicated with the primary code **\"en\"**; British English and American English can be distinguished by using **\"en-GB\"** and **\"en-US\"**, respectively. Use of the primary code is important for this technique. Use of sub-codes is optional but may be helpful in certain circumstances.\n\nExamples:\n- **Example 1: The use of thelangattribute to define a quote written in German**  ```html <blockquote lang=\"de\"> <p> Da dachte der Herr daran, ihn aus dem Futter zu schaffen, aber der Esel merkte, daß kein guter Wind wehte, lief fort und machte sich auf den Weg nach Bremen: dort, meinte er, könnte er ja Stadtmusikant werden. </p> </blockquote> ```    ---",
    "referenced_by": [
      "3.1.2"
    ]
  },
  {
    "id": "G101",
    "type": "technique",
    "code": "G101",
    "text": "[G101] Providing the definition of a word or phrase used in an unusual or restricted way\n\nDescription:\nThe objective of this technique is to provide a definition for any word used in an unusual or restricted way.\n\nA word is used in an unusual or restricted way when:\n\n- dictionaries give several definitions of the word but one specific definition must be used in order to understand the content;\n- a specific definition must be used in order to understand the content and dictionaries list that definition as rare, archaic, obsolete, etc.;\n- the author creates a new definition that must be used in order to understand the content.\n\nThis technique can also be used to provide definitions for jargon, that is, the specialized vocabulary used in a particular profession or technical field and understood by people in that field but not by people outside the field.\n\nThe technique can also be used to define idiomatic expressions.  For example, speakers of a language who live in a particular region may use idiomatic expressions that are accepted by everyone in the region but not by people from other regions where the same language is spoken.\n\nExamples:\n- **Example 1: A term used in a restricted way**  The word \"technology\" is widely used to cover everything from the stone tools used by early humans to contemporary digital devices such as cell phones.  But in WCAG 2.0, the word technology is used in a more restricted way:  it means a mechanism for encoding instructions to be rendered, played or executed by user agents, including  markup languages, data formats, and programming languages used in producing and delivering Web content.\n- **Example 2: A word used according to an obsolete definition**  The word \"ether\" is defined as a substance that filled interplanetary space:  \"He believed that sound traveled through the ether.\"\n- **Example 3: Jargon**  The word \"driver\" is defined as software that contains specific instructions for a printer: \"It may be necessary to update the driver for your printer.\"\n- **Example 4: An idiomatic expression**  Some people say \"spill the beans\" when they mean \"reveal a secret\", e.g., \"In the police station, Joe spilled the beans about the plot to kidnap the prime minister.\"\n- **Example 5: An idiomatic expression in Japanese**  This example uses parentheses to provide the definition of an idiomatic expression in Japanese. The phrase in Japanese says that \"he throws a spoon.\" It means that there was nothing he can do and finally he gives up.  さじを投げる（どうすることもできなくなり、あきらめること）。\n- **Example 6: An unfamiliar adopted foreign word in English**  Users may not understand the meaning of an unfamiliar word adopted from another language: \"We need to leave town pronto (quickly).\n- **Example 7: Unfamiliar adopted words in Japanese**  In Japanese, Kata-kana is used for adopted foreign words. If words are unfamiliar to users, provide the meaning or translation so that users can understand them.  アクセシビリティ（高齢者・障害者を含む全ての人が利用できること）は、Webサイトに不可欠である。  English translation: \"Accessibility\" (it can be accessed by all users including elderly people and people with disabilities) is an essential aspect of the Websites.  レイアウトテーブルとCSSの併用をハイブリッド（複合型）という。  English translation: Using both layout table and CSS is called \"hybrid\" (combination of multiple forms).    ---",
    "referenced_by": [
      "3.1.3"
    ]
  },
  {
    "id": "G55",
    "type": "technique",
    "code": "G55",
    "text": "[G55] Linking to definitions\n\nDescription:\nThe objective of this technique is to make the definition of a word, phrase, or abbreviation available by providing the definition, either within the same web page or in a different web page, and establishing a link between the item and its definition.\n\nLinks are a powerful option for providing access to the definition of a word, phrase, or abbreviation. A user can use the link to find the definition quickly and easily, and then return to their place in the content via the user agent's Back button.\n\nExamples:\n- **Example 1**  Technical terms and abbreviations in an article about sports injuries are linked to definitions in a medical dictionary.\n- **Example 2**  A textbook contains a glossary of new vocabulary words introduced in each chapter. The first occurrence of each of these words is linked to its definition in the glossary.\n- **Example 6**  A Japanese idiom is linked to its definition. This example uses a link within the page to navigate to the definition of an idiomatic expression.  ```html <p>...<a href=\"#definition\">さじを投げる</a>...</p> <h3>脚注：</h3> <dl> <dt id=\"definition\">さじを投げる</dt> <dd>どうすることもできなくなり、あきらめること。</dd> </dl> ```    ---\n- **Example 4**  The wordjargonis linked to its definition in the WCAG2 Glossary.\n- **Example 5**  The word \"modulo\" is jargon used in Web content about mathematics. A definition for modulo is included within the web page. Each occurrence of the word modulo is linked to its definition.\n- **Example 3**  A general glossary of abbreviations is provided. All occurrences of abbreviations are linked directly to the appropriate definition within that glossary.",
    "referenced_by": [
      "3.1.3",
      "3.1.4"
    ]
  },
  {
    "id": "H40",
    "type": "technique",
    "code": "H40",
    "text": "[H40] Using description lists\n\nDescription:\nThe objective of this technique is to provide the description of names or terms by presenting them in a description list. The list is marked up using the **dl** element. Within the list, each term is put in a separate **dt** element, and its description goes in the **dd** element directly following it. Multiple terms can be associated with a single description, as can a single term with multiple descriptions, provided that semantic sequence is maintained. The **title** attribute can be used to provide additional information about the description list. Usage of description lists ensures that terms and their descriptions are semantically related even as presentation format changes, as well as ensuring that these terms and descriptions are semantically grouped as a unit.\n\nDescription lists are easiest to use when the descriptions are ordered alphabetically. A common use for description lists is a glossary of terms.\n\nExamples:\n- **Example 1**  A list of descriptions of nautical terms used on a website about sailing.  ```html <dl title=\"Nautical Terms\"> <dt>Knot</dt> <dd> A <i>knot</i> is a unit of speed equaling 1 nautical mile per hour (1.15 miles per hour or 1.852 kilometers per hour). </dd> <dt>Port</dt> <dd> <i>Port</i> is the nautical term (used on boats and ships) that refers to the left side of a ship, as perceived by a person facing towards the bow (the front of the vessel). </dd> <dt>Starboard</dt> <dd> <i>Starboard</i> is the nautical term (used on boats and ships) that refers to the right side of a vessel, as perceived by a person facing towards the bow (the front of the vessel). </dd> </dl> ```    ---",
    "referenced_by": [
      "3.1.3"
    ]
  },
  {
    "id": "G112",
    "type": "technique",
    "code": "G112",
    "text": "[G112] Using inline definitions\n\nDescription:\nThe objective of this technique is to provide a definition in context for any word used in an unusual or restricted way. The definition is provided in the text, either just before or just after the word is used. The definition may be included in the same sentence as the word that is being defined, or in a separate sentence.\n\nExamples:\n- **Example 1: Ether**  He believed that sound traveled through the ether, which was thought to be a substance that filled interplanetary space.\n- **Example 2: Driver**  It may be necessary to update the driver for your printer (the driver is software that contains specific instructions for your printer).\n- **Example 3: W3C key words**  Definition: The key words \"must\", \"must not\", \"required\", \"shall\", \"shall not\", \"should\", \"should not\", \"recommended\", \"may\", and \"optional\" in this specification are to be interpreted as described inRFC 2119.\n- **Example 4: A Japanese idiomatic expression defined in context**  This example uses parentheses to provide the definition of an idiomatic expression in Japanese. The phrase in Japanese says that \"he throws a spoon.\" It means that there was nothing he can do and finally he gives up.  さじを投げる（どうすることもできなくなり、あきらめること）。    ---",
    "referenced_by": [
      "3.1.3"
    ]
  },
  {
    "id": "H54",
    "type": "technique",
    "code": "H54",
    "text": "[H54] Using the dfn element to identify the defining instance of a word\n\nDescription:\nThe objective of this technique is to use the **dfn** to mark the use of a\nword or phrase where it is defined. The **dfn** element is used to indicate the\ndefining instance of the enclosed term. In other words, it marks the occurrence of the\nterm where the term is defined. Note that it encloses the term, not the definition. This\ntechnique would be used in combination with [Using\ninline definitions](../general/G112) to provide the definition.\n\nExamples:\n- **Example 1**  ```html <p>The Web Content Accessibility Guidelines require that non-text content has a text alternative. <dfn>Non-text content</dfn> is content that is not a sequence of characters that can be programmatically determined or where the sequence is not expressing something in human language; this includes ASCII Art (which is a pattern of characters), emoticons, leetspeak (which is character substitution), and images representing text.</p> ```    ---",
    "referenced_by": [
      "3.1.3"
    ]
  },
  {
    "id": "G62",
    "type": "technique",
    "code": "G62",
    "text": "[G62] Providing a glossary\n\nDescription:\nThe objective of this technique is to make the definition of a word, phrase, or abbreviation available by providing the definition in a glossary. A glossary is an alphabetical list of words, phrases, and abbreviations with their definitions. Glossaries are most appropriate when the words, phrases, and abbreviations used within the content relate to a specific discipline or technology area. A glossary can also provide the pronunciation of a word or phrase.\n\nThe glossary is included at the end of the web page or the glossary is located via one of the mechanisms for locating content within a set of web pages. (See [Understanding Success Criterion 2.4.5](https://www.w3.org/WAI/WCAG22/Understanding/multiple-ways).)\n\nIf the glossary contains several definitions for the same word, phrase, or abbreviation, simply providing the glossary is not sufficient to satisfy this Success Criterion.  A different technique should be used to find the correct definition. This is especially important if the uses of the word, phrase, or abbreviation are not unique within the web page, that is, if different occurrences of the item have different definitions.\n\nExamples:\n- **Example 3**  A textbook contains a glossary of new vocabulary words introduced in each chapter.\n- **Example 1**  Users of on line chat forums have created several acronyms and abbreviations to speed up typing conversations on the computer. For example, LOL refers to \"laughing out loud\" and FWIW abbreviates \"for what it's worth\". The site provides a glossary page that lists the expansions for the commonly used acronyms and abbreviations.\n- **Example 5: A glossary of idiomatic expressions**  The American novel \"The Adventures of Huckleberry Finn\" includes many idiomatic expressions that were used in the southwestern United States in the 1840s. In an online edition designed for students, each idiomatic expression is linked to an item in the glossary.    ---\n- **Example 4**  Dutch text uses the phrase 'Hij ging met de kippen op stok' (He went to roost with the chickens). The glossary explains that this phrase means 'Hij ging vroeg naar bed' (He went to bed early).\n- **Example 2**  A web page discussing mathematical theory includes a glossary of commonly used mathematical terms, abbreviations and acronyms.",
    "referenced_by": [
      "3.1.3",
      "3.1.4",
      "3.1.6"
    ]
  },
  {
    "id": "G70",
    "type": "technique",
    "code": "G70",
    "text": "[G70] Providing a function to search an online dictionary\n\nDescription:\nThe objective of this technique is to provide the definition of words, phrases, jargon, or abbreviation expansions by adding a mechanism to access an on-line dictionary to the web page. This technique uses existing resources on the Web to provide the definition rather than requiring the author to create a glossary or other mechanism within the site. By providing access from within the web page, a user can easily locate the desired definition. This technique can only be used if the online dictionary returns the correct definition.\n\nExamples:\n- **Example 2**  An online course in English grammar provides a paragraph of text which introduces new vocabulary words. Each of the vocabulary words is a link to an on-line dictionary to find the definition of the word. Activating a link will open up a new window to an online dictionary site with the specific vocabulary word defined.    ---\n- **Example 1**  A site that describes how a computer works would include a search feature on each web page. The search would be performed against an on-line dictionary of computer terms, acronyms, and abbreviations. Since the dictionary is specialized for computer terms, the acronym expansion found should be more accurate than with a general dictionary.",
    "referenced_by": [
      "3.1.3",
      "3.1.4"
    ]
  },
  {
    "id": "G102",
    "type": "technique",
    "code": "G102",
    "text": "[G102] Providing the expansion or explanation of an abbreviation\n\nDescription:\nThe objective of this technique is to provide information necessary to understand an abbreviation.\n\nAn abbreviation is the shortened form of a word, phrase, or name. For most abbreviations, providing the full word, phrase, or name is sufficient.\n\nSome abbreviations represent words or phrases that are borrowed from a foreign language. For instance, many commonly used abbreviations in English are derived from Latin phrases, such as the short list of examples given below. The expanded form is only provided here as background information. For this category of abbreviations, providing an explanation is more helpful than the original expanded form, and the explanation of the abbreviation is provided instead of the expansion.\n\nIf abbreviations do not need an expansion (for example, because the original expansion has been rejected by the organization that it refers to or if the abbreviation has become part of the language), provide an explanation, if appropriate, or treat the abbreviation as a word that does not require explanation.\n\nExamples:\n- **Example 1: ADA**  Some abbreviations have more than one meaning, and the meaning depends on the context. For example, ADA means \"American Dental Association\" in one context and \"Americans with Disabilities Act\" in another. Only the expansion relevant to the context needs to be provided.\n- **Example 2: English abbreviations for phrases borrowed from Latin**  In the following sentence, the explanation \"for example\" would be provided for \"e.g.\": Students participating in team sports, e.g., basketball or football, must set their schedules around team practice time.\n- **Example 3: ABS**  Some languages (including English and Dutch) borrowed the acronym ABS (Antiblockiersystem: anti-lock brakes) from German. An explanation (anti-lock brakes) is provided, rather than the expansion\n- **Example 4: acronyms with no expansion**  Examples of acronyms which no longer have expansions include  For this category of examples, a short explanation of what the organization is or does is sufficient.\n- **Example 5: Phrases that were once abbreviations, but have become part of the language**  The Dutch fragment \"'s nachts\" meaning \"at night\" was originally an abbreviation for \"des nachts\". In the current Dutch language, the word \"des\" is rarely used anymore and perceived as archaic. Providing an expansion could be confusing. For \"'s nachts\" an expansion is not provided.  The English phrase \"o'clock\" was originally an abbreviation for \"of the clock\". Since then, \"o'clock\" has become part of the English language and an expansion does not need to be provided.    ---",
    "referenced_by": [
      "3.1.4"
    ]
  },
  {
    "id": "G97",
    "type": "technique",
    "code": "G97",
    "text": "[G97] Providing the first use of an abbreviation immediately before or after the expanded form\n\nDescription:\nThe objective of this technique is to make the expanded form of an abbreviation available by associating the expanded form with its abbreviation the first time it occurs within a web page. The expansion of any abbreviation can be found by searching the web page for the first use.\n\nFor English, when shortening a word, phrase or name by means of an abbreviation, initialism, acronym, or other shortened form, it is advisable to provide the full form before providing the abbreviated form. This makes the text easier to read and is advised by many style guides. Other languages may have different conventions.\n\nNote that some abbreviations require explanations rather than expansions. This technique is not appropriate for such abbreviations.\n\nThis technique is applied to the first occurrence of an abbreviation in a web page. When combining multiple resources into a single web page, the abbreviation would be expanded at the beginning of each resource. In this case, however, using a different technique for providing the expanded form may be more appropriate.\n\nExamples:\n- **Example 1**  \"The United Nations High Commissioner for Human Rights (UNHCR) was established in 1950 to provide protection and assistance to refugees.\"  \"The WAI (Web Accessibility Initiative) demonstrates the W3C commitment to accessibility.\"    ---",
    "referenced_by": [
      "3.1.4"
    ]
  },
  {
    "id": "H28",
    "type": "technique",
    "code": "H28",
    "text": "[H28] Providing definitions for abbreviations by using the abbr element\n\nDescription:\nThe objective of this technique is to provide expansions or definitions for\nabbreviations by using the **abbr** element. It is always appropriate to use the **abbr** element for any abbreviation, including acronyms and initialisms.\n\nThis technique has been altered from a sufficient technique to an advisory technique because it uses the **title** attribute of **abbr** to provide the expansion of the abbreviation needed to achieve a sufficient technique when used in combination with [G102](../general/G102). As noted in the [specification](https://html.spec.whatwg.org/multipage/dom.html#the-title-attribute):\n\nExamples:\n- **Example 1: Usingabbrelement to expand abbreviations**  ```html <p>Sugar is commonly sold in 5 <abbr title=\"pound\">lb.</abbr> bags.</p> <p>Welcome to the <abbr title=\"World Wide Web\">WWW</abbr>!</p> ```\n- **Example 2: Usingdfnandabbrelement to define abbreviations**  ```html <p>Tasini <dfn id=\"etal\"><abbr title=\"and others\">et al.</abbr></dfn> <abbr title=\"versus\">v.</abbr> The New York Times <abbr title=\"and others\">et al.</abbr> is the landmark lawsuit brought by members of the National Writers Union against ... </p> ```\n- **Example 3: Using theabbrelement to expand an acronym**  ```html <p>Recent updates to the <abbr title=\"Cascading Style Sheets\">CSS</abbr> color module ...</p> ```\n- **Example 4:  Using theabbrelement to expand an initialism**  ```html <p><abbr title=\"British Broadcasting Corporation\">BBC</abbr></p> ```    ---",
    "referenced_by": [
      "3.1.4"
    ]
  },
  {
    "id": "PDF8",
    "type": "technique",
    "code": "PDF8",
    "text": "[PDF8] Providing definitions for abbreviations via an E entry for a structure element\n\nDescription:\nThe objective of this technique is to provide an expansion or definition of an abbreviation for the first occurrence of the abbreviation. For example, a reference to an abbreviation, such as \"WCAG\", should be available as \"Web Content Accessibility Guidelines (WCAG)\" on its first occurrence in a document.\n\nThis is done by setting expansion text using an **/E** entry for a structure element, and is normally accomplished using a tool for authoring PDF. A **Span** structure element is typically used to tag the abbreviation, but the **/E** entry is valid with any structure element.\n\nThis technique is applicable for any abbreviation, including acronyms and initialisms. Note that on the first occurrence of the abbreviation, both the abbreviation and the expansion text must be provided. This will aid recognition of later use of the abbreviation.\n\nPDF documents may be enhanced by providing expansions for abbreviations. In fact, such expansions are required for accessibility to ensure understanding by people who have difficulty decoding words; rely on screen magnification (which may obscure context); have limited memory; or who have difficulty using context to aid understanding.\n\nExamples:\n- **Example 1: Adding an/Eentry to an abbreviation using Adobe Acrobat Pro's Tags panel**  This example is shown with Adobe Acrobat Pro. There are other software tools that perform similar functions.  In a tagged PDF document:  The following image illustrates this technique:  This example is shown in operation in:\n- **Example 2: Using a/Spanstructure element with an/Eentry to define an abbreviation**  The following code fragment illustrates code that is typical for using the/Spanstructure element to define an abbreviation.  This example uses the sentence \"Sugar is commonly sold in 5 lb bags.\" The abbreviation \"lb\" is tagged as a/Spanstructure element with an/Eentry (typically accomplished by an authoring tool).  ```html 1 0 obj                                  % structure element << /Type /StructElemen /S /Span                      % element type /P ...                        % Parent in structure hierarchy /K << /Type /MCR /Page 2 0 R        % Page containing marked-content sequence /MCID 0             % Marked content identifier for \"lb\" >> /E  (pound, lb) >> endobj ```\n- **Example 3: Using a/THstructure element with an/Eentry to define an abbreviation**  As noted in the Description, the/Eentry is valid with any structure element.  The following code fragment illustrates code that is typical for using an/Eentry to define an abbreviation.  A table that contains columns for each month uses abbreviations as the values of column headers. The expansion for each abbreviation is provided as the/Eentry of the/THstructure element (typically accomplished by an authoring tool).  ```html 1 0 obj                                  % structure element << /Type /StructElemen /S /TH                        % element type /P ...                        % Parent in structure hierarchy /K << /Type /MCR /Page 2 0 R       % Page containing marked-content sequence /MCID 0           % Marked content identifier for \"Dec\" >> /E  (December, Dec) >> endobj ```    ---",
    "referenced_by": [
      "3.1.4"
    ]
  },
  {
    "id": "G86",
    "type": "technique",
    "code": "G86",
    "text": "[G86] Providing a text summary that can be understood by people with lower secondary education level reading ability\n\nDescription:\nThe objective of this technique is to provide a summary of complex content. The summary is provided in addition to the original content.\n\nUsers with disabilities that make it difficult to decode words and sentences are likely to have trouble reading and understanding complex text. This technique provides a short statement of the most important ideas and information in the content. The summary is easier to read because it uses shorter sentences and more common words than the original.\n\nThe following steps can be used to prepare the summary:\n\nExamples:\n- **Example 1: A technical article with a readable summary**  An article describes a technical innovation. The first item after the title of the article is a section with the heading, “Summary.\" The average length of the sentences in the summary is 16 words (compared to 23 words for sentences in the article), and it uses short, common words instead of the technical jargon in the article.  A readability formula is applied; the summary requires reading ability less advanced than the lower secondary education level.    ---",
    "referenced_by": [
      "3.1.5"
    ]
  },
  {
    "id": "G103",
    "type": "technique",
    "code": "G103",
    "text": "[G103] Providing visual illustrations, pictures, and symbols to help explain ideas, events, and processes\n\nDescription:\nThe objective of this technique is to provide visual illustrations that help users with reading disabilities understand difficult text that describes concepts or processes. The illustrations are provided in addition to the text.\n\nUsers with disabilities that make it difficult to decode words and sentences are likely to have trouble reading and understanding complex text. Charts, diagrams,\nanimations, photographs, graphic organizers, or other visual materials often help these users. For example:\n\n- Charts and graphs help users understand complex data.\n- Diagrams, flowcharts, videos, and animations help users understand processes.\n- Concept maps and other graphic organizers help users understand how ideas are related to each other.\n- Photographs, drawings, and videos can help users understand natural or historical events or objects.\n\nExamples:\n- **Example 1: An annual report for a company**  An annual report discusses multiple factors that influenced the company's performance in the past year. The report also includes charts and graphs that illustrate how these factors interact. Each chart or graph has a text alternative as required bySuccess Criterion 1.1.1. Each one also has a number in its caption (e.g., “Figure 7\"). These numbers are used in the text to reference the charts or graphs.\n- **Example 2: Screen shots in technical documentation**  Online documentation for a product includes step by step instructions. Each step is illustrated by a screen shot that shows the visual appearance of the screen. Each screen shot has text alternatives as required by Success Criterion  1.1.1.\n- **Example 3: Illustrations of a complex natural event**  A website discusses the tsunami of 2004. The site describes how the tsunami affected different places around the Indian Ocean. Photographs of the devastation in each area are included. Each photograph has a text alternative as required by Success Criterion 1.1.1. The site also explains what happens underwater during a tsunami. The explanation is accompanied by an animation that shows how a tsunami occurs and spreads over the ocean. The animation has a text alternative as required by Success Criterion 1.1.1.    ---",
    "referenced_by": [
      "3.1.5"
    ]
  },
  {
    "id": "G79",
    "type": "technique",
    "code": "G79",
    "text": "[G79] Providing a spoken version of the text\n\nDescription:\nSome users who have difficulty sounding out (decoding) words in written text find it very helpful to hear the text read aloud. This service can now be provided easily using either recorded human speech or synthetic speech. For example, there are a number of products that authors can use to convert text to synthetic speech, then save the spoken version as an audio file. A link to the spoken version can then be provided within the content.  Cost depends in part on the quality of the voice used and whether the text is likely to change frequently.\n\n- Spoken versions of short texts and static text contentThis method is effective for small amounts of text and for longer documents that do not change often.Make a recording of someone reading the text aloud, or use a tool that converts individual documents or selected passages into synthetic speech.   Choose the clearest, most attractive voice if a choice is available.Save the spoken version as an audio file. Use an audio format that is widely available and supported by media players.Provide a link to the audio version.Identify the audio format (for example, .MP3, .WAV, .AU, etc.).Provide a link to a media player that supports the format.\n- Spoken versions of text that changesServer-based methods may be best when pages change often or when user choice determines text content. Some server-based tools allow users to select any text they are interested in and listen to it. Typically, the user presses a button which starts the text-to-speech conversion and reads the text aloud.\n\nExamples:\n- **Example 1: A website for a government agency**  The website for a municipal housing authority has a button on every page labeled \"Read this page aloud.\" The user selects the button and the page is spoken by a synthetic voice.    ---",
    "referenced_by": [
      "3.1.5"
    ]
  },
  {
    "id": "G153",
    "type": "technique",
    "code": "G153",
    "text": "[G153] Making the text easier to read\n\nDescription:\nThe objective of this technique is to ensure that the text of the web page is not difficult to read. Users with disabilities that make it difficult to decode words and sentences are likely to have trouble reading and understanding complex text. If the text does not require reading ability more advanced than the lower secondary education level, no supplements or alternative versions are needed.\n\nIn order to reduce the complexity of the text:\n\n- Develop a single topic or subtopic per paragraph.\n- Use the simplest sentence forms consistent with the purpose of the content. For example, the simplest sentence form for English consists of Subject-Verb-Object, as inJohn hit the ballorThe website conforms to WCAG 2.1.\n- Use sentences that are no longer than the typical accepted length for secondary education. (Note: In English that is 25 words.)\n- Consider dividing longer sentences into two.\n- Use sentences that contain no more than two conjunctions.\n- Indicate logical relationships between phrases, sentences, paragraphs, or sections of the text.\n- Avoid professional jargon, slang, and other terms with a specialized meaning that may not be clear to people.\n- Replace long or unfamiliar words with shorter, more common terms.\n- Remove redundant words, that is, words that do not change the meaning of the sentence.\n- Use single nouns or short noun phrases.\n- Remove complex words or phrases that could be replaced with more commonly used words without changing the meaning of the sentence.\n- Use bulleted or numbered lists instead of paragraphs that contain long series of words or phrases separated by commas.\n- Make clear pronoun references and references to other points in the document.\n- Use the active voice for documents written in English and some other Western languages, unless there is a specific reason for using passive constructions. Sentences in the active voice are often shorter and easier to understand than those in the passive voice.\n- Use verb tenses consistently.\n- Use names and labels consistently.\n\nExamples:\n- **Example 1:** The help pages for a web application are written in language that is not more advanced than the lower secondary education level.  ---",
    "referenced_by": [
      "3.1.5"
    ]
  },
  {
    "id": "G160",
    "type": "technique",
    "code": "G160",
    "text": "[G160] Providing sign language versions of information, ideas, and processes that must be understood in order to use the content\n\nDescription:\nFor some people who are deaf or have certain cognitive disabilities, sign language may be their first language. A sign language version of the page may be easier for them to understand than a written language version. The objective of this technique is to provide sign language versions of content that help signing users understand difficult text that describes concepts or processes. The sign language content is provided in addition to the text.\n\nSince this is supplemental content (and not sign language for speech in content) it should be viewed as separate from the content and would not necessarily be synchronized. Although there may be occasions when that would be useful, it is not required.\n\nTo make the sign language version available with the rest of the web page contents, the video may be embedded in the web page directly or the web page may include a link that brings up a video player in a separate window. The sign language version could also be provided via a link to a separate web page that displays the video.\n\nSign language is a three-dimensional, visual language that uses the hands, arms, shoulders, head, face, lips and tongue of the signer. For viewers to understand what is being signed, the video must record the sign language completely. Generally speaking, the signer should be as close to the camera as possible without risking cut-offs (such as hands moving outside the video).\n\nInformation on how to find sign language interpreters is listed in the resources section below.\n\nExamples:\n- **Example 1:** The information about how to contact support or send questions about a website is provided in a sign language video as well as in text.\n- **Example 2:** Help pages for a web application are provided in sign language as well as in text.\n- **Example 3:** A company website provides sign language videos describing the technical details of each product.\n- **Example 4:** A religious website includes American Sign Language among the different languages in which it makes its site available.  ---",
    "referenced_by": [
      "3.1.5"
    ]
  },
  {
    "id": "G120",
    "type": "technique",
    "code": "G120",
    "text": "[G120] Providing the pronunciation immediately following the word\n\nDescription:\nThe objective of this technique is to make the pronunciation of a word available by providing the pronunciation after the word at least the first time it occurs within a web page.\n\nWhen a web page contains words with the same spelling but different pronunciations, this technique is not appropriate for providing the pronunciation unless it is provided for each instance.\n\nThis technique is applied to the first occurrence of an abbreviation in a web page. When combining multiple resources into a single web page, the abbreviation would be expanded at the beginning of each resource. In this case, however, using a different technique for providing the expanded form may be more appropriate.\n\nExamples:\n- **Example 1**  In the following example of Japanese text, the information giving the pronunciation in Han characters (Kanji) is rendered in parentheses immediately following the text.  ```html <p>慶應大学 (けいおうだいがく)</p> ```    ---",
    "referenced_by": [
      "3.1.6"
    ]
  },
  {
    "id": "G121",
    "type": "technique",
    "code": "G121",
    "text": "[G121] Linking to pronunciations\n\nDescription:\nThe objective of this technique is to make the pronunciation of a word available by providing information about the pronunciation, either within the same web page or in a different web page, and establishing a link between the item and its pronunciation.\n\nExamples:\n- **Example 1**  A word is linked to its entry in a dictionary that includes pronunciation information.\n- **Example 2**  A word is linked to a sound file that will speak the pronunciation.\n- **Example 3**  A word in linked to its entry in a pronouncing dictionary.\n- **Example 4**  A word is linked to an International Phonetic Alphabet (IPA) representation of its pronunciation.\n- **Example 5**  A word is linked to an unambiguous phonetic spelling of the pronunciation.    ---",
    "referenced_by": [
      "3.1.6"
    ]
  },
  {
    "id": "G163",
    "type": "technique",
    "code": "G163",
    "text": "[G163] Using standard diacritical marks that can be turned off\n\nDescription:\nThe objective of this technique is to provide users with a mechanism for turning standard diacritical marks on or off.\n\nMany languages use diacritical marks or diacritics to indicate the pronunciation of words or to help distinguish between words. Some languages may use diacritics to denote vowels, to indicate consonant doubling, to indicate the absence of a vowel or a consonant, or for other purposes. Although text without such diacritics can be readable, the addition of diacritics can improve readability.\n\nExamples:\n- **Example 1**  A web page in Hawaiian displays all diacritical marks by default and provides links that allow users to select the level of display of diacritical marks:  Visitors select the level they prefer, and this preference is stored into a session cookie. All subsequent pages during that same session have access to the cookie, and show or hide diacritics according to the selected level.  On the server side, content is stored with all diacritical markings. If a visitor prefers fewer or no diacritics, a server-side function replaces or removes diacritics as desired before sending the response.  Example atHawaiian language online.    ---",
    "referenced_by": [
      "3.1.6"
    ]
  },
  {
    "id": "H62",
    "type": "technique",
    "code": "H62",
    "text": "[H62] Using the ruby element\n\nDescription:\nThe objective of this technique is to use ruby annotation to provide information about the pronunciation and meaning of a run of text where meaning is determined by pronunciation.\n\nThere are many languages in which a run of text may mean different things depending on how the text is pronounced. This is common in East Asian languages as well as Hebrew, Arabic, and other languages; it also occurs in English and other Western European languages.\n\nRuby Annotation allows the author to annotate a \"base text,\" providing a guide to pronunciation and, in some cases, a definition as well. Ruby is commonly used for text in Japanese and other East Asian languages.\n\nThere are two types of Ruby markup: simple and complex. Simple Ruby markup applies to a run of text such as a complete word or phrase. This is known as the \"base\" text (**rb** element). The Ruby annotation that indicates how to pronounce the term (the **rt** element, or Ruby text) is shown in a smaller font. (The term \"Ruby\" is derived from a small font used for this purpose in printed texts.) The Ruby text is usually rendered above or immediately before the base text, that is, immediately above horizontal text or immediately to the right of vertical text. Sometimes Japanese uses Ruby to provide the meaning of text on the other side of the base text (visually) from the phonetic annotation. Simple Ruby markup also provides a \"fallback\" option for user agents that do not support Ruby markup (that is, user agents that do not support HTML).\n\nComplex Ruby markup makes it possible to divide the base text into smaller units, each of which may be associated with a separate Ruby annotation. Complex Ruby markup does not support the fallback option.\n\nRuby annotation is uncommon in languages such as Hebrew, where Unicode fonts can include diacritical marks that convey pronunciation. It is also uncommon in English and European languages.\n\nNote: The primary reason for indicating pronunciation through Ruby or any other means is to make the content accessible to people with disabilities who could read and understand the language of the content if information about pronunciation were provided. It is not necessary to provide information about pronunciation for use by people who are not familiar with the language of the content.\n\nExamples:\n- **Example 1: Ruby markup providing pronunciation information for an initialism**  This example uses Ruby annotation to give the pronunciation of the initialism (acronym) formed by the first letters of the words Web Content Accessibility Guidelines. The letters WCAG are the base (the rb element), and the pronunciation information is shown by the Ruby text (thertelement). The Ruby parenthesis elementrpis used for user agents that do not support Ruby annotations to indicate that the text in thertelement provides the pronunciation information. The pronunciation information is rendered in parentheses immediately following the base text. (User agents that support Ruby do not show the parentheses.)  ```html <p>When we talk about these guidelines, we often just call them <ruby> <rb>WCAG</rb> <rp>(</rp> <rt>Wuh-KAG</rt> <rp>)</rp> </ruby>. </p> ```\n- **Example 2: Ruby annotation for Japanese**  The following is an example in Japanese. For Japanese, the Ruby is used to give the reading of Han characters (Kanji). the Ruby parenthesis elementrpis used for user agents that do not support Ruby annotations to indicate that the text in thertelement provides the pronunciation information. The pronunciation information is rendered in parentheses immediately following the base text. (User agents that support Ruby do not show the parentheses.)  ```html <p> <ruby> <rb>慶應大学</rb> <rp>(</rp> <rt>けいおうだいがく</rt> <rp>)</rp> </ruby> </p> ```    ---",
    "referenced_by": [
      "3.1.6"
    ]
  },
  {
    "id": "G107",
    "type": "technique",
    "code": "G107",
    "text": "[G107] Using \"activate\" rather than \"focus\" as a trigger for changes of context\n\nDescription:\nThe objective of this technique is to provide a method for activating things that is predictable by the user. Users with cognitive disabilities and people using screen readers or screen magnifiers may be confused by an unexpected event such as automatic form submission or activation of a function that causes a change of context.\n\nWith this technique, all changes of context would be triggered only by a specific action on the part of the user.  Further, that action would be one that usually causes changes in context, such as clicking on a link or pressing a submit button.  Actions that simply move the focus to an element would not cause a change of context.\n\nExamples:\n- **Example 1**    ---",
    "referenced_by": [
      "3.2.1"
    ]
  },
  {
    "id": "G200",
    "type": "technique",
    "code": "G200",
    "text": "[G200] Opening new windows and tabs from a link only when necessary\n\nDescription:\nThe objective of this technique is to limit the use of links or  buttons that open new windows or tabs within Web content. In general, it is better not to open new windows and tabs since they can be disorienting for people, especially people who have difficulty  perceiving visual content. However there are some situations where it is preferable from an accessibility perspective to open a new window or tab. Here are two such situations:\n\nIt is recommended that when links are opened to a new window, there is advance warning.\n\nExamples:\n- **Example 2: Secure website**  A page on a secure website includes a link to an external page that  is outside of the secure session. The link opens in a new window or tab  since opening the link in the same window will break or destroy the  secure session.\n- **Example 1: Online Form**  An online form provides extensive context-sensitive help for each  form field on a separate page because there is too much text to include  within the form. The links to the context-sensitive help open in new  windows or tabs to prevent the loss of any form data that has already  been entered.\n- **Example 3: Date Picker**  An online form includes a date field that allows the user to  manually type in the date or select a date from a calendar-based date  picker on a separate page. The link to the calendar-based date picker  opens in a new window or tab to prevent the loss of any form data that  has already been entered.    ---",
    "referenced_by": [
      "3.2.1",
      "3.2.5"
    ]
  },
  {
    "id": "G201",
    "type": "technique",
    "code": "G201",
    "text": "[G201] Giving users advanced warning when opening a new window\n\nDescription:\nThe objective of this technique is to provide a warning before automatically\nopening a new window or tab. Opening new windows automatically when\na link is activated can be disorienting for people who have difficulty\nperceiving visual content, and for some people with cognitive disabilities,\nif they are not warned in advance. Providing a warning allows the user\nto decide it they want to leave the current window, and the warning\nwill help them find their way back, if they do decide they would like\nto go to the new window. It will help them understand that the \"back\" button\nwill not work and that they have to return to the last window they\nhad open, in order to find their previous location.\n\nExamples:\n- **Example 2: Using CSS to provide a warning before opening a new window**  The code below uses CSS to provide a warning before opening a new window.  Aworking example of Using CSS to provide a warning before opening a new windowis available.  ```html <!DOCTYPE html> <html lang=\"en\"> <head> <meta charset=\"utf-8\"> <title>Link opens in new window notification</title> <style> body { background:#fff; color: #000; font: 1rem/1.5 system-ui, \"Segoe UI\", Roboto, Helvetica, sans-serif; }  [hidden] { display:none; }  .new-window-icon { fill:currentColor; height:0.75rem; margin-inline-start:0.3em; vertical-align:middle; width:0.75rem; } </style> </head> <body> <svg hidden> <symbol id=\"new-window-icon\" viewBox=\"0 0 12 12\"> <title id=\"new-win-desc\">opens in a new window</title> ... </symbol> </svg>  <h1>Link opens in new window notification</h1> <p>This is an example of an <a aria-describedby=\"new-win-desc\" href=\"https://example.com\" rel=\"noopener\" target=\"_blank\">external link<svg class=\"new-window-icon\" aria-hidden=\"true\" role=\"img\"><use href=\"#new-window-icon\"></use></svg></a></p> </body> </html> ```    ---\n- **Example 1: Including the warning in the text describing a control**  The name or label that describes a control can include the warning about opening in a new window.  ```html <a href=\"knitting.html\" rel=\"noopener\" target=\"_blank\"> All about Knitting (opens in new window) </a> ```",
    "referenced_by": [
      "3.2.1",
      "3.2.2"
    ]
  },
  {
    "id": "G80",
    "type": "technique",
    "code": "G80",
    "text": "[G80] Providing a submit button to initiate a change of context\n\nDescription:\nThe objective of this technique is to provide a mechanism that allows users\nto explicitly request changes of context. Since the intended use of a submit\nbutton is to generate an HTTP request that submits data entered in a form,\nthis is an appropriate control to use for causing a change of context and is\na practice that does not create confusion for users.\n\nExamples:\n- **Example 1**  Example 1: A submit button is used for each form that causes a change in context.    ---",
    "referenced_by": [
      "3.2.2"
    ]
  },
  {
    "id": "H32",
    "type": "technique",
    "code": "H32",
    "text": "[H32] Providing submit buttons\n\nDescription:\nThe objective of this technique is to provide a mechanism that allows users to explicitly request changes of context. The intended use of a submit button is to generate an HTTP request that submits data entered in a form, so it is an appropriate control to use for causing a change of context.\n\nExamples:\n- **Example 1: A basic example of a form with a submit button**  ```html <form action=\"/subscribe\" method=\"post\"> <p>Enter your email address to subscribe to our mailing list.</p> <label for=\"address\">Your email address:</label> <input autocomplete=\"email\" id=\"address\" name=\"address\" type=\"text\"> <input type=\"submit\" value=\"Subscribe\"> </form> ```    ---",
    "referenced_by": [
      "3.2.2"
    ]
  },
  {
    "id": "H84",
    "type": "technique",
    "code": "H84",
    "text": "[H84] Using a button with a select element to perform an action\n\nDescription:\nThe objective of this technique is to allow the user to control when an action is performed, rather than having the action occur as a side effect of choosing a value for the **select** element. The user may inspect the different values of the **select** element, or may accidentally choose the wrong value, without causing the action to occur. When the user is satisfied with their choice, they select the button to perform the action.\n\nThis is particularly important for users who are choosing the value of the **select** element via the keyboard, since navigating through the options of the **select** element changes the value of the control.\n\nExamples:\n- **Example 1: A calendar**  A web page lets the user choose a quarter of any year and display the calendar for those months. After the user has set the quarter and year, they display the calendar by pressing the \"Show\" button. This example relies on client-side scripting to implement the action.  ```html <label for=\"quarter\">Quarter:</label> <select id=\"quarter\" name=\"quarter\"> <option value=\"1\">Quarter 1 (January - March)</option> <option value=\"2\">Quarter 2 (April - June)</option> <option value=\"3\">Quarter 3 (July - September)</option> <option value=\"4\">Quarter 4 (October - December)</option> </select> <label for=\"year\">Year:</label> <input name=\"year\" type=\"text\" id=\"year\"> <button name=\"show\" type=\"button\">Show</button> ```\n- **Example 2: Choosing an action**  Aselectelement contains a list of possible actions. The action is not performed until the user presses the \"Update\" button.  ```html <form action=\"/process-form\" method=\"post\"> <label for=\"action\">Options:</label> <select name=\"action\" id=\"action\"> <option value=\"add\">Add</option> <option value=\"remove\">Remove</option> <option value=\"cancel\">Cancel</option> <option value=\"order\">Order</option> </select> <button name=\"submit\" type=\"submit\">Update</button> </form> ```    ---",
    "referenced_by": [
      "3.2.2"
    ]
  },
  {
    "id": "PDF15",
    "type": "technique",
    "code": "PDF15",
    "text": "[PDF15] Providing submit buttons with the submit-form action in PDF forms\n\nDescription:\nThe objective of this technique is to provide a mechanism that allows users to explicitly request a change of context using the submit-form action in a PDF form. The intended use of a submit button is to generate an HTTP request that submits data entered in a form, so it is an appropriate control to use for causing a change of context. In PDF documents, submit buttons are normally implemented using a tool for authoring PDF.\n\nExamples:\n- **Example 1: Adding a submit button using Adobe Acrobat Pro**  This example is shown with Adobe Acrobat Pro. There are other software tools that perform similar functions.\n- **Example 2: Adding a script action to a submit button in a PDF document using JavaScript**  The following JavaScript code illustrates the use of a script to specify the submit-form action. To add this script to the form field:  This example is shown in operation in theworking example of adding a script action to a submit button.    ---",
    "referenced_by": [
      "3.2.2"
    ]
  },
  {
    "id": "G13",
    "type": "technique",
    "code": "G13",
    "text": "[G13] Describing what will happen before a change to a form control that causes a change of context to occur is made\n\nDescription:\nThe objective of this technique is to provide information to users about\nwhat will happen when a change to a form control results in a change of\ncontext. Because changing the value of a form control does not typically\nresult in a change of context, it is important that authors provide\ninstructions that make the user aware of the behavior in advance. Where\npossible, it is a good idea to programmatically associate the instructions\ndescribing the change with the form control itself.\n\nThe following are some examples of how to provide the instruction in different situations.\n\n- Provide instruction on the web page with reading order that precedes the user interface element that causes change of context by change of setting.\n- For a multi-step process where users must complete particular steps in order to reach the user interface element where changes of setting would cause a change of context, provide the instruction as part of the process prior to the step where they would encounter the change of context.\n- In the case of an intranet where user training is required prior to the use of a web application where user interface elements that cause changes of context when settings are changed, instruction is provided as part of the training.\n\nExamples:\n- **Example 2:** A 50 question online survey displays one question at a time. Instructions appear at the beginning of the survey that explain that users will be taken to the next question of the survey upon selecting an answer to each question.  ---\n- **Example 1:** A series of radio buttons at the top of a page include options for German, French and Spanish. Instructions precede the buttons that instruct the user that the language will be changed upon selecting an option.",
    "referenced_by": [
      "3.2.2",
      "3.3.2"
    ]
  },
  {
    "id": "SCR19",
    "type": "technique",
    "code": "SCR19",
    "text": "[SCR19] Using an onchange event on a select element without causing a change of context\n\nDescription:\nThe objective of this technique is to demonstrate how to correctly use an onchange event with a select element to update other elements on the web page. This technique will not cause a change of context. When there are one or more select elements on the web page, an onchange event on one, can update the options in another select element on the web page. All of the data required by the select elements is included within the web page.\n\nIt is important to note that the select item which is modified is after the trigger select element in the reading order of the web page. This ensures that assistive technologies will pick up the change and users will encounter the new data when the modified element receives focus. This technique relies on JavaScript support in the user agent.\n\nExamples:\n- **Example 1**  This example contains two select elements. When an item is selected in the first select, the choices in the other select are updated appropriately. The first select element contains a list of continents. The second select element will contain a partial list of countries located in the selected continent. There is an onchange event associated with the continent select. When the continent selection changes, the items in the country select are modified using JavaScript via the Document Object Model (DOM). All of the data required, the list of countries and continents, is included within the web page.  Overview of the code below  Here is a working example:Dynamic Select  ```html <!doctype html> <html lang=\"en\"> <head> <meta charset=utf-8\"> <title>Dynamic Select Statements</title> <script> // array of possible countries in the same order as they appear // in the country selection list var countryLists = new Array(4) countryLists[\"empty\"] = [\"Select a Country\"]; countryLists[\"North America\"] = [\"Canada\", \"United States\", \"Mexico\"]; countryLists[\"South America\"] = [\"Brazil\", \"Argentina\", \"Chile\", \"Ecuador\"]; countryLists[\"Asia\"] = [\"Russia\", \"China\", \"Japan\"]; countryLists[\"Europe\"]= [\"Britain\", \"France\", \"Spain\", \"Germany\"];  /* CountryChange() is called from the onchange event of a select element. * param selectObj - the select object which fired the on change event. */  function countryChange(selectObj) { // get the index of the selected option var idx = selectObj.selectedIndex;  // get the value of the selected option var which = selectObj.options[idx].value;  // use the selected option value to retrieve the list of items // from the countryLists array cList = countryLists[which];  // get the country select element via its known id var cSelect = document.getElementById(\"country\");  // remove the current options from the country select var len=cSelect.options.length;  while (cSelect.options.length > 0) { cSelect.remove(0); }  var newOption; // create new options for (var i=0; i<cList.length; i++) { newOption = document.createElement(\"option\"); newOption.value = cList[i];  // assumes option string and value are the same newOption.text=cList[i];  // add the new option try { cSelect.add(newOption);  // this will fail in DOM browsers but is needed for IE } catch (e) { cSelect.appendChild(newOption); } } } </script> </head> <body> <h1>Dynamic Select Statements</h1> <label for=\"continent\">Select Continent</label> <select id=\"continent\" onchange=\"countryChange(this);\"> <option value=\"empty\">Select a Continent</option> <option value=\"North America\">North America</option> <option value=\"South America\">South America</option> <option value=\"Asia\">Asia</option> <option value=\"Europe\">Europe</option> </select> <div> <label for=\"country\">Select a country</label> <select id=\"country\"> <option value=\"0\">Select a country</option> </select> </div> </body> </html> ```    ---",
    "referenced_by": [
      "3.2.2",
      "3.2.5"
    ]
  },
  {
    "id": "F36",
    "type": "technique",
    "code": "F36",
    "text": "[F36] Failure of Success Criterion 3.2.2 due to automatically submitting a form and given a value\n\nDescription:\nForms are frequently designed so that they submit automatically when the user\nhas filled in all the fields, or when focus leaves the last field. There are\ntwo problems with this approach. First is that a disabled user who needs\nmore context may move focus away from the field to the directions on how to\nfill in the form, or to other text, accidentally submitting the form. The\nother is that, with some form elements, the value of the field changes as\neach item is navigated with the keyboard, again accidentally submitting the\nform. It is better to rely on the standard form behavior of the submit\nbutton and enter key.\n\nExamples:\n- **Example 1**  This failure example submits a form when the user leaves the last field of a three-field telephone number form. The form will submit if the user leaves the field after editing it, even navigating backwards in the tab order. Developers should not use this method to submit a form, and should instead use a submit button, or rely on the form's default behavior of submitting when the user hits enter in a text field.  ```html <form method=\"get\" id=\"form1\"> <input type=\"text\" name=\"text1\" size=\"3\" maxlength=\"3\"> - <input type=\"text\" name=\"text2\" size=\"3\" maxlength=\"3\"> - <input type=\"text\" name=\"text3\" size=\"4\" maxlength=\"4\" onchange=\"form1.submit();\"> </form> ```\n- **Example 2**  This is a  example that submits a form when the user selects an option from the menu when there is no warning of this behavior in advance. The form will submit as soon as an item from the menu is selected. A user using a keyboard will not be able to navigate past the first item in the menu. Blind users and users with hand tremors can easily make a mistake on which item on the dropdown menu to choose and they are taken to the wrong destination before they can correct it.  ```html <form method=\"get\" id=\"form2\"> <input type=\"text\" name=\"text1\"> <select name=\"select1\" onchange=\"form2.submit();\"> <option>one</option> <option>two</option> <option>three</option> <option>four</option> </select> </form> ```    ---",
    "referenced_by": [
      "3.2.2"
    ]
  },
  {
    "id": "F37",
    "type": "technique",
    "code": "F37",
    "text": "[F37] Failure of Success Criterion 3.2.2 due to launching a new window without prior warning when the selection of a radio button, check box or select list is changed\n\nDescription:\nThis document describes a failure that occurs when changing the selection of a\nradio button, a check box or an item in a select list causes a new window to\nopen. It is possible to use scripting to create an input\nelement that causes a change of context (submit the form, open a new page, a\nnew window) when the element is selected. Developers can instead use a\nsubmit button (see [Providing a submit\nbutton to initiate a change of context](../general/G80)) or clearly indicate the\nexpected action.\n\nExamples:\n- **Example 1**  The example below fails the success criterion because it processes the form when a radio button is selected instead of using a submit button.  ```html <script> function goToMirror(theInput) { var mirrorSite = \"https://download.\" + theInput.value + \"/\"; window.open(mirrorSite); } </script> ... <form name=\"mirror_form\" id=\"mirror_form\" action=\"\" method=\"get\"> <p>Please select a mirror download site:</p> <p> <input type=\"radio\" onclick=\"goToMirror(this);\" name=\"mirror\" id=\"mirror_belnet\" value=\"belnet.be\" /> <label for=\"mirror_belnet\">belnet (<abbr>BE</abbr>)</label><br /> <input type=\"radio\" onclick=\"goToMirror(this);\" name=\"mirror\" id=\"mirror_surfnet\" value=\"surfnet.nl\" /> <label for=\"mirror_surfnet\">surfnet (<abbr>NL</abbr>)</label><br /> <input type=\"radio\" onclick=\"goToMirror(this);\" name=\"mirror\" id=\"mirror_puzzle\" value=\"puzzle.ch\" /> <label for=\"mirror_puzzle\">puzzle (<abbr>CH</abbr>)</label><br /> <input type=\"radio\" onclick=\"goToMirror(this);\" name=\"mirror\" id=\"mirror_voxel\" value=\"voxel.com\" /> <label for=\"mirror_voxel\">voxel (<abbr>US</abbr>)</label><br /> </p> </form> ```    ---",
    "referenced_by": [
      "3.2.2"
    ]
  },
  {
    "id": "G61",
    "type": "technique",
    "code": "G61",
    "text": "[G61] Presenting repeated components in the same relative order each time they appear\n\nDescription:\nThe objective of this technique is to make content easier to use by making\nthe placement of repeated components more predictable. This technique helps\nmaintain consistent layout or presentation between web pages by presenting components that are repeated in these Web  units in the same relative order each time they appear. Other\ncomponents can be inserted between them, but their relative order is not\nchanged.\n\nThis technique also applies to navigational components that are repeated.\nWeb pages often contain a navigation menu or other\nnavigational component that allows the user to jump to other web pages. This technique makes the placement of navigational\ncomponents more predictable by presenting the links or programmatic\nreferences inside a navigational component in the same relative order each\ntime the navigational component is repeated. Other links can be removed or\ninserted between the existing ones, for example to allow navigation inside a\nsubsection of a set of web pages, but the relative order is not\nchanged.\n\nExamples:\n- **Example 1:** A website has a logo, a title, a search form and a navigation bar at the top of each page; these appear in the same relative order on each page where they are repeated. On one page the search form is missing but the other items are still in the same order.\n- **Example 2:** A website has a left-hand navigation menu with links to the major sections of the site. When the user follows a link to another section of the site, the links to the major sections appear in the same relative order in the next page. Sometime links are dropped and other links are added, but the other links always stay in the same relative order. For example, on a website of a company that sells products and offers training, when a user moves from the section on products to the section on training, the links to individual products are removed from the navigation list, while links to training offerings are added.  ---",
    "referenced_by": [
      "3.2.3"
    ]
  },
  {
    "id": "F66",
    "type": "technique",
    "code": "F66",
    "text": "[F66] Failure of Success Criterion 3.2.3 due to presenting navigation links in a different relative order on different pages\n\nDescription:\nThis describes a failure condition for  all techniques involving navigation mechanisms that are repeated on multiple web pages within a set of web pages (Success Criterion 3.2.3). If the mechanism presents the order of links in a different order on two or more pages, then the failure is triggered.\n\nExamples:\n- **Example 1: Navigation presenting a series of links that are in a different relative order on two different pages**  Examples of a navigation mechanism that presents links in a different order.  ```html <nav> <ul> <li><a href=\"brazil.html\">Brazil</a></li> <li><a href=\"canada.html\">Canada</a></li> <li><a href=\"germany.html\">Germany</a></li> <li><a href=\"poland.html\">Poland</a></li> </ul> </nav> ```  ```html <nav> <ul> <li><a href=\"canada.html\">Canada</a></li> <li><a href=\"brazil.html\">Brazil</a></li> <li><a href=\"germany.html\">Germany</a></li> <li><a href=\"poland.html\">Poland</a></li> </ul> </nav> ```    ---",
    "referenced_by": [
      "3.2.3"
    ]
  },
  {
    "id": "G197",
    "type": "technique",
    "code": "G197",
    "text": "[G197] Using labels, names, and text alternatives consistently for content that has the same functionality\n\nDescription:\nThe purpose of this technique is to help  users with cognitive disabilities, blindness and vision loss to understand what will happen when they interact with a function on a web page. If there are different labels on user interface components (i.e., elements, links, JavaScript objects, etc.) that have the same function, the user will not know that they have encountered a component with the same function and will not know what to expect. This could lead to many unnecessary errors. It is also recommended that this approach to consistent labelling be applied across the website.\n\nExamples:\n- **Example 1:** A web page has a form field at the top of the page labeled \"Search\". On the bottom of the page is another form field which provides the same function. It is also labeled \"Search.\"\n- **Example 2:** A picture of a question mark is used to steer users to sections of the page that provide additional information. Each time the picture of the question mark appears it has the same text alternative \"more information.\"\n- **Example 3:** A link to the Contact Us page of a website has the link text \"Contact\". At the bottom of the page there is a link that also goes to the Contact Us page. It also has the link text \"Contact\".  ---",
    "referenced_by": [
      "3.2.4"
    ]
  },
  {
    "id": "F31",
    "type": "technique",
    "code": "F31",
    "text": "[F31] Failure of Success Criterion 3.2.4 due to using two different labels for the same function on different Web pages within a set of Web pages\n\nDescription:\nComponents that have the same function in different web pages are more\neasily recognized if they are labeled consistently. If the naming is not\nconsistent, some users may get confused.\n\nExamples:\n- **Example 1**  One of the most common examples of using inconsistent labels for components with the same function is to use a button that says \"search\" in one page and to use a button that says \"find\" on another page when they both serve the identical function.\n- **Example 2**  An online authoring tool that uses a button with \"Save page\" on one page and \"Save\" on another page, in both cases for the same function.    ---",
    "referenced_by": [
      "3.2.4"
    ]
  },
  {
    "id": "SVR1",
    "type": "technique",
    "code": "SVR1",
    "text": "[SVR1] Implementing automatic redirects on the server side instead of on the client side\n\nDescription:\nThe objective of this technique is to avoid confusion that may be caused when two new pages are loaded in quick succession because one page (the one requested by the user) redirects to another. Some user agents support the use of the HTML meta element to redirect the user to another page after a specified number of seconds. This makes a page inaccessible to some users, especially users with screen readers. Server-side technologies provide methods to implement redirects in a way that does not confuse users. A server-side script or configuration file can cause the server to send an appropriate HTTP response with a status code in the 3xx range and a Location header with another URL. When the browser receives this response, the location bar changes and the browser makes a request with the new URL.\n\nExamples:\n- **Example 1: JSP/Servlets**  In Java Servlets or JavaServer Pages (JSP), developers can useHttpServletResponse.sendRedirect(String url).  This sends a response with a302status code (\"Found\") and aLocationheader with the new URL to the user agent. It is also possible to set another status code withresponse.sendError(int code, String message)with one of the constants defined in the interfacejavax.servlet.http.HttpServletResponseas status code.  If an application usesHttpServletResponse.encodeURL(String url)for URL rewriting because the application depends on sessions, the methodHttpServletResponse.encodeRedirectURL(String url)should be used instead ofHttpServletResponse.sendRedirect(String url). It is also possible to rewrite a URL withHttpServletResponse.encodeURL(String url)and then pass this URL toHttpServletResponse.sendRedirect(String url).  ```html ... public void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { ... response.sendRedirect(\"/newUserLogin.do\"); } ```  ```html ... public void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { ... response.sendError(response.SC_MOVED_PERMANENTLY, \"/newUserLogin.do\"); } ```\n- **Example 2:ASP**  In Active Server Page (ASP) with VBScript, developers can useResponse.Redirect.  or  The code below is a more complete example with a specific HTTP status code.  ```html Response.Redirect \"newUserLogin.asp\" ```  ```html Response.Redirect(\"newUserLogin.asp\") ```  ```html Response.Clear Response.Status = 301 Response.AddHeader \"Location\", \"newUserLogin.asp\" Response.Flush Response.End ```\n- **Example 3:PHP**  In PHP, developers can send a raw HTTP header with the header method. The code below sends a 301 status code and a new location. If the status is not explicitly set, the redirect response sends an HTTP status code302.  ```html <?php header(\"HTTP/1.1 301 Moved Permanently\"); header(\"Location: https://www.example.com/newUserLogin.php\"); ?> ```\n- **Example 4: Apache**  Developers can configure the Apache Web server to handle redirects, as in the following example.  ```html redirect 301 /oldUserLogin.jsp http://www.example.com/newUserLogin.do ```    ---",
    "referenced_by": [
      "3.2.5"
    ]
  },
  {
    "id": "G110",
    "type": "technique",
    "code": "G110",
    "text": "[G110] Using an instant client-side redirect\n\nDescription:\nThe objective of this technique is to enable redirects on the client side\nwithout confusing the user. Redirects are preferably implemented on the\nserver side (see [Implementing automatic redirects on the server side instead of on the client side](../server-side-script/SVR1)), because a server-side\nredirect does not cause new content to be displayed before the server sends\nthe content located at the new URI. However, authors do not always have\ncontrol over server-side technologies; in that case, they can use a\nclient-side redirect. A client-side redirect is implemented by code inside\nthe content that instructs the user agent to retrieve content from a\ndifferent URI. It is important that the redirecting page or web page\nonly contains information related to the redirect.\n\nExamples:\n- **Example 1: HTML:  meta  Refresh With a URI and No Timeout**  In HTML, it is possible to implement a client-side redirect using the  meta  element: seeUsing meta refresh to create an instant client-side redirect.    ---",
    "referenced_by": [
      "3.2.5"
    ]
  },
  {
    "id": "H76",
    "type": "technique",
    "code": "H76",
    "text": "[H76] Using meta refresh to create an instant client-side redirect\n\nDescription:\nThe objective of this technique is to enable redirects on the client side without confusing the user. Redirects are preferably implemented on the server side (see [Implementing automatic redirects on the server side instead of on the client side](../server-side-script/SVR1)), but authors do not always have control over server-side technologies.\n\nIn HTML, one can use the **meta** element with the value of the **http-equiv** attribute set to **refresh** and the value of the **content** attribute set to **0** (meaning zero seconds), followed by the URI that the browser should request. It is important that the time-out is set to zero, to avoid that content is displayed before the new page is loaded. The page containing the redirect code should only contain information related to the redirect.\n\nExamples:\n- **Example 1: Instantly redirecting a page**  ```html <!doctype html> <html lang=\"en\"> <head> <meta charset=\"utf-8\"> <title>Panucci's Pizza</title> <meta http-equiv=\"refresh\" content=\"0; URL=https://planet-express.example.com\"> </head> <body> <p>This page has moved to <a href=\"https://planet-express.example.com\"> Planet Express</a>.</p> </body> </html> ```    ---",
    "referenced_by": [
      "3.2.5"
    ]
  },
  {
    "id": "H83",
    "type": "technique",
    "code": "H83",
    "text": "[H83] Using the target attribute to open a new window on user request and indicating this in link text\n\nDescription:\nThe objective of this technique is to avoid confusion that may be caused by the appearance of new windows that were not requested by the user. Suddenly opening new windows can disorient users or be missed completely by some. In HTML, the **target** attribute can be used to open a new window.\n\nUse of the **target** attribute provides an unambiguously machine-readable indication that a new window will open. User agents can inform the user, and can also be configured not to open the new window. For those not using assistive technology, the indication would also be available from the link text.\n\nExamples:\n- **Example 1: Using thetargetattribute in a link to indicate it will open in a new window**  ```html <a href=\"help.html\" target=\"_blank\">Show Help (opens new window)</a> ```    ---",
    "referenced_by": [
      "3.2.5"
    ]
  },
  {
    "id": "SCR24",
    "type": "technique",
    "code": "SCR24",
    "text": "[SCR24] Using progressive enhancement to open new windows on user request\n\nDescription:\nThe objective of this technique is to avoid confusion that may be caused by the appearance of new windows that were not requested by the user. Suddenly opening new windows can disorient or be missed completely by some users. New windows / tabs can be opened with the HTML **target** attribute or JavaScript. The example below demonstrates how to open new windows with script: it adds an event handler to a link and warns the user that the content will open in a new window.\n\nExamples:\n- **Example 1: Using JavaScript to open a new tab / window**  ```html <script src=\"popup.js\"></script> ... <a href=\"help.html\" id=\"newwin\">Show Help</a> ```  ```html window.onload = addHandlers;  function addHandlers(){ var objAnchor = document.getElementById('newwin');  if (objAnchor){ objAnchor.firstChild.data = objAnchor.firstChild.data + ' (opens in a new window)'; objAnchor.onclick = function(event){return launchWindow(this, event);} // UAAG requires that user agents handle events in a device-independent manner // but only some browsers do this, so add keyboard event to be sure objAnchor.onkeypress = function(event){return launchWindow(this, event);} } }  function launchWindow(objAnchor, objEvent) { var iKeyCode, bSuccess=false;  // If the event is from a keyboard, we only want to open the // new window if the user requested the link (return or space) if (objEvent && objEvent.type == 'keypress') { if (objEvent.keyCode) iKeyCode = objEvent.keyCode; else if (objEvent.which) iKeyCode = objEvent.which;  // If not carriage return or space, return true so that the user agent // continues to process the action if (iKeyCode != 13 && iKeyCode != 32) return true; }  bSuccess = window.open(objAnchor.href);  // If the window did not open, allow the browser to continue the default // action of opening in the same window if (!bSuccess) return true;  // The window was opened, so stop the browser processing further return false; } ```    ---",
    "referenced_by": [
      "3.2.5"
    ]
  },
  {
    "id": "F60",
    "type": "technique",
    "code": "F60",
    "text": "[F60] Failure of Success Criterion 3.2.5 due to launching a new window when a user enters text into an input field\n\nDescription:\nThis document describes a failure that occurs when a new window is created in\nresponse to a user filling in a text field for other than error reporting.\n\nExamples:\n- **Example 1**  This is a deprecated example showing a failure: A user is filling in their mailing address. When they fill in their postal code, a new window opens containing advertisements for services available in their city.\n- **Example 2**  This example is acceptable: A user is filling in their mailing address in a form. When they fill in the postal code field, a script runs to validate that it is a valid postal code. If the value is not valid, a window opens with instructions on how to fill in the field.    ---",
    "referenced_by": [
      "3.2.5"
    ]
  },
  {
    "id": "F61",
    "type": "technique",
    "code": "F61",
    "text": "[F61] Failure of Success Criterion 3.2.5 due to complete change of main content through an automatic update that the user cannot disable from within the content\n\nDescription:\nThis document describes a failure that occurs when the content in the main [viewport](https://www.w3.org/TR/WCAG22/#dfn-viewport) is automatically updated, and there is no option for a user to disable this behavior.\n\nTwo procedures are presented below to test for the existence of a failure against Success Criterion 3.2.5. Procedure 1 is the preferred procedure and assumes that content authors have access to the code that generates the viewport content.\n\nHowever there may be instances where this may not be possible (eg: in certain content management systems, application environments such as django or ruby-on-rails, or content generated through scripting languages such as AJAX or PHP that are generated by third parties.) To that end, the second procedure is supplied to allow testing in these instances. Note that timeframes are indicative only, and that any change after any amount of time should be treated as a failure if the test otherwise does not pass the other step evaluations.\n\nExamples:\n- **Example 1**  A news site automatically refreshes itself to ensure that it has the newest headlines. There is no option to disable this behavior.\n- **Example 2**  A slideshow fills the entire viewport and advances to the next slide automatically. There is no stop button.\n- **Example 3**  A search engine automatically generates results and dynamically updates content based on user input. There is no option to disable this behavior.    ---",
    "referenced_by": [
      "3.2.5"
    ]
  },
  {
    "id": "F9",
    "type": "technique",
    "code": "F9",
    "text": "[F9] Failure of Success Criterion 3.2.5 due to changing the context when the user removes focus from a form element\n\nDescription:\nThis document describes a failure that occurs when removing focus from a form\nelement, such as by moving to the next element, causes a change of context.\n\nExamples:\n- **Example 1**  Users are going through the form filling out the fields in order. When they move from the third field to the forth, the form submits.    ---",
    "referenced_by": [
      "3.2.5"
    ]
  },
  {
    "id": "F22",
    "type": "technique",
    "code": "F22",
    "text": "[F22] Failure of Success Criterion 3.2.5 due to opening windows that are not requested by the user\n\nDescription:\nFailure due to opening new windows when the user does not expect them. New\nwindows take the focus away from what the user is reading or doing. This is\nfine when the user has interacted with a piece of User Interface and expects\nto get a new window, such as an options dialogue. The failure comes when\npop-ups appear unexpectedly.\n\nExamples:\n- **Example 1**  When a user navigates to a page, a new window appears over the existing user agent window, and the focus is moved to the new window.\n- **Example 2**  A user clicks on a link, and a new window appears. The original link has no associated text saying that it will open a new window.\n- **Example 3**  A user clicks on the body of a page and a new window appears. No indication that the area that was clicked has functionality is present.\n- **Example 4**  A user clicks on undecorated text within the page and a new window appears. The page has no visible indication that the area is functional.    ---",
    "referenced_by": [
      "3.2.5"
    ]
  },
  {
    "id": "F52",
    "type": "technique",
    "code": "F52",
    "text": "[F52] Failure of Success Criterion 3.2.1 and 3.2.5 due to opening a new window as soon as a new page is loaded\n\nDescription:\nSome websites open a new window when a page is loaded, to advertise a\nproduct or service. The objective of this technique is to ensure that pages\ndo not disorient users by opening up one or more new windows that automatically attain focus as soon as a\npage is loaded.\n\nExamples:\n- **Example 1: example commonly used to open new windows when pages are loaded**  ```html window.addEventListener(\"load\", showAdvertisement, true); window.attachEvent(\"onload\", showAdvertisement);  function showAdvertisement(){ window.open('noscript.html', '_blank', 'height=200,width=150'); } ```    ---",
    "referenced_by": [
      "3.2.5"
    ]
  },
  {
    "id": "G220",
    "type": "technique",
    "code": "G220",
    "text": "[G220] Provide a contact-us link in a consistent location\n\nDescription:\nThe objective of this technique is to provide a mechanism for finding contact details in a consistent location across pages to make it easier for users to find it. The interactive item in the web page is a link to the contact details page. The programmatic and visual location is consistent on each page in the set of web pages, when viewed within the same size viewport. Activating the link brings users to a web page with contact details such as a phone number and/or email address.\n\nExamples:\n- **Example 2: A link in the footer region**  A web page's footer region contains links repeated on every page in a set of web pages. The visual and programmatic order are consistent when viewed in the same size display. One of the first links in the footer region is labeled visually and programmatically \"Contact Us\". A user activates the link and is brought to the contact details page. The contact details page has an email address for a company representative or general information inbox which is then shared with appropriate personnel.\n- **Example 3: A link sometimes in a disclosure widget**  On some pages in a set of web pages, there is a link to a help mechanism directly on the page. On one or more other pages in the set, the link is within a disclosure widget which is in the same relative order as the link that is directly on the page.    ---\n- **Example 1: A link at the top of the page**  An on-line job application asks for many types of information from the user, such as their identification number, but they may have several and not know which one to enter. They may need more information from someone that can answer their question when the contextual help provided does not meet their needs. One of the first links that the user reaches when tabbing through the page is titled \"Contact Us\". This link is also visually in the same location on each page. Activating the link brings the user to the contact details page. The contact details page has an email address for a company representative or general information inbox which is then shared with appropriate personnel.",
    "referenced_by": [
      "3.2.6"
    ]
  },
  {
    "id": "G83",
    "type": "technique",
    "code": "G83",
    "text": "[G83] Providing text descriptions to identify required fields that were not completed\n\nDescription:\nThe objective of this technique is to notify the user when a field that must be completed has not been completed. When users fail to provide input for any mandatory form fields, information is provided in text to enable the users to identify which fields were omitted. One approach is to use client-side validation and provide an alert dialog box identifying the mandatory fields which were omitted. Another approach, using server-side validation, is to re-display the form (including any  previously entered data), with either a text description at the location of the omitted mandatory field, or a text description that identifies the omitted mandatory fields.\n\nExamples:\n- **Example 1:** A user attempts to submit a form but has neglected to provide input or select a choice in one or more mandatory fields. Using client-side validation, the omission is detected and an alert dialog appears informing the user that mandatory fields have not been completed. The labels of the fields with this problem are changed to identify the problem field, and links to the problem fields are inserted in the document after the submit button so the user can move to them after dismissing the alert.\n- **Example 2:** A user attempts to submit a form but has neglected to provide input or select a choice in one or more mandatory fields. Using server-side validation, the omission is detected and the form is re-displayed with a text description at the top informing which mandatory fields were omitted. Each omitted mandatory field is also identified using a text label so that the user does not have to return to the list at the top of the form to find the omitted fields.\n- **Example 3:** A user is completing a form that contains mandatory fields.  The labels of the fields indicate whether or not they are mandatory.  The user tabs to a mandatory field, and tabs out of the field without entering any data or selecting a choice.  A client-side script modifies the label of the field to indicate that leaving it blank was an error.NoteSome screen readers may not notice and announce the change to the label so screen reader users may be unaware of the error.  ---",
    "referenced_by": [
      "3.3.1",
      "3.3.2",
      "4.1.3"
    ]
  },
  {
    "id": "ARIA21",
    "type": "technique",
    "code": "ARIA21",
    "text": "[ARIA21] Using Aria-Invalid to Indicate An Error Field\n\nDescription:\nThis technique demonstrates how **aria-invalid** may be employed to specifically identify fields that have failed validation. Its use is most suitable when:\n\n- The error description does not programmatically identify the failed fields\n- The failed fields are identified in a manner that is not available to some users - for example by using an error-icon rendered visually by some technique that does not rely on color such as a visual cue like a border.\n\nWhile it is always preferable to programmatically associate specific error description with the failed field, the page's design or the framework employed may sometimes constrain the author's ability to do so. In these cases, authors may programmatically set **aria-invalid** to **\"true\"** on the fields that have failed validation. This is interpretable mainly by assistive technologies (like screen readers / screen magnifiers) employed by users who are vision impaired. When a field has **aria-invalid** set to “true”, VoiceOver in Safari announces invalid data when the field gets focus; JAWS and NVDA notify the error as an invalid entry.\n\nThis ARIA attribute has to be set / turned on programmatically. It should not be set to “true” before input validation is performed or the form is submitted. Setting **aria-invalid** to “false” is the same as not placing the attribute for the form control at all. Quite understandably, nothing is conveyed by assistive technology to users in this case.\n\nWhen visible text is used to programmatically identify a failed field and / or convey how the error can be corrected, setting **aria-invalid** to \"true\" is not required from a strict compliance standpoint but may still provide helpful information for users.\n\nExamples:\n- **Example 1: Using aria-invalid on required fields**  Thearia-invalidattribute is used on required fields that have no input. A message above the form conveys that form submission has failed due to this.  A portion of the jQuery code and the HTML form markup follow:  Working example: Using aria-invalid on required fields.  ```html <script> ... ... if ($('#first').val() === '') { $('#first').attr(\"aria-invalid\", \"true\"); $(\"label[for='first']\").addClass('failed'); } if ($('#last').val() === '') { $('#last').attr(\"aria-invalid\", \"true\"); $(\"label[for='last']\").addClass('failed'); } if ($('#email').val() === '') { $('#email').attr(\"aria-invalid\", \"true\"); $(\"label[for='email']\").addClass('failed'); } ... ... </script>  <style> label.failed { border: red thin solid; } </style>  <form name=\"signup\" id=\"signup\"> <div> <label for=\"first\">First Name (required)</label> <input type=\"text\" name=\"first\" id=\"first\"> </div> <div> <label for=\"last\">Last Name (required)</label> <input type=\"text\" name=\"last\" id=\"last\"> </div> <div> <label for=\"email\">Email (required)</label> <input type=\"text\" name=\"email\" id=\"email\"> </div> <div> <input type=\"submit\" name=\"button\" id=\"button\" value=\"Submit\"> </div> </form> ```\n- **Example 2: Identifying errors in data format**  Aria-invalidandaria-describedbyare used together to indicate an error when the personal identification number (PIN), email address, or start date are not in the expected format. The error message is associated with the field usingaria-describedby, andaria-invalidmakes it easier to programmatically find fields with errors.  Below is the rendered HTML code for the email address field in Example 1: When an invalid email address is entered by the user such as \"samexample.com\" (instead of sam@example.com), the HTML code is:  And when no data is entered in the email field, the HTML code is:  jQuery code: jQuery is used to add aria-invalid or aria-describedby attributes as well as the class attribute and append the error text. This is the code that inserts aria-invalid and class=\"error\" but does not associate the error text \"incorrect data\" with the control programmatically:  CSS Code:  Working example: Identifying errors in data format.  ```html <div class=\"control\"> <div> <label for=\"email\">Email address: [*]</label> <input type=\"text\" name=\"email\" id=\"email\" class=\"error\" aria-invalid=\"true\" aria-describedBy=\"err_1\"> </div> <span class=\"errtext\" id=\"err_1\">Error: Incorrect data</span> </div> ```  ```html <div class=\"control\"> <div><label for=\"email\">Email address: [*]</label> <input type=\"text\" name=\"email\" id=\"email\" class=\"error\" aria-invalid=\"true\" aria-describedBy=\"err_2\"> </div> <span class=\"errtext\" id=\"err_2\">Error: Input data missing</span> </div> ```  ```html $(errFld).attr(\"aria-invalid\", \"true\").attr(\"class\", \"error\"); // Suffix error text: $(errFld).parent().append('<span class=\"errtext\">Error: Incorrect data</span>'); ```  ```html input.error { border: red thin solid; }  span.errtext { background-color: #EEEEFF; background-image:url('images/iconError.gif'); background-position:right; background-repeat:no-repeat; border: red thin solid; margin-bottom: 1em; padding: .25em 1.4em .25em .25em; } ```    ---",
    "referenced_by": [
      "3.3.1"
    ]
  },
  {
    "id": "SCR18",
    "type": "technique",
    "code": "SCR18",
    "text": "[SCR18] Providing client-side validation and alert\n\nDescription:\nThe objective of this technique is to validate user input as values are entered for each field, by means of client-side scripting. If errors are found, an alert dialog describes the nature of the error in text. Once the user dismisses the alert dialog, it is helpful if the script positions the keyboard focus on the field where the error occurred.\n\nExamples:\n- **Example 1: Checking a single control with an event handler**  The following script will check that a valid date has been entered in the form control.  ```html <label for=\"date\">Date:</label> <input type=\"text\" name=\"date\" id=\"date\" onchange=\"if(isNaN(Date.parse(this.value))) alert('This control is not a valid date. Please re-enter the value.');\"> ```\n- **Example 2: Checking multiple controls when the user submits the form**  The following sample shows multiple controls in a form. Theformelement uses theonsubmitattribute which creates an event handler to execute the validation script when the user attempts to submit the form. If the validation is successful, the event returnstrueand the form submission proceeds; if the validation finds errors, it displays an error message and returnsfalseto cancel the submit attempt so the user can fix the problems.  Script code:  Form code:  This is demonstrated in theworking example of checking multiple controls when the user submits the form.  ```html function validate() { // initialize error message var msg = \"\";  //validate name var pattern = /^[a-zA-Z\\s]+$/; var el = document.getElementById(\"name\");  if (!pattern.test(el.value)) { msg += \"Name can only have letters and spaces. \"; }  // validate number var pattern = /^[\\d\\-+\\.\\s]+$/; var el = document.getElementById(\"tel\");  if (!pattern.test(el.value)) { msg += \"Telephone number can only have digits and separators. \"; }  if (msg != \"\") { alert(msg); return false; } else { return true; } ```  ```html <form action=\"multiple-controls.html\" onsubmit=\"return validate()\"> <div> <label for=\"name\">Name:</label> <input autocomplete=\"name\" id=\"name\" name=\"name\" type=\"text\"> </div> <div> <label for=\"tel\">Telephone number:</label> <input autocomplete=\"tel\" id=\"tel\" name=\"tel\" type=\"tel\"> </div> <div> <input type=\"submit\"> </div> </form> ```    ---",
    "referenced_by": [
      "3.3.1",
      "3.3.3",
      "3.3.4"
    ]
  },
  {
    "id": "PDF5",
    "type": "technique",
    "code": "PDF5",
    "text": "[PDF5] Indicating required form controls in PDF forms\n\nDescription:\nThe objective of this technique is to notify the user when a field that must be completed has not been completed in a PDF form. Required fields are implemented using the **/Ff** entry in the form field's dictionary. This is normally accomplished using a tool for authoring PDFs.\n\nIf errors are found, an alert dialog describes the nature of the error in text. This may be accomplished through scripting created by the author (see, for example, [SCR18: Providing client-side validation and alert](../client-side-script/SCR18)). User agents, such as Adobe Acrobat Pro and LiveCycle, can provide automatic alerts (as described in the examples below).\n\nEnsuring that users are aware an error has occurred, can determine what is wrong, and can correct it are keys to software usability and accessibility. Meeting this objective helps ensure that all users can complete transactions with ease and confidence.\n\nExamples:\n- **Example 1: Creating a required field in a PDF form using Acrobat Pro**  This example is shown in operation in theworking example of creating a required field in Acrobat.\n- **Example 2: Adding a required text field in a PDF form using the /Tx field type and Ff flag**  The following code fragment illustrates code that is typical for the object definitions for a typical text field. Note that the text field is required, using the Ff flag. This is typically accomplished by an authoring tool.  ```html << /AP -dict- /DA /Helv  0 Tf 0 g /DR -dict- /F 0x4 /FT Tx              % FT key set to Tx for Text Field /Ff 0x2             % Ff integer 0x2 value indicates required /P -dict- /Rect -array- /StructParent 0x1 /Subtype Widget /T First            % Partial field name First /TU First name (required)  % TU tool tip value serves as short description /Type Annot /V Pat Jones >> ... <Start Stream> BT /P <</MCID 0 >>BDC /CS0 cs 0  scn /TT0 1 Tf -0.001 Tc 0.003 Tw 11.04 0 0 11.04 72 709.56 Tm [(P)-6(le)-3(as)10(e)-3( )11(P)-6(rin)2(t)-3( Y)8(o)-7(u)2(r N)4(a)11(m)-6(e)]TJ 0 Tc 0 Tw 9.533 0 Td ( )Tj -0.004 Tc 0.004 Tw 0.217 0 Td [(\\()-5(R)-4(e)5(q)-1(u)-1(i)-3(r)-3(e)-6(d)-1(\\))]TJ EMC /P <</MCID 1 >>BDC 0 Tc 0 Tw 4.283 0 Td [( )-2( )]TJ EMC /ArtifactSpan <</MCID 2 >>BDC 0.002 Tc -0.002 Tw 0.456 0 Td [(__)11(___)11(___)11(___)11(___)11(_)11(____)11(___)11(___)11(__)]TJ 0 Tc 0 Tw 13.391 0 Td ( )Tj EMC ET <End Stream> ```    ---",
    "referenced_by": [
      "3.3.1",
      "3.3.2"
    ]
  },
  {
    "id": "ARIA18",
    "type": "technique",
    "code": "ARIA18",
    "text": "[ARIA18] Using aria-alertdialog to Identify Errors\n\nDescription:\nThe purpose of this technique is to alert people that an input error has occurred. Using **role=\"alertdialog\"** creates a notification. This notification should be modal with the following characteristics:\n\n- aria-labeloraria-labelledbyattribute gives the alertdialog an accessible name.\n- Thealertdialogcontains at least one focusable element, and the focus should move to that element when thealertdialogopens.\n- The tab order is constrained within thealertdialogwhilst it is open.\n- When thealertdialogis dismissed, the focus moves back to the position it had before thealertdialogopened, if possible.\n\nNote that the **alertdialog** should not be present in a way that it will be accessed by assistive technology until it is needed. One way to do this is not to include it in the static HTML and instead to insert it into the DOM via script when the error condition is triggered. The insertion would correspond to the following HTML sample.\n\nExamples:\n- **Example 1: Alert dialog**  This example shows how a notification usingrole=\"alertdialog\"can be used to notify someone they have entered invalid information.  Working example:Alert dialog.  ```html <div role=\"alertdialog\" aria-labelledby=\"alertHeading\"> <h1 id=\"alertHeading\">Error</h1> <p>Employee's Birth Date is after their hire date. Please verify the birth date and hire date.</p> <button>Save and Continue</button> <button>Return to page and correct error</button> </div> ```    ---",
    "referenced_by": [
      "3.3.1",
      "3.3.3",
      "4.1.3"
    ]
  },
  {
    "id": "ARIA19",
    "type": "technique",
    "code": "ARIA19",
    "text": "[ARIA19] Using ARIA role=alert or Live Regions to Identify Errors\n\nDescription:\nThe purpose of this technique is to notify Assistive Technologies (AT) when an input error occurs. The **aria-live** attribute makes it possible for an AT (such as a screen reader) to be notified when error messages are injected into a Live Region container. The content within the **aria-live** region is automatically read by the AT, without the AT having to focus on the place where the text is displayed.\n\nThere are also a number of [special case live region roles](https://www.w3.org/TR/wai-aria/#live_region_roles) which can be used instead of applying live region properties directly.\n\nExamples:\n- **Example 1: Injecting error messages into a container with role=alert already present in the DOM**  The following example uses role=alert which is equivalent to using aria-live=assertive.  In the example there is an empty error message container element with aria-atomic=true and an aria-live property or alert role present in the DOM on page load. The error container must be present in the DOM on page load for the error message to be spoken by most screen readers. aria-atomic=true is necessary to make Voiceover on iOS read the error messages after more than one invalid submission.  jQuery is used to test if the inputs are empty on submit and inject error messages into the live region containers if so. Each time a new submit is attempted the previous error messages are removed from the container and new error messages injected.  Working example:Using role=alert to identify errors.  ```html $(document).ready(function(e) { $('#signup').submit(function() { $('#errors').html(''); if ($('#first').val() === '') { $('#errors').append('<p>Please enter your first name.</p>'); } if ($('#last').val() === '') { $('#errors').append('<p>Please enter your last name.</p>'); } if ($('#email').val() === '') { $('#errors').append('<p>Please enter your email address.</p>'); } return false; }); }); <form name=\"signup\" id=\"signup\"> <p id=\"errors\" role=\"alert\" aria-atomic=\"true\"></p> <div> <label for=\"first\">First Name (required)</label><br> <input type=\"text\" name=\"first\" id=\"first\"> </div> <div> <label for=\"last\">Last Name (required)</label><br> <input type=\"text\" name=\"last\" id=\"last\"> </div> <div> <label for=\"email\">Email (required)</label><br> <input type=\"text\" name=\"email\" id=\"email\"> </div> <div> <input type=\"submit\" name=\"button\" id=\"button\" value=\"Submit\"> </div> </form> ```    ---",
    "referenced_by": [
      "3.3.1",
      "4.1.3"
    ]
  },
  {
    "id": "G84",
    "type": "technique",
    "code": "G84",
    "text": "[G84] Providing a text description when the user provides information that is not in the list of allowed values\n\nDescription:\nWhen users enter input that is validated, and errors are detected, the nature of the error needs to be described to the user in manner they can access. One approach is to present an alert dialog that describes fields with errors when the user attempts to submit the form. Another approach, if validation is done by the server, is to return the form (with the user's data still in the fields) and a text description at the top of the page that indicates the fact that there was a validation problem, describes the nature of the problem, and provides ways to locate the field(s) with a problem easily. The \"in text\" portion of the success criterion underscores that it is not sufficient simply to indicate that a field has an error by putting an asterisk on its label or turning the label red. A text description of the problem should be provided.\n\nWhen input must be one of a set of allowed values, the text description should indicate this fact. It should include the list of values if possible, or suggest the allowed value that is most similar to the entered value.\n\nExamples:\n- **Example 2:** The user inputs invalid data on a form field and submits the form. The server returns the form, with the user's data still present, and indicates clearly in text at the top of the page that there were input errors. The text describes the nature of the error(s) and clearly indicates which field had the problem so the user can easily navigate to it to fix the problem.  ---\n- **Example 1:** The user inputs invalid data on a form field. Before the user submits the form, an alert dialog appears that describes the nature of the error so the user can fix it.",
    "referenced_by": [
      "3.3.1",
      "3.3.3",
      "4.1.3"
    ]
  },
  {
    "id": "G85",
    "type": "technique",
    "code": "G85",
    "text": "[G85] Providing a text description when user input falls outside the required format or values\n\nDescription:\nThe objective of this technique is to provide assistance in correcting input errors where the information supplied by the user is not accepted. When users enter data input that is validated, and input errors are detected, information about the nature and location of the input error is provided in text to enable the users to identify the problem. One approach is to use client-side validation and provide an alert dialog box that describes the error immediately when users enter invalid data in field. Another approach, using server-side validation, is to re-display the form (including any previously entered data), and a text description at the top of the page that indicates the fact that there was an error, describes the nature of the problem, and provides ways to easily locate the field(s) with a problem.\n\nHowever the text description is provided, it should do one of the following things to assist the user:\n\n- Provide examples of the correct data entry for the field,\n- Describe the correct data entry for the field,\n- Show values of the correct data entry that are similar to the user's data entry, with instructions to the user as to how to enter one of these correct values should the user choose to do so.\n\nExamples:\n- **Example 3:** The user inputs invalid data on a form field and attempts to submit the form. Client side scripting detects the error, cancels the submit, and modifies the document to provide a text description after the submit button describing the error, with links to the field(s) with the error. The script also modifies the labels of the fields with the problems to highlight them.  ---\n- **Example 2:** The user inputs invalid data on a form field and submits the form. The server returns the form, with the user's data still present, and indicates clearly in text at the top of the page that there were input errors. The text describes the nature of the error(s) and clearly indicates which field had the problem so the user can easily navigate to it to fix the problem.\n- **Example 1:** The user inputs invalid data on a form field. When the user exits the field, an alert dialog appears that describes the nature of the error so the user can fix it.",
    "referenced_by": [
      "3.3.1",
      "3.3.3",
      "4.1.3"
    ]
  },
  {
    "id": "SCR32",
    "type": "technique",
    "code": "SCR32",
    "text": "[SCR32] Providing client-side validation and adding error text via the DOM\n\nDescription:\nThe objective of this technique is to demonstrate the display of an error message when client side validation of a form field has failed. Anchor elements are used to display the error messages in a list and are inserted above the fields to be validated. Anchor elements are used in the error messages so that focus can be placed on the error message(s), drawing the user's attention to it. The **href** of the anchor elements contain an in-page link which references the fields where error(s) have been found.\n\nIn a deployed application, if Javascript is turned off, client side validation will not occur. Therefore, this technique would only be sufficient in situations where scripting is relied upon for conformance or when server side validation techniques are also used to catch any errors and return the page with information about the fields with errors.\n\nExamples:\n- **Example 1: Listing errors in a block at the top of a form**  This example validates required fields as well as fields where a specific format is required. When an error is identified, the script inserts a list of error messages into the DOM and moves focus to them.  ```html <!DOCTYPE HTML> <html lang=\"en\"> <head> <title>Form Validation</title> <meta charset=\"utf-8\"> <link href=\"css/validate.css\" rel=\"stylesheet\"> <script src=\"scripts/validate.js\"> </head> <body> <h1>Form Validation</h1> <p>The following form is validated before being submitted if scripting is available, otherwise the form is validated on the server. All fields are required, except those marked optional. If errors are found in the submission, the form is cancelled and a list of errors is displayed at the top of the form.</p>  <p>Please enter your details below.</p>  <h2>Validating Form</h2> <form id=\"personalform\"> <div class=\"validationerrors\"></div> <fieldset> <legend>Personal Details</legend> <div> <label for=\"forename\">Please enter your forename</label> <input autocomplete=\"given-name\" class=\"string\" id=\"forename\" name=\"forename\" type=\"text\" value=\"\"> </div> <div> <label for=\"age\">Please enter your age</label> <input class=\"number\" id=\"age\" name=\"age\" type=\"text\" value=\"\"> </div> <div> <label for=\"email\">Please enter your email address</label> <input autocomplete=\"email\" class=\"email\" id=\"email\" name=\"email\" type=\"text\" value=\"\"> </div> </fieldset> <div> <input type=\"submit\" name=\"signup\" value=\"Sign up\"> </div> </form>  <h2>Second Form</h2> <form id=\"secondform\"> <div class=\"validationerrors\"></div> <fieldset> <legend>Second Form Details</legend> <div> <label for=\"suggestion\">Enter a suggestion</label> <input class=\"string\" id=\"suggestion\" name=\"suggestion\" type=\"text\" value=\"\"> </div> <div> <label for=\"optemail\">Please enter your email address (optional)</label> <input autocomplete=\"email\" class=\"optional email\" id=\"optemail\" name=\"optemail\" type=\"text\" value=\"\"> </div> <div> <label for=\"rating\">Please rate this suggestion</label> <input class=\"number\" id=\"rating\" name=\"rating\" type=\"text\" value=\"\"> </div> <div> <label for=\"jibberish\">Enter some jibberish (optional)</label> <input id=\"jibberish\" name=\"jibberish\" type=\"text\" value=\"\"> </div> </fieldset> <div> <input type=\"submit\" name=\"submit\" value=\"Add Suggestion\"> </div> </form> </body> </html> ```  ```html window.onload = initialise; function initialise() { var objForms = document.getElementsByTagName('form'); var iCounter;  // Attach an event handler for each form for (iCounter=0; iCounter<objForms.length; iCounter++) { objForms[iCounter].onsubmit = function(){return validateForm(this);}; } }  // Event handler for the form function validateForm(objForm) { var arClass = []; var iErrors = 0; var objField = objForm.getElementsByTagName('input'); var objLabel = objForm.getElementsByTagName('label'); var objList = document.createElement('ol'); var objError, objExisting, objNew, objTitle, objParagraph, objAnchor, objPosition; var strLinkID, iFieldCounter, iClassCounter, iCounter;  // Get the id or name of the form, to make a unique // fragment identifier if (objForm.id) { strLinkID = objForm.id + 'ErrorID'; } else { strLinkID = objForm.name + 'ErrorID'; }  // Iterate through input form controls, looking for validation classes for (iFieldCounter=0; iFieldCounter<objField.length; iFieldCounter++) {  // Get the class for the field, and look for the appropriate class arClass = objField[iFieldCounter].className.split(' '); for (iClassCounter=0; iClassCounter<arClass.length; iClassCounter++) { switch (arClass[iClassCounter]) { case 'string': if (!isString(objField[iFieldCounter].value, arClass)) { if (iErrors === 0) { logError(objField[iFieldCounter], objLabel, objList, strLinkID); } else { logError(objField[iFieldCounter], objLabel, objList, ''); } iErrors++; } break; case 'number': if (!isNumber(objField[iFieldCounter].value, arClass)) { if (iErrors === 0) { logError(objField[iFieldCounter], objLabel, objList, strLinkID); } else { logError(objField[iFieldCounter], objLabel, objList, ''); } iErrors++; } break; case 'email' : if (!isEmail(objField[iFieldCounter].value, arClass)) { if (iErrors === 0) { logError(objField[iFieldCounter], objLabel, objList, strLinkID); } else { logError(objField[iFieldCounter], objLabel, objList, ''); } iErrors++; } break; } } }  if (iErrors > 0) {  // If not valid, display error messages objError = objForm.getElementsByTagName('div');  // Look for existing errors for (iCounter=0; iCounter<objError.length; iCounter++) { if (objError[iCounter].className == 'validationerrors') { objExisting = objError[iCounter]; } }  objNew = document.createElement('div'); objTitle = document.createElement('h2'); objParagraph = document.createElement('p'); objAnchor = document.createElement('a');  if (iErrors == 1) { objAnchor.appendChild(document.createTextNode('1 Error in Submission')); } else { objAnchor.appendChild(document.createTextNode(iErrors + ' Errors in Submission')); }  objAnchor.href = '#' + strLinkID; objAnchor.className = 'submissionerror';  objTitle.appendChild(objAnchor); objParagraph.appendChild(document.createTextNode('Please review the following')); objNew.className = 'validationerrors';  objNew.appendChild(objTitle); objNew.appendChild(objParagraph); objNew.appendChild(objList);  // If there were existing error, replace them with the new lot, // otherwise add the new errors to the start of the form if (objExisting) { objExisting.parentNode.replaceChild(objNew, objExisting); } else { objPosition = objForm.firstChild; objForm.insertBefore(objNew, objPosition); }  // Allow for latency setTimeout(function() { objAnchor.focus(); }, 50);  // Don't submit the form objForm.submitAllowed = false; return false; }  // Submit the form return true; }  // Function to add a link in a list item that points to problematic field control function addError(objList, strError, strID, strErrorID) {  var objListItem = document.createElement('li'); var objAnchor = document.createElement('a');  // Fragment identifier to the form control objAnchor.href='#' + strID;  // Make this the target for the error heading if (strErrorID.length > 0) { objAnchor.id = strErrorID; }  // Use the label prompt for the error message objAnchor.appendChild(document.createTextNode(strError));  // Add keyboard and mouse events to set focus to the form control objAnchor.onclick = function(event){return focusFormField(this, event);}; objAnchor.onkeypress = function(event){return focusFormField(this, event);}; objListItem.appendChild(objAnchor); objList.appendChild(objListItem); }  function focusFormField(objAnchor, objEvent) { var strFormField, objForm;  // Allow keyboard navigation over links if (objEvent && objEvent.type == 'keypress') { if (objEvent.keyCode != 13 && objEvent.keyCode != 32) { return true; } }  // set focus to the form control strFormField = objAnchor.href.match(/[^#]\\w*$/); objForm = getForm(strFormField); objForm[strFormField].focus(); return false; }  // Function to return the form element from a given form field name function getForm(strField) { var objElement = document.getElementById(strField);  // Find the appropriate form do { objElement = objElement.parentNode; } while (!objElement.tagName.match(/form/i) && objElement.parentNode);  return objElement; }  // Function to log the error in a list function logError(objField, objLabel, objList, strErrorID) { var iCounter, strError;  // Search the label for the error prompt for (iCounter=0; iCounter<objLabel.length; iCounter++) { if (objLabel[iCounter].htmlFor == objField.id) { strError = objLabel[iCounter].firstChild.nodeValue; } }  addError(objList, strError, objField.id, strErrorID); }  // Validation routines - add as required  function isString(strValue, arClass) { var bValid = (typeof strValue == 'string' && strValue.replace(/^\\s*|\\s*$/g, '') !== '' && isNaN(strValue));  return checkOptional(bValid, strValue, arClass); }  function isEmail(strValue, arClass) { var objRE = /^[\\w-\\.\\']{1,}\\@([\\da-zA-Z\\-]{1,}\\.){1,}[\\da-zA-Z\\-]{2,}$/; var bValid = objRE.test(strValue);  return checkOptional(bValid, strValue, arClass); }  function isNumber(strValue, arClass) { var bValid = (!isNaN(strValue) && strValue.replace(/^\\s*|\\s*$/g, '') !== '');  return checkOptional(bValid, strValue, arClass); }  function checkOptional(bValid, strValue, arClass) { var bOptional = false; var iCounter;  // Check if optional for (iCounter=0; iCounter<arClass.length; iCounter++) { if (arClass[iCounter] == 'optional') { bOptional = true; } }  if (bOptional && strValue.replace(/^\\s*|\\s*$/g, '') === '') { return true; }  return bValid; } ```    ---",
    "referenced_by": [
      "3.3.1",
      "3.3.3"
    ]
  },
  {
    "id": "PDF22",
    "type": "technique",
    "code": "PDF22",
    "text": "[PDF22] Indicating when user input falls outside the required format or values in PDF forms\n\nDescription:\nThe objective of this technique is to notify the user when user\ninput to a field that requires a specific, required format (e.g.,\ndate fields) is not submitted in that format.\n\nIf the required format is not used, an alert dialog describes the\nnature of the error in text. This may be accomplished through scripting\ncreated by the author (see, for example, [SCR18: Providing client-side validation and alert](../client-side-script/SCR18)). User agents can provide automatic alerts (as described in the examples below).\n\nEnsuring that users are aware an error has occurred, can determine what is wrong, and can correct it are key to software usability and accessibility. Meeting this objective helps ensure that all users can complete for-based transactions with ease and confidence.\n\nExamples:\n- **Example 2: Validating a required date format in a PDF form using JavaScript using Adobe Acrobat Pro**  This example is shown with Adobe Acrobat Pro. There are other software tools that perform similar functions.  The following JavaScript illustrates the use of a script to validate form fields, in this case, a date field. To add this script to the form field, open the Text Field Properties dialog and select Edit in the Validate tab.  ```html // JavaScript code for date mask format MM/DD/YYYY var re = /^[mdy0-9]{2}\\/[mdy0-9]{2}\\/[mdy0-9]{4}$/ //Allow blank space in field if (event.value !=\"\") { if (re.test(event.value) == false) { app.alert ({ cTitle: \"Incorrect Format\", cMsg: \"Please enter date using\\nmm/dd/yyyy format\" }); } } ```    ---\n- **Example 1: Providing validation for an input field format using Adobe Acrobat Pro**  This example is shown with Adobe Acrobat Pro. There are other software tools that perform similar functions.  Many fields, for example: telephone number, postal code, and dates, must have data entered in a specific format or pattern.  When a user types a recognized date format, it is converted automatically to the specified format. If the date format or value is not recognized, an error alert appears and provides further information  This example is shown in operation in theworking example of Required Fields in Acrobat (PDF).",
    "referenced_by": [
      "3.3.1",
      "3.3.3"
    ]
  },
  {
    "id": "G139",
    "type": "technique",
    "code": "G139",
    "text": "[G139] Creating a mechanism that allows users to jump to errors\n\nDescription:\nThe objective of this technique is to help users find input errors where the information supplied by the user is not accepted. This includes fields with missing required information and fields with incorrect information. When users enter data input that is checked, and input errors are detected, a link to that error is provided so that the user does not have to search for it. One approach is to use server-side validation, and to re-display the form (including any previously entered data), and a text description at the top of the page that indicates the fact that there was an input error, describes the nature of the problem, and provides a link the field(s) with a problem.\n\nExamples:\n- **Example 1: Server-side error checking**  The user inputs invalid data on a form field and submits the form. The server returns the form, with the user's data still present, and indicates clearly in text at the top of the page that there were not accepted. The text describes the nature of the error(s) and provides a link to the field that had the problem so the user can easily navigate to it to fix the problem.\n- **Example 3: Client-side error checking with no popup**  When the user submits a form, instead of taking them to a new page, a script automatically sets focus to a text link that says \"Errors have occurred.\" The link goes to the first item in an ordered list of descriptive error messages. Each list item is a link to the control where the error had occurred. And there is a link from the error back to the ordered list of descriptive error messages. The process is repeated as needed.    ---\n- **Example 2: Client-side error checking with a popup**  The user inputs invalid data on a form field and attempts to submit the form. Client-side scripting detects the error, cancels the submit, and modifies the document to provide a text message describing the error, with links to the field(s) with the error. The script also modifies the labels of the fields with the problems to highlight them.",
    "referenced_by": [
      "3.3.1",
      "3.3.3"
    ]
  },
  {
    "id": "G199",
    "type": "technique",
    "code": "G199",
    "text": "[G199] Providing success feedback when data is submitted successfully\n\nDescription:\nThe objective of this technique is to reduce the effort required for users to confirm that an action, such as submitting a Web form, was completed successfully. This can be accomplished by providing consistently presented feedback that explicitly indicates success of an action, rather than requiring a user to navigate through content to discover if the action was successful.\n\nSignificant effort can be expended by users who can not easily scan through information to confirm their action (such as that data submitted has been successfully entered into a database, sent to a person, or added to content being edited).\n\nExamples:\n- **Example 1:** A user logs into a system and gets a response indicating that: \"You have successfully logged in,\" so they do not need to navigate through the screen to find an indicator that they are logged in, such as finding their user name, or perhaps the login link replaced with a logout link. Finding these cues can be time consuming.\n- **Example 2:** A user fills in a quiz or test and submits it. The response informs them that the test was successfully submitted, so that they don't need to navigate through data, such as a list of submitted tests, to confirm that the test is listed there.\n- **Example 3:** A visitor creates an account on a website. After submission of the form, feedback suggests that \"Registration was successfully submitted ...,\" If they are automatically logged in after registration, the response also says \"...and you have been logged in.\" If confirmation is required, the feedback includes a message such as \"...an email has been sent to you to which you must reply to confirm your registration.\"\n- **Example 4:** A user submits a form with information directed at support staff. The feedback indicates that the \"The message was successfully sent, and you should receive a reply within the next 48 hours.\"  ---",
    "referenced_by": [
      "3.3.1",
      "3.3.3",
      "3.3.4",
      "4.1.3"
    ]
  },
  {
    "id": "G89",
    "type": "technique",
    "code": "G89",
    "text": "[G89] Providing expected data format and example\n\nDescription:\nThe objective of this technique is to help the user avoid input errors by informing them about restrictions on the format of data that they must enter. This can be done by describing characteristics of the format or providing a sample of the format the data should have.\n\nExamples:\n- **Example 1: Date text input**  The followingHTMLform control for a date indicates in the label that the date must be in day-month-year format, not month-day-year as many users in the United States may assume.  ```html <label for=\"date\">Date (dd-mm-yyyy)</label> <input type=\"text\" name=\"date\" id=\"date\"> ```    ---",
    "referenced_by": [
      "3.3.2",
      "3.3.5"
    ]
  },
  {
    "id": "G184",
    "type": "technique",
    "code": "G184",
    "text": "[G184] Providing text instructions at the beginning of a form or set of fields that describes the necessary input\n\nDescription:\nThe objective of this technique is to help the user avoid input errors by informing them ahead of time about restrictions on the format of data that they must enter. Instructions on such restrictions are provided at the top of forms. This technique works best for forms that have a small number of fields or those where many form fields require data in the same format. In these cases, it is more efficient to describe the format once in instructions at the top of the form rather than repeating the same information for each field that has the same restricted format requirement.\n\nExamples:\n- **Example 2**  A corporate directory allows users to customize information such as telephone number and job responsibilities by editing their profile. At the top of the form are the following instructions:    ---\n- **Example 1**  A business networking site allows users to post descriptions of jobs they have held. The form to gather the information includes fields for the company name, job title, from and to dates, and job description. At the top of the form are the following instructions:",
    "referenced_by": [
      "3.3.2",
      "3.3.5"
    ]
  },
  {
    "id": "H90",
    "type": "technique",
    "code": "H90",
    "text": "[H90] Indicating required form controls using label or legend\n\nDescription:\nThe objective of this technique is to provide a clear indication that a specific form control in a web application or form is required for successful data submission. A symbol or text indicating that the control is required is programmatically associated with the field by using the **label** element, or the **legend** for groups of controls associated via **fieldset**. If a symbol is used, the user is advised of its meaning before the first use.\n\nExamples:\n- **Example 1: Using text to indicate required state**  The text field in the example below has the explicit label of \"First name (required):\". Thelabelelement'sforattribute matches theidattribute of theinputelement and thelabeltext indicates that the control is required.  ```html <label for=\"firstname\">First name (required):</label> <input id=\"firstname\" name=\"firstname\" type=\"text\"> ```\n- **Example 2: Using an asterisk to indicate required state**  The text field in the example below has an explicit label that includes an asterisk to indicate the control is required. It is important that the asterisk meaning is defined at the start of the form. In this example, the asterisk is contained within aabbrelement to allow for the asterisk character to be styled so that it is larger than the default asterisk character, since the asterisk character can be difficult to see for those with impaired vision.  ```html .req {font-size: 150%} ```  ```html <p>Required fields are marked with an asterisk (<abbr class=\"req\" title=\"required\">*</abbr>).</p> <form action=\"https://example.com\" method=\"post\"> <label for=\"firstname\">First name <abbr class=\"req\" title=\"required\">*</abbr>:</label> <input id=\"firstname\" name=\"firstname\" type=\"text\"> ... </form> ```\n- **Example 3: Using an image to indicate required state**  The text field in the example below has an explicit label that includes an image to indicate the control is required. It is important that the image meaning is defined at the start of the form.  ```html <p><img alt=\"required\" src=\"req_img.gif\"> indicates that the information is required</p> <form action=\"https://www.example.com\" method=\"post\"> <label for=\"firstname\">First name <img alt=\"required\" src=\"req_img.gif\">:</label> <input id=\"firstname\" name=\"firstname\" type=\"text\"> ... </form> ```\n- **Example 4: Indicating required state for groups of radio buttons or check box controls**  Radio buttons and checkboxes are treated differently than other interactive controls since individual radio buttons and checkboxes are not required but indicates that a response for the group is required. The methods used in examples 1-3 apply to radio buttons and checkboxes, but the indication of the required state should be placed in thelegendelement instead of thelabelelement.  ```html <fieldset> <legend>I am interested in the following (Required):</legend> <div> <input id=\"photo\" name=\"interests\" type=\"checkbox\" value=\"ph\"> <label for=\"photo\">Photography</label> </div> <div> <input checked id=\"watercol\" name=\"interests\" type=\"checkbox\" value=\"wa\"> <label for=\"watercol\">Watercolor</label> </div> <div> <input checked id=\"acrylic\" name=\"interests\" type=\"checkbox\" value=\"ac\"> <label for=\"acrylic\">Acrylic</label> </div> ... </fieldset> ```    ---",
    "referenced_by": [
      "3.3.2"
    ]
  },
  {
    "id": "G167",
    "type": "technique",
    "code": "G167",
    "text": "[G167] Using an adjacent button to label the purpose of a field\n\nDescription:\nWhen a button invokes a function on an input field, has a clear text label or name, and is rendered adjacent to the input field, the button also acts as a label for the input field. This label helps users understand the purpose of the field without introducing repetitive text on the web page. Buttons that label single text fields typically follow the input field.\n\nExamples:\n- **Example 1: A search function**  A web page contains a text field where the user can enter search terms and a button labeled \"Search\" for performing the search. The button is positioned right after the text field so that it is clear to the user that the text field is where to enter the search term.  Alternatively, a button visually labeled with a \"loupe\" or \"magnify glass\" icon, with the alternative text of \"search\", could be used instead of a button with a text label. Variants of this icon are used to identify search inputs across not just websites, but user interfaces of non-web software as well.\n- **Example 2: A \"reply\" or \"send message\" field**  A chat or email web application will often present users a single or multi-line text field used for composing a message. The field does not have a visible text label, but the purpose of the field - to compose a message to send - is indicated by its pairing with a button represented by a \"send message\" icon. The icon serving the dual purpose of visually labelling the button, as well as the text field.\n- **Example 3: Picking a form**  A user in the United States must fill in a form. Since the laws and requirements are different in different states within the United States, the user must select the version of a form for their state of residence. A dropdown list allows the user to pick a state. The adjacent button is labeled \"Get Form for State.\" Pressing the button takes the user to the web page containing the form for the selected state.    ---",
    "referenced_by": [
      "3.3.2"
    ]
  },
  {
    "id": "F82",
    "type": "technique",
    "code": "F82",
    "text": "[F82] Failure of Success Criterion 3.3.2 by visually formatting a set of phone number fields but not including a text label\n\nDescription:\nThis failure ensures that people with visual or cognitive disabilities will recognize phone number fields and understand what information to provide to fill in the fields. Phone numbers are frequently formatted in fixed, distinctive ways, and authors may feel that just providing visual formatting of the fields will be sufficient to identify them. However, even if all the fields have programmatically determined names, a text label must also identify the set of fields as a phone number.\n\nExamples:\n- **Example 1**  In the United States, phone numbers are broken into a three digit area code, a three digit prefix, and a four digit extension. A web page creates fixed length text input fields for the three parts of the phone number, surrounding the first field with parenthesis and separating the second and third fields with a dash. Because of this formatting, some users recognize the fields as a phone number. However, there is no text label for the phone number on the web page. This is because the label for each field will be the closest preceding text, so the three fields would be labeled \"(\", \")\" , and \"-\" respectively.    ---",
    "referenced_by": [
      "3.3.2"
    ]
  },
  {
    "id": "G177",
    "type": "technique",
    "code": "G177",
    "text": "[G177] Providing suggested correction text\n\nDescription:\nThe objective of this technique is to suggest correct text where the information supplied by the user is not accepted and possible correct text is known. The suggestions may include correct spelling or similar text from a known pool of possible text.\n\nDepending on the form, suggestions could be located next to the field where the error was identified, elsewhere on the page or via a search mechanism or reference where results would be listed on another URI. Where possible, suggestions for correction should be incorporated in a way that is easy for the user. For example, an incorrect submission may return a list of possible corrections where the user can select a checkbox or radio button to indicate which option was intended. Suggestions or links to the suggestions should be placed close to the form fields they are associated with, such as at the top of the form, preceding the form fields, or next to the form fields requiring correction.\n\nExamples:\n- **Example 1:** A form field requires the user to input a length of time that could range from days to years. The user enters the number \"6\". The server returns the form as the user had submitted it and also includes a suggested text next to the form field: \"Error detected. Did you mean: 6 days, 6 weeks, 6 months or 6 years?\"\n- **Example 2:** The user enters an incorrectly spelled city name. The server returns the form as the user had submitted it and also includes a message at the top of the form informing the user of the error and a link to a list of city names that the user may have meant, as determined by comparing their original input to a database of city names.\n- **Example 3:** A bus route trip planner allows users to enter their origin an destination, allowing users to enter street addresses, intersections and city landmarks. When a user enters \"Kohl,\" they are prompted with a list of search results with similar matches that reads, \"Your search for 'Kohl' returned the following\". A select box follows the prompt lists, \"Kohl Center,\" \"Kohl's Dept. Store-East\" and \"Kohl's Dept. Store-West\" as options the user can choose from.\n- **Example 4:** A search runs a spell check on input and provides a link of alternatives if a spelling error is detected. When the user clicks on the link, the search is automatically resubmitted with the correct spelling.  ---",
    "referenced_by": [
      "3.3.3",
      "4.1.3"
    ]
  },
  {
    "id": "G164",
    "type": "technique",
    "code": "G164",
    "text": "[G164] Providing a stated time within which an online request (or transaction) may be amended or canceled by the user after making the request\n\nDescription:\nThe objective of this technique is to allow users to recover from errors made when placing an order by providing them with a period of time during which they can cancel or change the order. In general, a contract or an order is a legal commitment and cannot be canceled. However, a website may choose to offer this capability, and it provides a way for users to recover from errors.\n\nThe Web content would need to tell the user how long the cancellation period is after submitting the form and what the procedure would be to cancel the order. The cancellation procedure may not be possible online. It may, for instance, require written notice be sent to an address listed on the web page.\n\nAfter submitting the form, the user is informed of the length of the cancellation period and the procedure for canceling the transaction. It's best to provide the cancellation procedure at the same website where the transaction was submitted so that it is as easy to cancel as it was to submit and to accommodate users who may be unable to use other mechanisms. But, if necessary, the cancellation procedure may be provided through some other mechanism or combination of mechanisms as long as it has equivalent cross-disability accessibility. In this case, users are warned prior to submitting the form that they will not be able to cancel their order online.\n\nExamples:\n- **Example 1: Online shopping**  An online shopping website lets users cancel purchases up to 24 hours after they have been made. The website explains their policy, and includes a summary of the policy on the purchase receipt emailed to the user. After 24 hours, the purchase will be shipped to the user and can no longer be canceled.\n- **Example 2: Custom orders**  A website sells custom sports jackets that are made to order. The customer chooses the fabric and provides body measurements for the tailor. The website gives customers up to three days to change or cancel an order. Once the material has been cut to the customer's specifications, it is no longer possible to change or cancel the order. The company policy is described on its website.    ---",
    "referenced_by": [
      "3.3.4"
    ]
  },
  {
    "id": "G98",
    "type": "technique",
    "code": "G98",
    "text": "[G98] Providing the ability for the user to review and correct answers before submitting\n\nDescription:\nThe objective of this technique is to provide users with a way to ensure their input is correct before completing an irreversible transaction. Testing, financial, and legal applications permit transactions to occur which cannot be \"undone\". It is therefore important that there be no errors in the data submission, as the user will not have the opportunity to correct the error once the transaction has been committed.\n\nOn a simple, 1-page form this is easy because the user can review the form before submitting. On a form that spans multiple web pages, however, data is collected from the user in multiple steps before the transaction is committed. The user may not recall all of the data that was entered in previous steps before the step which commits the transaction.\n\nOne approach is to cache the results of each individual step and allow the user to navigate back and forth at will to review all data entered. Another approach is to provide a summary of all data collected in all steps for the user to review prior to the final commitment of the transaction.\n\nBefore the final step that commits the transaction to occur, instructions are provided to prompt the user to review the data entered and confirm. Once the user confirms, the transaction is completed.\n\nExamples:\n- **Example 1:** An online banking application provides multiple steps to complete a transfer of funds between accounts as follows:Select \"transfer from\" accountSelect \"transfer to\" accountEnter transfer amountA summary of the transaction is provided showing the from and to accounts and the transfer amount. The user can select a button to either complete the transaction or cancel it.\n- **Example 2:** Select \"transfer from\" account\n- **Example 3:** Select \"transfer to\" account\n- **Example 4:** Enter transfer amount\n- **Example 5:** A testing application provides multiple pages of questions. At any time, the user can choose to return to previously completed sections to review and change answers. A final page is displayed providing buttons to either submit the test answers or review answers.  ---",
    "referenced_by": [
      "3.3.4"
    ]
  },
  {
    "id": "G155",
    "type": "technique",
    "code": "G155",
    "text": "[G155] Providing a checkbox in addition to a submit button\n\nDescription:\nThe objective of this technique is to provide a checkbox that users must select to indicate they have reviewed their input and are ready for it to be committed. This is important when the nature of the transaction is such that it may not be reversible if input errors are subsequently discovered or when the result of an action is that data is deleted. The author provides a checkbox that is not selected when the page loads, with a label like \"I confirm that the input is correct and am ready to submit\" or \"I confirm that I wish to delete this data\". The checkbox should be located near the submit button to help the user notice it during the submission process. If the checkbox is not selected when the form is submitted, the input is rejected and the user is prompted to review their entry, select the checkbox, and resubmit. Only if the checkbox is selected will the input be accepted and the transaction processed.\n\nThis checkbox helps to guard against the consequences of an accidental form submission, and also serves to prompt the user to be sure they have entered accurate data. This is more secure than simply putting a label on the submit button like \"input is correct, submit\". Providing the checkbox as a separate control from the submit button forces the user to \"double-check\", as they must both select the checkbox and activate the submit button for the transaction to proceed. As such, this is a mechanism for reviewing, confirming, and correcting information before finalizing the submission.\n\nExamples:\n- **Example 1:** An online bank service allows users to transfer money between accounts in different currencies. Because exchange rates are constantly in flux, the money cannot be re-exchanged at the same rate if the user discovers an error in their input after the transaction has been carried out. In addition to the \"account from\", \"account to\", and \"amount\" fields, there is a checkbox with a label \"I have checked that the amount I wish to transfer is correct\". If this checkbox is not selected when the user submits the form, the transaction is not carried out and the user is notified. If the checkbox is selected, the (irreversible) transaction is carried out.\n- **Example 2:** An online payment system stores user bank account information in order to process payments. There is an elaborate procedure for users to enter new accounts and verify that they are the owner. There is the facility to delete old accounts, but if an account is accidentally deleted, it would be difficult to reinstate it, and the transaction history with that account would be lost. Therefore, on pages that allow users to delete accounts, there is a checkbox with the label \"I confirm that I wish to delete this account.\" If this checkbox is not selected when the user submits the form, the account is not deleted and the user is given an error message. Only if the checkbox is selected is the account deleted.\n- **Example 3:** A checkout form on a shopping site includes a form that collects order, shipping and billing information. After submitting the form, the user is taken to a page where the information they have submitted is summarized for review. Below the summary, a checkbox with the label \"I have reviewed and confirmed that this data is correct\" is shown. The user must mark the checkbox and activate a \"complete order\" button in order to complete the transaction.  ---",
    "referenced_by": [
      "3.3.4"
    ]
  },
  {
    "id": "G99",
    "type": "technique",
    "code": "G99",
    "text": "[G99] Providing the ability to recover deleted information\n\nDescription:\nWhen a web application provides the capability of deleting information, the server can provide a means to recover information that was deleted in error by a user. One approach is to delay deleting the data by merely marking it for deletion or moving it to a holding area (such as a trash can) and waiting some period of time before actually deleting it. During this time period, the user can request that the data be restored or can retrieve it from the holding area. Another approach is to record all delete transactions in such a way that data can be restored if requested by the user, such as in the edit history stored by wikis and source control applications.The retrievable information that is stored should be that which would be needed to correct the transaction.\n\nExamples:\n- **Example 1:** A web application allows users to set up folders and store data within them. Each folder and data item is accompanied by a checkbox to mark it for action, and two buttons, one to move and one to delete. If the user selects the delete button by mistake, large amounts of data could be lost. The application presents the data as deleted to the user right away, but schedules it for actual deletion in one week. During the week, the user may go into a \"deleted items\" folder and request any folder or data item awaiting actual deletion to be restored.  ---",
    "referenced_by": [
      "3.3.4"
    ]
  },
  {
    "id": "G168",
    "type": "technique",
    "code": "G168",
    "text": "[G168] Requesting confirmation to continue with selected action\n\nDescription:\nThis technique is to seek confirmation from the user that the selected action is their intended action. Use this technique in situations where the action can not be undone after it has been followed through. This will help users avoid submitting a form or deleting data by mistake.\n\nFor example, this may occur when the user expects the 'submit' and 'cancel' buttons to occur in an order contrary to what is provided and selects a button too quickly to notice the unexpected order. Presenting the user with a confirmation request allows the user to recognize the error and either stop the submission of data or stop the loss of entered data.\n\nThe request for confirmation should inform the user of the action that was selected and the consequences of continuing with the action.\n\nExamples:\n- **Example 1: Airline travel**  An online travel website lets users create travel itineraries that reserve seats with different airlines. Users may look up, amend and cancel their current itineraries. If the user needs to cancel their travel plans, they find the itinerary on the web page and delete it from their list of current itineraries. This action results in the cancellation of their seat reservations and is not reversible. The user is informed that the selected action will cancel their current seat reservations and that it may not be possible to make a comparable booking on the same flights once this action has been taken. The user is asked to confirm or cancel the deletion of the itinerary.\n- **Example 2: Webmail**  A Webmail application stores a user's email on a server, so that it can be accessed from anywhere on the web. When a user deletes an email message, it is moved to a trash folder from which it can be retrieved if it was deleted by accident. There is an \"empty trash\" command for deleting the messages in the trash folder from the server. Once the trash folder has been emptied, the messages can no longer be retrieved. Before emptying the trash folder, the user is asked to confirm or cancel deletion of the email in the trash folder.\n- **Example 3: An online test**  A form is used to collect answers for a test. When the 'submit' or 'reset' button is selected the user is presented with a web page that informs them of their choice and asks for confirmation to continue. Example 1: \"You have selected to reset the form. This will delete all previously entered data and will not submit any answers. Would you like to reset the form? [yes button] [no button]\" Example 2: \"You have selected to submit the form. This will submit entered data as your final answers and can not be changed. Would you like to submit the form? [yes button] [no button]\"\n- **Example 4: Trading stocks**  A brokerage site allows users to buy and sell stocks and other securities. If the user makes a transaction during trading hours, a dialog is presented informing the user that the transaction is immediate and irreversible, and has buttons that say \"continue\" and \"cancel.\"    ---",
    "referenced_by": [
      "3.3.4"
    ]
  },
  {
    "id": "G71",
    "type": "technique",
    "code": "G71",
    "text": "[G71] Providing a help link on every Web page\n\nDescription:\nThe objective of this technique is to provide context sensitive help for users as they enter data in forms by providing at least one link to the help information on each web page. The link targets a help page with information specific to that web page. Another approach is to provide a help link for every interactive control. Positioning this link immediately before or after the control allows users to easily tab to it if they have problems in the control. Displaying the help information in a new browser window ensures that any data that has already been entered into the form will not be lost. NOTE: A link is not the only means to provide help.\n\nExamples:\n- **Example 1**  The example below shows a label element that includes a help link. Including the help link within the label element allows screen reader users to have access to the help link when interacting with the input form control.  ```html <form> <label for=\"serial-number\"><span>Serial Number</span> <a href=\"help.html\" target=\"_blank\">Help</a></label> <input type=\"text\" name=\"serial-number\" id=\"serial-number\"> </form> ```    ---",
    "referenced_by": [
      "3.3.5"
    ]
  },
  {
    "id": "G193",
    "type": "technique",
    "code": "G193",
    "text": "[G193] Providing help by an assistant in the Web page\n\nDescription:\nThe purpose of this technique is to provide help using a multimedia avatar that provides assistance in using the web page. An avatar can be particularly helpful to people with cognitive disabilities who may have trouble reading text. The use of visuals will help some people to focus on the material presented.\n\nExamples:\n- **Example 1:** The home page of an online banking application has an embedded avatar named Vanna. She gives new online banking clients a tour of the features provided in the application. The assistant can be started and stopped and paused. The client can rewind and fast forward through the material. A text alternative of the information is available from a link next to the avatar.\n- **Example 2:** A volunteer site has a welcoming page for new volunteers. In it there is an application form. On the right side of the page there an interactive multimedia file with an avatar that explains all the features and sections of the application form.  ---",
    "referenced_by": [
      "3.3.5"
    ]
  },
  {
    "id": "G194",
    "type": "technique",
    "code": "G194",
    "text": "[G194] Providing spell checking and suggestions for text input\n\nDescription:\nIn this technique spell checking and suggestions for text are provided. Often people with cognitive disabilities have trouble spelling a word, but may be able to get the spelling approximately correct. A spell checking program will save them time-consuming research on how to spell the word. This may also be true for blind and low vision users who might make a mistake when typing. It will also help people with dexterity disabilities who may be using a head pointer, or who may have scanning software which makes it very slow and difficult to type. A spell-checking solution that provides word suggestion(s) and a simple mechanism to select one and input it into the text input field provides important help for these users and others.\n\nExamples:\n- **Example 1:** A search engine has a form field for search terms. When the form is submitted, a server-side application checks the spelling. If the spelling doesn't match any words for that language, it sends back a page with a text message at the top saying \"Did you mean ...\" with a link to the suggested word. If the user clicks on the link the suggested term is entered into the form field and is resubmitted.\n- **Example 2:** An airline has a on online ticket purchasing application. When a user types the name of a city into the form field a dropdown menu shows the closest match to the city in the top of the menu and other suggestions below.  ---",
    "referenced_by": [
      "3.3.5",
      "4.1.3"
    ]
  },
  {
    "id": "H89",
    "type": "technique",
    "code": "H89",
    "text": "[H89] Using the title attribute to provide context-sensitive help\n\nDescription:\nThe objective of this technique is to provide context sensitive help for users as they enter data in forms by providing the help information in a **title** attribute. The help may include format information or examples of input.\n\nExamples:\n- **Example 1**  A mapping application provides a form consisting of a label \"Address:\", an input component and a submit button with value \"Find map\". The input component has atitleattribute value with an example of the address format the user should enter.  ```html <label for=\"search-address\">Address:</label> <input id=\"search-address\" name=\"search-address\" size=\"30\" title=\"Address example: 101 Collins St, Melbourne, Australia\" type=\"text\" value=\"\"> ```\n- **Example 2**  A form that allows users to pay their bill online requires the user to enter their account number. The input component associated with the \"Account number\" label has atitleattribute providing information on locating the account number.  ```html <label for=\"acc-num1\">Account number:</label> <input id=\"acc-num1\" size=\"10\" title=\"Your account number can be found in the top right-hand corner of your bill\" type=\"text\" value=\"\"> ```    ---",
    "referenced_by": [
      "3.3.5"
    ]
  },
  {
    "id": "G221",
    "type": "technique",
    "code": "G221",
    "text": "[G221] Provide data from a previous step in a process\n\nDescription:\nThe objective of this technique is to provide information that was previously provided by the user or by the system, rather than requiring the user to remember and re-enter the information from a previous step. This improves success for individuals with cognitive and learning disabilities and memory impairments.\n\nExamples:\n- **Example 1: Populate previously entered information with a trigger**  An ecommerce site provides a checkbox that triggers the shipping address to be pre-populated based on the billing address the user had entered in a previous step.\n- **Example 2: Automatically populate information based on previous answers**  During a two-step process for setting up a business, the first step provides a business identification number after the user enters a name, and address. The second step requires creating a user profile. The business identification number, name and address are prepopulated.\n- **Example 3: Display the information from a previous step**  During a two-step process for setting up a business, the first step provides a business identification number after the user enters a name and address. The second step requires creating a user profile. The interface allows the user to select the business they just set up with all associated information.    ---",
    "referenced_by": [
      "3.3.7"
    ]
  },
  {
    "id": "G218",
    "type": "technique",
    "code": "G218",
    "text": "[G218] Email link authentication\n\nDescription:\nThe objective of this technique is to provide an easy way for users to authenticate without needing a password. This technique involves providing an authentication mechanism where the user can enter their email address, and they are sent an email with a link to click. When the user clicks the link in the email, they are directed back to the website and automatically logged in.\n\nExamples:\n- **Example 1: Author provides an email mechanism to login with a link**  A social media website has a username and password based login mechanism. As part of the forgotten password feature, there is a separate link to login with an email. When the user enters their email and submits the form, the site sends an email to the user. Clicking the link in the email opens  the website and the user is logged in.    ---",
    "referenced_by": [
      "3.3.8",
      "3.3.9"
    ]
  },
  {
    "id": "H100",
    "type": "technique",
    "code": "H100",
    "text": "[H100] Providing properly marked up email and password inputs\n\nDescription:\nThe objective of this technique is to provide examples of properly marked up email and password inputs. This technique involves providing form mechanism where the user can enter their email address and password to log into the website.\n\nBrowsers and password managers generally use the accessible name of the input to determine how to fill it in. The user agent (including password managers) should not be blocked from populating the fields, and pasting by the user should also not be blocked.\n\nExamples:\n- **Example 1: properly marked up email and password inputs**  A secure website has an email and password based login form.  ```html <form method=\"post\" action=\"login\"> <div> <label for=\"email\">Email</label> <input autocomplete=\"email\" id=\"email\" type=\"email\" ...> </div> <div> <label for=\"password\">Password</label> <input autocomplete=\"current-password\" id=\"password\" type=\"password\" ...> </div> <input type=\"submit\" value=\"Login\"> </div> </form> ```    ---",
    "referenced_by": [
      "3.3.8",
      "3.3.9"
    ]
  },
  {
    "id": "F109",
    "type": "technique",
    "code": "F109",
    "text": "[F109] Failure of Success Criterion 3.3.8 and 3.3.9 due to preventing password or code re-entry in the same format\n\nDescription:\nRequiring users to authenticate by entering a password or code in a different format from which it was originally created is a failure to meet Success Criteria 3.3.8 and 3.3.9 (unless alternative authentication methods are available). The string to be entered could include a password, verification code, or any string of characters the user has to remember or record to authenticate.\n\nIf a user is required to enter individual characters across multiple fields in a way that prevents pasting the password in a single action, it prevents use of a password manager or pasting from local copy of the password. This means users cannot avoid transcription, resulting in a [cognitive function test](https://www.w3.org/TR/WCAG22/#dfn-cognitive-function-test). This applies irrespective of whether users are required to enter all characters in the string, or just a subset.\n\nExamples:\n- **Example 3:** A password input fieldset composed of<select>elements that requires a user to select each character of a fixed-length password from individual dropdown fields.  ---\n- **Example 2:** A fieldset that prompts a user to enter each digit of a verification code in a separate input (unless the user can paste the entire code in the first input, and the remaining inputs are populated automatically).\n- **Example 1:** A fieldset that prompts a user to \"Enter the 2nd, 6th and last characters of your password\", with separate input fields for each character.",
    "referenced_by": [
      "3.3.8",
      "3.3.9"
    ]
  }
]